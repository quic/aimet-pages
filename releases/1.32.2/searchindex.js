Search.setIndex({"docnames": ["Examples/onnx/quantization/adaround", "Examples/onnx/quantization/cle", "Examples/onnx/quantization/quantsim", "Examples/tensorflow/compression/channel_pruning", "Examples/tensorflow/compression/spatial_svd", "Examples/tensorflow/compression/spatial_svd_channel_pruning", "Examples/tensorflow/quantization/adaround", "Examples/tensorflow/quantization/autoquant", "Examples/tensorflow/quantization/bn_reestimation", "Examples/tensorflow/quantization/cle_bc", "Examples/tensorflow/quantization/keras/adaround", "Examples/tensorflow/quantization/keras/autoquant", "Examples/tensorflow/quantization/keras/bn_reestimation", "Examples/tensorflow/quantization/keras/keras_transformer_qat", "Examples/tensorflow/quantization/keras/model_preparer", "Examples/tensorflow/quantization/keras/qat", "Examples/tensorflow/quantization/keras/qat_range_learning", "Examples/tensorflow/quantization/keras/quant_analyzer", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq", "Examples/tensorflow/quantization/keras/quantsim_cle", "Examples/tensorflow/quantization/qat", "Examples/tensorflow/quantization/qat_range_learning", "Examples/tensorflow/quantization/quant_analyzer", "Examples/torch/compression/channel_pruning", "Examples/torch/compression/spatial_svd", "Examples/torch/compression/spatial_svd_channel_pruning", "Examples/torch/quantization/adaround", "Examples/torch/quantization/autoquant", "Examples/torch/quantization/bn_reestimation", "Examples/torch/quantization/cle_bc", "Examples/torch/quantization/qat", "Examples/torch/quantization/qat_range_learning", "Examples/torch/quantization/quant_analyzer", "api_docs/convert_tf_sess_to_keras", "api_docs/index", "api_docs/keras", "api_docs/keras_adaround", "api_docs/keras_batchnorm_re_estimation", "api_docs/keras_compression", "api_docs/keras_cross_layer_equalization", "api_docs/keras_layer_output_generation", "api_docs/keras_model_guidelines", "api_docs/keras_model_preparer", "api_docs/keras_primitive_apis_cle", "api_docs/keras_quant_analyzer", "api_docs/keras_quantization", "api_docs/keras_quantsim", "api_docs/onnx", "api_docs/onnx_adaround", "api_docs/onnx_auto_quant", "api_docs/onnx_cross_layer_equalization", "api_docs/onnx_layer_output_generation", "api_docs/onnx_quant_analyzer", "api_docs/onnx_quantization", "api_docs/onnx_quantsim", "api_docs/quantization_encoding_specification", "api_docs/tensorflow", "api_docs/tensorflow_adaround", "api_docs/tensorflow_auto_quant", "api_docs/tensorflow_batchnorm_re_estimation", "api_docs/tensorflow_bias_correction", "api_docs/tensorflow_compress", "api_docs/tensorflow_cross_layer_equalization", "api_docs/tensorflow_layer_output_generation", "api_docs/tensorflow_model_guidelines", "api_docs/tensorflow_primitive_apis_cle", "api_docs/tensorflow_quant_analyzer", "api_docs/tensorflow_quantization", "api_docs/tensorflow_quantsim", "api_docs/tensorflow_visualization_quantization", "api_docs/torch", "api_docs/torch_adaround", "api_docs/torch_architecture_checker", "api_docs/torch_auto_quant", "api_docs/torch_batchnorm_re_estimation", "api_docs/torch_bias_correction", "api_docs/torch_compress", "api_docs/torch_cross_layer_equalization", "api_docs/torch_layer_output_generation", "api_docs/torch_model_guidelines", "api_docs/torch_model_preparer", "api_docs/torch_model_validator", "api_docs/torch_multi_gpu", "api_docs/torch_peft_lora", "api_docs/torch_primitive_apis_cle", "api_docs/torch_quant_analyzer", "api_docs/torch_quantization", "api_docs/torch_quantsim", "api_docs/torch_visualization_compression", "api_docs/torch_visualization_quantization", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/examples", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["Examples/onnx/quantization/adaround.ipynb", "Examples/onnx/quantization/cle.ipynb", "Examples/onnx/quantization/quantsim.ipynb", "Examples/tensorflow/compression/channel_pruning.ipynb", "Examples/tensorflow/compression/spatial_svd.ipynb", "Examples/tensorflow/compression/spatial_svd_channel_pruning.ipynb", "Examples/tensorflow/quantization/adaround.ipynb", "Examples/tensorflow/quantization/autoquant.ipynb", "Examples/tensorflow/quantization/bn_reestimation.ipynb", "Examples/tensorflow/quantization/cle_bc.ipynb", "Examples/tensorflow/quantization/keras/adaround.ipynb", "Examples/tensorflow/quantization/keras/autoquant.ipynb", "Examples/tensorflow/quantization/keras/bn_reestimation.ipynb", "Examples/tensorflow/quantization/keras/keras_transformer_qat.ipynb", "Examples/tensorflow/quantization/keras/model_preparer.ipynb", "Examples/tensorflow/quantization/keras/qat.ipynb", "Examples/tensorflow/quantization/keras/qat_range_learning.ipynb", "Examples/tensorflow/quantization/keras/quant_analyzer.ipynb", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq.ipynb", "Examples/tensorflow/quantization/keras/quantsim_cle.ipynb", "Examples/tensorflow/quantization/qat.ipynb", "Examples/tensorflow/quantization/qat_range_learning.ipynb", "Examples/tensorflow/quantization/quant_analyzer.ipynb", "Examples/torch/compression/channel_pruning.ipynb", "Examples/torch/compression/spatial_svd.ipynb", "Examples/torch/compression/spatial_svd_channel_pruning.ipynb", "Examples/torch/quantization/adaround.ipynb", "Examples/torch/quantization/autoquant.ipynb", "Examples/torch/quantization/bn_reestimation.ipynb", "Examples/torch/quantization/cle_bc.ipynb", "Examples/torch/quantization/qat.ipynb", "Examples/torch/quantization/qat_range_learning.ipynb", "Examples/torch/quantization/quant_analyzer.ipynb", "api_docs/convert_tf_sess_to_keras.rst", "api_docs/index.rst", "api_docs/keras.rst", "api_docs/keras_adaround.rst", "api_docs/keras_batchnorm_re_estimation.rst", "api_docs/keras_compression.rst", "api_docs/keras_cross_layer_equalization.rst", "api_docs/keras_layer_output_generation.rst", "api_docs/keras_model_guidelines.rst", "api_docs/keras_model_preparer.rst", "api_docs/keras_primitive_apis_cle.rst", "api_docs/keras_quant_analyzer.rst", "api_docs/keras_quantization.rst", "api_docs/keras_quantsim.rst", "api_docs/onnx.rst", "api_docs/onnx_adaround.rst", "api_docs/onnx_auto_quant.rst", "api_docs/onnx_cross_layer_equalization.rst", "api_docs/onnx_layer_output_generation.rst", "api_docs/onnx_quant_analyzer.rst", "api_docs/onnx_quantization.rst", "api_docs/onnx_quantsim.rst", "api_docs/quantization_encoding_specification.rst", "api_docs/tensorflow.rst", "api_docs/tensorflow_adaround.rst", "api_docs/tensorflow_auto_quant.rst", "api_docs/tensorflow_batchnorm_re_estimation.rst", "api_docs/tensorflow_bias_correction.rst", "api_docs/tensorflow_compress.rst", "api_docs/tensorflow_cross_layer_equalization.rst", "api_docs/tensorflow_layer_output_generation.rst", "api_docs/tensorflow_model_guidelines.rst", "api_docs/tensorflow_primitive_apis_cle.rst", "api_docs/tensorflow_quant_analyzer.rst", "api_docs/tensorflow_quantization.rst", "api_docs/tensorflow_quantsim.rst", "api_docs/tensorflow_visualization_quantization.rst", "api_docs/torch.rst", "api_docs/torch_adaround.rst", "api_docs/torch_architecture_checker.rst", "api_docs/torch_auto_quant.rst", "api_docs/torch_batchnorm_re_estimation.rst", "api_docs/torch_bias_correction.rst", "api_docs/torch_compress.rst", "api_docs/torch_cross_layer_equalization.rst", "api_docs/torch_layer_output_generation.rst", "api_docs/torch_model_guidelines.rst", "api_docs/torch_model_preparer.rst", "api_docs/torch_model_validator.rst", "api_docs/torch_multi_gpu.rst", "api_docs/torch_peft_lora.rst", "api_docs/torch_primitive_apis_cle.rst", "api_docs/torch_quant_analyzer.rst", "api_docs/torch_quantization.rst", "api_docs/torch_quantsim.rst", "api_docs/torch_visualization_compression.rst", "api_docs/torch_visualization_quantization.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/examples.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["Adaptive Rounding (AdaRound)", "Cross-Layer Equalization (CLE)", "Quantization Simulation", "Model Compression Using Channel Pruning", "Model compression Using Spatial SVD", "Model Compression Using Spatial SVD Followed by Channel Pruning", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Adaptive Rounding (Adaround)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Quantization-Aware Training with a Keras Transformer Model", "Keras Model Preparer", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Quantsim and Adaround - Per Channel Quantization (PCQ)", "Cross-Layer Equalization (CLE) with QuantSim", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Model compression using Channel Pruning", "Model compression using Spatial SVD", "Model compression using Spatial SVD followed by Channel Pruning", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Using AIMET Tensorflow APIs with Keras Models", "Welcome to AI Model Efficiency Toolkit API Docs!", "AIMET Keras APIs", "AIMET Keras AdaRound API", "AIMET Keras BatchNorm Re-estimation APIs", "AIMET Keras Compression API", "AIMET Keras Cross Layer Equalization APIs", "AIMET Keras Layer Output Generation API", "Keras Model Guidelines", "Model Preparer API", "AIMET Keras Cross Layer Equalization Primitive API", "AIMET Keras Quant Analyzer API", "AIMET Keras Quantization APIs", "AIMET Keras Quantization SIM API", "AIMET ONNX APIs", "AIMET ONNX AdaRound API", "AIMET ONNX AutoQuant API", "AIMET ONNX Cross Layer Equalization APIs", "AIMET ONNX Layer Output Generation API", "AIMET ONNX Quant Analyzer API", "AIMET ONNX Quantization APIs", "AIMET ONNX Quantization SIM API", "Encoding Format Specification", "AIMET TensorFlow APIs", "AIMET TensorFlow AdaRound API", "AIMET TensorFlow AutoQuant API", "AIMET TensorFlow BatchNorm Re-estimation APIs", "AIMET TensorFlow Bias Correction API", "AIMET TensorFlow Compression API", "AIMET TensorFlow Cross Layer Equalization APIs", "AIMET Tensorflow Layer Output Generation API", "TensorFlow Model Guidelines", "AIMET TensorFlow Cross Layer Equalization Primitive API", "AIMET Tensorflow Quant Analyzer API", "AIMET TensorFlow Quantization APIs", "AIMET TensorFlow Quantization SIM API", "AIMET Visualization for Quantization for TensorFlow API", "AIMET PyTorch APIs", "AIMET PyTorch AdaRound API", "Architecture Checker API", "AIMET PyTorch AutoQuant API", "AIMET PyTorch BatchNorm Re-estimation APIs", "AIMET PyTorch Bias Correction API", "AIMET PyTorch Compression API", "AIMET PyTorch Cross Layer Equalization APIs", "AIMET PyTorch Layer Output Generation API", "PyTorch Model Guidelines", "Model Preparer API", "Model Validator Utility", "PyTorch Multi-GPU support", "Top-level API", "AIMET PyTorch Cross Layer Equalization Primitive API", "AIMET PyTorch Quant Analyzer API", "AIMET PyTorch Quantization APIs", "AIMET PyTorch Quantization SIM API", "AIMET Visualization Compression API", "AIMET Visualization for Quantization API", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Examples", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"show": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48, 57, 58, 59, 62, 68, 69, 71, 72, 73, 74, 77, 81, 85, 87, 89, 101, 106, 110], "work": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 46, 48, 54, 59, 66, 68, 71, 81, 82, 87, 96, 99, 103, 104, 106, 109], "code": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 94], "how": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48, 54, 55, 57, 58, 59, 62, 68, 71, 72, 73, 74, 75, 77, 81, 85, 87, 99, 103, 106, 107, 110, 111], "us": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 96, 97, 98, 99, 100, 101, 104, 106, 107, 108, 109, 110, 111, 112, 115], "aimet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 41, 42, 55, 64, 72, 79, 80, 81, 82, 83, 101, 104, 109], "perform": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 17, 18, 19, 22, 23, 24, 25, 26, 29, 32, 33, 36, 37, 39, 44, 48, 50, 52, 55, 57, 58, 59, 60, 61, 62, 64, 66, 68, 71, 72, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 89, 95, 96, 97, 98, 100, 103, 105, 106, 107, 108, 110], "featur": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 41, 42, 43, 45, 50, 55, 64, 65, 71, 77, 79, 80, 81, 82, 84, 86, 87, 94, 95, 96, 99, 103, 106, 107, 111, 112, 114, 115], "typic": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 58, 71, 87, 98, 105, 107, 108, 109, 111, 114], "nearest": [0, 1, 6, 9, 10, 13, 15, 16, 18, 19, 26, 29, 44, 46, 54, 58, 60, 66, 68, 73, 75, 87, 94], "techniqu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 38, 39, 45, 48, 49, 50, 53, 57, 58, 60, 61, 62, 67, 71, 73, 75, 76, 77, 85, 86, 94, 95, 97, 98, 101, 105, 107, 108, 110, 111, 112, 113, 116], "achiev": [0, 3, 4, 5, 6, 7, 8, 10, 16, 18, 23, 24, 25, 26, 27, 38, 61, 76, 91, 94, 98, 100, 113, 116], "when": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 46, 50, 55, 61, 64, 66, 76, 77, 79, 80, 85, 86, 87, 94, 101, 103, 105, 106, 107, 108, 109, 110, 111, 114, 115, 117], "weight": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 38, 42, 43, 44, 45, 46, 52, 53, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 71, 75, 81, 83, 84, 85, 86, 87, 89, 94, 96, 98, 103, 105, 106, 107, 108, 109, 110, 111, 115], "valu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 52, 55, 57, 58, 61, 65, 66, 71, 75, 76, 78, 80, 83, 84, 85, 87, 94, 100, 103, 105, 106, 107, 108, 111, 113, 115, 116], "integ": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 85, 87, 94, 105, 107], "optim": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 44, 45, 46, 49, 53, 54, 57, 61, 67, 71, 72, 73, 76, 86, 87, 88, 89, 94, 95, 101, 103, 105, 108, 111, 112, 114], "loss": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 36, 44, 46, 52, 57, 66, 71, 85, 87, 94, 101, 105, 107, 111], "function": [0, 1, 3, 4, 5, 6, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 100, 103, 104, 105, 107, 111, 112, 114, 115], "unlabel": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 49, 52, 54, 58, 66, 68, 71, 73, 85, 87, 94, 105, 107, 111], "data": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 43, 44, 46, 48, 49, 52, 54, 57, 58, 61, 65, 66, 68, 71, 73, 74, 75, 76, 80, 82, 83, 85, 87, 88, 94, 96, 102, 105, 106, 107, 108, 110, 111], "decid": [0, 1, 2, 6, 10, 18, 23, 24, 25, 26, 29, 30, 31, 32, 94, 114], "whether": [0, 1, 2, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 45, 51, 61, 63, 78, 80, 81, 86, 94, 108], "specif": [0, 6, 7, 8, 10, 11, 12, 14, 18, 20, 21, 26, 28, 30, 31, 38, 42, 46, 60, 61, 68, 76, 87, 94, 95, 96, 98, 101, 103, 104, 105, 106, 109, 112], "closer": [0, 6, 10, 18, 26, 94], "farther": [0, 6, 26], "one": [0, 3, 4, 5, 6, 9, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 43, 55, 60, 61, 64, 65, 68, 71, 72, 80, 81, 83, 84, 87, 91, 97, 99, 103, 108, 109, 112, 113, 116], "abl": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42, 80, 81, 85, 94, 114, 115], "while": [0, 1, 3, 4, 5, 6, 9, 10, 13, 16, 18, 19, 23, 24, 25, 26, 29, 38, 58, 61, 71, 76, 83, 94, 100, 104, 105, 108, 110, 111, 114], "low": [0, 3, 4, 5, 6, 9, 10, 18, 23, 25, 26, 29, 94, 96, 103, 105, 106, 110], "bit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 55, 68, 71, 85, 90, 94, 96, 105, 110, 111, 112], "width": [0, 1, 2, 6, 10, 18, 26, 28, 29, 30, 31, 32, 55, 85, 94, 110, 111, 113, 116, 117], "cover": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 96, 109, 111], "follow": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 50, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 111, 113, 116, 117], "instanti": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 79, 82, 108, 114], "fake": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 71, 87], "op": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 33, 38, 43, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 81, 87, 105, 109, 112], "insert": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 71, 80, 87, 105, 111], "simuat": [0, 1, 6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31], "get": [0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 23, 24, 25, 33, 38, 40, 43, 51, 60, 61, 62, 63, 65, 68, 69, 72, 76, 78, 80, 83, 87, 89, 90, 91, 92, 94, 97, 105, 115], "score": [0, 1, 2, 8, 12, 15, 16, 27, 28, 38, 58, 61, 71, 73, 76, 85, 88, 100, 103, 114], "post": [0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 45, 53, 54, 55, 58, 67, 68, 73, 86, 94, 95, 101, 103, 108, 111, 112], "finetun": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 54, 59, 68, 87], "design": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 81, 106], "state": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 64, 103], "art": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "result": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 42, 44, 58, 61, 66, 71, 73, 76, 85, 87, 94, 95, 97, 98, 101, 106, 107, 108, 109, 111], "For": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 51, 52, 54, 57, 58, 59, 61, 62, 63, 68, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 90, 91, 92, 94, 97, 98, 99, 100, 101, 102, 103, 105, 107, 109, 111, 114, 117], "rel": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 38, 61, 69, 76, 89, 98, 105, 110, 115], "friendli": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 95, 105, 106], "like": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 39, 42, 43, 62, 71, 77, 84, 87, 101, 103, 105, 107, 108, 109, 114], "resnet18": [0, 1, 2, 7, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 59, 71, 73, 74, 77, 84, 85, 87, 88, 89], "also": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 44, 46, 52, 55, 57, 58, 60, 66, 68, 71, 79, 80, 85, 87, 97, 98, 99, 100, 105, 107, 109, 110, 111, 112, 114, 115, 117], "some": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 38, 42, 43, 45, 46, 61, 65, 68, 71, 76, 80, 84, 86, 87, 89, 94, 98, 100, 103, 104, 105, 106, 108, 110, 111], "paramet": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 40, 42, 43, 44, 45, 46, 52, 53, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 96, 97, 103, 104, 105, 106, 107, 108, 109, 115], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 52, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 90, 94, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 114, 115, 117], "deliber": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "chosen": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 99, 103], "have": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 50, 52, 55, 61, 65, 66, 71, 72, 77, 78, 80, 81, 85, 87, 89, 92, 100, 103, 105, 106, 107, 110, 111], "execut": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 73, 80, 88, 99, 100, 114], "more": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 43, 44, 46, 48, 49, 50, 52, 55, 57, 58, 60, 61, 62, 65, 66, 68, 71, 72, 73, 75, 76, 77, 81, 84, 85, 87, 90, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 114, 115], "quickli": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 100], "reli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "imagenet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 54, 58, 59, 60, 62, 65, 68, 69, 71, 74, 75, 87, 99], "task": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 114, 115], "imag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 58, 66, 73, 75, 85, 90, 94, 99, 107], "classif": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 103], "If": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 41, 42, 43, 46, 55, 57, 58, 60, 61, 62, 64, 65, 66, 68, 71, 73, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 92, 95, 104, 105, 106, 107, 109, 110, 114, 115, 117], "you": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 58, 61, 64, 68, 71, 76, 80, 82, 87, 91, 92, 99, 100, 104, 113, 116], "alreadi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 87, 91, 100, 110], "version": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 71, 80, 87, 90, 91, 92, 99, 101], "readili": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "avail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 39, 62, 71, 80, 87, 90, 104, 107, 109, 110], "otherwis": [0, 6, 26, 58, 81, 83, 87, 91, 92, 110], "download": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 90, 91, 92], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 97, 98, 99, 100, 104, 105, 106, 107, 108, 109, 110, 111, 114, 117], "appropri": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 71, 76, 84, 87, 90, 91, 92, 98, 99, 100, 103, 110], "locat": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 99], "e": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 45, 46, 52, 54, 55, 57, 66, 68, 71, 75, 85, 87, 96, 98, 101, 108, 110, 117], "g": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 71, 85, 87, 91, 96, 98, 101, 110, 117], "http": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 80, 90, 91, 92, 98, 99, 106, 112, 114], "net": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 99], "org": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 80, 91, 92, 99, 106], "challeng": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "lsvrc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "2012": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "index": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 73, 85, 98, 112], "php": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 99], "note1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 43, 44, 46, 48, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 90, 92, 94, 95, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117], "dataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48, 49, 52, 54, 66, 68, 71, 73, 74, 85, 99, 107], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 42, 43, 44, 45, 48, 53, 54, 55, 57, 58, 61, 66, 67, 68, 71, 72, 73, 81, 85, 86, 87, 88, 91, 92, 94, 98, 99, 100, 103, 105, 106, 107, 109, 110, 111, 114, 115, 117], "characterist": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "subfold": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "sampl": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 46, 52, 54, 55, 57, 58, 60, 61, 65, 66, 68, 71, 73, 75, 85, 87, 97, 105, 106, 107, 108, 111], "val": [0, 1, 2, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "valid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 44, 52, 54, 61, 62, 65, 66, 68, 71, 75, 76, 85, 86, 87, 95, 105, 112], "pleas": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 44, 46, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 66, 68, 71, 73, 74, 75, 76, 77, 81, 83, 85, 87, 90, 91, 92, 94, 95, 96, 97, 99, 101, 103, 106, 107, 111], "see": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 42, 46, 48, 49, 50, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 77, 85, 87, 97, 100, 101, 103, 105, 109, 110, 111, 113, 114, 115, 116], "descript": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 104], "detail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 61, 71, 80, 87, 97, 99, 100, 101, 103, 105, 110, 111, 114, 115], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 38, 43, 44, 46, 52, 58, 61, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 87, 88, 89, 98, 105, 107, 108, 109, 110, 111], "subdirectori": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "per": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 44, 52, 55, 59, 61, 65, 66, 74, 76, 78, 83, 85, 87, 96, 105, 106, 107, 109, 110, 111, 112], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 40, 41, 42, 43, 44, 46, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 75, 76, 78, 79, 80, 81, 83, 84, 85, 87, 88], "file": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 44, 46, 57, 58, 61, 64, 66, 68, 71, 72, 73, 75, 76, 83, 85, 87, 88, 90, 91, 92, 105, 107, 108, 111, 112, 115], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 43, 55, 57, 61, 65, 69, 71, 72, 75, 76, 81, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 105, 106, 107, 108, 109, 110, 111, 115, 117], "note2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "To": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 42, 46, 48, 49, 50, 57, 58, 60, 61, 62, 68, 71, 73, 75, 76, 77, 83, 85, 87, 90, 96, 99, 100, 103, 104, 107, 109, 110, 111, 114, 115], "speed": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 71, 76, 103, 106, 112], "up": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 44, 46, 52, 57, 61, 64, 66, 68, 71, 76, 85, 87, 92, 103, 108, 109, 111, 117], "mai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 55, 71, 73, 80, 83, 87, 94, 98, 103, 105, 106, 107, 109, 110, 111], "reduc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 97, 103, 106, 110, 112, 117], "subset": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 44, 52, 60, 65, 66, 85, 94, 96, 107, 117], "entir": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 60, 61, 66, 76, 83, 85, 100, 103], "ilsvrc2012": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "ha": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 43, 44, 50, 52, 57, 60, 64, 65, 66, 71, 72, 76, 77, 80, 81, 83, 84, 85, 87, 89, 98, 99, 100, 103, 106, 108, 111, 114, 117], "1000": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 52, 54, 58, 66, 68, 71, 73, 75, 76, 85, 87, 94, 106, 107], "50": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 68, 76, 98], "But": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 80, 87, 94, 103], "purpos": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 109], "run": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 42, 44, 45, 46, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 63, 66, 68, 72, 73, 74, 76, 78, 80, 81, 87, 91, 96, 101, 103, 105, 106, 107, 111, 112, 114], "could": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 71, 79, 85, 87, 97, 117], "exercis": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "left": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 100, 117], "reader": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "necessari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 58, 61, 71, 73, 76, 85, 87, 114], "edit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 54, 55, 65, 68, 71, 87], "cell": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "below": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 39, 40, 41, 42, 43, 50, 51, 55, 60, 61, 62, 63, 65, 66, 71, 77, 78, 79, 83, 91, 92, 94, 95, 96, 105, 106, 107, 109, 110, 111, 117], "specifi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 46, 55, 58, 61, 66, 68, 71, 76, 85, 87, 89, 91, 92, 95, 103, 109, 111, 115], "directori": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 40, 44, 58, 61, 63, 66, 69, 73, 76, 78, 83, 85, 89, 99, 115], "where": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 46, 55, 57, 58, 61, 68, 71, 76, 79, 80, 83, 87, 96, 100, 107, 108, 113, 116, 117], "save": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 43, 44, 46, 51, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 76, 78, 83, 84, 85, 87, 89, 95, 111, 115], "dataset_dir": [0, 1, 2, 7, 9, 10, 11, 12, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38], "path": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 44, 46, 51, 57, 58, 61, 63, 66, 68, 71, 73, 75, 76, 78, 80, 83, 85, 87, 88, 91, 92, 99], "replac": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 54, 59, 62, 65, 68, 71, 74, 75, 80, 83, 84, 87, 91, 106, 111], "real": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 58, 73], "loop": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 80, 110], "doe": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 42, 44, 50, 52, 57, 61, 66, 76, 77, 79, 80, 85, 100, 102, 105, 110], "ani": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 41, 42, 43, 44, 45, 46, 52, 61, 65, 66, 68, 71, 74, 76, 79, 80, 81, 84, 85, 86, 87, 91, 92, 94, 95, 99, 109, 112], "limit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 64, 102], "written": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 104, 105], "Not": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 82, 83, 85, 94, 100], "realli": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 40, 42, 51, 52, 58, 59, 61, 63, 71, 72, 74, 75, 78, 80, 81, 83, 85, 87, 89, 91, 92, 100, 103, 105, 106, 109, 110, 111, 115], "later": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 87, 90], "modifi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 43, 46, 51, 65, 80, 83, 84, 87, 91, 92, 105, 111, 112, 117], "user": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 41, 42, 43, 44, 45, 52, 54, 55, 59, 61, 64, 65, 66, 74, 76, 79, 80, 82, 84, 86, 88, 89, 91, 94, 95, 98, 99, 103, 105, 107, 108, 109, 110, 111, 112, 114, 115], "quantizationsim": [0, 1, 2, 6, 7, 8, 9, 10, 11, 13, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 71, 82], "which": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 42, 43, 45, 51, 52, 55, 57, 60, 61, 63, 66, 68, 71, 72, 75, 76, 78, 80, 81, 83, 84, 86, 87, 89, 94, 95, 96, 98, 100, 103, 105, 106, 107, 109, 111, 112, 113, 114, 115, 116], "still": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 41, 105, 110], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 51, 52, 54, 55, 57, 60, 61, 62, 63, 65, 66, 68, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 95, 96, 98, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116], "place": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 46, 60, 62, 65, 66, 68, 71, 75, 77, 84, 87, 108, 109], "origin": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 42, 51, 61, 63, 68, 76, 78, 80, 87, 97, 98, 103, 105, 106, 107, 108, 111, 114], "do": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 42, 46, 68, 71, 80, 82, 89, 92, 103, 107, 111], "infer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 45, 46, 49, 52, 53, 54, 55, 57, 67, 68, 71, 86, 87, 96, 98, 101, 106, 108, 111, 112], "put": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "interfac": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 90], "method": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 40, 46, 58, 61, 63, 64, 68, 75, 78, 80, 87, 91, 92, 100, 103, 105, 110, 111], "should": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 46, 48, 49, 52, 54, 55, 58, 60, 61, 64, 66, 68, 71, 73, 76, 78, 79, 80, 83, 85, 86, 87, 91, 92, 98, 103, 109, 114, 117], "your": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 49, 54, 59, 68, 71, 74, 75, 80, 81, 87, 90, 91, 92, 99, 104], "exist": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 71, 87, 91, 105, 111], "routin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 71, 87], "import": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 89, 92, 96, 97, 110], "torch": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 99, 104, 112], "onnxruntim": [0, 1, 2, 49, 51, 52], "ort": [0, 1, 2, 49], "common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 58, 61, 68, 87, 91, 110, 115], "image_net_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59], "util": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 43, 44, 46, 57, 58, 59, 60, 64, 65, 66, 68, 72, 73, 83, 84, 87, 88, 96, 99, 105], "image_net_evalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 66], "imagenetevalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 66], "image_net_data_load": [0, 1, 2, 23, 25, 26, 28, 29, 30, 31, 32], "imagenetdataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32], "imagenetdatapipelin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59, 71, 74, 75, 87], "staticmethod": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 80], "def": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 41, 42, 43, 44, 46, 48, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 87, 88, 89], "get_val_dataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 71, 75, 87], "return": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 95, 100, 101, 107, 111], "data_load": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 48, 49, 54, 68, 71, 73, 75, 76, 87], "image_s": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 66, 73], "batch_siz": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 44, 49, 52, 54, 57, 58, 60, 61, 66, 68, 71, 73, 76, 85, 87], "is_train": [0, 1, 2, 23, 25, 26, 28, 29, 30, 31, 32], "fals": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 46, 51, 54, 55, 57, 58, 60, 61, 63, 64, 66, 68, 72, 73, 75, 76, 80, 81, 83, 87, 104, 109], "num_work": [0, 1, 2, 23, 24, 25, 26, 28, 29, 30, 31, 32], "sess": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 38, 58, 59, 60, 61, 62, 65, 68, 69], "inferencesess": [0, 1, 2, 49, 51, 52], "float": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 44, 46, 49, 52, 55, 57, 58, 61, 66, 68, 71, 73, 75, 76, 85, 87, 105, 107, 110, 111, 115], "given": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 39, 43, 46, 55, 58, 60, 61, 62, 64, 65, 68, 69, 71, 73, 74, 76, 77, 84, 87, 95, 97, 100, 101, 103, 106, 113, 114, 116], "its": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 42, 69, 99, 101, 105, 107, 111, 117], "top": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 60, 97, 114], "param": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 38, 39, 43, 44, 46, 48, 49, 52, 54, 57, 60, 61, 65, 66, 68, 71, 73, 76, 83, 85, 87, 88, 109], "iter": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 38, 44, 49, 52, 57, 60, 61, 66, 71, 73, 76, 85, 94, 106], "none": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 42, 43, 44, 46, 48, 49, 51, 52, 54, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 87, 88, 89, 92, 114], "go": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 59, 71, 74, 87, 91, 92, 99, 114], "load": [0, 1, 2, 13, 33, 40, 43, 46, 51, 59, 60, 62, 63, 64, 65, 68, 69, 71, 74, 75, 76, 78, 80, 81, 83, 87, 103], "pretrain": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59, 71, 73, 74, 77, 84, 85, 87, 88, 89, 107, 108, 111], "torchvis": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 73, 74, 77, 84, 85, 87, 88, 89], "similarli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 110], "instead": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 71, 79, 80, 81, 87, 105, 106], "differ": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 38, 58, 61, 76, 80, 97, 99, 100, 103, 105, 106, 108, 109, 110, 111], "framework": [0, 1, 2, 34, 54, 101, 105, 109, 111], "altogeth": [0, 1, 2, 109], "input_shap": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 39, 41, 44, 49, 52, 54, 58, 59, 60, 61, 62, 65, 69, 71, 73, 75, 76, 77, 80, 84, 85, 87, 88], "224": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 44, 46, 49, 52, 54, 58, 59, 60, 61, 62, 65, 66, 69, 71, 73, 75, 77, 78, 84, 85, 87, 88, 89], "shape": [0, 1, 2, 12, 13, 14, 18, 26, 28, 29, 30, 31, 32, 33, 41, 42, 61, 72, 76, 77, 80, 81, 83, 84, 107], "channel": [0, 1, 2, 9, 19, 24, 26, 28, 29, 30, 31, 32, 38, 55, 59, 69, 72, 74, 83, 85, 89, 96, 98, 99, 100, 102, 103, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117], "x": [0, 1, 2, 10, 13, 14, 17, 18, 22, 26, 28, 29, 30, 31, 32, 38, 41, 42, 46, 64, 68, 72, 79, 80, 81, 90, 98, 104, 107], "height": [0, 1, 2, 13, 26, 28, 29, 30, 31, 32, 113, 116, 117], "dummy_input": [0, 1, 2, 26, 27, 28, 29, 30, 31, 32, 37, 40, 49, 51, 52, 54, 71, 72, 73, 77, 78, 79, 83, 84, 85, 87], "randn": [0, 1, 2, 27, 46, 49, 52, 54, 71, 73, 80, 81, 85, 87], "filenam": [0, 1, 2, 46, 57, 61, 68, 71, 83, 87, 92], "resnet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 38, 58, 59, 98], "18": [0, 1, 2], "pt_model": [0, 1, 2], "true": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 43, 46, 48, 55, 60, 61, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 80, 81, 83, 84, 85, 87, 88, 89, 104, 109], "export": [0, 1, 2, 6, 9, 10, 13, 18, 20, 21, 26, 29, 30, 31, 40, 44, 46, 51, 52, 54, 55, 59, 63, 66, 68, 71, 74, 78, 79, 83, 85, 87, 91, 92, 96, 99, 101, 103, 104, 105, 108, 111, 112], "eval": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 44, 49, 52, 57, 58, 61, 66, 71, 73, 75, 76, 77, 80, 82, 84, 85, 87, 88, 89, 100, 103, 114], "export_param": [0, 1, 2], "do_constant_fold": [0, 1, 2], "input_nam": [0, 1, 2, 87], "input": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 33, 38, 40, 41, 42, 44, 49, 51, 52, 54, 58, 59, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 87, 97, 103, 107, 109, 111, 113, 114, 116, 117], "output_nam": [0, 1, 2, 87], "output": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 38, 41, 42, 44, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 72, 73, 75, 79, 80, 81, 83, 85, 86, 87, 89, 97, 103, 106, 107, 109, 111, 112, 113, 116, 117], "dynamic_ax": [0, 1, 2], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 42, 46, 49, 54, 57, 58, 61, 66, 68, 71, 72, 73, 75, 76, 80, 81, 83, 84, 87, 88, 90, 91, 92, 94, 98, 100, 104, 109], "load_model": [0, 1, 2, 40], "cpu": [0, 1, 2, 3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 61, 71, 73, 74, 78, 80, 84, 87, 89, 90, 91, 92, 105, 112], "cuda": [0, 1, 2, 3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 73, 74, 75, 76, 85, 87, 88, 90, 92], "devic": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 40, 51, 63, 71, 73, 74, 75, 78, 80, 83, 84, 87, 88, 89, 111], "environ": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 90, 99], "chang": [0, 1, 2, 3, 4, 5, 8, 9, 12, 13, 15, 16, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 45, 55, 71, 73, 79, 80, 83, 86, 87, 89, 94, 103, 107, 108, 109, 111, 115, 117], "logic": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32, 112], "forc": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32], "placement": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32, 109], "need": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 41, 42, 43, 46, 52, 55, 61, 63, 65, 71, 75, 76, 78, 82, 84, 85, 87, 91, 95, 98, 103, 105, 106, 107, 108, 109, 111, 112, 114, 115], "cudnn_conv_algo_search": [0, 1, 2], "fix": [0, 1, 2, 55, 81, 101, 105, 110, 111, 112], "default": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 44, 46, 57, 58, 60, 61, 66, 68, 71, 73, 75, 76, 80, 85, 87, 92, 94, 100, 103, 109, 111, 112, 114], "avoid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 46, 52, 71, 79, 85, 87, 98], "everi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 44, 52, 57, 63, 66, 71, 78, 85, 87, 100, 103, 108, 115], "cudaexecutionprovid": [0, 1, 2], "get_available_provid": [0, 1, 2], "cpuexecutionprovid": [0, 1, 2], "use_cuda": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 48, 51, 54, 57, 60, 61, 63, 66, 68, 71, 74, 76, 87], "els": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 43, 49, 74, 80, 81, 106], "let": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 71, 80, 87], "session": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 36, 38, 49, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 88], "point": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 42, 43, 44, 45, 52, 53, 55, 66, 67, 75, 83, 84, 85, 86, 87, 101, 103, 105, 107, 110, 111, 115], "32": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 33, 36, 41, 42, 44, 49, 55, 57, 58, 61, 66, 71, 72, 80, 81, 87, 91, 92, 110], "print": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 49, 61, 68, 71, 72, 73, 76, 80, 81, 87, 92, 105, 107], "befor": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 40, 41, 42, 43, 45, 49, 51, 60, 63, 64, 65, 71, 73, 78, 84, 86, 87, 89, 94, 95, 96, 103, 105, 108, 114, 115], "quantizationsimmodel": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 37, 40, 43, 46, 48, 51, 54, 57, 59, 63, 68, 71, 74, 78, 83, 85, 87, 94, 96], "batchnorm": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 39, 42, 43, 45, 50, 58, 62, 64, 65, 72, 73, 75, 77, 84, 89, 95, 106, 117], "bn": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 37, 43, 60, 62, 64, 65, 67, 75, 84, 86, 105, 112], "These": [0, 1, 2, 6, 9, 10, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 33, 36, 46, 57, 58, 68, 73, 87, 91, 92, 95, 96, 97, 98, 104, 105, 106, 107, 110, 111], "adjac": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 109], "convolut": [0, 1, 2, 3, 4, 5, 6, 9, 10, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 38, 42, 43, 61, 65, 72, 96, 98, 103, 110], "cannot": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 72, 80, 81], "thei": [0, 1, 2, 3, 4, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 43, 61, 65, 80, 84, 86, 109, 114], "why": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 110], "On": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 55, 90], "runtim": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 46, 54, 55, 61, 68, 71, 76, 87, 98, 101, 103, 105, 107, 109, 111, 112], "tflite": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "snapdragon": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "neural": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 95, 98, 101, 103, 105, 108, 110, 111, 116], "process": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 38, 40, 51, 61, 63, 68, 71, 78, 87, 88, 95, 101, 103, 105, 106, 111], "sdk": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 101], "etc": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 55, 61, 64, 71, 87, 91, 92, 98, 105], "practic": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 103], "so": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 44, 46, 52, 57, 61, 66, 68, 71, 76, 80, 81, 82, 85, 87, 92, 104, 107, 114], "sec": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "speedup": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "sinc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 54, 71, 87, 96, 98, 100, 111], "unnecessari": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 117], "perspect": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "mathemat": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 79], "equival": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 32, 71, 79, 87], "produc": [0, 1, 2, 6, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 55, 73, 80, 100, 107, 114], "same": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 40, 42, 51, 57, 63, 71, 78, 80, 81, 83, 85, 87, 96, 106, 109, 111, 115], "howev": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 41, 42, 61, 71, 76, 87, 105, 106, 108, 109, 111], "increas": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 23, 25, 26, 29, 30, 31, 38, 61, 76, 89, 100, 106, 109], "rang": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 26, 27, 28, 29, 30, 42, 44, 52, 59, 66, 68, 69, 71, 73, 74, 80, 85, 87, 89, 94, 96, 99, 100, 105, 106, 107, 108, 110, 111, 112, 115], "tensor": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 40, 42, 45, 46, 53, 54, 55, 57, 60, 66, 67, 68, 71, 72, 73, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 94, 97, 104, 105, 107, 109, 110, 111, 112, 113, 116], "neg": [0, 1, 2, 6, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "impact": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 100, 110], "especi": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 90, 105, 108, 110], "int8": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 108, 111, 115], "lower": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 100, 105, 110], "precis": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 55, 71, 105], "want": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 40, 43, 46, 51, 58, 63, 65, 66, 68, 71, 78, 80, 84, 86, 87, 91], "target": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40, 42, 46, 49, 51, 54, 55, 59, 61, 63, 68, 71, 74, 76, 78, 87, 96, 98, 100, 101, 103, 105, 110, 111, 112], "behavior": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 80, 101], "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 38, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 80, 85, 87, 98, 99, 108, 114], "call": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 37, 38, 39, 41, 42, 43, 52, 55, 58, 61, 62, 65, 71, 76, 77, 80, 84, 85, 87, 96, 103, 105, 107, 109, 111, 112, 113, 116], "aimet_onnx": [0, 1, 2, 48, 49, 50, 51, 52, 54, 90, 91, 92], "batch_norm_fold": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 37, 43, 59, 60, 65, 74, 84, 89], "fold_all_batch_norms_to_weight": [0, 1, 2], "_": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 33, 36, 40, 42, 43, 44, 51, 52, 54, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 73, 78, 85, 90, 91, 92], "now": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 42, 71, 80, 81, 87, 105, 112, 117], "basic": [0, 1, 2, 8, 9, 12, 13, 15, 16, 19, 20, 21, 28, 29, 30, 31, 71, 87, 92], "mean": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 45, 59, 71, 74, 87, 89, 97, 109, 111], "graph": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 55, 57, 58, 60, 61, 62, 64, 65, 68, 69, 71, 72, 80, 84, 87, 88, 104, 105, 111, 114], "configur": [0, 1, 2, 6, 8, 9, 12, 13, 15, 16, 20, 21, 26, 28, 29, 30, 31, 36, 44, 55, 57, 58, 71, 73, 75, 83, 85, 87, 98, 102, 112], "them": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 46, 52, 60, 66, 71, 80, 81, 85, 87, 94, 117], "few": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 98, 105, 110, 111], "explain": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 71, 87, 97, 103, 106, 111, 117], "quant_schem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 54, 55, 57, 66, 68, 71, 73, 75, 85, 87], "set": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 42, 43, 48, 49, 54, 55, 57, 58, 60, 61, 64, 65, 68, 71, 73, 76, 80, 81, 83, 84, 85, 87, 92, 94, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111, 117], "quantschem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 54, 57, 58, 59, 66, 68, 71, 73, 74, 75, 85, 87, 95], "post_training_tf_enhanc": [0, 1, 2, 6, 8, 9, 12, 13, 15, 17, 19, 20, 22, 26, 28, 29, 30, 32, 36, 44, 46, 52, 55, 57, 58, 66, 68, 71, 73, 75, 85, 87], "support": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 19, 20, 21, 22, 28, 29, 30, 31, 33, 34, 38, 39, 41, 42, 44, 46, 54, 57, 58, 61, 62, 64, 66, 68, 71, 75, 76, 79, 80, 85, 87, 90, 97, 98, 101, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 116, 117], "option": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 43, 44, 46, 49, 57, 58, 60, 61, 66, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 85, 87, 89, 92, 94, 99, 107, 109, 111, 114], "tf_enhanc": [0, 1, 2, 8, 9, 12, 13, 15, 19, 20, 28, 29, 30, 46, 60, 68, 75], "tf": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 75, 85, 91, 107, 111, 112], "quant": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 28, 29, 30, 31, 36, 45, 46, 54, 57, 60, 68, 71, 75, 83, 86, 87, 96], "scheme": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 36, 38, 44, 46, 54, 57, 58, 60, 61, 66, 68, 71, 73, 75, 76, 78, 85, 87, 95, 96, 100, 103, 107], "enum": [0, 1, 2, 8, 9, 12, 13, 15, 19, 20, 28, 29, 30, 38, 61, 75, 76], "post_training_tf": [0, 1, 2, 8, 9, 10, 12, 13, 15, 18, 19, 20, 28, 29, 30, 36, 44, 46, 54, 55, 57, 58, 66, 68, 71, 75, 85, 87], "default_activation_bw": [0, 1, 2, 48, 52, 54], "8": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 36, 43, 44, 46, 48, 52, 54, 55, 57, 58, 61, 66, 68, 71, 73, 75, 76, 80, 81, 85, 87, 88, 90, 92, 105, 117], "essenti": [0, 1, 2, 8, 9, 12, 13, 15, 16, 19, 20, 21, 28, 29, 30, 31], "ask": [0, 1, 2, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 28, 29, 30, 31, 32], "all": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 37, 39, 41, 42, 43, 46, 52, 55, 59, 61, 62, 65, 66, 68, 71, 74, 75, 76, 80, 81, 83, 84, 85, 87, 89, 91, 97, 100, 103, 106, 107, 109, 110], "activ": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 41, 42, 43, 44, 46, 52, 54, 55, 60, 65, 66, 68, 71, 72, 75, 79, 80, 83, 84, 85, 87, 105, 107, 108, 109, 110, 111], "default_param_bw": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 48, 52, 54, 57, 58, 66, 68, 71, 85, 87], "In": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 49, 52, 55, 58, 61, 64, 71, 72, 73, 76, 79, 80, 81, 85, 86, 87, 94, 95, 98, 100, 103, 105, 106, 108, 109, 111, 115, 117], "case": [0, 2, 13, 14, 17, 22, 32, 44, 49, 52, 55, 58, 65, 73, 79, 80, 81, 83, 85, 91, 92, 100, 106, 108, 109], "custom": [0, 2, 13, 16, 27, 42, 46, 55, 80, 99, 110, 111], "compil": [0, 2, 11, 12, 13, 17, 33, 44, 46], "via": [0, 2, 42, 98, 101, 111], "user_onnx_lib": [0, 2], "custom_op1": [0, 2], "custom_op2": [0, 2], "There": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 78, 81, 87, 90, 94, 104, 106, 108, 114, 115], "other": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 61, 65, 79, 80, 84, 87, 90, 100, 102, 103, 105, 107, 110, 111, 112], "check": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 42, 44, 45, 51, 52, 63, 66, 72, 78, 79, 80, 81, 85, 86, 87, 95, 105, 108, 110], "api": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 41, 79, 82, 91, 99, 101, 104, 105, 109, 112, 114], "document": [0, 1, 2, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 34, 88, 98, 99, 101, 112], "refer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 60, 71, 75, 78, 83, 86, 87, 94, 95, 96, 99, 101, 105, 107, 108, 109, 111], "copi": [0, 4, 5, 6, 26, 29, 30, 31, 42, 46, 87, 89, 99, 111], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "quantsim": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 20, 21, 26, 28, 29, 30, 31, 36, 40, 46, 48, 51, 52, 54, 57, 59, 63, 68, 71, 74, 75, 78, 83, 85, 87, 99, 105, 108, 109, 112], "deepcopi": [0, 89], "even": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 105], "though": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 109], "ad": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 55, 61, 68, 71, 81, 83, 87, 102, 105, 109, 112], "node": [0, 1, 2, 6, 8, 9, 10, 12, 13, 18, 20, 21, 26, 29, 30, 31, 46, 61, 68, 71, 72, 79, 80, 87, 108, 111], "readi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 46, 68, 71, 87, 110], "yet": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87], "find": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 43, 61, 65, 71, 75, 81, 84, 87, 89, 100, 105, 107, 108, 111], "scale": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 37, 39, 43, 50, 55, 59, 62, 65, 71, 74, 77, 84, 87, 96, 105, 106, 107, 108, 111], "offset": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 44, 52, 55, 66, 71, 85, 87, 105, 107, 108, 111], "pass": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 40, 42, 43, 44, 46, 48, 51, 52, 54, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 87, 101, 104, 105, 106, 107, 108, 110, 111, 112, 114], "through": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 61, 71, 75, 80, 85, 87, 89, 91, 92, 106, 107, 111, 114, 115], "collect": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 73, 85, 87, 97, 107], "statist": [0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 37, 38, 44, 45, 52, 59, 61, 66, 67, 69, 71, 74, 76, 85, 86, 87, 89, 96, 105, 107, 115], "calcul": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 46, 57, 58, 61, 65, 66, 68, 71, 73, 84, 87, 100, 106, 107, 111], "sometim": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 97, 103, 106, 107], "calibr": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 44, 48, 52, 54, 66, 68, 71, 85, 87, 105, 107, 108, 110, 111], "simpli": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 44, 46, 52, 57, 66, 68, 71, 80, 85, 87, 117], "fairli": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "simpl": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 36, 44, 52, 57, 61, 66, 71, 76, 80, 85, 87, 105, 117], "loader": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 44, 52, 54, 66, 68, 71, 74, 75, 85, 87, 94], "extract": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 106], "don": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 80, 87, 94], "t": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 71, 80, 82, 87, 91, 94], "metric": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 44, 46, 61, 71, 76, 87, 107, 111], "just": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 66, 71, 87, 111, 114, 117], "ignor": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 60, 61, 62, 65, 71, 75, 76, 80, 87], "pointer": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "regard": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "veri": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 71, 87, 96, 98, 103, 107, 115, 117], "small": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 71, 87, 96, 101, 105], "percentag": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "1m": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "onli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 41, 46, 48, 51, 52, 54, 60, 61, 63, 64, 68, 71, 72, 75, 78, 79, 80, 82, 84, 85, 87, 90, 91, 92, 96, 102, 105, 107, 108, 109, 112, 117], "500": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 49, 71, 76, 87, 94, 106, 107], "It": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 39, 42, 43, 44, 49, 52, 55, 61, 62, 65, 66, 71, 76, 80, 84, 85, 87, 96, 99, 100, 105, 106, 109, 114, 115, 117], "benefici": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 94, 107, 108], "well": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 52, 61, 66, 71, 72, 81, 83, 85, 87, 98, 103, 105, 106, 107, 111, 113], "distribut": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 33, 38, 61, 71, 76, 87, 106, 110, 111], "look": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 42, 60, 71, 87, 114], "definit": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 45, 79, 80, 83, 86, 105], "extrem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "scenario": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 96, 103, 105, 117], "dark": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "light": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "pictur": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 97, 101], "captur": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 40, 51, 63, 71, 78, 80, 87, 100], "night": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "might": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 55, 71, 87, 103, 107], "give": [0, 1, 2, 6, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 113, 116], "ideal": [0, 1, 2, 4, 5, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 71, 87], "mani": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 80, 94, 106, 111], "wai": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 61, 76, 78, 87, 90, 99, 100], "pass_calibration_data": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 48, 54, 68, 71, 87], "get_input": [0, 1, 2], "name": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 16, 17, 20, 21, 22, 32, 33, 38, 40, 42, 51, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 75, 78, 83, 85, 87, 91, 106, 111, 112, 114], "batch_cntr": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 49], "input_data": [0, 1, 2, 26, 28, 29, 30, 31, 32, 36, 49, 54, 57, 61, 66, 68, 71, 87], "target_data": [0, 1, 2, 26, 28, 29, 30, 31, 32, 71, 87], "inputs_batch": [0, 1, 2, 26, 28, 29, 30, 31, 32, 71, 87], "numpi": [0, 1, 2, 7, 8, 14, 33, 36, 38, 44, 46, 49, 52, 54, 57, 58, 61, 66], "break": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 38, 49, 54, 68, 71, 87], "abov": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 44, 52, 57, 61, 66, 71, 76, 80, 82, 85, 87, 91, 92, 95, 96, 99, 100, 101, 103, 104, 106, 110, 111, 117], "subsequ": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 71, 87, 104, 106, 108, 109], "compute_encod": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 36, 46, 54, 57, 68, 71, 87], "forward_pass_callback": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 57, 66, 68, 85, 87], "forward_pass_callback_arg": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 46, 48, 68, 71, 87], "first": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 45, 60, 61, 71, 80, 86, 98, 103, 105, 108, 114], "u": [0, 1, 2, 6, 8, 9, 10, 13, 18, 20, 21, 26, 29, 30, 31, 71, 91, 110], "saw": [0, 1, 2, 6, 8, 9, 10, 18, 20, 21, 26, 29, 30, 31], "describ": [0, 6, 10, 18, 26, 46, 55, 68, 71, 80, 87, 105, 106, 110, 111], "over": [0, 42, 49, 61, 73, 76, 85, 94, 100, 103, 115], "learn": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 36, 37, 38, 39, 46, 48, 49, 50, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 77, 85, 87, 96, 99, 103, 105, 108, 111, 112], "vector": [0, 6, 10, 18, 26, 71], "compli": [0, 26, 29, 30, 31, 32, 71, 87], "signatur": [0, 3, 4, 5, 23, 24, 25, 36, 38, 44, 49, 52, 57, 61, 66, 76, 85], "expect": [0, 3, 4, 5, 8, 12, 23, 24, 25, 28, 38, 41, 43, 44, 46, 48, 52, 54, 58, 60, 61, 65, 66, 68, 71, 72, 76, 80, 81, 84, 85, 87, 103, 105, 107], "num_batch": [0, 1, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 22, 26, 27, 28, 29, 32, 36, 44, 48, 49, 52, 57, 58, 59, 66, 71, 73, 74, 85], "number": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 37, 38, 42, 44, 46, 52, 57, 58, 59, 61, 66, 68, 71, 74, 75, 76, 80, 85, 87, 91, 94, 100, 101, 103, 108, 111, 112, 114, 117], "around": [0, 6, 10, 13, 18, 26, 44, 52, 54, 58, 66, 68, 71, 85, 87, 104], "2000": [0, 6, 7, 9, 10, 11, 18, 26, 27, 29, 49, 58, 71, 73], "size": [0, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 18, 26, 42, 46, 54, 58, 60, 61, 66, 68, 71, 72, 73, 81, 85, 87, 94, 103, 104, 113, 116], "translat": [0, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 71], "64": [0, 6, 10, 18, 26, 41, 42, 44, 52, 54, 58, 66, 68, 71, 85, 87, 90, 94], "default_num_iter": [0, 6, 10, 18, 26, 27, 36, 48, 57, 71], "10000": [0, 6, 7, 10, 11, 18, 26, 36, 57, 71, 94], "strongli": [0, 6, 10, 18, 26, 42, 71, 80], "recommend": [0, 2, 6, 10, 14, 18, 26, 27, 38, 42, 44, 52, 61, 66, 71, 72, 76, 85, 90, 94, 96, 98, 105, 110], "o": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 61, 68, 76], "adaround_weight": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 49, 57, 58, 71, 73], "adaroundparamet": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 49, 57, 58, 71, 73], "satisfi": [0, 27, 80, 95], "requir": [0, 2, 3, 4, 5, 14, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 36, 37, 38, 39, 42, 43, 44, 46, 48, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 94, 96, 98, 103, 105, 106, 109, 111], "deriv": [0, 55], "form": [0, 17, 22, 32, 33, 42, 99], "arrai": [0, 8], "__init__": [0, 14, 27, 41, 42, 58, 72, 73, 76, 79, 80, 81], "self": [0, 14, 27, 41, 42, 58, 61, 72, 73, 76, 79, 80, 81], "_torch_data_load": 0, "_iter": 0, "__iter__": 0, "__next__": 0, "next": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 43, 65, 71, 83, 84, 87, 91, 110], "__len__": [0, 27, 73, 85], "len": [0, 13, 27, 38, 49, 71, 73, 80], "forward_fn": [0, 8, 12, 28, 48, 71, 74], "makedir": [0, 3, 4, 5, 8, 9, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31], "exist_ok": [0, 3, 4, 5, 8, 9, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31], "ada_model": [0, 6, 10, 18, 26], "apply_adaround": [0, 6, 10, 18, 26, 36, 48, 57, 71], "filename_prefix": [0, 6, 8, 9, 10, 12, 18, 19, 20, 21, 26, 28, 29, 30, 31, 36, 46, 57, 68, 71, 83, 87], "default_quant_schem": [0, 6, 10, 18, 26, 36, 57, 58, 71], "after": [0, 1, 3, 4, 6, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 36, 37, 43, 49, 57, 59, 60, 62, 65, 71, 73, 74, 80, 81, 83, 84, 85, 87, 89, 94, 95, 96, 98, 103, 105, 108, 110, 114, 115], "again": [0, 1, 3, 4, 5, 6, 9, 10, 18, 19, 23, 24, 25, 26, 29, 107, 108, 114], "note": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 31, 42, 43, 44, 46, 49, 50, 51, 52, 54, 58, 61, 65, 66, 68, 73, 76, 77, 82, 83, 84, 85, 87, 91, 92, 97, 98, 100, 101, 103, 104, 105, 107], "two": [0, 1, 3, 4, 5, 6, 9, 10, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 42, 43, 60, 61, 65, 76, 80, 81, 84, 90, 100, 101, 103, 105, 106, 107, 108, 111, 113, 114, 115, 116], "thing": [0, 6, 10, 18, 26, 105], "understand": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 105, 109, 114, 115], "biwidth": [0, 6, 10, 18, 26], "must": [0, 6, 10, 12, 13, 15, 16, 17, 18, 22, 26, 32, 42, 61, 71, 96, 101, 102, 107, 109, 117], "bitwidth": [0, 6, 10, 18, 26, 44, 46, 55, 57, 58, 66, 68, 71, 73, 75, 83, 85, 87, 96, 105, 110, 111], "wa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40, 51, 55, 61, 63, 71, 76, 78, 83, 97, 103, 109], "freez": [0, 6, 10, 18, 26, 36, 57, 71, 83, 94], "set_and_freeze_param_encod": [0, 6, 10, 18, 26, 36, 48, 57, 71], "been": [0, 3, 4, 5, 6, 7, 10, 11, 12, 13, 18, 19, 23, 24, 25, 26, 27, 42, 71, 81, 89, 105, 108, 111, 117], "down": [0, 1, 6, 9, 10, 18, 19, 26, 29, 55, 71], "base": [0, 6, 7, 8, 10, 11, 12, 18, 26, 27, 28, 36, 37, 48, 54, 57, 60, 61, 68, 71, 83, 85, 87, 91, 97, 98, 105], "initi": [0, 6, 10, 16, 17, 18, 20, 21, 22, 26, 30, 31, 32, 36, 57, 60, 68, 71, 87, 94, 108, 110, 111], "intern": [0, 6, 7, 10, 11, 13, 14, 18, 26, 42, 66, 68, 71, 73, 87, 103, 105, 106, 109], "NOT": [0, 6, 10, 18, 26, 71, 96, 117], "frozen": [0, 6, 10, 18, 26, 71], "alter": [0, 6, 10, 18, 26, 71], "reflect": [0, 6, 26, 105, 111], "encoding_path": [0, 6, 7, 10, 11, 18, 26, 27, 36, 49, 57, 58, 71, 73], "join": [0, 6, 10, 15, 16, 18, 26, 27, 61, 68, 76, 88], "newli": [0, 6, 26], "updat": [0, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 55, 59, 60, 62, 64, 65, 71, 72, 87, 88, 92, 99, 105, 106, 108, 111, 112], "depend": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 61, 80, 91, 92, 98, 99, 100, 105, 109, 112], "observ": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 89, 100, 103, 105, 106, 107, 108, 111], "slight": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31], "gain": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31, 97, 103], "serv": [0, 6, 26, 44, 49, 52, 58, 73, 85, 114], "try": [0, 3, 4, 5, 6, 7, 9, 10, 11, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31, 38, 61, 72, 76, 88, 95, 97, 100, 103, 105, 110], "workflow": [0, 6, 26, 98, 101], "against": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 44, 52, 58, 66, 85, 89], "choic": [0, 1, 3, 4, 5, 6, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 44, 55, 103, 111], "plai": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31], "best": [0, 3, 4, 5, 6, 7, 9, 10, 11, 18, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 58, 73, 95, 98, 103, 105, 111], "step": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 43, 49, 59, 64, 65, 71, 73, 74, 80, 83, 85, 87, 91, 94, 95, 96, 97, 98, 100, 103, 105, 106, 108, 110, 111], "would": [0, 3, 4, 5, 6, 8, 9, 10, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 39, 42, 62, 71, 77, 87, 98, 103, 109, 112, 114], "take": [0, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 43, 58, 61, 71, 76, 84, 87, 101, 103, 105, 106, 108, 109, 110, 117], "without": [0, 6, 7, 9, 10, 11, 13, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 46, 68, 71, 83, 87, 95, 105, 108, 111, 117], "resnet18_after_adaround": [0, 6, 26], "illustr": [0, 6, 10, 18, 26, 68, 87, 94, 100, 105, 113, 116], "invok": [0, 6, 10, 18, 26, 33, 36, 38, 43, 45, 57, 60, 61, 62, 65, 71, 76, 85, 86, 87, 103, 105, 114, 115], "As": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 79, 87, 95, 97, 98, 100, 103, 105, 106, 107, 111, 113, 116], "indic": [0, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 27, 38, 43, 55, 60, 61, 64, 65, 73, 76, 98, 117], "make": [0, 6, 8, 10, 12, 13, 14, 18, 26, 28, 33, 37, 41, 43, 45, 59, 60, 64, 65, 79, 82, 86, 100, 103, 104, 105, 111], "faster": [0, 3, 4, 5, 6, 7, 10, 11, 12, 18, 23, 24, 25, 26, 27, 94, 101, 108], "hope": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "addit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 59, 87, 95, 105, 108, 109, 112], "resourc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "doc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 80, 83, 107, 109, 114], "know": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "qat": [0, 1, 6, 9, 10, 13, 18, 19, 26, 29, 37, 54, 57, 59, 68, 71, 74, 82, 86, 94, 96, 99, 101, 105, 110, 111, 112], "showcas": [1, 9, 17, 19, 22, 29, 32], "appli": [1, 3, 4, 5, 8, 9, 12, 13, 19, 23, 24, 25, 27, 28, 29, 36, 38, 39, 43, 45, 48, 57, 58, 61, 62, 65, 71, 73, 75, 76, 81, 84, 86, 89, 94, 95, 96, 99, 100, 103, 105, 106, 108, 109, 110, 111, 112, 114, 115], "aim": [1, 3, 4, 5, 8, 9, 12, 19, 23, 24, 25, 28, 29, 37], "improv": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 34, 68, 71, 87, 98, 105, 108, 110, 115], "help": [1, 3, 4, 5, 6, 7, 9, 17, 19, 20, 21, 22, 29, 32, 62, 65, 72, 81, 87, 89, 94, 100, 103, 105, 106, 107, 110, 114, 115], "recov": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 101, 110, 111], "sensit": [1, 9, 19, 29, 44, 45, 52, 53, 66, 67, 85, 86, 100, 105, 107, 110, 111, 112], "oppos": [1, 9, 19, 29, 105, 109], "about": [1, 8, 9, 14, 19, 28, 29, 36, 38, 39, 43, 46, 48, 49, 50, 54, 55, 57, 58, 60, 61, 62, 65, 68, 71, 73, 75, 76, 77, 84, 85, 87], "free": [1, 3, 4, 5, 8, 9, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 87, 91, 105, 106, 108], "bia": [1, 8, 12, 19, 39, 43, 50, 62, 65, 67, 72, 77, 80, 81, 83, 84, 86, 94, 97, 105, 106, 109, 110, 112], "correct": [1, 10, 18, 19, 27, 32, 43, 65, 67, 71, 73, 84, 86, 92, 94, 96, 105, 106, 110], "paper": [1, 9, 19, 29, 106], "iccv": [1, 9, 19, 29, 103, 106], "2019": [1, 9, 19, 29, 106], "arxiv": [1, 9, 19, 29, 106], "ab": [1, 9, 19, 29, 106], "1906": [1, 9, 19, 29, 106], "04721": [1, 9, 19, 29, 106], "norm": [1, 9, 19, 29, 43, 59, 65, 72, 74, 84, 94, 96, 105, 106, 107], "conv": [1, 3, 4, 5, 6, 7, 8, 9, 12, 19, 20, 21, 22, 29, 33, 37, 43, 57, 59, 60, 61, 65, 71, 74, 75, 80, 84, 89, 102, 109, 112, 113, 116, 117], "immedi": [1, 9, 19, 27, 29], "consecut": [1, 9, 19, 29, 43, 65, 83, 84, 105, 106], "correspond": [1, 3, 4, 5, 6, 7, 8, 9, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 33, 36, 37, 40, 43, 57, 59, 60, 63, 65, 71, 74, 78, 83, 84, 85, 87, 92, 97, 100, 105, 107, 117], "high": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 39, 43, 50, 62, 65, 77, 84, 94, 96, 98, 100, 101, 106, 110, 112, 115], "perhap": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "sai": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 80, 103], "upto": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "trainingmod": [1, 2], "preserv": [1, 2, 3, 4, 5, 23, 24, 25, 80], "current": [1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 42, 46, 61, 65, 66, 68, 72, 76, 81, 82, 97, 101, 102, 103, 104, 109, 113, 116], "comput": [1, 3, 4, 5, 7, 10, 12, 13, 17, 18, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 38, 40, 44, 46, 51, 52, 54, 55, 57, 58, 61, 63, 66, 68, 71, 73, 76, 78, 82, 83, 85, 87, 90, 92, 94, 103, 104, 105, 106, 107, 111, 114, 117], "And": [1, 2, 9, 10, 15, 16, 18, 19, 20, 21, 29, 30, 31, 43, 65, 84, 103], "default_output_bw": [1, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 57, 58, 66, 68, 71, 85, 87], "encod": [1, 3, 4, 5, 7, 10, 11, 12, 13, 18, 26, 27, 29, 30, 31, 36, 40, 44, 46, 48, 51, 52, 54, 57, 58, 59, 63, 66, 68, 71, 73, 74, 78, 82, 83, 85, 87, 94, 96, 105, 107, 108, 112], "5": [1, 3, 4, 5, 6, 9, 13, 18, 20, 21, 23, 24, 25, 29, 30, 31, 33, 38, 48, 49, 59, 61, 73, 74, 76, 80, 87, 88, 90, 98, 108, 110], "suffici": [1, 9, 19, 29, 105, 107, 108, 111], "rounding_mod": [1, 9, 10, 13, 15, 16, 18, 19, 29, 44, 46, 54, 66, 68, 73, 87], "round": [1, 9, 18, 19, 29, 36, 38, 44, 45, 46, 53, 57, 58, 60, 61, 66, 67, 68, 73, 75, 76, 86, 87, 94, 99, 105, 107, 111], "mode": [1, 3, 4, 5, 6, 7, 9, 19, 20, 21, 22, 23, 24, 25, 29, 33, 38, 39, 46, 50, 58, 61, 62, 68, 73, 75, 76, 77, 80, 82, 84, 87, 88, 104, 105, 109], "possibl": [1, 7, 9, 11, 14, 19, 27, 29, 41, 42, 46, 68, 73, 79, 81, 87, 107, 109, 110], "stochast": [1, 9, 19, 29, 44, 46, 58, 60, 66, 68, 75, 87], "bias": [1, 9, 19, 29, 105], "interestingli": [1, 9, 19, 29], "procedur": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 100, 103], "cl": [1, 9, 19, 29, 43, 62, 65, 84, 112], "skip": [1, 9, 19, 29, 33, 39, 62, 71, 73, 75, 91, 97], "hba": [1, 9, 19, 29], "absorpt": [1, 9, 19, 29], "cross_layer_equ": [1, 9, 19, 29, 39, 43, 50, 60, 62, 65, 77, 84, 89, 104], "equalize_model": [1, 9, 19, 29, 39, 50, 60, 62, 77, 89, 104], "add": [2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 31, 41, 42, 46, 55, 66, 68, 79, 80, 81, 87, 91, 109, 111, 112, 114, 115, 117], "train": [2, 3, 14, 27, 33, 34, 36, 37, 38, 42, 44, 45, 52, 53, 54, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 71, 73, 74, 76, 82, 85, 86, 90, 94, 95, 96, 99, 101, 103, 110, 111, 112], "ml": [2, 13, 15, 16, 20, 21, 30, 31, 34, 87, 103, 105, 106, 114, 115], "order": [2, 3, 4, 5, 8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 41, 43, 45, 64, 65, 79, 81, 84, 86, 87, 91, 92, 96, 97, 98, 105, 108, 111, 115], "estim": [2, 45, 67, 86, 105, 106], "deploi": [2, 111], "acceler": [2, 13, 15, 16, 20, 21, 30, 31, 61, 76, 87, 90, 101, 103], "awar": [2, 37, 45, 59, 68, 74, 82, 94, 96, 99, 101, 105, 110, 111], "adaround": [2, 49, 53, 58, 73, 95, 99, 105, 110, 112], "cross": [2, 45, 53, 58, 60, 67, 73, 75, 82, 86, 89, 94, 95, 99, 104, 105, 107, 115], "equal": [2, 14, 45, 53, 58, 60, 67, 73, 75, 82, 86, 89, 94, 95, 98, 99, 100, 104, 105, 107, 115], "emploi": [2, 30, 31, 71, 87], "act": [2, 15, 16, 19, 85], "regular": [2, 3, 4, 5, 13, 23, 24, 25, 36, 46, 57, 68, 71, 87, 94, 105, 111], "automat": [2, 27, 38, 43, 61, 65, 76, 84, 91, 92, 98, 103, 105, 107, 112], "regist": 2, "oper": [2, 14, 38, 42, 60, 61, 65, 79, 80, 81, 104, 105, 106, 109, 110], "quantizationsimul": 2, "exampl": [3, 13, 14, 27, 41, 72, 79, 81, 82, 83, 94, 98, 100, 101, 105, 107, 109, 111, 112, 117], "brief": [3, 4, 5, 23, 24, 25], "introduct": [3, 4, 5, 23, 24, 25], "guid": [3, 4, 5, 7, 9, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 38, 61, 76, 98, 99, 106, 110, 112], "spatial": [3, 23, 33, 98, 99, 100, 102, 103, 112], "svd": [3, 23, 33, 98, 99, 100, 102, 103, 112], "decomposit": [3, 4, 5, 23, 24, 25, 61, 113, 116], "gener": [3, 4, 5, 9, 13, 15, 16, 23, 24, 25, 29, 34, 46, 55, 61, 68, 72, 83, 99, 103, 105, 107, 108, 109, 111], "layer": [3, 4, 5, 7, 13, 22, 23, 24, 25, 33, 36, 37, 38, 41, 42, 44, 45, 46, 52, 53, 57, 58, 59, 61, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 81, 82, 83, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117], "conv2d": [3, 4, 5, 12, 13, 18, 23, 24, 25, 33, 42, 43, 55, 60, 61, 65, 69, 72, 80, 81, 84, 97, 103, 112, 117], "decompos": [3, 4, 5, 23, 24, 25, 103, 113, 116], "singl": [3, 4, 5, 17, 18, 22, 23, 24, 25, 32, 33, 36, 44, 52, 57, 61, 66, 76, 80, 82, 85, 94, 106], "split": [3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 58], "flattend": [3, 4, 5, 23, 24, 25], "2d": [3, 4, 5, 18, 23, 24, 25], "matrix": [3, 4, 5, 18, 23, 24, 25, 97], "singular": [3, 4, 5, 23, 24, 25, 61, 113, 116], "discard": [3, 4, 5, 23, 24, 25, 52, 66, 85], "least": [3, 4, 5, 23, 24, 25, 94, 97], "signific": [3, 4, 5, 23, 24, 25, 110], "diagon": [3, 4, 5, 23, 24, 25], "matric": [3, 4, 5, 23, 24, 25], "combin": [3, 4, 5, 7, 11, 23, 24, 25, 27, 75, 80, 95, 98, 103, 105, 106], "back": [3, 4, 5, 23, 24, 25, 33, 71, 82, 87, 109], "separ": [3, 4, 5, 20, 21, 23, 24, 25, 30, 31, 42, 43, 46, 57, 68, 71, 80, 81, 84, 87, 96, 107, 110, 112], "magnitud": [3, 4, 5, 23, 24, 25, 97], "feed": [3, 4, 5, 13, 14, 23, 24, 25, 42, 111], "dimens": [3, 4, 5, 23, 24, 25, 103, 110, 113, 116], "reconstruct": [3, 4, 5, 23, 24, 25, 36, 57, 61, 71], "minim": [3, 4, 5, 15, 16, 20, 21, 23, 24, 25, 30, 31, 36, 57, 61, 68, 71, 87, 101, 103, 105, 111], "distanc": [3, 4, 5, 23, 24, 25], "both": [3, 4, 5, 16, 19, 20, 21, 23, 24, 25, 30, 31, 42, 55, 71, 80, 85, 87, 90, 105, 106, 108, 109, 110, 111, 113, 117], "structur": [3, 4, 5, 17, 23, 24, 25, 32, 55, 60, 80, 103], "mac": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88, 98, 103, 113, 116], "memori": [3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 38, 61, 76, 98, 103, 113, 116, 117], "either": [3, 4, 5, 6, 10, 18, 19, 23, 24, 25, 26, 34, 38, 43, 60, 61, 71, 76, 79, 83, 101, 111], "epoch": [3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 46, 59, 61, 74, 76, 87, 101, 103, 105, 108], "close": [3, 4, 5, 23, 24, 25, 57, 60, 62, 65, 68, 69, 97, 98, 111], "folder": [3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 24, 25, 30, 31, 32, 64, 89, 107], "pipelin": [3, 13, 40, 51, 59, 63, 68, 73, 74, 78, 87, 105, 108, 110, 111], "num_comp_ratio_candid": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "num_eval_iter": [3, 4, 5, 23, 24, 25], "convert": [3, 4, 5, 6, 7, 8, 9, 19, 20, 21, 22, 33, 41, 42, 43, 65, 80, 95, 105, 115], "tfrecord": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 26, 61, 66, 68], "contain": [3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 24, 25, 32, 43, 55, 61, 63, 65, 72, 76, 80, 81, 85, 90, 105, 107, 108, 109, 111], "start": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 33, 36, 38, 42, 57, 58, 59, 61, 62, 63, 65, 66, 68, 71, 76, 80, 81, 87, 94, 99, 100, 103, 109, 111], "label": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 20, 21, 22, 27, 38, 44, 52, 58, 66, 68, 71, 73, 85, 87, 107, 108], "tfrecords_dir": [3, 4, 5, 6, 8, 9, 20, 21, 22], "dir": [3, 4, 5, 7, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 92], "disabl": [3, 4, 5, 6, 7, 9, 20, 21, 23, 25, 33, 44, 66, 83, 85, 87, 100, 103, 107, 109, 111], "log": [3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 20, 21, 22, 36, 57, 81, 107], "info": [3, 4, 5, 6, 7, 9, 20, 21, 22, 43, 60, 65, 72, 75, 81, 84, 112], "level": [3, 4, 5, 6, 7, 9, 13, 20, 21, 22, 39, 60, 62, 77, 96, 98, 100, 101, 105, 110, 114], "eager": [3, 4, 5, 6, 7, 9, 20, 21, 22], "verbos": [3, 4, 5, 6, 7, 9, 20, 21, 22], "displai": [3, 4, 5, 6, 7, 9, 13, 20, 21, 22, 99, 107, 114, 115], "erorr": [3, 4, 5, 9, 20, 21], "tensorflow": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 32, 34, 36, 38, 39, 40, 41, 43, 44, 46, 90, 91, 94, 95, 96, 99, 101, 102, 106, 107, 109, 111, 112], "messag": [3, 4, 5, 6, 7, 9, 20, 21, 22, 61], "error": [3, 4, 5, 6, 7, 8, 9, 11, 20, 21, 22, 42, 61, 68, 73, 80, 95, 105, 108, 110, 111], "critic": [3, 4, 5, 6, 7, 9, 20, 21, 22], "tf_cpp_min_log_level": [3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 20, 21, 22], "todo": [3, 4, 5, 9, 20, 21], "compat": [3, 4, 5, 6, 7, 8, 9, 12, 13, 20, 21, 22, 33, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 79, 90], "v1": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69], "abhijit": [3, 4], "disable_eager_execut": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 58], "set_verbos": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22], "type": [3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 17, 20, 21, 22, 23, 24, 25, 27, 30, 31, 33, 36, 37, 38, 39, 43, 44, 46, 52, 57, 58, 59, 61, 62, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 85, 87, 89, 105, 107, 109, 111, 114], "list": [3, 4, 5, 6, 8, 9, 12, 14, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 42, 43, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 71, 74, 75, 76, 77, 78, 80, 84, 85, 87, 89, 92, 100, 102, 104, 109], "image_net_train": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 29, 30, 31], "imagenettrain": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 29, 30, 31], "format_bgr": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "int": [3, 4, 5, 6, 7, 8, 9, 11, 12, 17, 20, 21, 22, 23, 24, 25, 27, 36, 37, 38, 44, 46, 49, 55, 57, 58, 59, 60, 61, 66, 68, 71, 73, 74, 75, 76, 83, 85, 87], "bool": [3, 4, 5, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 43, 46, 60, 61, 64, 65, 66, 68, 73, 75, 76, 80, 83, 84, 87], "maximum": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 32, 36, 57, 58, 71, 87], "training_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "keras_learning_phas": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "data_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66, 68], "input_1": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 60, 61, 62, 65, 66], "validation_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "update_ops_nam": [3, 4, 5, 6, 8, 9, 20, 21, 59], "str": [3, 4, 5, 6, 8, 9, 14, 20, 21, 33, 38, 40, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 73, 75, 78, 79, 80, 83, 85, 87, 89], "learning_r": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 30, 31, 59, 74, 87], "decay_step": [3, 4, 5, 6, 8, 9, 20, 21, 59], "mostli": [3, 4, 5, 6, 8, 9, 20, 21, 25], "move": [3, 4, 5, 6, 8, 9, 20, 21, 82], "averag": [3, 4, 5, 6, 8, 9, 20, 21], "graphkei": [3, 4, 5, 6, 8, 9, 20, 21, 22], "update_op": [3, 4, 5, 6, 8, 9, 20, 21, 22], "alwai": [3, 4, 5, 6, 8, 9, 20, 21, 61, 90, 100], "dure": [3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 42, 57, 61, 65, 68, 71, 76, 87, 88, 94, 101, 103, 105, 108, 109, 111, 114, 115], "rate": [3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 42, 87, 103, 108], "adjust": [3, 4, 5, 6, 7, 8, 9, 20, 21, 29, 36, 57, 58, 71, 72, 87, 96, 97, 98, 105, 106, 110], "decai": [3, 4, 5, 6, 8, 9, 20, 21, 103], "trainer": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 30, 31, 38, 61, 76, 99], "num_epoch": [3, 4, 5, 6, 8, 9, 20, 21], "resnet50": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 33, 38, 39, 43, 44, 46, 58, 59, 60, 62, 65, 69], "kera": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 34, 42, 56, 58, 59, 60, 61, 62, 64, 65, 69, 94, 96, 99, 101, 105, 106, 107, 109, 111, 112], "covert": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22], "clear_sess": [3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 33, 36, 59, 60, 62, 65, 69], "releas": [3, 4, 5, 6, 7, 9, 20, 21, 22, 99, 104], "global": [3, 4, 5, 6, 7, 9, 20, 21, 22, 110], "clutter": [3, 4, 5, 6, 7, 9, 20, 21, 22], "old": [3, 4, 5, 6, 7, 9, 20, 21, 22], "By": [3, 4, 5, 6, 8, 9, 12, 20, 21, 22, 26, 28, 29, 30, 31, 37, 38, 42, 58, 61, 76, 103, 109, 111], "train_op": [3, 4, 5, 6, 9, 20, 21, 22], "fold": [3, 4, 5, 7, 22, 37, 39, 43, 50, 58, 59, 62, 65, 67, 72, 73, 74, 77, 84, 86, 89, 94, 95, 96, 105, 106, 107, 112], "applic": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 33, 38, 39, 43, 44, 46, 55, 58, 59, 60, 61, 62, 65, 69, 84, 100, 104], "backend": [3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 33, 36, 58, 59, 60, 62, 65, 69], "allow": [3, 4, 5, 6, 7, 9, 11, 13, 20, 21, 22, 27, 38, 40, 42, 45, 46, 51, 53, 55, 58, 61, 63, 67, 76, 78, 79, 80, 86, 87, 95, 101, 103, 105, 107, 108, 109, 110, 111, 112, 114], "easili": [3, 4, 5, 6, 7, 9, 20, 21, 22, 61, 76], "read": [3, 4, 5, 6, 7, 9, 20, 21, 22, 107], "eventu": [3, 4, 5, 6, 7, 9, 20, 21, 22], "aimet_tensorflow": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 90, 91, 92], "update_keras_bn_ops_trainable_flag": [3, 4, 5, 6, 7, 9, 20, 21, 22, 58, 64], "load_save_path": [3, 4, 5, 6, 7, 9, 20, 21, 22, 58, 64], "trainabl": [3, 4, 5, 6, 9, 16, 20, 21, 22, 31, 64, 68, 105], "add_image_net_computational_nodes_in_graph": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "an": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 42, 44, 46, 52, 54, 55, 57, 58, 59, 60, 61, 62, 66, 68, 71, 73, 74, 75, 76, 77, 79, 80, 81, 85, 87, 90, 94, 95, 97, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 115, 117], "softmax": [3, 4, 5, 6, 7, 9, 13, 14, 20, 21, 22, 33, 42, 57, 60, 61, 62, 65], "add_computational_nodes_in_graph": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "get_sess": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 58, 59, 60, 62, 65, 69], "creat": [3, 4, 5, 7, 11, 13, 17, 22, 32, 33, 36, 38, 42, 43, 44, 46, 49, 51, 52, 57, 58, 59, 61, 64, 65, 66, 68, 71, 73, 74, 76, 80, 82, 83, 84, 85, 87, 89, 94, 96, 103, 104, 105, 108, 111], "within": [3, 4, 5, 6, 7, 9, 13, 21, 33, 98, 107, 111], "images_class": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "identifi": [3, 4, 5, 6, 7, 9, 20, 21, 22, 75, 81, 91, 92, 99, 107, 110, 112, 117], "input_op_nam": [3, 4, 5, 6, 7, 8, 9, 20, 21, 33, 38, 58, 59, 60, 61, 62, 65], "output_op_nam": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 38, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68], "starting_op_nam": [3, 4, 5, 6, 7, 9, 20, 21, 22, 57, 58, 59, 63, 68], "append": [3, 4, 5, 8, 43, 65, 76], "test": [3, 4, 5, 6, 7, 9, 12, 13, 14, 20, 21, 22, 44, 52, 59, 66, 68, 72, 74, 85, 92], "is_gpu_avail": [3, 4, 5, 6, 7, 9, 20, 21, 22], "cuda_onli": [3, 4, 5, 6, 7, 9, 20, 21, 22], "": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 39, 41, 42, 43, 44, 46, 49, 52, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 68, 71, 74, 75, 76, 80, 84, 85, 87, 89, 92, 98, 102, 103, 105, 106, 107, 108, 110, 111, 114, 115, 117], "determin": [3, 4, 5, 8, 13, 23, 24, 25, 27, 36, 38, 44, 46, 52, 55, 57, 61, 62, 65, 66, 68, 71, 76, 85, 87, 95, 98, 103, 105, 106, 107], "fp32": [3, 4, 5, 12, 13, 22, 23, 24, 25, 32, 40, 44, 51, 63, 66, 78, 85, 94, 101, 106, 107, 108, 110, 111], "defin": [3, 4, 5, 9, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 41, 42, 44, 45, 49, 52, 55, 57, 58, 61, 64, 66, 71, 73, 76, 79, 80, 81, 85, 86, 87, 104, 105, 107, 109, 111], "target_comp_ratio": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "desir": [3, 4, 5, 23, 24, 25, 38, 46, 52, 61, 68, 76, 85, 87, 91, 92, 98, 103, 105, 110], "compess": [3, 4, 5], "ratio": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88, 97, 98, 114], "denot": [3, 4, 5, 23, 24, 25, 38, 95], "20": [3, 4, 5, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 36, 38, 42, 55, 57, 61, 71, 87, 90, 94, 108], "80": [3, 4, 5, 38], "pre": [3, 4, 5, 15, 16, 40, 51, 63, 78, 90, 91, 92, 99, 101, 106], "9": [3, 4, 5, 23, 25, 26, 29, 30, 31, 32, 38, 61, 71, 80, 87, 92, 110], "10": [3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 36, 38, 41, 42, 43, 46, 57, 60, 61, 68, 74, 76, 80, 81, 87, 88, 90, 91, 92, 100, 103, 108], "part": [3, 4, 5, 23, 24, 25, 42, 44, 49, 52, 58, 66, 73, 82, 85, 103, 105, 106, 107], "variou": [3, 4, 5, 7, 11, 17, 22, 23, 24, 25, 27, 32, 38, 61, 76, 95, 98, 103, 105, 110, 111, 112, 115], "measur": [3, 4, 5, 23, 24, 25, 27, 38, 61, 76, 85], "tri": [3, 4, 5, 23, 24, 25, 98, 105], "33": [3, 4, 5, 23, 24, 25], "66": [3, 4, 5, 23, 24, 25, 98], "00": [3, 4, 5, 23, 24, 25], "higher": [3, 4, 5, 23, 24, 25, 61, 71, 76, 96, 100, 108, 110], "candid": [3, 4, 5, 23, 24, 25, 38, 39, 60, 61, 62, 76, 100, 103], "granular": [3, 4, 5, 13, 23, 24, 25, 38, 61, 76, 103, 110, 111, 115], "time": [3, 4, 5, 7, 11, 17, 22, 23, 24, 25, 27, 32, 38, 43, 55, 61, 65, 76, 80, 81, 95, 103, 104, 108, 114], "taken": [3, 4, 5, 23, 24, 25, 42, 117], "complet": [3, 4, 5, 7, 11, 22, 23, 24, 25, 27, 38, 96, 110], "modules_to_ignor": [3, 4, 5, 23, 24, 25, 38, 61, 76, 85, 88, 102], "interact": [3, 4, 5, 23, 24, 25], "too": [3, 4, 5, 23, 24, 25], "choss": [3, 4, 5, 23, 24, 25], "auto": [3, 4, 5, 23, 24, 25, 34, 38, 39, 43, 50, 55, 61, 62, 65, 76, 77, 84, 88], "analysi": [3, 4, 5, 13, 23, 24, 25, 27, 38, 44, 52, 61, 66, 76, 85, 103, 110], "much": [3, 4, 5, 7, 11, 16, 21, 23, 24, 25, 31, 117], "altern": [3, 4, 5, 23, 24, 25, 91, 92, 103], "manual": [3, 4, 5, 7, 11, 23, 24, 25, 33, 38, 55, 61, 76, 84, 95, 103], "retriev": [3, 4, 5, 23, 25], "those": [3, 4, 5, 14, 16, 21, 23, 24, 25, 31, 52, 85, 103], "num_reconstruction_sampl": [3, 4, 5, 23, 25, 61, 76], "last": [3, 4, 5, 100, 102, 110], "stage": [3, 4, 5, 95], "map": [3, 4, 5, 7, 10, 11, 12, 14, 18, 22, 44, 46, 55, 58, 65, 81, 83, 107, 109], "linear": [3, 4, 5, 37, 43, 57, 59, 60, 65, 71, 74, 80, 81, 83, 84, 89, 96, 97], "regress": [3, 4, 5, 97], "attempt": [3, 4, 5, 97, 105, 106], "done": [3, 4, 5, 8, 14, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 41, 91, 97, 103, 109, 111, 117], "random": [3, 4, 5, 14, 27, 33, 36, 42, 44, 46, 49, 52, 54, 57, 58, 61, 66, 73, 97, 107], "ridicul": [3, 4, 5, 23, 25], "enabl": [3, 4, 5, 16, 18, 21, 23, 25, 31, 34, 38, 44, 59, 61, 66, 68, 74, 76, 83, 85, 90, 91, 96, 101, 105, 107, 109, 111, 112], "allow_custom_downsample_op": [3, 4, 5, 23, 25, 61, 76], "flag": [3, 4, 5, 23, 25, 43, 60, 64, 65, 73, 80, 87], "downsampl": [3, 4, 5, 23, 25], "consid": [3, 4, 5, 13, 23, 25, 65, 72, 94, 100, 105, 110], "bandwidth": [3, 4, 5, 23, 25, 98], "overhead": [3, 4, 5, 23, 25], "trade": [3, 4, 5, 23, 25, 36, 57, 71], "off": [3, 4, 5, 23, 25, 36, 46, 57, 68, 71, 87, 105, 106, 109], "suggest": [3, 4, 5, 23, 25, 46, 87, 100, 103, 106], "eval_callback": [3, 4, 5, 7, 11, 12, 17, 22, 23, 24, 25, 27, 32, 33, 38, 44, 49, 52, 58, 61, 66, 73, 76, 85, 88], "function_nam": [3, 4, 5, 23, 24, 25], "eval_iter": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "batch": [3, 4, 5, 7, 8, 11, 12, 22, 23, 24, 25, 28, 36, 37, 38, 40, 43, 44, 52, 54, 57, 58, 59, 60, 61, 63, 65, 66, 68, 71, 72, 74, 78, 84, 85, 87, 94, 96, 105, 106, 107], "choos": [3, 4, 5, 23, 24, 25, 66, 68, 87, 89, 97, 98, 103], "enough": [3, 4, 5, 23, 24, 25, 72], "trust": [3, 4, 5, 23, 24, 25], "callback": [3, 4, 5, 13, 15, 16, 17, 22, 23, 24, 25, 32, 38, 44, 46, 49, 52, 58, 61, 66, 68, 73, 76, 85, 87, 107, 111], "invoc": [3, 4, 5, 23, 24, 25], "compress_schem": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "cost_metr": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "actual": [3, 4, 5, 8, 9, 12, 14, 20, 21, 28, 30, 31, 40, 44, 49, 51, 52, 58, 63, 66, 71, 73, 78, 82, 85, 87, 92, 98, 105], "greedi": [3, 4, 5, 103, 114], "select": [3, 4, 5, 36, 57, 60, 71, 87, 89, 95, 98, 107, 111, 114, 117], "among": [3, 4, 5, 71], "reach": [3, 4, 5, 7, 11, 27, 95, 98], "previou": [3, 4, 5, 9, 29, 38, 43, 61, 76, 84, 90, 98, 100, 110], "rule": [3, 4, 5, 46, 66, 68, 109], "thumb": [3, 4, 5], "found": [3, 4, 5, 14, 33, 43, 84, 108, 111], "compressionschem": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "costmetr": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "greedyselectionparamet": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "channelpruningparamet": [3, 5, 23, 25, 61, 76], "decim": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "greedy_param": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "get_operation_by_nam": [3, 4, 5, 6, 8, 9, 20, 21, 22, 33, 60, 61, 65, 68, 69], "conv1_conv": [3, 4, 5, 69], "auto_param": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "automodeparam": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "greedy_select_param": [3, 4, 5, 23, 24, 25, 38, 61, 76], "data_set": [3, 5, 6, 9, 10, 18, 36, 57, 60, 61], "channel_prun": [3, 5, 23, 25, 38, 61, 76], "modelcompressor": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "compress_model": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88, 114], "relev": [3, 4, 5, 23, 24, 25], "our": [3, 4, 5, 8, 9, 12, 13, 15, 16, 19, 20, 23, 24, 25, 28, 37, 52, 85, 90, 92, 100, 110, 111], "new": [3, 5, 6, 9, 10, 14, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 32, 41, 42, 43, 55, 62, 65, 71, 79, 80, 83, 87, 91, 105, 109, 112], "final": [3, 5, 8, 12, 13, 15, 16, 17, 22, 28, 32, 38, 42, 61, 76, 81, 88, 97, 98, 100, 108, 110, 114], "compressed_sess": [3, 4, 33], "comp_stat": [3, 4, 23, 24], "working_dir": [3, 4, 5, 33, 61], "fell": [3, 4, 5, 23, 24, 25], "sharpli": [3, 4, 5, 23, 24, 25], "15": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 87, 103, 108], "job": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 87], "hyper": [3, 4, 5, 8, 9, 12, 13, 20, 21, 23, 24, 25, 28, 30, 31, 87, 94, 108], "search": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 34, 36, 57, 71, 87, 100, 108, 109], "good": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 42, 87, 94], "end": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 36, 37, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 80, 81, 85, 87, 103], "drop": [3, 4, 5, 7, 8, 11, 12, 13, 15, 16, 20, 21, 23, 24, 25, 27, 28, 30, 31, 58, 61, 87, 95, 98, 103, 106, 107, 108, 110, 111], "factor": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 43, 65, 84, 87, 98, 103, 106], "feel": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 87, 91], "fit": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 38, 46, 61, 76, 87, 100], "reduced_": [3, 4, 5], "accordingli": [3, 4, 5, 58, 91, 92], "compr_graph_all_ops_nam": [3, 4, 5], "get_oper": [3, 4, 5], "update_ops_name_after_cp": [3, 4, 5], "op_nam": [3, 4, 5], "1e": [3, 4, 5, 13, 14, 20, 21, 42, 68, 72, 108], "finetu": [3, 4, 5, 23, 24, 25], "ofcours": [3, 4, 5, 9, 20, 21, 23, 24, 25, 29, 30, 31], "graph_sav": [3, 4, 5, 6, 60, 65, 68], "save_model_to_meta": [3, 4, 5], "meta_path": [3, 4, 5], "finetuned_model": [3, 4, 5, 23, 24], "quantiz": [3, 4, 5, 7, 11, 14, 23, 24, 25, 27, 34, 35, 36, 37, 40, 42, 44, 47, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 66, 70, 71, 73, 74, 78, 79, 80, 82, 83, 85, 94, 95, 96, 98, 99, 101, 103, 107, 112, 114], "pytorch": [4, 5, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 72, 80, 81, 89, 90, 91, 94, 95, 96, 99, 101, 106, 107, 109, 111, 112], "repres": [4, 5, 17, 22, 23, 24, 25, 32, 36, 38, 42, 44, 46, 52, 55, 57, 58, 60, 61, 66, 68, 76, 79, 83, 85, 87, 100, 105, 106, 107, 108, 111], "spatialsvdparamet": [4, 5, 24, 25, 33, 38, 61, 76, 88], "spatial_svd": [4, 5, 24, 25, 33, 38, 61, 76, 88], "comp_accuraci": 4, "ssvd_compressed_sess": 5, "ssvd_comp_stat": [5, 25], "ssvd_finetuned_model": [5, 25], "further": [5, 25, 34, 62, 65, 80, 97, 101, 103, 105, 109], "similar": [5, 16, 21, 25, 31, 106, 108, 111], "out": [5, 7, 11, 14, 25, 42, 44, 45, 46, 52, 53, 66, 67, 68, 80, 83, 85, 86, 87, 95, 98, 103, 107], "ssvd_cp_compressed_sess": 5, "cp_comp_stat": [5, 25], "ok": [5, 25], "fine": [6, 7, 8, 9, 13, 15, 16, 20, 21, 30, 31, 34, 38, 46, 61, 68, 76, 87, 98, 101, 105, 108, 111], "tune": [6, 7, 8, 9, 13, 15, 16, 20, 21, 30, 31, 34, 38, 46, 61, 68, 76, 87, 98, 101, 105, 108, 111], "fold_all_batch_norm": [6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 43, 60, 65, 84, 89], "bn_folded_sess": [6, 9, 20, 21], "maintain": [6, 49], "fresh": 6, "save_and_load_graph": [6, 60, 65], "bn_folded_sess_copi": 6, "With": [6, 14, 16, 17, 21, 22, 31, 32], "enhanc": [6, 16, 17, 21, 22, 31, 32, 44, 54, 66, 68, 85, 107, 111], "input_label_tensor": [6, 8, 9, 20, 21, 22], "get_tensor_by_nam": [6, 7, 8, 9, 20, 21, 22, 57, 58, 68], "train_tensor": [6, 8, 9, 20, 21, 22, 68], "train_tensors_dict": [6, 8, 9, 20, 21, 22], "dict": [6, 8, 9, 20, 21, 22, 38, 43, 46, 60, 61, 65, 75, 76, 78, 79, 80, 83, 84, 85, 87], "fromkei": [6, 8, 9, 20, 21, 22], "eval_output": [6, 8, 9, 20, 21, 22], "top1": [6, 8, 9, 20, 21, 22, 27, 38], "acc": [6, 8, 9, 11, 12, 13, 17, 20, 21, 22, 44], "input_label": [6, 8, 9, 20, 21, 22], "input_label_tensors_dict": [6, 8, 9, 20, 21, 22], "zip": [6, 8, 9, 20, 21, 22, 38, 44, 58], "feed_dict": [6, 7, 8, 9, 20, 21, 22, 57, 58, 63, 68], "as_default": [6, 7, 8, 9, 20, 21, 22, 58, 60, 61, 62, 65, 68, 69], "ensur": [6, 18, 78, 91, 105, 110], "prior": [6, 26, 29, 30, 31, 97, 105, 107], "num_iter": [6, 7, 11, 38], "offer": [7, 11, 27, 52, 68, 85, 95], "suit": [7, 11, 27, 95], "network": [7, 11, 13, 14, 18, 27, 42, 61, 68, 95, 98, 100, 103, 105, 108, 110, 111, 114, 116], "often": [7, 11, 94, 95, 103, 108], "sequenc": [7, 11, 13, 27, 72, 95, 96, 104, 109], "better": [7, 8, 11, 18, 28, 72, 89, 94, 95, 105, 106, 108], "prone": [7, 11, 95], "consum": [7, 11, 19, 27, 55, 95, 103], "analyz": [7, 11, 27, 38, 45, 53, 61, 67, 76, 86, 95, 97, 103, 104, 107, 111, 114, 115], "amount": [7, 11, 17, 22, 27, 32, 95, 109], "toler": [7, 11, 27, 95, 98], "soon": [7, 11, 95], "threshold": [7, 11, 61, 95], "stop": [7, 11, 36, 57, 71, 95], "autom": [7, 11, 26, 29, 30, 31, 32, 45, 71, 79, 80, 86, 87, 95, 105], "input_tensor_nam": [7, 58], "output_tensor_nam": [7, 58], "section": [7, 9, 11, 12, 27, 29, 72, 81, 91, 92, 94, 96, 97, 99, 103, 105, 111], "eval_dataset_s": [7, 11, 12, 27, 49, 58, 73], "5000": [7, 11, 27, 49, 58, 73], "calibration_dataset_s": [7, 11, 27, 49, 58, 73], "_create_sampled_data_load": [7, 11, 27, 73], "_sampled_dataset": [7, 58], "_create_sampled_dataset": [7, 58], "num_sampl": [7, 11, 12, 27, 44, 58, 73], "_graph": [7, 22, 58], "shuffle_buffer_s": [7, 58], "300": [7, 58], "buffer": [7, 58], "shuffle_se": [7, 58], "22222": [7, 58], "shuffl": [7, 10, 15, 16, 18, 33, 38, 58, 76], "buffer_s": [7, 58], "seed": [7, 58, 76], "object": [7, 11, 12, 17, 22, 26, 29, 30, 31, 32, 33, 36, 40, 44, 46, 49, 51, 52, 57, 58, 59, 61, 63, 66, 68, 73, 76, 78, 83, 85, 87, 96, 105, 108, 111], "eval_dataset": [7, 11, 12, 44, 58, 73], "image_dataset": [7, 44, 58], "lambda": [7, 10, 11, 12, 13, 14, 18, 22, 44], "unlabeled_dataset": [7, 11, 12, 17, 22, 44, 58, 66, 73], "argument": [7, 11, 12, 17, 22, 32, 33, 36, 40, 44, 46, 51, 52, 57, 58, 61, 63, 66, 68, 71, 78, 80, 85, 87], "whole": [7, 11, 12, 58, 111], "np": [7, 8, 14, 33, 36, 38, 42, 44, 46, 49, 52, 54, 57, 58, 61, 65, 66], "iterate_tf_dataset": [7, 58], "sampled_dataset": [7, 11, 12, 17, 58], "global_variables_initi": [7, 57, 58, 61], "input_tensor": [7, 10, 18, 19, 33, 42, 54, 57, 58, 68, 80], "output_tensor": [7, 33, 57, 58], "num_correct_predict": [7, 58, 73], "prob": [7, 58], "predict": [7, 17, 38, 40, 44, 58, 61, 73, 105], "argmax": [7, 58, 73], "axi": [7, 17, 22, 32, 55, 58, 107], "sum": [7, 27, 38, 58, 73], "allowed_accuracy_drop": [7, 11, 27, 49, 58, 73], "convei": [7, 11], "seri": [7, 11, 27, 87], "auto_qu": [7, 11, 27, 49, 58, 73], "01": [7, 11, 27, 36, 49, 57, 58, 71, 73, 92, 94], "shown": [7, 11, 17, 22, 32, 43, 65, 79, 82, 83, 94, 103, 106, 107, 110], "adaround_dataset_s": [7, 11, 27, 49, 58, 73], "adaround_dataset": [7, 11, 58], "adaround_param": [7, 11, 27, 49, 58, 73], "set_adaround_param": [7, 11, 27, 49, 58, 73], "associ": [7, 11, 17, 22, 32, 36, 43, 57, 58, 60, 61, 73, 81, 105], "eval_scor": [7, 11, 38, 61, 76, 85], "cle": [7, 11, 27, 39, 60, 62, 77, 82, 86, 94, 99, 105, 110, 112], "standalon": [7, 11, 27, 72, 105], "fashion": [7, 11, 18, 27], "counter": [8, 12, 28, 45, 46, 68, 87], "potenti": [8, 12, 28, 43, 45, 65, 72, 104, 107, 114, 115], "instabl": [8, 12, 28, 45], "batchnrom": [8, 28], "varianc": [8, 12, 28, 45, 106], "recalcul": [8, 12, 28, 37], "stabl": [8, 12, 28, 37, 80, 94], "rather": [8, 12, 28, 37, 80, 114], "than": [8, 12, 13, 28, 37, 38, 43, 55, 61, 65, 71, 72, 76, 80, 81, 84, 87, 102, 108, 114], "noisi": [8, 12, 28, 37], "compar": [8, 12, 13, 14, 15, 16, 17, 22, 28, 32, 61, 72, 80, 89, 107, 108, 115], "focu": [8, 28], "itself": [8, 17, 22, 28, 32, 51, 103, 111, 113, 116], "inform": [8, 28, 43, 55, 61, 65, 75, 81, 84, 105, 107], "accuraci": [8, 12, 13, 17, 22, 27, 28, 32, 34, 36, 38, 40, 46, 49, 51, 57, 58, 61, 63, 68, 71, 73, 76, 78, 87, 94, 95, 98, 100, 101, 103, 105, 106, 107, 108, 110, 111, 112, 115, 117], "line": [8, 54, 59, 68, 69, 71, 74, 75, 87, 89, 99], "difficult": 8, "model_sess_bn_mut": 8, "easier": 8, "bn_mutabl": 8, "modify_sess_bn_mut": 8, "training_tf_placehold": 8, "unlik": [8, 28], "script": [8, 28], "didn": [8, 28], "becaus": [8, 14, 28, 42, 80], "present": [8, 14, 28, 34, 72, 78, 81, 103, 106], "statatist": [8, 28], "json": [8, 12, 17, 19, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "default_config_per_channel": [8, 12], "is_output_quant": [8, 12, 109], "is_quant": [8, 12, 109], "is_symmetr": [8, 12, 55, 109], "strict_symmetr": [8, 12, 109], "unsigned_symmetr": [8, 12, 109], "per_channel_quant": [8, 12, 18, 55, 109], "op_typ": [8, 12, 109], "squeez": [8, 12], "pad": [8, 12, 42, 72, 80, 81], "supergroup": [8, 12, 109, 112], "op_list": [8, 12, 109], "relu": [8, 12, 13, 14, 41, 42, 43, 55, 62, 65, 72, 75, 79, 80, 81, 84, 106, 109, 117], "clip": [8, 12, 109, 111], "gemm": [8, 12, 109], "model_input": [8, 12, 81, 109], "is_input_quant": [8, 12, 109], "model_output": [8, 12, 109], "config_file_path": 8, "tmp": [8, 12, 17, 22, 32, 44, 58, 66, 73, 85], "open": [8, 12], "w": [8, 12, 85, 91, 117], "f": [8, 12, 27, 49, 73, 80, 81, 91, 92], "dump": [8, 12], "training_range_learning_with_tf_init": [8, 12, 16, 21, 28, 31, 36, 57, 68, 71, 87], "config_fil": [8, 12, 17, 18, 22, 32, 44, 46, 52, 66, 68, 73, 75, 85, 87], "5e": [8, 24, 25, 28, 30, 31, 59, 74, 87], "7": [8, 12, 24, 25, 28, 30, 31, 43, 59, 73, 74, 87, 92, 117], "finetuned_accuraci": [8, 28, 30, 31], "helper": [8, 12, 28, 58, 60, 64, 73], "reestimate_bn_stat": [8, 12, 28, 37, 59, 74], "full": [8, 12, 28, 38, 41, 45, 64, 79, 86, 116], "100": [8, 12, 28, 37, 58, 59, 61, 68, 73, 74], "adapt": [8, 12, 18, 28, 45, 67, 74, 83, 86, 94, 99, 105, 107, 112], "forward": [8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 44, 46, 52, 66, 68, 71, 72, 74, 79, 80, 81, 82, 84, 85, 87, 91, 104, 107, 110, 112], "yield": [8, 12, 28, 52, 66, 71, 74, 85, 111], "directli": [8, 12, 16, 28, 37, 49, 82, 85, 107, 111], "bn_reestim": [8, 12, 28, 37, 59, 74], "real_input": 8, "vstack": 8, "from_tensor_slic": [8, 36, 37, 44, 57, 58, 61, 66], "bn_re_restimation_dataset": [8, 59], "start_op_nam": [8, 9, 22, 59, 60, 62, 65, 66], "bn_re_estimation_dataset": [8, 37, 59], "bn_num_batch": [8, 37, 59], "finetuned_accuracy_bn_reestim": [8, 28], "far": [8, 12, 28, 94], "effici": [8, 12, 28, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "fold_all_batch_norms_to_scal": [8, 12, 28, 37, 59, 74], "resnet50_after_qat": [8, 20], "lead": [9, 29, 44, 52, 66, 85, 94, 96, 106, 110, 111], "shift": [9, 29, 67, 86, 106], "training_range_learning_with_tf_enhanced_init": [9, 16, 21, 31, 36, 57, 71, 87], "aimet_cl": [9, 19], "cle_applied_sess": 9, "under": [9, 29, 39, 62, 99, 107, 109, 114, 115], "hood": [9, 29], "correct_bia": [9, 29, 60, 75], "num_quant_sampl": [9, 29, 60, 75], "num_bias_correct_sampl": [9, 29, 60, 75], "bias_correct": [9, 29, 60, 75], "aimet_bc": 9, "quant_param": [9, 60, 75], "quantparam": [9, 29, 60, 75], "quant_mod": [9, 60], "round_mod": [9, 29, 60, 75], "ops_to_ignor": [9, 60], "bias_correction_param": [9, 60], "biascorrectionparam": [9, 60], "56": 9, "16": [9, 12, 29, 36, 38, 46, 54, 55, 57, 68, 71, 80, 83, 87, 94], "after_bc_sess": 9, "biascorrect": [9, 60], "bias_correct_param": [9, 60], "resnet50_after_qat_range_learn": [9, 21], "smaller": [10, 18, 71, 72, 94, 101, 110, 113, 116], "awai": [10, 18, 94], "image_net_dataset": [10, 11, 12, 17, 18, 19], "imagenetdataset": [10, 11, 12, 17, 18, 19], "get_val_dataset": [10, 11, 12, 17, 18, 19], "include_top": [10, 18, 19], "pool": [10, 12, 18, 19], "rest": [10, 15, 16, 18, 19, 33, 110], "sim": [10, 12, 13, 18, 26, 27, 36, 37, 48, 49, 57, 59, 71, 73, 74, 75, 82, 83, 85, 108, 111], "progbar": [10, 15, 16, 18, 19], "preprocess_input": [10, 15, 16, 18, 19, 33, 38], "sim_model": [10, 15, 16, 17, 18, 19, 26, 28, 29, 30, 31, 32, 71, 87], "tf_dataset": [10, 18, 19], "progbar_stat_upd": [10, 15, 16, 18, 19], "preprocess": [10, 13, 15, 16, 18, 38], "image_dataset_from_directori": [10, 15, 16, 18, 38], "ada_round_data": [10, 18], "label_mod": [10, 15, 16, 18, 38], "categor": [10, 15, 16, 18, 38], "image_width": [10, 18], "image_height": [10, 18], "y": [10, 17, 18, 22, 32, 46, 68, 80, 91, 92, 107], "fo": [10, 18, 71], "r": [10, 18, 71, 83, 85], "Of": [10, 18], "cours": [10, 18], "resnet50_after_adaround": 10, "quick": [10, 14, 18, 99], "dictionari": [11, 12, 14, 38, 61, 76, 85, 87, 88, 100, 103, 109], "adam": [11, 12, 13, 15, 16, 17, 44, 46, 68], "categoricalcrossentropi": [11, 12, 17, 44], "categoricalaccuraci": [11, 12, 17, 44], "thi": [12, 13, 14, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 89, 91, 92, 94, 95, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117], "notebook": [12, 13, 14], "i": [12, 13, 14, 33, 34, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117], "6": [12, 13, 14, 36, 42, 49, 57, 61, 71, 73, 80, 87, 108], "simul": [12, 13, 15, 16, 32, 40, 45, 46, 51, 53, 55, 60, 63, 67, 68, 71, 75, 78, 79, 82, 86, 87, 101, 105, 108, 112], "train_dataset_s": 12, "re_estimation_dataset_s": 12, "train_dataset": 12, "re_estimation_dataset": 12, "built": [12, 13, 90, 91], "sequenti": [12, 13, 14, 41, 42, 109, 110], "subclass": [12, 13, 33, 41, 42], "incompat": [12, 13], "therefor": [12, 13, 14, 98, 106], "conv1": [12, 23, 24, 25, 33, 42, 72, 76, 79, 80, 81, 84, 88], "fuse": [12, 109, 111], "maxpooling2d": 12, "conv2": [12, 42, 55, 76, 79, 80, 84], "flatten": [12, 80], "dens": [12, 13, 14, 41, 42, 43], "functional_model": [12, 13, 14], "baselin": [12, 13, 27, 100, 108], "loss_fn": 12, "qsim": [12, 37], "posit": [12, 13, 14, 42], "quantized_callback": [12, 13, 15, 16], "tensorboard": [12, 13, 15, 16], "log_dir": [12, 13, 15, 16], "histori": [12, 13, 15, 16], "validation_data": [12, 13, 15, 16], "reestim": [12, 37], "mnist_after_bn_re_estimation_qat_range_learn": 12, "standard": [13, 15, 16, 20, 21, 30, 31, 80, 87, 89], "1": [13, 33, 36, 37, 38, 42, 43, 46, 48, 49, 52, 54, 57, 58, 59, 60, 61, 64, 68, 71, 72, 73, 74, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 100, 102, 103, 104, 105, 109, 110, 111, 113, 116, 117], "dataset": [13, 33, 36, 37, 38, 44, 49, 52, 54, 57, 58, 59, 60, 61, 66, 68, 71, 73, 74, 75, 85, 87, 99, 105, 106, 111], "2": [13, 33, 36, 38, 42, 43, 46, 49, 54, 57, 58, 59, 61, 64, 68, 71, 72, 73, 74, 76, 78, 80, 81, 83, 84, 85, 87, 90, 91, 94, 105, 110, 111], "3": [13, 33, 36, 38, 39, 43, 44, 46, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 84, 85, 87, 88, 89, 90, 98, 105, 108, 110, 117], "evalu": [13, 27, 33, 36, 38, 44, 46, 52, 54, 57, 58, 61, 62, 65, 66, 71, 73, 76, 85, 87, 88, 95, 99, 100, 103, 105, 107, 108, 111, 114], "4": [13, 17, 22, 23, 32, 33, 36, 37, 43, 44, 49, 52, 57, 58, 59, 61, 66, 71, 73, 74, 75, 76, 80, 83, 84, 85, 87, 96, 100, 105, 117], "imdb": 13, "sentiment": 13, "vocab_s": [13, 14, 42], "20000": [13, 14, 42], "20k": 13, "word": 13, "maxlen": [13, 14, 42], "200": [13, 14, 27, 42], "movi": 13, "review": 13, "x_train": [13, 33, 37], "y_train": [13, 33], "x_val": 13, "y_val": 13, "load_data": 13, "num_word": 13, "pad_sequ": 13, "embed_dim": [13, 14, 42], "embed": [13, 14, 42, 80, 87, 103, 110], "token": [13, 14, 42, 110], "num_head": [13, 14, 42], "attent": [13, 14, 42], "head": [13, 14, 42], "ff_dim": [13, 14, 42], "hidden": [13, 14, 42], "insid": [13, 14, 38, 42, 80, 91], "delta": [13, 14, 42, 44, 52, 66, 85, 111], "input_dim": [13, 14, 42], "output_dim": [13, 14, 42], "block": [13, 73], "multiheadattent": [13, 14, 42, 112], "key_dim": [13, 14, 42], "dropout": [13, 14, 42], "layernorm": [13, 14, 42], "epsilon": [13, 14, 42], "globalaveragepooling1d": [13, 14, 42], "functional_callback": 13, "histogram_freq": 13, "sparse_categorical_crossentropi": 13, "128": [13, 15, 16, 66, 80], "wrap": [13, 15, 16, 17, 19, 22, 32, 80], "wrapper": [13, 19, 26, 29, 30, 31, 36, 44, 52, 57, 61, 66, 76, 85], "effect": [13, 15, 16, 20, 21, 30, 31, 36, 37, 46, 57, 59, 68, 71, 74, 83, 87, 96, 105, 107, 109, 111], "visual": [13, 17, 22, 32, 34, 38, 56, 61, 70, 76, 91, 103, 105, 106, 107, 110, 112, 113, 116], "right": [13, 27, 105, 117], "multi": [13, 33, 65, 86, 112], "encount": 13, "access": [13, 26, 29, 30, 31, 91, 105], "mha": [13, 112], "accur": 13, "clone_lay": 13, "clone": [13, 99], "diagram": [13, 96, 100, 103, 111, 113, 116], "m": [13, 90, 91, 92, 99], "convert_to_pb": [13, 46], "onc": [13, 15, 16, 20, 21, 23, 24, 25, 29, 30, 31, 41, 79, 81, 83, 87, 96, 97, 103, 107, 108, 111], "inspect": 13, "1024": [13, 54, 68, 71, 87, 94, 104], "artifact": [13, 15, 16, 40, 51, 63, 69, 78, 91], "3000": 13, "model_after_qat": [13, 15, 16], "anoth": [13, 16, 21, 31, 83, 87, 116, 117], "most": [13, 109], "complex": [13, 36, 44, 46, 52, 57, 66, 68, 85, 87], "elementari": 13, "logdir": 13, "summari": [13, 69, 89, 95], "vanilla": [13, 16, 21, 27, 31, 110], "tool": [14, 44, 66, 85, 103, 106, 115, 117], "sequanti": 14, "build": [14, 42], "dicuss": 14, "text": [14, 42], "transform": [14, 26, 27, 29, 30, 31, 32, 42, 71, 73, 80, 87, 112], "tokenandpositionembed": [14, 42], "transformerblock": [14, 42], "super": [14, 42, 72, 80, 81], "att": [14, 42], "ffn": [14, 42], "layernorm1": [14, 42], "layernorm2": [14, 42], "dropout1": [14, 42], "dropout2": [14, 42], "kwarg": [14, 42], "attn_output": [14, 42], "out1": [14, 42], "ffn_output": [14, 42], "token_emb": [14, 42], "pos_emb": [14, 42], "random_input": [14, 42], "embedding_lay": [14, 42], "transformer_block": [14, 42], "token_and_position_embed": 14, "re": [14, 33, 45, 67, 86, 99, 105], "symmetr": [14, 55, 83, 109, 111], "model_prepar": [14, 26, 28, 29, 30, 31, 32, 42, 44, 71, 74, 80, 85, 87], "prepare_model": [14, 26, 28, 29, 30, 31, 32, 42, 44, 71, 74, 80, 85, 87], "input_lay": [14, 42], "begin": [14, 42, 72, 80, 81, 108, 109], "unwrap": 14, "ident": [14, 41, 79], "total": [14, 38, 100, 111], "get_weight": 14, "represent": [14, 55], "reorder": 14, "get_original_models_weights_in_functional_model_ord": 14, "original_model": [14, 42], "class_nam": [14, 38], "ndarrai": [14, 43, 63, 65, 84], "arg": [14, 87], "lookup": 14, "remov": [14, 37, 59, 74, 80, 91, 97, 101, 111, 117], "match": [14, 36, 40, 44, 51, 52, 57, 61, 63, 66, 76, 78, 85, 87, 97, 103, 107, 109, 110, 111, 117], "original_model_weight": 14, "pop": 14, "weight_nam": 14, "kei": [14, 16, 21, 31, 43, 55, 60, 65, 84, 92], "functional_model_weight_ord": 14, "enumer": [14, 36, 38, 57, 61, 71, 76, 78, 87, 96], "sort": 14, "weights_in_correct_ord": 14, "item": [14, 17, 22, 32, 49, 105], "weight_info": 14, "assert": [14, 80], "count_param": 14, "output_shap": 14, "textclassif": 14, "what": [14, 111, 114], "architectur": [14, 68, 86, 98], "model_weights_in_correct_ord": 14, "assert_array_equ": 14, "modelprepar": [14, 26, 29, 30, 31, 32, 37, 42, 71, 80, 87], "arthmet": [14, 42], "experss": [14, 42], "tfoplambda": [14, 42], "ressembl": 14, "conv_1": [14, 42], "conv_2": [14, 42], "becuas": [14, 42, 51], "rais": [14, 42, 61, 68], "except": [14, 17, 22, 32, 42], "hopefulli": [14, 19], "min": [15, 16, 18, 44, 52, 55, 66, 68, 85, 89, 107, 111], "max": [15, 16, 18, 44, 52, 55, 66, 68, 85, 89, 103, 106, 107, 111], "keep": [15, 20, 21, 30, 31, 80, 87, 109, 110], "constant": [15, 20, 21, 30, 31, 49, 58, 73, 80, 87, 100, 105], "imagenet_dir": 15, "assign": [15, 16, 55, 83], "dataset_train": [15, 16], "dataset_valid": [15, 16], "respect": [15, 16, 41, 61, 89, 107], "categorical_crossentropi": [15, 16, 46], "being": [15, 16, 19, 38, 41, 43, 55, 61, 76, 79, 80, 81, 84, 85], "hyperparamet": [15, 16, 108], "henc": 16, "jointli": [16, 20, 21, 30, 31], "ye": [16, 92, 103], "due": [16, 34, 42, 67, 81, 86, 105, 106], "restrict": [16, 104], "prevent": [16, 72, 80, 97], "mention": 16, "continu": [16, 21, 31, 42, 81, 87, 105, 106, 108, 110], "benefit": [16, 21, 31, 55, 94], "analys": [17, 22, 32, 107], "respond": [17, 22, 32], "One": [17, 22, 26, 29, 30, 31, 32, 44, 46, 60, 66, 68, 98, 103, 113], "second": [17, 22, 32, 42, 58, 71, 109], "anyth": [17, 22, 32], "tupl": [17, 22, 32, 33, 36, 37, 38, 40, 43, 44, 46, 52, 57, 58, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 87], "dummi": [17, 22, 32, 36, 46, 48, 57, 71, 72, 73, 77, 78, 84, 85, 87, 107], "val_dataset": 17, "callbackfunc": [17, 22, 32, 44, 52, 66, 85], "exactli": [17, 22, 32, 58, 111], "multipl": [17, 22, 32, 38, 61, 65, 68, 72, 76, 77, 78, 80, 81, 84, 87, 88, 90, 92, 101, 103, 105, 112], "eval_func": [17, 38, 61, 88], "v": [17, 22, 32, 36, 57, 71, 91, 100], "demonstr": [17, 22, 32], "quant_analyz": [17, 22, 32, 44, 52, 66, 85], "enable_per_layer_mse_loss": [17, 32, 44, 52, 85], "track": [17, 22, 32, 83, 107], "minimum": [17, 22, 32, 36, 57, 71, 80, 87, 89, 90], "histogram": [17, 22, 32, 44, 52, 66, 69, 85, 89, 105, 107, 111, 112], "seen": [17, 22, 32, 106, 107], "results_dir": [17, 22, 32, 44, 52, 58, 66, 69, 73, 85, 89], "html": [17, 22, 32, 80, 85, 91, 92, 98, 107, 112, 115], "plot": [17, 22, 32, 69, 89, 107], "per_layer_quant_en": [17, 32, 107], "per_layer_quant_dis": [17, 32, 107], "min_max_rang": [17, 22, 32, 107], "activations_pdf": [17, 22, 32, 107], "name_": [17, 32, 85], "index_0": [17, 32], "index_1": [17, 32], "index_n": [17, 32], "weights_pdf": [17, 22, 32, 107], "layer1": [17, 32, 43, 65, 84], "param_name_": [17, 22, 32, 85], "channel_index_0": [17, 22, 32], "channel_index_1": [17, 22, 32], "channel_index_n": [17, 32], "layer2": [17, 32, 43, 65, 84], "layern": [17, 32], "per_layer_mse_loss": [17, 32, 107], "sub": [17, 22, 32, 72, 92, 97, 103, 111, 117], "basi": [18, 55, 100, 103], "between": [18, 36, 38, 43, 57, 61, 65, 66, 71, 76, 78, 84, 85, 92, 106, 107, 109, 111], "imagin": 18, "filter": [18, 42], "kernel": [18, 97, 113, 116], "28": [18, 76], "were": [18, 27, 30, 31, 40, 43, 51, 55, 63, 65, 71, 78, 83, 84, 87, 92, 98, 105, 109, 117], "entireti": [18, 42], "contrast": [18, 42], "repeat": [18, 58, 97], "uniqu": 18, "attribut": [18, 42, 80, 83, 107], "conv2d_lay": 18, "kernel_s": [18, 42, 72, 80, 81], "snpe": [18, 19], "qnn": [18, 19], "config": [18, 46, 66, 68, 85, 109, 112], "style": 18, "mismatch": 18, "togeth": [18, 103], "pcq_quantsim_config": 18, "tell": [18, 114], "did": [18, 106], "resnet50_pcq_adaround": 18, "mimic": 19, "cle_applied_model": [19, 39], "yaml": 19, "h5": [19, 40, 101, 105], "savedmodel": 19, "protobuff": 19, "safe": 19, "resnet50_after_cl": 19, "Then": [20, 21, 30, 31, 36, 52, 57, 71, 85, 87], "meta": [20, 33, 61, 63, 68, 83, 101, 105], "No": [22, 75, 81, 105], "func": [22, 85], "func_callback_arg": [22, 52, 66, 85], "data_pipelin": 22, "per_op_quant_en": 22, "per_op_quant_dis": 22, "quant_op_name0": 22, "quant_op_name1": 22, "quant_op_namen": 22, "op1": 22, "channel_index_x": 22, "op2": 22, "channel_index_i": 22, "opn": 22, "channel_index_z": 22, "per_op_mse_loss": 22, "nn": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 76, 79, 80, 81, 82, 84, 85, 87, 104, 112], "modul": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 41, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 89, 90, 94, 105, 112, 117], "gpu": [23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 60, 61, 66, 68, 76, 78, 86, 90, 91, 105, 112], "learning_rate_schedul": [23, 24, 25, 28, 30, 31, 74, 87], "schedul": [23, 24, 25, 28, 30, 31, 108], "max_epoch": [23, 24, 25, 28, 30, 31], "is_avail": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 74], "aimet_torch": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 92, 104], "compressed_model": [23, 24, 38, 61, 76], "15e": [23, 25], "prune": [24, 38, 98, 99, 100, 102, 103, 112, 117], "ssvd_compressed_model": 25, "ssvd_cp_compressed_model": 25, "ssvd_cp_finetuned_model": 25, "certain": [26, 29, 30, 31, 32, 71, 79, 80, 85, 87, 103, 104, 105, 109], "guidelin": [26, 29, 30, 31, 32, 34, 45, 48, 54, 56, 58, 68, 71, 80, 86, 94, 98, 108], "rand": [26, 28, 29, 30, 31, 32, 33, 36, 44, 57, 58, 61, 66, 72, 78, 81], "modif": [26, 29, 30, 31], "made": [26, 29, 30, 31, 80, 109], "overrid": [26, 29, 30, 31, 61, 80, 87], "no_grad": [26, 27, 29, 30, 31, 32, 71, 81, 87], "ptq": [27, 58, 73, 101, 105, 107, 108], "success": 27, "care": 27, "non": [27, 72, 80, 111], "expert": 27, "effort": [27, 58, 73, 95], "known": [27, 81, 100, 101], "heurist": [27, 61], "cumul": 27, "until": [27, 58, 73, 95], "val_transform": 27, "compos": [27, 73], "centercrop": 27, "totensor": [27, 73], "normal": [27, 43, 72, 96, 107], "485": 27, "456": 27, "406": 27, "std": 27, "229": 27, "225": 27, "imagenet_dataset": 27, "imagefold": 27, "root": 27, "eaxmpl": 27, "tqdm": 27, "subsetrandomsampl": [27, 73], "in_eval_mod": 27, "get_devic": 27, "_dataset": [27, 73], "logit": 27, "topk": [27, 49], "k": [27, 113], "view_a": 27, "unlabeleddatasetwrapp": [27, 73], "__getitem__": [27, 73], "unlabeled_imagenet_dataset": 27, "unlabeled_imagenet_data_load": 27, "initial_accuraci": [27, 49, 73], "run_infer": [27, 49, 73], "predefin": [27, 100], "empir": [27, 60, 106], "adaround_data_load": [27, 49, 73], "furhter": 27, "optimized_accuraci": [27, 49, 73], "train_load": [28, 74, 76], "images_dir": 28, "resnet18_after_qat": [28, 30, 31], "bc_param": 29, "weight_bw": [29, 75], "act_bw": [29, 75], "resnet18_after_cle_bc": 29, "matter": 32, "involv": [33, 105, 110], "four": [33, 111], "convert_tf_sess_to_kera": 33, "save_tf_session_single_gpu": 33, "sourc": [33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 87, 88, 89, 91, 92, 110], "variabl": [33, 38, 42, 61, 76, 80, 91, 92, 99], "load_tf_sess_variables_to_keras_single_gpu": 33, "compressed_op": 33, "save_session_graph_and_vari": 33, "creation": 33, "compress": [33, 34, 35, 56, 70, 97, 99, 101, 112, 113, 115, 116, 117], "isol": 33, "strategi": 33, "save_as_tf_module_multi_gpu": 33, "loading_path": 33, "saving_path": 33, "load_keras_model_multi_gpu": 33, "funetun": 33, "instanc": [33, 61, 80, 81, 87, 114], "moblinetv1": 33, "convert_tf_session_to_keras_model": 33, "mirroredstrategi": 33, "get_sess_from_keras_model": 33, "mobilnetv1": 33, "compress_sess": 33, "mobilenet": 33, "act_softmax": 33, "saved_model_single_gpu": 33, "correspnd": 33, "set_learning_phas": 33, "saved_model_multi_gpu": 33, "scope": [33, 80], "vgg16": [33, 61], "modulecompratiopair": [33, 38, 61, 76], "compressible_op": 33, "layer_a": 33, "list_of_module_comp_ratio_pair": [33, 38, 61, 76], "manual_param": [33, 61, 76], "manualmodeparam": [33, 38, 61, 76], "pylint": 33, "unus": 33, "to_categor": [33, 46], "rmsprop": 33, "mse": [33, 44, 52, 66, 85, 107, 111], "qualcomm": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "innov": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "center": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "inc": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "ai": [33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "toolkit": [33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "quantsim_config": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "default_config": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "softwar": [34, 101, 103], "dramat": 34, "lost": [34, 101], "At": [34, 98, 103], "onnx": [34, 55, 78, 79, 83, 87, 90, 91, 94, 95, 99, 101, 104, 105, 106, 107, 109, 111], "link": [34, 90, 94, 95, 96, 99, 106, 107, 111], "debug": [34, 35, 36, 40, 47, 51, 55, 56, 57, 61, 63, 70, 78, 110], "codebas": 34, "sphinx": 34, "page": [34, 91, 92, 98, 111, 112], "model": [35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117], "default_reg_param": [36, 57, 71], "default_beta_rang": [36, 57, 71], "default_warm_start": [36, 57, 71], "datasetv2": [36, 37, 57, 60, 61], "beta": [36, 57, 71, 94], "anneal": [36, 57, 71], "start_beta": [36, 57, 71], "end_beta": [36, 57, 71], "warm": [36, 57, 71, 94], "period": [36, 57, 71, 94], "zero": [36, 57, 60, 71, 83, 111, 112], "post_training_percentil": [36, 57, 71, 87], "percentil": [36, 57, 71, 87], "absolut": [36, 57, 61, 71, 76, 87], "nois": [36, 57, 67, 71, 86, 87, 105, 106, 107, 108, 109], "aimetlogg": [36, 57], "test_model": [36, 57], "keras_model": [36, 57], "dummy_forward_pass": [36, 57], "intend": [36, 44, 52, 55, 57, 61, 66, 76, 85, 98], "Or": [36, 44, 46, 52, 57, 66, 68, 78, 80, 85, 87, 103], "someth": [36, 44, 46, 52, 57, 66, 68, 85, 87, 103, 114], "apply_adaround_exampl": [36, 48, 57], "set_level_for_all_area": [36, 57], "dataset_s": [36, 57, 66], "possible_batch": [36, 57], "w4a8": [36, 57], "param_bw": [36, 57, 71, 73, 83], "output_bw": [36, 57, 71, 73, 83], "adarounded_model": [36, 71], "adarounded_sess": [36, 57], "grid": [36, 57, 71], "handl": [37, 59, 73, 74], "undo": [37, 59, 74], "upon": [37, 59, 74], "batch_norm": [37, 43, 59, 65, 74, 84], "qcquantizewrapp": [37, 74], "pair": [37, 38, 43, 61, 65, 74, 75, 76, 84], "got": [37, 65, 74, 80, 84], "prepar": [37, 41, 44, 45, 49, 52, 58, 66, 71, 73, 79, 83, 85, 86, 87, 95, 105, 112], "overal": [38, 61, 71, 76, 87, 98, 103, 110], "algorithm": [38, 55, 60, 61, 76, 98, 100, 103, 110, 117], "pick": [38, 42, 43, 60, 61, 65, 76, 98, 100, 103], "tweak": [38, 43, 61, 65, 76, 84], "compressor": [38, 61, 76], "static": [38, 42, 61, 65, 76, 80, 111], "visualization_url": [38, 61, 76, 88], "callabl": [38, 58, 61, 68, 71, 73, 74, 76, 80, 85], "cost": [38, 61, 76, 100, 103, 108], "url": [38, 61, 76, 88, 91, 92, 99, 114], "appear": [38, 43, 61, 65, 72, 76, 80, 81, 84], "compressionstat": [38, 61, 76], "use_monotonic_fit": [38, 61, 76], "saved_eval_scores_dict": [38, 61, 76, 88], "express": [38, 61, 76], "comp": [38, 61, 76], "greater": [38, 43, 61, 65, 76, 84], "monoton": [38, 61, 76, 100], "pickl": [38, 61, 76], "experi": [38, 61, 76, 103], "union": [38, 40, 42, 43, 46, 61, 62, 63, 65, 68, 71, 72, 73, 75, 76, 77, 78, 84, 85, 87], "rank": [38, 61, 76, 113, 116], "noth": [38, 61, 76], "space": [38, 61, 76], "weight_svd": [38, 61, 76], "comp_ratio": [38, 61, 76], "decode_predict": 38, "aimet_common_def": 38, "aimet_tensorflow_def": 38, "get_eval_func": 38, "50000": 38, "func_wrapp": 38, "validation_d": 38, "inp_data": 38, "img": 38, "pred": [38, 49], "cnt": 38, "b": [38, 59, 74, 83], "aimet_spatial_svd": 38, "evalfunct": 38, "driver": [38, 90, 92], "stat": [38, 61, 74, 76], "three": [39, 62, 80, 95, 98, 115], "comprehens": [39, 62], "detect": [39, 62, 103], "shall": [39, 55, 62], "rtype": [39, 42, 43], "cross_layer_equalization_auto": [39, 62, 77], "individu": [39, 43, 62, 65, 77, 85, 96, 97, 98, 100, 103, 105, 107, 110], "intermedi": [40, 51, 63, 72, 78, 87, 111], "accord": [40, 51, 63, 78, 105, 108, 109, 111], "comparison": [40, 51, 63, 78], "amongst": [40, 51, 63, 78], "miss": [40, 42, 51, 55, 63, 78, 81], "issu": [40, 42, 51, 63, 72, 78, 81, 96, 101, 104, 110, 112, 114, 115], "layer_output_util": [40, 51, 63, 78], "layeroutpututil": [40, 51, 63, 78], "save_dir": 40, "keraslayeroutput": 40, "implement": [40, 44, 46, 49, 52, 58, 63, 66, 73, 78, 85, 87, 104, 110], "constructor": [40, 43, 60, 61, 63, 75, 78, 79, 80, 84, 87], "generate_layer_output": [40, 51, 63, 78], "input_batch": [40, 51, 63, 78], "disk": [40, 63, 78], "obtain": [40, 43, 51, 52, 55, 60, 63, 65, 78, 84, 92, 97, 98, 107, 111], "aimet_export_artifact": [40, 51, 63, 78], "sake": [40, 51, 63, 78], "simplic": [40, 51, 63, 78], "mandatori": [40, 51, 63, 78], "load_encodings_to_sim": [40, 51, 63, 78], "construct": [40, 51, 61, 63, 72, 78, 104], "properli": [40, 51, 63, 78], "get_pre_processed_input": [40, 51, 63, 78], "fp32_layer_output_util": [40, 51, 63, 78], "fp32_layer_output": [40, 51, 63, 78], "quantsim_layer_output_util": [40, 51, 63, 78], "quantsim_layer_output": [40, 51, 63, 78], "sever": [41, 45, 64, 79, 81, 86, 98], "encourag": [41, 42, 45, 79, 80, 86], "format": [41, 43, 46, 57, 60, 61, 65, 68, 71, 83, 85, 87, 90, 95, 102], "get_model": 41, "mix": [41, 60], "reus": [41, 79, 80, 81], "had": [41, 79], "x2": [41, 79, 80], "relu2": [41, 42, 79, 81], "manditori": 42, "submodul": [42, 79], "inherit": 42, "pure": [42, 79], "inputlay": 42, "portion": 42, "get_text_classificaiton_model": 42, "model_preparer_two_subclassed_lay": 42, "get_subclass_model_with_functional_lay": 42, "sigmoid": [42, 80], "binary_classifi": 42, "myfunctionalmodel": 42, "my_functional_model": 42, "classifi": 42, "model_preparer_subclassed_model_with_functional_lay": 42, "resembl": 42, "piec": [42, 80], "python": [42, 61, 68, 87, 90, 91, 92], "caus": [42, 104, 110, 111], "trace": [42, 79], "symbol": 42, "touch": 42, "static_patch_count": 42, "guarante": 42, "verifi": [42, 80], "furthermor": 42, "resu": 42, "resblock": 42, "twice": 42, "bad": 42, "bn1": [42, 72, 81, 84], "bn2": 42, "relu1": [42, 79, 81], "plug": [43, 65, 84], "conv2dtranspos": 43, "depthwiseconv2d": [43, 102], "crosslayersc": [43, 60, 65, 84], "scale_model": [43, 65, 84], "clssetinfo": [43, 65], "highbiasfold": [43, 60, 65, 84], "bias_fold": [43, 65, 84], "cls_set_info_list": [43, 65, 84], "bn_layer": [43, 84], "sigma": [43, 65, 84], "element": [43, 55, 65, 84], "model_transform_util": 43, "replace_relu6_with_relu": 43, "cross_layer_equalization_auto_stepwis": [43, 65], "relu6": [43, 62, 65, 75, 84, 106], "model_for_cl": 43, "folded_pair": [43, 65, 84], "bn_dict": [43, 84], "conv_or_linear": 43, "group": [43, 65, 91, 109, 111], "fold_given_batch_norm": [43, 60, 65, 84], "layer_pair": [43, 65, 84], "conv_linear": 43, "is_batch_norm_second": 43, "scale_cls_set": [43, 65, 84], "cls_set": [43, 65, 84], "cls_pair_1": [43, 65, 84], "cls_pair_2": [43, 65, 84], "hold": [43, 65, 75, 84, 109], "along": [43, 60, 65, 84, 108, 111], "depth": [43, 84, 98, 110], "wise": [43, 76, 84, 85, 110], "clssetlayerpairinfo": [43, 65, 84], "scale_factor": [43, 65, 84], "relu_activation_between_lay": [43, 65, 84], "relat": [43, 60, 61, 62, 65, 75, 76, 84, 107, 111], "whose": [43, 63, 78, 80, 84, 106, 109, 117], "cross_layer_equalization_manu": [43, 65, 84], "get_example_layer_pairs_resnet50_for_fold": 43, "consecutive_layer_list": [43, 65, 84], "get_consecutive_layer_list_from_resnet50_for_sc": [43, 65], "scaling_factor_list": [43, 65, 84], "format_info_for_high_bias_fold": [43, 65], "conv_op_1": [43, 65], "bn_op_1": [43, 65], "conv_op_2": [43, 65], "bn_op_2": [43, 65], "conv_op_3": [43, 65], "bn_op_3": [43, 65], "11": [43, 55, 90, 92], "bn_op": [43, 65], "upstream": [43, 65, 97, 117], "downstream": [43, 55, 65], "usag": [43, 55, 64, 65, 81, 87, 98, 99, 103, 110], "conv_op": [43, 65, 69], "bn_op_with_meta": [43, 65], "_fold_upstream_flag": [43, 65], "boolean": [43, 65], "is_relu_activation_in_cls_set": [43, 65], "fill": [43, 65, 87], "create_cls_set_info_list": [43, 65], "quantanalyz": [44, 52, 53, 66, 67, 85, 105, 112], "pdf": [44, 66, 85, 112], "scalar": [44, 52, 58, 66, 85], "hotspot": [44, 66, 85, 107], "31": [44, 57, 58, 61, 71, 72, 75, 85, 87, 90, 91, 92], "toi": 44, "256": [44, 52, 66, 85, 107], "num_class": [44, 46, 58, 73], "ey": 44, "label_dataset": [44, 58], "own": [44, 49, 52, 54, 58, 59, 66, 68, 71, 73, 74, 75, 85, 87], "goal": [44, 49, 52, 58, 73, 85, 95], "action": [44, 52, 54, 59, 66, 68, 71, 74, 75, 85, 87, 117], "prepared_model": [44, 71, 80, 85, 87], "forward_pass_callback_fn": [44, 52, 66, 85], "eval_callback_fn": [44, 52, 66, 85], "approxim": [44, 52, 66, 85, 94, 98, 106, 107], "quant_analyzer_result": [44, 52, 66, 85], "abil": [45, 53, 67, 86, 112], "hardwar": [45, 53, 67, 86, 89, 105, 106, 111], "in_plac": [46, 87], "default_data_typ": [46, 68, 87], "quantizationdatatyp": [46, 68, 87], "mechan": [46, 80, 87], "custom_object": 46, "store": [46, 57, 60, 65, 68, 71, 83, 87], "pth": [46, 68, 76, 78, 83, 87], "prefix": [46, 57, 61, 68, 71, 83, 87], "quantize_model": [46, 54, 68], "dummy_x": 46, "dummy_i": 46, "randint": [46, 58], "lr": 46, "001": 46, "write": [48, 54, 68, 71, 87], "ada_rounded_model": 48, "math": 49, "auto_quant_v2": [49, 73], "onnx_model": [49, 50, 52, 54], "dummy_data": [49, 52, 54], "astyp": [49, 52, 54], "float32": [49, 52, 54], "Its": 49, "fed": 49, "unlabelled_data_load": 49, "ceil": [49, 71], "num_of_sampl": 49, "evaldataload": 49, "acc_top1": 49, "acc_top5": 49, "batch_avg_top_1_5": 49, "4f": [49, 73], "happen": [50, 77], "dummy_input_dict": 51, "serializetostr": 51, "dir_path": [51, 63, 78], "interest": [52, 85], "create_quantsim_and_encod": 52, "unlabeled_data_load": [52, 73, 85], "_get_unlabled_data_load": [52, 85], "unlabeled_dataset_iter": [52, 73, 85], "autoqu": [53, 67, 86, 99, 105, 108, 112], "unifi": [53, 67, 86], "integr": [53, 58, 67, 73, 82, 86, 105], "max_batch_count": [54, 68, 71, 87], "current_batch_count": [54, 68, 71, 87], "use_symmetric_encod": 54, "forward_pass_funct": 54, "syntax": 55, "usabl": 55, "xx": 55, "yy": 55, "zz": 55, "major": [55, 103], "revis": 55, "minor": [55, 112], "patch": 55, "substanti": 55, "fulli": [55, 61, 102], "bug": [55, 112], "backward": [55, 84], "assum": [55, 73, 91, 92], "string": [55, 109], "activation_encod": 55, "tensor_nam": 55, "param_encod": 55, "constraint": 55, "depict": 55, "6086959838867188": 55, "109158515930176": 55, "114": 55, "018501389771699905": 55, "21": 55, "558866932988167": 55, "12636379897594452": 55, "12": [55, 90], "010530316270887852": 55, "06318144500255585": 55, "06268782913684845": 55, "127": 55, "0004936049808748066": 55, "fc1": [55, 80], "05589814856648445": 55, "05546144023537636": 55, "0004367042565718293": 55, "184721499681473": 55, "10788747668266296": 55, "0089906234367221": 55, "conv2d_1": [55, 61], "1020304188132286": 55, "10380396991968155": 55, "008650330936207491": 55, "readvariableop": [55, 68], "1462666392326355": 55, "1451239287853241": 55, "126": 55, "0011427081098743512": 55, "08333279937505722": 55, "08268175274133682": 55, "0006510374592799766": 55, "includ": [55, 58, 73, 87, 90, 96, 103, 105, 107, 109, 111, 112], "field": 55, "dtype": [55, 80, 83], "datatyp": 55, "snippet": [55, 80], "highlight": [55, 106, 114, 115], "quantizer_arg": 55, "activation_bitwidth": 55, "param_bitwidth": 55, "popul": [55, 60], "broken": 55, "occur": [55, 61, 68], "who": 55, "knowledg": 55, "default_config_fil": [57, 58, 71], "conv2d_input": 57, "reset_default_graph": [57, 63, 68], "init": [57, 61, 83], "get_default_graph": 57, "default_rounding_mod": 58, "manner": [58, 73, 95], "meet": [58, 73, 90, 95, 98, 100], "datasetv1": [58, 59, 66], "unless": [58, 75, 92, 117], "n": [58, 85, 112], "andoutput": 58, "fp32_sess": 58, "cache_id": [58, 73], "explicitli": [58, 117], "preced": [59, 74, 109], "var": [59, 74, 92], "load_fp32_model": [59, 74], "imagenetpipelin": [59, 74], "quant_sim": [59, 74, 87], "main": [60, 96, 109, 112, 115], "reference_model": 60, "conv_bn_dict": [60, 75], "perform_only_empirical_bias_corr": [60, 75], "convbninfotyp": 60, "find_all_convs_bn_with_activ": 60, "nest": 60, "graphsearchutil": [60, 65], "biasutil": [60, 65], "bias_correction_empir": 60, "biascorrectparam": 60, "fc1000": [60, 62, 65], "_new_sess": 60, "analyt": [60, 106, 114, 115], "bias_correction_empirical_analyt": 60, "bias_correction_after_cl": 60, "sess_after_cl": 60, "bias_correction_per_lay": 60, "corrected_model": 60, "layer_name_to_be_correct": 60, "analytical_bias_correction_per_lay": 60, "preceeding_bn_layer_info": 60, "is_first_conv": 60, "bc": [60, 94], "preceed": [60, 96], "bias_correction_single_layer_empir": 60, "initialize_model_with_bia": 60, "example_conv_lay": 60, "res2a_branch2a": [60, 65], "bias_correction_single_layer_analyt": 60, "convs_bn_activation_info_dict": 60, "sure": [60, 100, 104], "preceding_bn_layer_info": 60, "tar": 61, "train_model": [61, 76], "train_flag": [61, 76], "channels_last": 61, "downsamplelay": 61, "upsamplelay": 61, "teh": [61, 117], "evaluate_model": [61, 76], "honor": [61, 76], "obvious": [61, 76], "spatial_svd_auto_mod": [61, 76], "block1_conv1": 61, "compr_model_sess": 61, "pretti": [61, 76], "spatial_svd_manual_mod": [61, 76], "block1_conv2": 61, "channel_pruning_auto_mod": [61, 76], "channel_pruning_manual_mod": [61, 76], "block1_conv2_op": 61, "block2_conv2_op": 61, "block2_conv2": 61, "checkpoint": [61, 68, 87, 105], "output_fil": 61, "svd_graph": 61, "svd_type": 61, "num_lay": 61, "layer_rank": 61, "num_rank": 61, "no_evalu": 61, "layer_selection_threshold": 61, "connect": [61, 97, 102, 116], "balanc": [61, 103], "multipli": [61, 98], "accumul": [61, 98], "footprint": 61, "ssvd": [61, 98], "length": 61, "compression_point": 61, "valueerror": [61, 68], "compress_net": 61, "eval_nam": 61, "run_graph": 61, "evaluate_graph": [61, 68], "default_eval_func": [61, 68], "error_margin": 61, "avg": 61, "graph_ev": [61, 68], "prototyp": 61, "accept": [61, 106, 110], "degrad": [61, 103], "invalid": [61, 80], "runtimeerror": 61, "tfrecord_gener": 61, "tf_gen": [61, 68], "mnistpars": [61, 68], "weight_svd_auto_mod": [61, 76], "alloc": [61, 68], "wish": [61, 68, 91, 92], "tfrecordgener": [61, 68], "mnist": [61, 68, 76], "parser": [61, 68], "mnist_sav": [61, 68], "95": 61, "pretty_print": 61, "weight_svd_manual_mod": [61, 76], "matmul_1": 61, "connectedgraph": [62, 65, 81], "hbf": [62, 65, 94], "new_sess": 62, "wherein": [63, 78], "saver": 63, "import_meta_graph": 63, "restor": [63, 87, 110], "trainbl": 64, "recompil": 64, "temp": 64, "clean": 64, "recurr": [64, 112], "rnn": [64, 112], "lstm": [64, 112], "graph_util": 65, "after_relu_replace_sess": 65, "find_and_replace_relu6_with_relu": 65, "after_bn_fold_sess": 65, "after_cls_sess": 65, "after_hbf_sess": 65, "updated_sess": 65, "map_cls_sets_to_new_sess": 65, "tf_names_op_dict": 65, "get_layer_pairs_resnet50_for_fold": 65, "after_fold_sess": 65, "graph_search": 65, "bn2a_branch2a": 65, "cond": 65, "fusedbatchnorm_1": 65, "res2a_branch2b": 65, "bn2a_branch2b": 65, "res2a_branch2c": 65, "bn2a_branch2c": 65, "conv1_op": 65, "conv1_depthwise_op": 65, "conv1_pointwise_op": 65, "temp_cl": 65, "model_start_op_nam": 66, "model_output_op_nam": 66, "learnt": 68, "orig_sess": 68, "quantisim": 68, "tutori": 68, "load_model_from_meta": 68, "reshape_input": 68, "dense_1": 68, "biasadd": 68, "trainingextens": [68, 87], "src": [68, 87], "quantization_aware_training_range_learn": 68, "parser2": 68, "generator2": 68, "cross_entropi": 68, "xent": 68, "train_step": 68, "simultan": 68, "fc1_w": 68, "matmul": [68, 112], "perf": 68, "ce": 68, "adamoptim": 68, "tempadam": 68, "initialize_uninitialized_var": 68, "read_data_set": 68, "one_hot": 68, "next_batch": 68, "plotting_util": 69, "visualize_weight_ranges_single_lay": 69, "scatter": [69, 89], "bokeh": [69, 88, 89], "visualize_relative_weight_ranges_single_lay": 69, "publish": [69, 88, 89], "visualizing_weight_ranges_for_single_lay": 69, "visualiza": 69, "visualizing_relative_weight_ranges_for_single_lay": 69, "param_bw_override_list": 71, "ignore_quant_ops_list": 71, "pars": [71, 84, 87], "affect": [71, 96, 109, 117], "commonli": 71, "10k": 71, "15k": 71, "get_train_dataload": [71, 74], "quantized_resnet18": [71, 87], "experiment": [72, 103, 109], "arch_check": 72, "archcheck": 72, "check_model_arch": 72, "result_dir": 72, "_node_check_dict": 72, "record": [72, 85], "fail": [72, 80, 81, 95, 104, 105], "arch_checker_report": 72, "dotted_name_op": 72, "nodeerrorreportobject": 72, "archcheckerreport": 72, "condit": [72, 80, 81], "less": [72, 97, 100], "modelwithnotenoughchannel": 72, "prelu": 72, "stride": [72, 80, 81], "batchnorm2d": [72, 81, 84], "example_check_for_number_of_conv_channel": 72, "fewer": 72, "logger": [72, 81], "_check_conv_channel_32_bas": 72, "_check_conv_channel_larger_than_32": 72, "layer_nam": [72, 85], "modelwithprelu": 72, "prelu1": 72, "example_check_for_non_performant_activ": 72, "num_paramet": 72, "_activation_check": 72, "modelwithnonfoldablebn": 72, "foldabl": 72, "avg_pool1": 72, "avgpool2d": 72, "example_check_for_standalone_bn": 72, "averagepool": 72, "ep": 72, "05": [72, 92], "momentum": 72, "affin": [72, 83], "track_running_stat": 72, "_check_batch_norm_fold": 72, "strict_valid": 73, "model_prepare_requir": 73, "id": [73, 88, 91, 114], "cach": [73, 92], "hen": 73, "proce": 73, "unid": 73, "unintuit": 73, "_subset_sampl": 73, "sampler": 73, "fp32_model": 73, "fakedata": 73, "eval_data_load": 73, "dim": 73, "deprec": [73, 105], "dummy_input_on_cpu": 73, "dummy_input_on_gpu": 73, "layers_to_ignor": 75, "remain": [75, 100, 105, 106, 111], "calc": 75, "corr": 75, "irrespect": 75, "fact": 75, "elig": 75, "input_bn": 75, "output_bn": 75, "in_activation_typ": 75, "no_activ": 75, "out_activation_typ": 75, "hode": 75, "mobilenetv2": [75, 84], "512": 75, "module_prop_dict": 75, "find_all_conv_bn_with_activ": 75, "weightsvdparamet": 76, "tarrankselectionparamet": 76, "num_rank_indic": 76, "rank_select_schem": 76, "select_param": 76, "rankselectschem": 76, "mnist_trained_on_gpu": 76, "rank_select": 76, "mnist_torch_model": 76, "dataloadermnist": 76, "_layer_db": 76, "ture": 76, "batch_callback": 76, "spatial_svd_auto_mode_with_layerwise_finetun": 76, "torchscript": [78, 87], "naming_schem": 78, "namingschem": 78, "onnx_export_arg": [78, 87], "onnxexportapiarg": [78, 87], "consist": [78, 95, 111, 117], "numer": 78, "onnx_util": 78, "pythonpath": [78, 99], "successfulli": [78, 104], "map_loc": 78, "model_torch": 78, "convers": [79, 110], "onnx_file_nam": 79, "jit": 79, "traceabl": [79, 80], "stateless": 79, "former": 79, "retrain": 79, "whenev": 79, "image_rgb": 79, "rgb_output": 79, "image_bw": 79, "bw_output": 79, "rgb": 79, "bw": [79, 83, 87], "elementwis": [80, 112], "unrol": 80, "independ": [80, 110], "modules_to_exclud": 80, "module_classes_to_exclud": 80, "concrete_arg": 80, "duplic": 80, "exclud": [80, 81, 85], "partial": 80, "special": 80, "control": [80, 111], "flow": [80, 82, 96, 105, 108, 110, 111], "won": 80, "symbolic_trac": 80, "graphmodul": 80, "modelwithfunctionalrelu": 80, "9216": 80, "fc2": 80, "model_preparer_functional_exampl": 80, "allclos": 80, "modelwithreusedrelu": 80, "model_preparer_reused_exampl": 80, "modelwithelementwiseaddop": 80, "x1": 80, "model_preparer_elementwise_add_exampl": 80, "dynam": [80, 106, 111, 112, 115], "statement": [80, 104], "branch": [80, 99, 109], "weren": 80, "traceerror": 80, "workaround": [80, 104], "problem": [80, 110], "across": [80, 106, 107], "Such": 80, "concret": 80, "truli": 80, "custom_function_not_to_be_trac": 80, "call_funct": 80, "__torch_function__": 80, "sqrt": 80, "modelwithnontorchfunct": 80, "model_transform": 80, "tracer": 80, "is_leaf_modul": 80, "leaf": [80, 112], "expos": [80, 94], "module_to_exclud": 80, "examin": 80, "custommodul": 80, "softplu": 80, "custommodel": 80, "arang": 80, "traceback": 80, "typeerror": 80, "receiv": 80, "proxi": 80, "layout": 80, "pin_memori": 80, "requires_grad": 80, "problemat": [80, 110, 115], "determinist": 80, "hard": 80, "do_not_trace_m": 80, "share": [81, 92], "modelwithreusednod": 81, "inplac": 81, "2592": 81, "view": [81, 94, 95, 96, 101, 104, 106, 107, 111, 114], "model_valid": 81, "modelvalid": 81, "validate_example_model": 81, "validate_model": 81, "validate_for_reused_modul": 81, "0x7f127685a598": 81, "resolv": 81, "warn": [81, 105], "redefin": 81, "distinct": 81, "rewrit": [81, 104], "modelwithoutreusednod": 81, "rerun": 81, "0x7ff577373598": 81, "validate_for_missing_modul": 81, "0x7ff5703eff28": 81, "modelwithfunctionallinear": 81, "0x7f9dd9bd90d0": 81, "matmul_8": 81, "reason": 81, "op_type_map": 81, "recogn": [81, 109, 111], "functional_op": 81, "modelwithoutfunctionallinear": 81, "parallel": 82, "dataparallel": [82, 86], "doesn": 82, "forth": 82, "peft": 83, "adaptermetadata": 83, "lora": 83, "lora_a": 83, "alpha": 83, "lora_b": 83, "replace_lora_layers_with_quantizable_lay": 83, "save_lora_weights_after_adapt": 83, "track_lora_meta_data": 83, "replaced_module_typ": 83, "peftquantutil": 83, "adapater_name_to_meta_data": 83, "name_to_module_dict": 83, "track_meta_data": 83, "pt": 83, "disable_lora_adapt": 83, "enable_adapter_and_load_weight": 83, "adapter_weights_path": 83, "use_safetensor": 83, "bin": [83, 91, 92], "safetensor": 83, "export_adapter_weight": 83, "onnx_model_path": 83, "freeze_base_model": 83, "freeze_base_model_activation_quant": 83, "freeze_base_model_param_quant": 83, "get_quantized_lora_lay": 83, "vice": [83, 111], "versa": [83, 111], "set_bitwidth_for_lora_adapt": 83, "loraconfig": 83, "get_peft_model": 83, "lora_config": 83, "lora_alpha": 83, "lora_dropout": 83, "target_modul": 83, "tmp_dir": 83, "lora_weights_after_adaptation_for_adapter1": 83, "meta_data": 83, "convinplacelinear": 83, "peft_util": 83, "tmpdir": 83, "export_model": [83, 87], "filename_prefix_encod": [83, 87], "base_encod": 83, "lora_modul": 83, "param_quant": 83, "quantizedequant": 83, "base_model": 83, "adapter1": 83, "adapter1_weight": 83, "conv1d": [84, 112], "convtranspose2d": 84, "batchnorm1d": 84, "cross_layer_equalization_auto_step_by_step": 84, "conv_bn": 84, "replace_modules_of_type1_with_type2": 84, "layer_list": 84, "clspairinfo": 84, "depthwis": [84, 96, 112], "cross_layer_equalization_depthwise_lay": 84, "encapsul": 85, "check_model_sensitivity_to_quant": 85, "perform_per_layer_analysis_by_enabling_quant_wrapp": 85, "occurr": [85, 97], "perform_per_layer_analysis_by_disabling_quant_wrapp": 85, "export_per_layer_encoding_min_max_rang": 85, "esults_dir": 85, "pcq": [85, 96, 107], "wrapped_module_nam": 85, "param_nam": 85, "export_per_layer_stats_histogram": 85, "ctivations_pdf": 85, "eights_pdf": 85, "am": 85, "channel_index": 85, "export_per_layer_mse_loss": 85, "tap": 85, "checker": 86, "concern": 86, "save_checkpoint": 87, "file_path": 87, "load_checkpoint": 87, "quant_sim_model": 87, "propagate_encod": 87, "export_to_torchscript": 87, "use_embedded_encod": 87, "opset_vers": 87, "enable_onnx_check": 87, "entri": [87, 109], "data_typ": 87, "fakequ": 87, "forward_pass_arg": 87, "quatiz": 87, "unction": 87, "visualize_serialized_data": 88, "visualizecompress": [88, 114], "server": [88, 99], "tabl": [88, 99, 100, 104, 114], "display_eval_scor": [88, 114], "saved_eval_scores_dict_path": 88, "display_comp_ratio_plot": [88, 114], "comp_ratio_list_path": 88, "pkl": 88, "start_bokeh_server_sess": 88, "model_compression_with_visu": 88, "65": [88, 92, 98], "resnet18_eval_scor": 88, "comp_ratios_file_path": 88, "greedy_selection_comp_ratios_list": 88, "eval_scores_path": 88, "compression_visu": 88, "termin": [88, 99], "visualize_model": 89, "visualize_relative_weight_ranges_to_identify_problematic_lay": 89, "selected_lay": 89, "figur": [89, 94, 100, 110, 117], "visualize_weight_rang": 89, "deviat": 89, "visualize_changes_after_optim": 89, "old_model": 89, "new_model": 89, "visualize_changes_in_model_after_and_before_cl": 89, "visualiz": 89, "model_copi": 89, "visualize_weight_ranges_model": 89, "usual": [89, 108], "visualize_relative_weight_ranges_model": 89, "pypi": 90, "intel": 90, "x86": 90, "processor": 90, "linux": [90, 92], "ubuntu": [90, 92], "22": [90, 92], "04": [90, 92], "lt": [90, 92], "pip": [90, 91, 92, 99], "apt": [90, 91, 92], "liblapack": [90, 91, 92], "python3": [90, 91, 92, 99], "variant": [90, 92, 94, 95, 96, 106, 107, 108, 111], "latest": [90, 91], "whl": [90, 91, 92], "host": [90, 91, 92, 112, 114], "github": [90, 91, 92, 98, 99, 112], "com": [90, 91, 92, 99, 112], "quic": [90, 91, 92, 98, 99, 112], "13": [90, 91], "torch_gpu_": 90, "cp38": [90, 92], "linux_x86_64": [90, 91, 92], "torch_cpu_": 90, "tf_gpu_": 90, "tf_cpu_": 90, "14": 90, "onnx_gpu_": 90, "onnx_cpu_": 90, "brows": 90, "torch_gpu": [90, 91, 92], "torch_cpu": [90, 91, 92], "tf_gpu": [90, 91, 92], "tf_cpu": [90, 91, 92], "onnx_gpu": [90, 91, 92], "onnx_cpu": [90, 91, 92], "package_prefix": 90, "platform": [90, 105], "setup": 90, "bash": [90, 91], "command": [90, 91, 92, 99, 114], "shell": 90, "nvidia": [90, 91, 92], "card": 90, "capabl": [90, 114, 115], "docker": 90, "455": 90, "newer": 90, "cudnn": 90, "machin": [90, 91, 103], "develop": [90, 91, 92], "click": 90, "instruct": [91, 92, 99], "variant_str": [91, 92], "ONE": [91, 92], "pt113": 91, "aimet_vari": [91, 92], "workspac": [91, 99], "absolute_path_to_workspac": [91, 99], "docker_image_nam": 91, "codelinaro": 91, "dev": [91, 92], "docker_container_nam": 91, "any_nam": 91, "any_tag": 91, "jenkin": 91, "dockerfil": 91, "p": 91, "grep": 91, "kill": 91, "rm": 91, "passwd": 91, "ro": 91, "home": 91, "mnt": 91, "entrypoint": 91, "hostnam": 91, "filesystem": 91, "port": [91, 114], "port_id": 91, "project": [91, 92], "sudo": [91, 92, 99], "tag": [91, 92, 99, 112], "release_tag": [91, 92, 99], "download_url": [91, 92], "suffix": [91, 92], "wheel_file_suffix": [91, 92], "cp310": [91, 92], "pend": [91, 92, 99], "pip3": [91, 92], "h": [91, 92, 99, 116, 117], "usr": [91, 92], "lib": [91, 92], "dist": [91, 92], "torch_stabl": [91, 92], "OR": [91, 92], "envsetup": [91, 92], "sh": [91, 92], "local": [92, 114], "requisit": 92, "upgrad": 92, "wget": 92, "gnupg2": 92, "visit": [92, 101], "archiv": 92, "exact": [92, 96], "date": 92, "repo": [92, 99], "ubuntu2204": 92, "x86_64": 92, "pin": 92, "mv": 92, "prefer": [92, 103], "d": 92, "repositori": 92, "600": 92, "local_instal": 92, "local_11": 92, "520": 92, "61": 92, "1_amd64": 92, "deb": 92, "adv": 92, "fetch": 92, "3bf863cc": 92, "pub": 92, "dpkg": 92, "cp": [92, 98], "keyr": 92, "gpg": 92, "echo": 92, "515": 92, "torch_gpu_pt113": 92, "torch_cpu_pt113": 92, "cp36": 92, "cp36m": 92, "cp37": 92, "cp37m": 92, "py3": 92, "wheel": 92, "cat": 92, "reqs_deb_common": 92, "txt": 92, "xarg": 92, "reqs_deb_torch_common": 92, "reqs_deb_onnx_common": 92, "reqs_deb_tf_gpu": 92, "reqs_deb_torch_gpu": 92, "reqs_deb_onnx_gpu": 92, "uninstal": 92, "post1": 92, "onnxruntime_v": 92, "c": [92, 98], "__version__": 92, "ln": 92, "gnu": 92, "libjpeg": 92, "chose": 92, "bnf": 94, "coupl": 94, "moder": 94, "enter": 95, "preprat": 95, "mainli": 95, "decreas": 96, "oscil": 96, "presenc": 97, "residu": 97, "discuss": [98, 110, 111], "reduct": 98, "uncompress": 98, "latenc": 98, "vari": [98, 100, 106, 115], "io": [98, 112], "half": 98, "unknown": 98, "apriori": 98, "cssvd": 98, "75": 98, "2b": 98, "larg": [98, 108, 113, 116], "2a": 98, "revisit": 98, "ccp": 98, "csvd": 98, "becom": [99, 106], "familiar": 99, "browsabl": 99, "metapackag": 99, "ip": 99, "browser": 99, "past": 99, "mkdir": 99, "cd": 99, "packag": [99, 112], "git": 99, "www": 99, "navig": 99, "launch": 99, "ipynb": 99, "extens": 99, "therein": 99, "assess": 100, "highest": 100, "column": 100, "unmodifi": 100, "strict": [100, 109, 111], "curv": 100, "core": 100, "interpol": 100, "met": 100, "binari": 100, "solut": [100, 108, 110], "lesser": [100, 103], "fall": [100, 109], "drstical": 100, "edg": 101, "incur": [101, 107], "hw": 101, "redund": 101, "product": 101, "technologi": 101, "subsidiari": 101, "dilat": 102, "librari": 103, "guidebook": [103, 105], "advic": 103, "phase": [103, 105], "nomin": 103, "fc": 103, "term": [103, 113, 114, 115, 116], "notic": 103, "sharp": 103, "respons": 103, "carefulli": 103, "slow": 103, "searcher": 103, "strike": 103, "xiangyu": 103, "zhang": 103, "jianhua": 103, "zou": 103, "kaim": 103, "he": 103, "jian": 103, "sun": 103, "deep": 103, "ieee": [103, 106], "transact": 103, "pattern": 103, "intellig": 103, "vol": 103, "38": 103, "pp": 103, "1943": 103, "1955": 103, "oct": 103, "2016": 103, "yihui": 103, "confer": [103, 106], "vision": [103, 106], "venic": 103, "2017": 103, "1398": 103, "1406": 103, "jaderberg": 103, "andrea": 103, "vedaldi": 103, "andrew": 103, "zisserman": 103, "expans": 103, "british": 103, "jan": 103, "2014": 103, "andrei": 103, "kuzmin": 103, "marku": [103, 106], "nagel": [103, 106], "saurabh": 103, "pitr": 103, "sandeep": 103, "pendyam": 103, "tijmen": [103, 106], "blankevoort": [103, 106], "taxonomi": 103, "primit": 104, "slice": 104, "bilinear": 104, "upsampl": 104, "129": 104, "align_corn": 104, "deconvolut": 104, "deeplabv3": 104, "address": [104, 110, 114], "introduc": [105, 109, 111], "advantag": 105, "fast": 105, "easi": [105, 107], "gap": 105, "robust": 105, "longer": [105, 108], "account": [105, 108, 110], "advis": [105, 109], "prep": 105, "align": 105, "retri": 105, "hand": 105, "satisfactori": [105, 110], "bring": 105, "onto": 105, "pb": 105, "trial": 105, "particular": [105, 109], "seem": 105, "bat": 105, "surround": 106, "big": 106, "discrep": 106, "wide": 106, "significantli": 106, "quantizaion": 106, "bottleneck": [106, 110], "hybrid": 106, "approach": [106, 111], "mart": 106, "van": 106, "baalen": 106, "seoul": 106, "octob": 106, "rune": 107, "situat": 107, "pinpoint": 107, "culprit": 107, "toss": 107, "outlier": [107, 111], "monitor": 107, "contribut": [107, 110], "mitig": [108, 111], "come": [108, 111], "accompani": 108, "throughout": [108, 109, 115], "themselv": 108, "aid": 108, "converg": 108, "divid": 108, "six": 109, "overrul": 109, "turn": 109, "empti": 109, "omit": 109, "asymmetr": [109, 111], "asid": 109, "govern": 109, "unsign": [109, 111], "convent": 109, "member": 109, "whatev": 109, "earlier": 109, "diagnost": 110, "strictli": 110, "insight": [110, 114, 115], "underperform": 110, "tackl": 110, "underli": 110, "chart": 110, "saniti": 110, "behav": 110, "ofth": 110, "kept": 110, "toward": 110, "uneven": 110, "inner": 110, "bert": 110, "reveal": 110, "resort": 110, "revert": 110, "power": 110, "ultim": 111, "ingest": 111, "000": 111, "dequant": 111, "dequantiz": 111, "hook": 111, "intercept": 111, "q": 111, "clamp": 111, "equat": 111, "textrm": 111, "dfrac": 111, "quad": 111, "strong": 111, "excess": 111, "signal": 111, "sqnr": 111, "squar": 111, "qmin": 111, "qmax": 111, "satur": 111, "erro": 111, "alongsid": 111, "wherea": 111, "ones": 111, "sign": 111, "slim": 112, "backslash": 112, "user_guid": 112, "api_doc": 112, "quantizablemultiheadattent": 112, "kyuykim": 112, "mangal": 112, "geunle": 112, "correctli": 112, "klhsieh": 112, "akhobar": 112, "resid": 112, "ashvkuma": 112, "fp16": 112, "convtranspose1d": 112, "concat": 112, "stand": [112, 113, 116], "adaptiveround": 112, "gru": 112, "instal": 112, "\ud835\udc5a": [113, 116], "\ud835\udc5b": [113, 116], "\u210e": [113, 116], "\ud835\udc64": [113, 116], "\ud835\udc58": [113, 116], "larger": [113, 116], "degre": [113, 116], "assist": [114, 115], "progress": [114, 115], "computation": [114, 115], "heavi": [114, 115], "websocket": 114, "listen": 114, "5006": 114, "lot": 115, "lose": 117, "pictori": 117, "volum": 117, "hxwx8": 117, "hxwx5": 117, "propag": 117, "That": 117, "green": 117, "color": 117, "side": 117, "pink": 117, "orang": 117}, "objects": {"aimet_common.bias_correction": [[75, 0, 1, "", "ConvBnInfoType"]], "aimet_common.defs": [[75, 0, 1, "", "ActivationType"], [61, 0, 1, "", "CompressionScheme"], [61, 0, 1, "", "CostMetric"], [76, 0, 1, "", "GreedySelectionParameters"], [87, 0, 1, "", "QuantScheme"]], "aimet_common.defs.ActivationType": [[75, 1, 1, "", "no_activation"], [75, 1, 1, "", "relu"], [75, 1, 1, "", "relu6"]], "aimet_common.defs.CompressionScheme": [[61, 1, 1, "", "channel_pruning"], [61, 1, 1, "", "spatial_svd"], [61, 1, 1, "", "weight_svd"]], "aimet_common.defs.CostMetric": [[61, 1, 1, "", "mac"], [61, 1, 1, "", "memory"]], "aimet_common.defs.QuantScheme": [[87, 1, 1, "", "post_training_percentile"], [87, 1, 1, "", "post_training_tf"], [87, 1, 1, "", "post_training_tf_enhanced"], [87, 1, 1, "", "training_range_learning_with_tf_enhanced_init"], [87, 1, 1, "", "training_range_learning_with_tf_init"]], "aimet_common.utils": [[85, 0, 1, "", "CallbackFunc"]], "aimet_tensorflow.adaround.adaround_weight.Adaround": [[57, 2, 1, "", "apply_adaround"]], "aimet_tensorflow.adaround.adaround_weight": [[57, 0, 1, "", "AdaroundParameters"]], "aimet_tensorflow.auto_quant": [[58, 0, 1, "", "AutoQuant"]], "aimet_tensorflow.auto_quant.AutoQuant": [[58, 3, 1, "", "apply"], [58, 3, 1, "", "set_adaround_params"]], "aimet_tensorflow.batch_norm_fold": [[65, 2, 1, "", "fold_all_batch_norms"], [59, 2, 1, "", "fold_all_batch_norms_to_scale"], [65, 2, 1, "", "fold_given_batch_norms"]], "aimet_tensorflow.bias_correction.BiasCorrection": [[60, 2, 1, "", "analytical_bias_correction_per_layer"], [60, 2, 1, "", "bias_correction_per_layer"], [60, 2, 1, "", "correct_bias"]], "aimet_tensorflow.bias_correction": [[60, 2, 1, "", "BiasCorrectionParams"], [60, 0, 1, "", "QuantParams"]], "aimet_tensorflow.bn_reestimation": [[59, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.compress": [[61, 0, 1, "", "ModelCompressor"]], "aimet_tensorflow.compress.ModelCompressor": [[61, 3, 1, "", "compress_model"]], "aimet_tensorflow.cross_layer_equalization": [[65, 0, 1, "", "ClsSetInfo"], [62, 2, 1, "", "equalize_model"]], "aimet_tensorflow.cross_layer_equalization.ClsSetInfo": [[65, 0, 1, "", "ClsSetLayerPairInfo"], [65, 3, 1, "", "map_cls_sets_to_new_session"]], "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling": [[65, 2, 1, "", "scale_cls_sets"], [65, 2, 1, "", "scale_model"]], "aimet_tensorflow.cross_layer_equalization.HighBiasFold": [[65, 2, 1, "id0", "bias_fold"]], "aimet_tensorflow.defs": [[61, 0, 1, "", "ChannelPruningParameters"], [61, 0, 1, "", "ModuleCompRatioPair"], [61, 0, 1, "", "SpatialSvdParameters"]], "aimet_tensorflow.defs.ChannelPruningParameters": [[61, 0, 1, "", "AutoModeParams"], [61, 0, 1, "", "ManualModeParams"], [61, 0, 1, "", "Mode"]], "aimet_tensorflow.defs.ChannelPruningParameters.Mode": [[61, 1, 1, "", "auto"], [61, 1, 1, "", "manual"]], "aimet_tensorflow.defs.SpatialSvdParameters": [[61, 0, 1, "", "AutoModeParams"], [61, 0, 1, "", "ManualModeParams"], [61, 0, 1, "", "Mode"]], "aimet_tensorflow.defs.SpatialSvdParameters.Mode": [[61, 1, 1, "", "auto"], [61, 1, 1, "", "manual"]], "aimet_tensorflow.keras.batch_norm_fold": [[43, 2, 1, "", "fold_all_batch_norms"], [37, 2, 1, "", "fold_all_batch_norms_to_scale"], [43, 2, 1, "", "fold_given_batch_norms"]], "aimet_tensorflow.keras.bn_reestimation": [[37, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.keras.compress": [[38, 0, 1, "", "ModelCompressor"]], "aimet_tensorflow.keras.compress.ModelCompressor": [[38, 3, 1, "", "compress_model"]], "aimet_tensorflow.keras.cross_layer_equalization": [[43, 0, 1, "", "ClsSetInfo"], [39, 2, 1, "", "equalize_model"]], "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo": [[43, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling": [[43, 2, 1, "", "scale_cls_sets"], [43, 2, 1, "", "scale_model"]], "aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold": [[43, 2, 1, "id0", "bias_fold"]], "aimet_tensorflow.keras.layer_output_utils": [[40, 0, 1, "", "LayerOutputUtil"]], "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil": [[40, 3, 1, "", "generate_layer_outputs"]], "aimet_tensorflow.keras.model_preparer": [[42, 2, 1, "", "prepare_model"]], "aimet_tensorflow.keras.quant_analyzer": [[44, 0, 1, "", "QuantAnalyzer"]], "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer": [[44, 3, 1, "", "analyze"]], "aimet_tensorflow.keras.quantsim": [[46, 0, 1, "", "QuantizationSimModel"]], "aimet_tensorflow.keras.quantsim.QuantizationSimModel": [[46, 3, 1, "", "compute_encodings"], [46, 3, 1, "", "export"]], "aimet_tensorflow.layer_output_utils": [[63, 0, 1, "", "LayerOutputUtil"]], "aimet_tensorflow.layer_output_utils.LayerOutputUtil": [[63, 3, 1, "", "generate_layer_outputs"]], "aimet_tensorflow.plotting_utils": [[69, 2, 1, "", "visualize_relative_weight_ranges_single_layer"], [69, 2, 1, "", "visualize_weight_ranges_single_layer"]], "aimet_tensorflow.quant_analyzer": [[66, 0, 1, "", "QuantAnalyzer"]], "aimet_tensorflow.quant_analyzer.QuantAnalyzer": [[66, 3, 1, "", "analyze"]], "aimet_tensorflow.quantsim": [[68, 0, 1, "", "QuantizationSimModel"]], "aimet_tensorflow.quantsim.QuantizationSimModel": [[68, 3, 1, "", "compute_encodings"], [68, 3, 1, "", "export"]], "aimet_tensorflow.svd": [[61, 0, 1, "", "Svd"]], "aimet_tensorflow.svd.Svd": [[61, 3, 1, "", "compress_net"]], "aimet_tensorflow.utils.convert_tf_sess_to_keras": [[33, 2, 1, "", "load_keras_model_multi_gpu"], [33, 2, 1, "", "load_tf_sess_variables_to_keras_single_gpu"], [33, 2, 1, "", "save_as_tf_module_multi_gpu"], [33, 2, 1, "", "save_tf_session_single_gpu"]], "aimet_tensorflow.utils.graph": [[64, 2, 1, "", "update_keras_bn_ops_trainable_flag"]], "aimet_torch.adaround.adaround_weight.Adaround": [[71, 2, 1, "", "apply_adaround"]], "aimet_torch.adaround.adaround_weight": [[71, 0, 1, "", "AdaroundParameters"]], "aimet_torch.arch_checker.arch_checker.ArchChecker": [[72, 2, 1, "", "check_model_arch"]], "aimet_torch.auto_quant": [[73, 0, 1, "", "AutoQuant"]], "aimet_torch.batch_norm_fold": [[84, 2, 1, "", "fold_all_batch_norms"], [74, 2, 1, "", "fold_all_batch_norms_to_scale"], [84, 2, 1, "", "fold_given_batch_norms"]], "aimet_torch.bias_correction": [[75, 2, 1, "", "correct_bias"]], "aimet_torch.bn_reestimation": [[74, 2, 1, "", "reestimate_bn_stats"]], "aimet_torch.compress": [[76, 0, 1, "", "ModelCompressor"]], "aimet_torch.compress.ModelCompressor": [[76, 3, 1, "", "compress_model"]], "aimet_torch.cross_layer_equalization": [[84, 0, 1, "", "ClsSetInfo"], [77, 2, 1, "", "equalize_model"]], "aimet_torch.cross_layer_equalization.ClsSetInfo": [[84, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_torch.cross_layer_equalization.CrossLayerScaling": [[84, 2, 1, "", "scale_cls_sets"], [84, 2, 1, "", "scale_model"]], "aimet_torch.cross_layer_equalization.HighBiasFold": [[84, 2, 1, "id0", "bias_fold"]], "aimet_torch.defs": [[76, 0, 1, "", "ChannelPruningParameters"], [76, 0, 1, "", "ModuleCompRatioPair"], [76, 0, 1, "", "SpatialSvdParameters"], [76, 0, 1, "", "TarRankSelectionParameters"], [76, 0, 1, "", "WeightSvdParameters"]], "aimet_torch.defs.ChannelPruningParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.ChannelPruningParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.defs.SpatialSvdParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.SpatialSvdParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.defs.WeightSvdParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.WeightSvdParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.layer_output_utils": [[78, 0, 1, "", "LayerOutputUtil"], [78, 0, 1, "", "NamingScheme"]], "aimet_torch.layer_output_utils.LayerOutputUtil": [[78, 3, 1, "", "generate_layer_outputs"]], "aimet_torch.layer_output_utils.NamingScheme": [[78, 1, 1, "", "ONNX"], [78, 1, 1, "", "PYTORCH"], [78, 1, 1, "", "TORCHSCRIPT"]], "aimet_torch.model_preparer": [[80, 2, 1, "", "prepare_model"]], "aimet_torch.peft": [[83, 0, 1, "", "AdapterMetaData"], [83, 0, 1, "", "PeftQuantUtils"], [83, 3, 1, "", "replace_lora_layers_with_quantizable_layers"], [83, 3, 1, "", "save_lora_weights_after_adaptation"], [83, 3, 1, "", "track_lora_meta_data"]], "aimet_torch.peft.PeftQuantUtils": [[83, 3, 1, "", "disable_lora_adapters"], [83, 3, 1, "", "enable_adapter_and_load_weights"], [83, 3, 1, "", "export_adapter_weights"], [83, 3, 1, "", "freeze_base_model"], [83, 3, 1, "", "freeze_base_model_activation_quantizers"], [83, 3, 1, "", "freeze_base_model_param_quantizers"], [83, 3, 1, "", "get_quantized_lora_layer"], [83, 3, 1, "", "set_bitwidth_for_lora_adapters"]], "aimet_torch.quant_analyzer": [[85, 0, 1, "", "QuantAnalyzer"]], "aimet_torch.quant_analyzer.QuantAnalyzer": [[85, 3, 1, "", "analyze"], [85, 3, 1, "", "check_model_sensitivity_to_quantization"], [85, 3, 1, "", "enable_per_layer_mse_loss"], [85, 3, 1, "", "export_per_layer_encoding_min_max_range"], [85, 3, 1, "", "export_per_layer_mse_loss"], [85, 3, 1, "", "export_per_layer_stats_histogram"], [85, 3, 1, "", "perform_per_layer_analysis_by_disabling_quant_wrappers"], [85, 3, 1, "", "perform_per_layer_analysis_by_enabling_quant_wrappers"]], "aimet_torch.quantsim": [[75, 0, 1, "", "QuantParams"], [87, 0, 1, "", "QuantizationSimModel"], [87, 3, 1, "", "load_checkpoint"], [87, 3, 1, "", "save_checkpoint"]], "aimet_torch.quantsim.QuantizationSimModel": [[87, 3, 1, "", "compute_encodings"], [87, 3, 1, "", "export"]], "aimet_torch.visualize_model": [[89, 2, 1, "", "visualize_changes_after_optimization"], [89, 2, 1, "", "visualize_relative_weight_ranges_to_identify_problematic_layers"], [89, 2, 1, "", "visualize_weight_ranges"]], "aimet_torch.visualize_serialized_data": [[88, 0, 1, "", "VisualizeCompression"]], "aimet_torch.visualize_serialized_data.VisualizeCompression": [[88, 3, 1, "", "display_comp_ratio_plot"], [88, 3, 1, "", "display_eval_scores"]]}, "objtypes": {"0": "py:class", "1": "py:attribute", "2": "py:function", "3": "py:method"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "attribute", "Python attribute"], "2": ["py", "function", "Python function"], "3": ["py", "method", "Python method"]}, "titleterms": {"adapt": [0, 6, 10, 26, 48, 71], "round": [0, 6, 10, 26, 48, 71, 103], "adaround": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 57, 71, 94], "overal": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 97], "flow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 83, 106], "what": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "notebook": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 85, 87, 99], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "dataset": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 75, 92, 112], "exampl": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 84, 85, 87, 88, 89, 99], "evalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "train": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 87, 105, 106, 108], "pipelin": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 75, 92, 112], "convert": [0, 1, 2, 14], "an": [0, 1, 2], "fp32": [0, 1, 2, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31], "pytorch": [0, 1, 2, 55, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 84, 85, 86, 87, 92, 104, 105, 115], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 64, 79, 80, 81, 101, 103, 104, 105], "onnx": [0, 1, 2, 47, 48, 49, 50, 51, 52, 53, 54, 92], "": [0, 1, 2], "baselin": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31], "accuraci": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55], "creat": [0, 1, 2, 6, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31], "quantiz": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 45, 46, 53, 54, 67, 68, 69, 75, 86, 87, 89, 105, 106, 108, 109, 110, 111, 115], "simul": [0, 1, 2, 6, 8, 9, 10, 18, 19, 20, 21, 26, 28, 29, 30, 31, 109, 111], "determin": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 111], "fold": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31], "batch": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "normal": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "layer": [0, 1, 2, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 26, 28, 29, 30, 31, 32, 39, 40, 43, 50, 51, 60, 62, 63, 65, 77, 78, 84, 100, 103, 106], "sim": [0, 1, 2, 6, 8, 9, 15, 16, 19, 20, 21, 28, 29, 30, 31, 46, 54, 68, 87], "comput": [0, 2, 6, 8, 9, 15, 16, 19, 20, 21], "encod": [0, 2, 6, 8, 9, 15, 16, 17, 19, 20, 21, 22, 32, 55, 111], "4": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 25, 26, 28, 29, 30, 31, 55], "appli": [0, 6, 7, 10, 11, 17, 18, 22, 26, 32], "summari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "cross": [1, 9, 19, 29, 39, 43, 50, 62, 65, 77, 84, 106], "equal": [1, 9, 19, 29, 39, 43, 50, 62, 65, 77, 84, 106], "cle": [1, 9, 19, 29, 43, 65], "compress": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88, 98, 100, 103, 114], "us": [3, 4, 5, 23, 24, 25, 33, 43, 65, 91, 94, 103, 105, 114], "channel": [3, 4, 5, 18, 23, 25, 61, 76, 97], "prune": [3, 4, 5, 23, 25, 61, 76, 97], "load": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "find": [3, 4, 5, 23, 24, 25], "fine": [3, 4, 5, 23, 24, 25, 103], "tune": [3, 4, 5, 23, 24, 25, 103], "post": [3, 4, 5, 23, 24, 25, 92, 105, 106], "spatial": [4, 5, 24, 25, 38, 61, 76, 113], "svd": [4, 5, 24, 25, 38, 61, 76, 113, 116], "follow": [5, 25], "after": [5, 15, 16, 25], "get": [6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31, 101, 103], "score": [6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31], "autoqu": [7, 11, 27, 49, 58, 73, 95], "pretrain": [7, 11, 15, 16, 17, 27], "defin": [7, 11, 12, 27], "constant": [7, 11, 12, 27], "helper": [7, 11, 27, 43, 65], "function": [7, 11, 12, 14, 27, 33], "prepar": [7, 11, 12, 14, 42, 80], "unlabel": 7, "callback": [7, 11, 12], "5": [7, 8, 11, 12, 15, 16, 19, 28, 55], "option": [7, 11, 27, 103], "set": [7, 11, 27, 91], "paramet": [7, 11, 27, 36, 38, 48, 57, 60, 61, 71, 76, 111], "run": [7, 11, 27, 52, 85, 99], "awar": [8, 12, 13, 15, 16, 20, 21, 28, 30, 31, 87, 108], "batchnorm": [8, 12, 28, 37, 59, 74], "re": [8, 12, 28, 37, 59, 74, 96], "estim": [8, 12, 28, 37, 59, 74, 96], "rewrit": 8, "perform": [8, 12, 15, 16, 20, 21, 28, 30, 31, 43, 65], "qat": [8, 12, 15, 16, 20, 21, 28, 30, 31, 87, 108], "reestim": [8, 28, 59, 74], "statist": [8, 17, 22, 28, 32], "export": [8, 12, 15, 16, 19, 28], "bia": [9, 29, 60, 75], "correct": [9, 29, 60, 75], "bc": [9, 29], "instanti": 12, "kera": [12, 13, 14, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "quantizationsim": [12, 15, 16], "transform": 13, "subclass": 14, "show": 14, "similar": 14, "differ": 14, "between": 14, "origin": 14, "discuss": 14, "limit": [14, 37, 42, 80], "compil": [15, 16], "6": [15, 16, 55], "valid": [15, 16, 81], "7": [15, 16], "rang": [16, 17, 21, 22, 31, 32], "learn": [16, 21, 31], "quant": [17, 22, 32, 44, 52, 66, 85], "analyz": [17, 22, 32, 44, 52, 66, 85], "quantanalyz": [17, 22, 32, 107], "per": [17, 18, 22, 32, 60, 100, 103], "analysi": [17, 22, 32, 105, 107], "enabl": [17, 22, 32], "disabl": [17, 22, 32], "wrapper": [17, 32], "min": [17, 22, 32], "max": [17, 22, 32], "pdf": [17, 22, 32], "mse": [17, 22, 32], "loss": [17, 22, 32], "quantsim": [18, 19, 111], "pcq": 18, "op": [22, 111], "object": 27, "infer": 27, "optim": 27, "aimet": [33, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 103, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117], "tensorflow": [33, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 92, 105, 115], "api": [33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 106, 107, 111], "introduct": [33, 37, 38, 39, 43, 50, 59, 61, 62, 65, 74, 76, 77, 84], "code": [33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 84, 85, 87, 88, 89, 99], "util": [33, 52, 81, 85], "welcom": 34, "ai": [34, 101], "effici": [34, 101], "toolkit": [34, 101], "doc": 34, "indic": 34, "tabl": 34, "user": [36, 39, 46, 48, 49, 50, 57, 58, 60, 62, 68, 71, 73, 75, 77, 83, 85, 87, 101, 106], "guid": [36, 39, 46, 48, 49, 50, 57, 58, 60, 62, 68, 71, 73, 75, 77, 85, 87, 101], "link": [36, 37, 39, 46, 48, 49, 50, 57, 58, 59, 60, 62, 68, 71, 73, 74, 75, 77, 85, 87], "top": [36, 37, 38, 40, 42, 44, 46, 48, 49, 51, 52, 54, 57, 58, 59, 61, 63, 66, 68, 69, 71, 73, 74, 76, 78, 80, 83, 85, 87, 88, 89], "level": [36, 37, 38, 40, 42, 43, 44, 46, 48, 49, 51, 52, 54, 57, 58, 59, 61, 63, 65, 66, 68, 69, 71, 73, 74, 76, 78, 80, 83, 84, 85, 87, 88, 89], "enum": [36, 57, 71, 78, 87], "definit": [36, 38, 57, 61, 71, 76, 78, 84, 87], "greedi": [38, 61, 76, 100], "select": [38, 61, 76, 97, 100, 103], "configur": [38, 61, 76, 109, 111], "primit": [39, 43, 62, 65, 77, 84], "output": [40, 51, 63, 78], "gener": [40, 51, 63, 78], "guidelin": [41, 64, 79, 87, 104, 105], "higher": [43, 65, 84], "lower": [43, 65, 84], "custom": [43, 65], "datatyp": [43, 65], "method": [43, 65], "manual": [43, 65], "mode": [43, 65, 108], "specif": [52, 55, 85], "format": 55, "version": 55, "0": [55, 112], "up": 55, "file": [55, 109], "bn": [59, 74, 96], "input": 60, "type": 60, "data": 60, "weight": [61, 69, 76, 97, 116], "visual": [69, 88, 89, 114, 115], "tensor": 69, "architectur": 72, "checker": 72, "html": 72, "report": 72, "content": 72, "convbninfotyp": 75, "activationtyp": 75, "param": 75, "empir": 75, "analyt": 75, "tar": 76, "torch": [80, 92], "fx": 80, "symbol": 80, "trace": 80, "multi": 82, "gpu": [82, 92], "support": 82, "clssetinfo": 84, "instal": [90, 91, 92, 99, 101], "quick": 90, "releas": [90, 91, 92, 101, 112], "packag": [90, 91, 92], "system": 90, "requir": [90, 107], "advanc": 90, "instruct": 90, "docker": 91, "variant": 91, "prebuilt": 91, "imag": 91, "build": 91, "local": 91, "start": [91, 101, 114], "contain": 91, "from": [91, 92], "pypi": [91, 92], "environ": [91, 92], "setup": [91, 92], "prerequisit": 92, "13": [92, 112], "common": [92, 94], "debian": 92, "replac": 92, "pillow": 92, "simd": 92, "onnxruntim": 92, "step": 92, "case": [94, 103, 105], "terminologi": 94, "overview": [95, 96, 100, 101, 103, 106, 107, 108, 109, 111, 114, 115, 117], "workflow": [95, 96, 105, 108, 111], "procedur": 97, "winnow": [97, 117], "reconstruct": 97, "featur": [98, 101, 105, 110], "guidebook": [98, 110], "brows": 99, "jupyt": 99, "download": 99, "relat": 99, "ratio": [100, 103], "how": [100, 109, 114, 117], "work": [100, 117], "explor": 100, "inform": 101, "toc": 101, "tree": 101, "known": 102, "issu": 102, "techniqu": [103, 106], "better": 103, "result": 103, "rank": 103, "faq": [103, 106], "refer": [103, 106], "debug": 105, "tool": [105, 114], "detail": 107, "descript": 107, "recommend": 108, "structur": 109, "individu": 109, "section": 109, "nois": 111, "scheme": 111, "frequent": 111, "ask": 111, "question": 111, "note": 112, "22": 112, "21": 112, "20": 112, "19": 112, "py37": 112, "18": 112, "17": 112, "16": 112, "14": 112, "design": 114, "bokeh": 114, "server": 114, "session": 114}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Adaptive Rounding (AdaRound)": [[0, "Adaptive-Rounding-(AdaRound)"], [6, "Adaptive-Rounding-(AdaRound)"], [26, "Adaptive-Rounding-(AdaRound)"]], "Overall flow": [[0, "Overall-flow"], [1, "Overall-flow"], [2, "Overall-flow"], [3, "Overall-flow"], [4, "Overall-flow"], [5, "Overall-flow"], [6, "Overall-flow"], [7, "Overall-flow"], [8, "Overall-flow"], [9, "Overall-flow"], [10, "Overall-flow"], [11, "Overall-flow"], [12, "Overall-flow"], [13, "Overall-flow"], [14, "Overall-flow"], [15, "Overall-flow"], [16, "Overall-flow"], [17, "Overall-flow"], [18, "Overall-flow"], [19, "Overall-flow"], [20, "Overall-flow"], [21, "Overall-flow"], [22, "Overall-flow"], [23, "Overall-flow"], [24, "Overall-flow"], [25, "Overall-flow"], [26, "Overall-flow"], [27, "Overall-flow"], [28, "Overall-flow"], [29, "Overall-flow"], [30, "Overall-flow"], [31, "Overall-flow"], [32, "Overall-flow"]], "What this notebook is not": [[0, "What-this-notebook-is-not"], [1, "What-this-notebook-is-not"], [2, "What-this-notebook-is-not"], [3, "What-this-notebook-is-not"], [4, "What-this-notebook-is-not"], [5, "What-this-notebook-is-not"], [6, "What-this-notebook-is-not"], [7, "What-this-notebook-is-not"], [8, "What-this-notebook-is-not"], [9, "What-this-notebook-is-not"], [10, "What-this-notebook-is-not"], [11, "What-this-notebook-is-not"], [15, "What-this-notebook-is-not"], [16, "What-this-notebook-is-not"], [17, "What-this-notebook-is-not"], [18, "What-this-notebook-is-not"], [19, "What-this-notebook-is-not"], [20, "What-this-notebook-is-not"], [21, "What-this-notebook-is-not"], [22, "What-this-notebook-is-not"], [23, "What-this-notebook-is-not"], [24, "What-this-notebook-is-not"], [25, "What-this-notebook-is-not"], [26, "What-this-notebook-is-not"], [27, "What-this-notebook-is-not"], [28, "What-this-notebook-is-not"], [29, "What-this-notebook-is-not"], [30, "What-this-notebook-is-not"], [31, "What-this-notebook-is-not"], [32, "What-this-notebook-is-not"]], "Dataset": [[0, "Dataset"], [1, "Dataset"], [2, "Dataset"], [3, "Dataset"], [4, "Dataset"], [5, "Dataset"], [6, "Dataset"], [7, "Dataset"], [8, "Dataset"], [9, "Dataset"], [10, "Dataset"], [11, "Dataset"], [12, "Dataset"], [15, "Dataset"], [16, "Dataset"], [17, "Dataset"], [18, "Dataset"], [19, "Dataset"], [20, "Dataset"], [21, "Dataset"], [22, "Dataset"], [23, "Dataset"], [24, "Dataset"], [25, "Dataset"], [26, "Dataset"], [27, "Dataset"], [28, "Dataset"], [29, "Dataset"], [30, "Dataset"], [31, "Dataset"], [32, "Dataset"]], "1. Example evaluation and training pipeline": [[0, "1.-Example-evaluation-and-training-pipeline"], [1, "1.-Example-evaluation-and-training-pipeline"], [4, "1.-Example-evaluation-and-training-pipeline"], [5, "1.-Example-evaluation-and-training-pipeline"], [7, "1.-Example-evaluation-and-training-pipeline"], [8, "1.-Example-evaluation-and-training-pipeline"], [9, "1.-Example-evaluation-and-training-pipeline"], [10, "1.-Example-evaluation-and-training-pipeline"], [11, "1.-Example-evaluation-and-training-pipeline"], [17, "1.-Example-evaluation-and-training-pipeline"], [18, "1.-Example-evaluation-and-training-pipeline"], [19, "1.-Example-evaluation-and-training-pipeline"], [20, "1.-Example-evaluation-and-training-pipeline"], [22, "1.-Example-evaluation-and-training-pipeline"], [23, "1.-Example-evaluation-and-training-pipeline"], [24, "1.-Example-evaluation-and-training-pipeline"], [25, "1.-Example-evaluation-and-training-pipeline"], [26, "1.-Example-evaluation-and-training-pipeline"], [28, "1.-Example-evaluation-and-training-pipeline"], [29, "1.-Example-evaluation-and-training-pipeline"], [30, "1.-Example-evaluation-and-training-pipeline"], [31, "1.-Example-evaluation-and-training-pipeline"], [32, "1.-Example-evaluation-and-training-pipeline"]], "2. Convert an FP32 PyTorch model to ONNX and evaluate the model\u2019s baseline FP32 accuracy": [[0, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [1, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [2, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"]], "3. Create a quantization simulation model and determine quantized accuracy": [[0, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [1, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [2, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [6, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [9, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [10, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [18, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [19, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [20, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [21, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [26, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [29, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [30, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [31, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"]], "Fold Batch Normalization layers": [[0, "Fold-Batch-Normalization-layers"], [1, "Fold-Batch-Normalization-layers"], [2, "Fold-Batch-Normalization-layers"], [6, "Fold-Batch-Normalization-layers"], [9, "Fold-Batch-Normalization-layers"], [10, "Fold-Batch-Normalization-layers"], [15, "Fold-Batch-Normalization-layers"], [16, "Fold-Batch-Normalization-layers"], [18, "Fold-Batch-Normalization-layers"], [19, "Fold-Batch-Normalization-layers"], [20, "Fold-Batch-Normalization-layers"], [21, "Fold-Batch-Normalization-layers"], [26, "Fold-Batch-Normalization-layers"], [29, "Fold-Batch-Normalization-layers"], [30, "Fold-Batch-Normalization-layers"], [31, "Fold-Batch-Normalization-layers"]], "Create Quantization Sim Model": [[0, "Create-Quantization-Sim-Model"], [1, "Create-Quantization-Sim-Model"], [2, "Create-Quantization-Sim-Model"], [6, "Create-Quantization-Sim-Model"], [8, "Create-Quantization-Sim-Model"], [9, "Create-Quantization-Sim-Model"], [15, "Create-Quantization-Sim-Model"], [16, "Create-Quantization-Sim-Model"], [19, "Create-Quantization-Sim-Model"], [20, "Create-Quantization-Sim-Model"], [21, "Create-Quantization-Sim-Model"], [28, "Create-Quantization-Sim-Model"], [29, "Create-Quantization-Sim-Model"], [30, "Create-Quantization-Sim-Model"], [31, "Create-Quantization-Sim-Model"]], "Compute Encodings": [[0, "Compute-Encodings"], [2, "Compute-Encodings"], [6, "Compute-Encodings"], [8, "Compute-Encodings"], [9, "Compute-Encodings"], [15, "Compute-Encodings"], [16, "Compute-Encodings"], [19, "Compute-Encodings"], [20, "Compute-Encodings"], [21, "Compute-Encodings"]], "4. Apply Adaround": [[0, "4.-Apply-Adaround"], [10, "4.-Apply-Adaround"], [18, "4.-Apply-Adaround"], [26, "4.-Apply-Adaround"]], "Summary": [[0, "Summary"], [1, "Summary"], [2, "Summary"], [3, "Summary"], [4, "Summary"], [5, "Summary"], [6, "Summary"], [7, "Summary"], [8, "Summary"], [9, "Summary"], [10, "Summary"], [11, "Summary"], [12, "Summary"], [14, "Summary"], [15, "Summary"], [16, "Summary"], [18, "Summary"], [19, "Summary"], [20, "Summary"], [21, "Summary"], [23, "Summary"], [24, "Summary"], [25, "Summary"], [26, "Summary"], [27, "Summary"], [28, "Summary"], [29, "Summary"], [30, "Summary"], [31, "Summary"]], "Cross-Layer Equalization (CLE)": [[1, "Cross-Layer-Equalization-(CLE)"]], "4. 1 Cross Layer Equalization": [[1, "4.-1-Cross-Layer-Equalization"], [9, "4.-1-Cross-Layer-Equalization"], [29, "4.-1-Cross-Layer-Equalization"]], "Quantization Simulation": [[2, "Quantization-Simulation"]], "1. Example evaluation pipeline": [[2, "1.-Example-evaluation-pipeline"]], "Model Compression Using Channel Pruning": [[3, "Model-Compression-Using-Channel-Pruning"]], "2. Load the model and evaluate it to find the baseline accuracy": [[3, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [4, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [5, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [23, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [24, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [25, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"]], "3. Compress the model and fine-tune": [[3, "3.-Compress-the-model-and-fine-tune"], [4, "3.-Compress-the-model-and-fine-tune"], [5, "3.-Compress-the-model-and-fine-tune"], [23, "3.-Compress-the-model-and-fine-tune"], [24, "3.-Compress-the-model-and-fine-tune"], [25, "3.-Compress-the-model-and-fine-tune"]], "3.1. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[3, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [4, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [5, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [23, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.2. Fine-tune the model": [[3, "3.2.-Fine-tune-the-model"], [4, "3.2.-Fine-tune-the-model"], [23, "3.2.-Fine-tune-the-model"], [24, "3.2.-Fine-tune-the-model"]], "Model compression Using Spatial SVD": [[4, "Model-compression-Using-Spatial-SVD"]], "Model Compression Using Spatial SVD Followed by Channel Pruning": [[5, "Model-Compression-Using-Spatial-SVD-Followed-by-Channel-Pruning"]], "3.2. Fine-tune the model after Spatial SVD": [[5, "3.2.-Fine-tune-the-model-after-Spatial-SVD"], [25, "3.2.-Fine-tune-the-model-after-Spatial-SVD"]], "3.3. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[5, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [25, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.4. Fine-tune the model after Channel Pruning": [[5, "3.4.-Fine-tune-the-model-after-Channel-Pruning"], [25, "3.4.-Fine-tune-the-model-after-Channel-Pruning"]], "1. Example Evaluation and Training Pipeline": [[6, "1.-Example-Evaluation-and-Training-Pipeline"], [21, "1.-Example-Evaluation-and-Training-Pipeline"]], "2. Load the model and evaluate to get a baseline FP32 accuracy score": [[6, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [9, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [10, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [18, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [19, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [20, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [21, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [26, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [29, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [30, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [31, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"]], "4. Apply AdaRound": [[6, "4.-Apply-AdaRound"]], "AutoQuant": [[7, "AutoQuant"], [11, "AutoQuant"], [27, "AutoQuant"]], "2. Load a pretrained FP32 model": [[7, "2.-Load-a-pretrained-FP32-model"], [11, "2.-Load-a-pretrained-FP32-model"], [15, "2.-Load-a-pretrained-FP32-model"], [16, "2.-Load-a-pretrained-FP32-model"], [17, "2.-Load-a-pretrained-FP32-model"], [27, "2.-Load-a-pretrained-FP32-model"]], "3. Determine the baseline FP32 accuracy": [[7, "3.-Determine-the-baseline-FP32-accuracy"], [11, "3.-Determine-the-baseline-FP32-accuracy"], [15, "3.-Determine-the-baseline-FP32-accuracy"], [16, "3.-Determine-the-baseline-FP32-accuracy"]], "4. Define Constants and Helper functions": [[7, "4.-Define-Constants-and-Helper-functions"], [11, "4.-Define-Constants-and-Helper-functions"]], "Prepare unlabeled dataset": [[7, "Prepare-unlabeled-dataset"]], "Prepare the evaluation callback function": [[7, "Prepare-the-evaluation-callback-function"], [11, "Prepare-the-evaluation-callback-function"], [12, "Prepare-the-evaluation-callback-function"]], "5. Apply AutoQuant": [[7, "5.-Apply-AutoQuant"], [11, "5.-Apply-AutoQuant"]], "Optionally set AdaRound Parameters": [[7, "Optionally-set-AdaRound-Parameters"], [11, "Optionally-set-AdaRound-Parameters"]], "Run AutoQuant": [[7, "Run-AutoQuant"], [11, "Run-AutoQuant"]], "Quantization-Aware Training with BatchNorm Re-estimation": [[8, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [12, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [28, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"]], "2. Load FP32 model": [[8, "2.-Load-FP32-model"], [28, "2.-Load-FP32-model"]], "BatchNorm Rewriter": [[8, "BatchNorm-Rewriter"]], "3. Create a quantization simulation model and Perform QAT": [[8, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"], [28, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"]], "Perform QAT": [[8, "Perform-QAT"], [28, "Perform-QAT"]], "4. Perform BatchNorm Reestimation": [[8, "4.-Perform-BatchNorm-Reestimation"], [28, "4.-Perform-BatchNorm-Reestimation"]], "Re-estimate BatchNorm Statistics": [[8, "Re-estimate-BatchNorm-Statistics"], [28, "Re-estimate-BatchNorm-Statistics"]], "Fold BatchNorm Layers": [[8, "Fold-BatchNorm-Layers"], [12, "Fold-BatchNorm-Layers"], [28, "Fold-BatchNorm-Layers"]], "5. Export Model": [[8, "5.-Export-Model"], [12, "5.-Export-Model"], [28, "5.-Export-Model"]], "Cross-Layer Equalization (CLE) and Bias Correction (BC)": [[9, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"], [29, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"]], "4. 2 Bias Correction": [[9, "4.-2-Bias-Correction"], [29, "4.-2-Bias-Correction"]], "Adaptive Rounding (Adaround)": [[10, "Adaptive-Rounding-(Adaround)"]], "1. Instantiate the example evaluation and training pipeline": [[12, "1.-Instantiate-the-example-evaluation-and-training-pipeline"]], "2. Define Constants and Datasets Prepare": [[12, "2.-Define-Constants-and-Datasets-Prepare"]], "2. Create the model in Keras": [[12, "2.-Create-the-model-in-Keras"]], "3. Train and evaluate the model": [[12, "3.-Train-and-evaluate-the-model"]], "4. Create a QuantizationSim Model": [[12, "4.-Create-a-QuantizationSim-Model"]], "5. Perform QAT": [[12, "5.-Perform-QAT"], [15, "5.-Perform-QAT"], [16, "5.-Perform-QAT"]], "Quantization-Aware Training with a Keras Transformer Model": [[13, "Quantization-Aware-Training-with-a-Keras-Transformer-Model"]], "Keras Model Preparer": [[14, "Keras-Model-Preparer"]], "1. Creating a Keras model with subclass layers": [[14, "1.-Creating-a-Keras-model-with-subclass-layers"]], "2. Converting the Keras model with subclass layers to a Keras model with functional layers": [[14, "2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers"]], "3. Showing similarities and differences between the original and converted models": [[14, "3.-Showing-similarities-and-differences-between-the-original-and-converted-models"]], "4. Discussing the limitations of the Keras Model Preparer": [[14, "4.-Discussing-the-limitations-of-the-Keras-Model-Preparer"]], "Quantization-Aware Training": [[15, "Quantization-Aware-Training"], [20, "Quantization-Aware-Training"], [30, "Quantization-Aware-Training"]], "Example evaluation and training pipeline": [[15, "Example-evaluation-and-training-pipeline"], [16, "Example-evaluation-and-training-pipeline"]], "1. Load the dataset": [[15, "1.-Load-the-dataset"], [16, "1.-Load-the-dataset"]], "4. Create a QuantizationSim Model and determine quantized accuracy": [[15, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"], [16, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"]], "Compile the model": [[15, "Compile-the-model"], [16, "Compile-the-model"]], "Evaluate the performance of the quantized model": [[15, "Evaluate-the-performance-of-the-quantized-model"], [16, "Evaluate-the-performance-of-the-quantized-model"]], "6. Evaluate validation accuracy after QAT": [[15, "6.-Evaluate-validation-accuracy-after-QAT"], [16, "6.-Evaluate-validation-accuracy-after-QAT"]], "7. Export the encodings": [[15, "7.-Export-the-encodings"], [16, "7.-Export-the-encodings"]], "Quantization-Aware Training with Range Learning": [[16, "Quantization-Aware-Training-with-Range-Learning"], [21, "Quantization-Aware-Training-with-Range-Learning"], [31, "Quantization-Aware-Training-with-Range-Learning"]], "Quant Analyzer": [[17, "Quant-Analyzer"], [22, "Quant-Analyzer"], [32, "Quant-Analyzer"]], "3. Apply QuantAnalyzer to the model": [[17, "3.-Apply-QuantAnalyzer-to-the-model"], [22, "3.-Apply-QuantAnalyzer-to-the-model"], [32, "3.-Apply-QuantAnalyzer-to-the-model"]], "Per-layer analysis by enabling/disabling quantization wrappers": [[17, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"], [32, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"]], "Encoding min/max ranges": [[17, "Encoding-min/max-ranges"], [22, "Encoding-min/max-ranges"], [32, "Encoding-min/max-ranges"]], "PDF of statistics": [[17, "PDF-of-statistics"], [22, "PDF-of-statistics"], [32, "PDF-of-statistics"]], "Per-layer MSE loss": [[17, "Per-layer-MSE-loss"], [32, "Per-layer-MSE-loss"]], "Quantsim and Adaround - Per Channel Quantization (PCQ)": [[18, "Quantsim-and-Adaround---Per-Channel-Quantization-(PCQ)"]], "Cross-Layer Equalization (CLE) with QuantSim": [[19, "Cross-Layer-Equalization-(CLE)-with-QuantSim"]], "4 Cross Layer Equalization": [[19, "4-Cross-Layer-Equalization"]], "5 Exporting": [[19, "5-Exporting"]], "4. Perform QAT": [[20, "4.-Perform-QAT"], [21, "4.-Perform-QAT"], [30, "4.-Perform-QAT"], [31, "4.-Perform-QAT"]], "2. Load the model": [[22, "2.-Load-the-model"], [32, "2.-Load-the-model"]], "Per op analysis by enabling/disabling quantization ops": [[22, "Per-op-analysis-by-enabling/disabling-quantization-ops"]], "Per op MSE loss": [[22, "Per-op-MSE-loss"]], "Model compression using Channel Pruning": [[23, "Model-compression-using-Channel-Pruning"]], "Model compression using Spatial SVD": [[24, "Model-compression-using-Spatial-SVD"]], "3.1. Compress model using Spatial SVD and evaluate it to find post-compression accuracy": [[24, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"], [25, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"]], "Model compression using Spatial SVD followed by Channel Pruning": [[25, "Model-compression-using-Spatial-SVD-followed-by-Channel-Pruning"]], "1. Define Constants and Helper functions": [[27, "1.-Define-Constants-and-Helper-functions"]], "3. Run AutoQuant": [[27, "3.-Run-AutoQuant"]], "Create AutoQuant Object": [[27, "Create-AutoQuant-Object"]], "Run AutoQuant Inference": [[27, "Run-AutoQuant-Inference"]], "Set AdaRound Parameters (optional)": [[27, "Set-AdaRound-Parameters-(optional)"]], "Run AutoQuant Optimization": [[27, "Run-AutoQuant-Optimization"]], "Using AIMET Tensorflow APIs with Keras Models": [[33, "using-aimet-tensorflow-apis-with-keras-models"]], "Introduction": [[33, "introduction"], [37, "introduction"], [38, "introduction"], [39, "introduction"], [43, "introduction"], [50, "introduction"], [59, "introduction"], [61, "introduction"], [62, "introduction"], [65, "introduction"], [74, "introduction"], [76, "introduction"], [77, "introduction"], [84, "introduction"]], "APIs": [[33, "apis"]], "Code Example": [[33, "code-example"], [37, "code-example"], [39, "code-example"], [40, "code-example"], [50, "code-example"], [51, "code-example"], [62, "code-example"], [63, "code-example"], [66, "code-example"], [77, "code-example"], [78, "code-example"]], "Utility Functions": [[33, "utility-functions"]], "Welcome to AI Model Efficiency Toolkit API Docs!": [[34, "welcome-to-ai-model-efficiency-toolkit-api-docs"]], "Indices and tables": [[34, "indices-and-tables"]], "AIMET Keras APIs": [[35, "aimet-keras-apis"]], "AIMET Keras AdaRound API": [[36, "aimet-keras-adaround-api"]], "User Guide Link": [[36, "user-guide-link"], [39, "user-guide-link"], [46, "user-guide-link"], [48, "user-guide-link"], [49, "user-guide-link"], [50, "user-guide-link"], [57, "user-guide-link"], [58, "user-guide-link"], [60, "user-guide-link"], [62, "user-guide-link"], [68, "user-guide-link"], [71, "user-guide-link"], [73, "user-guide-link"], [75, "user-guide-link"], [77, "user-guide-link"], [85, "user-guide-link"], [87, "user-guide-link"]], "Examples Notebook Link": [[36, "examples-notebook-link"], [37, "examples-notebook-link"], [39, "examples-notebook-link"], [57, "examples-notebook-link"], [58, "examples-notebook-link"], [59, "examples-notebook-link"], [62, "examples-notebook-link"], [68, "examples-notebook-link"], [71, "examples-notebook-link"], [73, "examples-notebook-link"], [74, "examples-notebook-link"], [77, "examples-notebook-link"], [85, "examples-notebook-link"], [87, "examples-notebook-link"]], "Top-level API": [[36, "top-level-api"], [40, "top-level-api"], [42, "top-level-api"], [44, "top-level-api"], [46, "top-level-api"], [48, "top-level-api"], [49, "top-level-api"], [51, "top-level-api"], [52, "top-level-api"], [54, "top-level-api"], [57, "top-level-api"], [58, "top-level-api"], [63, "top-level-api"], [66, "top-level-api"], [68, "top-level-api"], [71, "top-level-api"], [73, "top-level-api"], [78, "top-level-api"], [80, "top-level-api"], [83, "top-level-api"], [85, "top-level-api"], [87, "top-level-api"]], "Adaround Parameters": [[36, "adaround-parameters"], [48, "adaround-parameters"], [57, "adaround-parameters"], [71, "adaround-parameters"]], "Enum Definition": [[36, "enum-definition"], [57, "enum-definition"], [71, "enum-definition"], [78, "enum-definition"], [87, "enum-definition"]], "Code Examples": [[36, "code-examples"], [38, "code-examples"], [42, "code-examples"], [44, "code-examples"], [46, "code-examples"], [49, "code-examples"], [52, "code-examples"], [54, "code-examples"], [57, "code-examples"], [58, "code-examples"], [61, "code-examples"], [68, "code-examples"], [73, "code-examples"], [76, "code-examples"], [80, "code-examples"], [85, "code-examples"], [88, "code-examples"], [89, "code-examples"]], "AIMET Keras BatchNorm Re-estimation APIs": [[37, "aimet-keras-batchnorm-re-estimation-apis"]], "Top-level APIs": [[37, "top-level-apis"], [59, "top-level-apis"], [74, "top-level-apis"]], "Limitations": [[37, "limitations"], [42, "limitations"]], "AIMET Keras Compression API": [[38, "aimet-keras-compression-api"]], "Top-level API for Compression": [[38, "top-level-api-for-compression"], [61, "top-level-api-for-compression"], [76, "top-level-api-for-compression"]], "Greedy Selection Parameters": [[38, "greedy-selection-parameters"], [61, "greedy-selection-parameters"], [76, "greedy-selection-parameters"]], "Spatial SVD Configuration": [[38, "spatial-svd-configuration"], [61, "spatial-svd-configuration"], [76, "spatial-svd-configuration"]], "Configuration Definitions": [[38, "configuration-definitions"], [61, "configuration-definitions"], [76, "configuration-definitions"]], "AIMET Keras Cross Layer Equalization APIs": [[39, "aimet-keras-cross-layer-equalization-apis"]], "Cross Layer Equalization API": [[39, "cross-layer-equalization-api"], [50, "cross-layer-equalization-api"], [62, "cross-layer-equalization-api"], [77, "cross-layer-equalization-api"]], "Primitive APIs": [[39, "primitive-apis"], [62, "primitive-apis"], [77, "primitive-apis"]], "AIMET Keras Layer Output Generation API": [[40, "aimet-keras-layer-output-generation-api"]], "Keras Model Guidelines": [[41, "keras-model-guidelines"]], "Model Preparer API": [[42, "model-preparer-api"], [80, "model-preparer-api"]], "AIMET Keras Cross Layer Equalization Primitive API": [[43, "aimet-keras-cross-layer-equalization-primitive-api"]], "Higher Level APIs for Cross Layer Equalization": [[43, "higher-level-apis-for-cross-layer-equalization"], [65, "higher-level-apis-for-cross-layer-equalization"], [84, "higher-level-apis-for-cross-layer-equalization"]], "Code Examples for Higher Level APIs": [[43, "code-examples-for-higher-level-apis"], [65, "code-examples-for-higher-level-apis"], [84, "code-examples-for-higher-level-apis"]], "Lower Level APIs for Cross Layer Equalization": [[43, "lower-level-apis-for-cross-layer-equalization"], [65, "lower-level-apis-for-cross-layer-equalization"], [84, "lower-level-apis-for-cross-layer-equalization"]], "Custom Datatype used": [[43, "custom-datatype-used"], [65, "custom-datatype-used"]], "Code Example for Lower level APIs": [[43, "code-example-for-lower-level-apis"], [65, "code-example-for-lower-level-apis"]], "Example helper methods to perform CLE in manual mode": [[43, "example-helper-methods-to-perform-cle-in-manual-mode"], [65, "example-helper-methods-to-perform-cle-in-manual-mode"]], "AIMET Keras Quant Analyzer API": [[44, "aimet-keras-quant-analyzer-api"]], "AIMET Keras Quantization APIs": [[45, "aimet-keras-quantization-apis"]], "AIMET Keras Quantization SIM API": [[46, "aimet-keras-quantization-sim-api"]], "AIMET ONNX APIs": [[47, "aimet-onnx-apis"]], "AIMET ONNX AdaRound API": [[48, "aimet-onnx-adaround-api"]], "Code Example - Adaptive Rounding (AdaRound)": [[48, "code-example-adaptive-rounding-adaround"], [71, "code-example-adaptive-rounding-adaround"]], "AIMET ONNX AutoQuant API": [[49, "aimet-onnx-autoquant-api"]], "AIMET ONNX Cross Layer Equalization APIs": [[50, "aimet-onnx-cross-layer-equalization-apis"]], "AIMET ONNX Layer Output Generation API": [[51, "aimet-onnx-layer-output-generation-api"]], "AIMET ONNX Quant Analyzer API": [[52, "aimet-onnx-quant-analyzer-api"]], "Run specific utility": [[52, "run-specific-utility"], [85, "run-specific-utility"]], "AIMET ONNX Quantization APIs": [[53, "aimet-onnx-quantization-apis"]], "AIMET ONNX Quantization SIM API": [[54, "aimet-onnx-quantization-sim-api"]], "Encoding Format Specification": [[55, "encoding-format-specification"]], "1. Versioning": [[55, "versioning"]], "2. Version 0.4.0 (up to)": [[55, "version-0-4-0-up-to"]], "2.1. Encoding Specification": [[55, "encoding-specification"]], "2.2. Encoding File Example for PyTorch": [[55, "encoding-file-example-for-pytorch"]], "2.3. Encoding File Example for TensorFlow": [[55, "encoding-file-example-for-tensorflow"]], "3. Version 0.5.0": [[55, "version-0-5-0"]], "3.1. Encoding Specification": [[55, "id1"]], "3.2. Encoding File Example for PyTorch": [[55, "id2"]], "3.3. Encoding File Example for TensorFlow": [[55, "id3"]], "4. Version 0.6.1": [[55, "version-0-6-1"]], "4.1. Encoding Specification": [[55, "id4"]], "AIMET TensorFlow APIs": [[56, "aimet-tensorflow-apis"]], "AIMET TensorFlow AdaRound API": [[57, "aimet-tensorflow-adaround-api"]], "AIMET TensorFlow AutoQuant API": [[58, "aimet-tensorflow-autoquant-api"]], "AIMET TensorFlow BatchNorm Re-estimation APIs": [[59, "aimet-tensorflow-batchnorm-re-estimation-apis"]], "Code Example - BN-Reestimation": [[59, "code-example-bn-reestimation"], [74, "code-example-bn-reestimation"]], "AIMET TensorFlow Bias Correction API": [[60, "aimet-tensorflow-bias-correction-api"]], "Bias Correction API": [[60, "bias-correction-api"], [75, "bias-correction-api"]], "Input Parameter Types": [[60, "input-parameter-types"]], "Data Input Type": [[60, "data-input-type"]], "Code Examples for Bias Correction": [[60, "code-examples-for-bias-correction"]], "Bias Correction Per Layer API": [[60, "bias-correction-per-layer-api"]], "Code Example for Per-Layer Bias Correction": [[60, "code-example-for-per-layer-bias-correction"]], "AIMET TensorFlow Compression API": [[61, "aimet-tensorflow-compression-api"]], "Channel Pruning Configuration": [[61, "channel-pruning-configuration"], [76, "channel-pruning-configuration"]], "Weight SVD Top-level API": [[61, "weight-svd-top-level-api"]], "Code Examples for Weight SVD": [[61, "code-examples-for-weight-svd"]], "AIMET TensorFlow Cross Layer Equalization APIs": [[62, "aimet-tensorflow-cross-layer-equalization-apis"]], "AIMET Tensorflow Layer Output Generation API": [[63, "aimet-tensorflow-layer-output-generation-api"]], "TensorFlow Model Guidelines": [[64, "tensorflow-model-guidelines"]], "AIMET TensorFlow Cross Layer Equalization Primitive API": [[65, "aimet-tensorflow-cross-layer-equalization-primitive-api"]], "AIMET Tensorflow Quant Analyzer API": [[66, "aimet-tensorflow-quant-analyzer-api"]], "AIMET TensorFlow Quantization APIs": [[67, "aimet-tensorflow-quantization-apis"]], "AIMET TensorFlow Quantization SIM API": [[68, "aimet-tensorflow-quantization-sim-api"]], "AIMET Visualization for Quantization for TensorFlow API": [[69, "aimet-visualization-for-quantization-for-tensorflow-api"]], "Top-level API for Visualization of Weight tensors": [[69, "top-level-api-for-visualization-of-weight-tensors"]], "Code Examples for Visualization of Weight tensors": [[69, "code-examples-for-visualization-of-weight-tensors"]], "AIMET PyTorch APIs": [[70, "aimet-pytorch-apis"]], "AIMET PyTorch AdaRound API": [[71, "aimet-pytorch-adaround-api"]], "Architecture Checker API": [[72, "architecture-checker-api"]], "HTML report content": [[72, "id1"]], "AIMET PyTorch AutoQuant API": [[73, "aimet-pytorch-autoquant-api"]], "AIMET PyTorch BatchNorm Re-estimation APIs": [[74, "aimet-pytorch-batchnorm-re-estimation-apis"]], "AIMET PyTorch Bias Correction API": [[75, "aimet-pytorch-bias-correction-api"]], "ConvBnInfoType": [[75, "convbninfotype"]], "ActivationType": [[75, "activationtype"]], "Quantization Params": [[75, "quantization-params"]], "Code Example #1 Empirical Bias Correction": [[75, "code-example-1-empirical-bias-correction"]], "Code Example #2 Analytical + Empirical Bias correction": [[75, "code-example-2-analytical-empirical-bias-correction"]], "AIMET PyTorch Compression API": [[76, "aimet-pytorch-compression-api"]], "TAR Selection Parameters": [[76, "tar-selection-parameters"]], "Weight SVD Configuration": [[76, "weight-svd-configuration"]], "AIMET PyTorch Cross Layer Equalization APIs": [[77, "aimet-pytorch-cross-layer-equalization-apis"]], "AIMET PyTorch Layer Output Generation API": [[78, "aimet-pytorch-layer-output-generation-api"]], "PyTorch Model Guidelines": [[79, "pytorch-model-guidelines"]], "Limitations of torch.fx symbolic trace API": [[80, "limitations-of-torch-fx-symbolic-trace-api"]], "Model Validator Utility": [[81, "model-validator-utility"]], "PyTorch Multi-GPU support": [[82, "pytorch-multi-gpu-support"]], "User flow": [[83, "user-flow"]], "AIMET PyTorch Cross Layer Equalization Primitive API": [[84, "aimet-pytorch-cross-layer-equalization-primitive-api"]], "ClsSetInfo Definition": [[84, "clssetinfo-definition"]], "Code Examples for Lower Level APIs": [[84, "code-examples-for-lower-level-apis"]], "AIMET PyTorch Quant Analyzer API": [[85, "aimet-pytorch-quant-analyzer-api"]], "AIMET PyTorch Quantization APIs": [[86, "aimet-pytorch-quantization-apis"]], "AIMET PyTorch Quantization SIM API": [[87, "aimet-pytorch-quantization-sim-api"]], "Guidelines": [[87, "guidelines"]], "Code Example - Quantization Aware Training (QAT)": [[87, "code-example-quantization-aware-training-qat"]], "AIMET Visualization Compression API": [[88, "aimet-visualization-compression-api"]], "Top-level API Compression": [[88, "top-level-api-compression"]], "AIMET Visualization for Quantization API": [[89, "aimet-visualization-for-quantization-api"]], "Top-level API Quantization": [[89, "top-level-api-quantization"]], "AIMET Installation": [[90, "aimet-installation"]], "Quick Install": [[90, "quick-install"]], "Release Packages": [[90, "release-packages"]], "System Requirements": [[90, "system-requirements"]], "Advanced Installation Instructions": [[90, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[91, "aimet-installation-in-docker"]], "Set variant": [[91, "set-variant"]], "Use prebuilt docker image": [[91, "use-prebuilt-docker-image"]], "Build docker image locally": [[91, "build-docker-image-locally"]], "Start docker container": [[91, "start-docker-container"]], "Install AIMET packages": [[91, "install-aimet-packages"], [92, "install-aimet-packages"]], "From PyPI": [[91, "from-pypi"], [92, "from-pypi"]], "From Release Package": [[91, "from-release-package"], [92, "from-release-package"]], "Environment setup": [[91, "environment-setup"], [92, "environment-setup"]], "AIMET Installation and Setup": [[92, "aimet-installation-and-setup"]], "Install prerequisite packages": [[92, "install-prerequisite-packages"]], "Install GPU packages": [[92, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or TensorFlow": [[92, "install-gpu-packages-for-pytorch-2-1-or-tensorflow"]], "Install GPU packages for PyTorch 1.13 or ONNX": [[92, "install-gpu-packages-for-pytorch-1-13-or-onnx"]], "Install common debian packages": [[92, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[92, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[92, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[92, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[92, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[92, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[92, "post-installation-steps"]], "AIMET AdaRound": [[94, "aimet-adaround"]], "AdaRound Use Cases": [[94, "adaround-use-cases"]], "Common terminology": [[94, "common-terminology"]], "Use Cases": [[94, "use-cases"], [105, "use-cases"]], "AdaRound API": [[94, "adaround-api"]], "AIMET AutoQuant": [[95, "aimet-autoquant"]], "Overview": [[95, "overview"], [96, "overview"], [100, "overview"], [101, "overview"], [103, "overview"], [106, "overview"], [107, "overview"], [108, "overview"], [109, "overview"], [111, "overview"], [114, "overview"], [115, "overview"], [117, "overview"]], "Workflow": [[95, "workflow"], [96, "workflow"]], "AutoQuant API": [[95, "autoquant-api"]], "AIMET BN Re-estimation": [[96, "aimet-bn-re-estimation"]], "BN Re-estimation API": [[96, "bn-re-estimation-api"]], "AIMET Channel Pruning": [[97, "aimet-channel-pruning"]], "Overall Procedure": [[97, "overall-procedure"]], "Channel Selection": [[97, "channel-selection"]], "Winnowing": [[97, "winnowing"]], "Weight Reconstruction": [[97, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[98, "aimet-compression-features-guidebook"]], "AIMET Examples": [[99, "aimet-examples"]], "Browse the notebooks": [[99, "browse-the-notebooks"]], "Running the notebooks": [[99, "running-the-notebooks"]], "Install Jupyter": [[99, "install-jupyter"]], "Download the Example notebooks and related code": [[99, "download-the-example-notebooks-and-related-code"]], "Run the notebooks": [[99, "run-the-notebooks"]], "AIMET Greedy Compression Ratio Selection": [[100, "aimet-greedy-compression-ratio-selection"]], "How it works": [[100, "how-it-works"]], "Per-layer Exploration": [[100, "per-layer-exploration"]], "Compression Ratio Selection": [[100, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[101, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[101, "features"]], "Release Information": [[101, "release-information"]], "Installation Guide": [[101, "installation-guide"]], "Getting Started": [[101, "getting-started"]], "toc tree": [[101, "toc-tree"]], "AIMET Known Issues": [[102, "aimet-known-issues"]], "AIMET Model Compression": [[103, "aimet-model-compression"]], "Use Case": [[103, "use-case"]], "Compression ratio selection": [[103, "compression-ratio-selection"]], "Model Compression": [[103, "model-compression"]], "Optional techniques to get better compression results": [[103, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[103, "rank-rounding"]], "Per-layer Fine-tuning": [[103, "per-layer-fine-tuning"]], "FAQs": [[103, "faqs"], [106, "faqs"]], "References": [[103, "references"], [106, "references"]], "Model Guidelines for PyTorch": [[104, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[105, "aimet-model-quantization"]], "AIMET Quantization Features": [[105, "aimet-quantization-features"]], "Post-Training Quantization": [[105, "post-training-quantization"]], "Debugging/Analysis Tools": [[105, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[105, "aimet-quantization-workflow"]], "PyTorch": [[105, "pytorch"], [115, "pytorch"]], "Tensorflow": [[105, "tensorflow"]], "Debugging Guidelines": [[105, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[106, "aimet-post-training-quantization-techniques"]], "User Flow": [[106, "user-flow"]], "Cross-Layer Equalization API": [[106, "cross-layer-equalization-api"]], "AIMET QuantAnalyzer": [[107, "aimet-quantanalyzer"]], "Requirements": [[107, "requirements"]], "Detailed Analysis Descriptions": [[107, "detailed-analysis-descriptions"]], "QuantAnalyzer API": [[107, "quantanalyzer-api"]], "AIMET Quantization Aware Training": [[108, "aimet-quantization-aware-training"]], "QAT workflow": [[108, "qat-workflow"]], "QAT modes": [[108, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[108, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[109, "quantization-simulation-configuration"]], "Configuration File Structure": [[109, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[109, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[110, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[111, "aimet-quantization-simulation"]], "QuantSim Workflow": [[111, "quantsim-workflow"]], "Simulating Quantization Noise": [[111, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[111, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[111, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[111, "configuring-quantization-simulation-ops"]], "Quantization Simulation APIs": [[111, "quantization-simulation-apis"]], "Frequently Asked Questions": [[111, "frequently-asked-questions"]], "AIMET Release Notes": [[112, "aimet-release-notes"]], "1.22.2": [[112, "id1"]], "1.22.1": [[112, "id2"]], "1.22.0": [[112, "id3"]], "1.21.0": [[112, "id4"]], "1.20.0": [[112, "id5"]], "1.19.1.py37": [[112, "py37"]], "1.19.1": [[112, "id6"]], "1.18.0.py37": [[112, "id7"]], "1.18.0": [[112, "id8"]], "1.17.0.py37": [[112, "id9"]], "1.17.0": [[112, "id10"]], "1.16.2.py37": [[112, "id11"]], "1.16.2": [[112, "id12"]], "1.16.1.py37": [[112, "id13"]], "1.16.1": [[112, "id14"]], "1.16.0": [[112, "id15"]], "1.14.0": [[112, "id16"]], "1.13.0": [[112, "id17"]], "AIMET Spatial SVD": [[113, "aimet-spatial-svd"]], "AIMET Visualization": [[114, "aimet-visualization"]], "Design": [[114, "design"]], "Compression": [[114, "compression"]], "Starting a Bokeh Server Session:": [[114, "starting-a-bokeh-server-session"]], "How to use the tool": [[114, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[115, "aimet-visualization-for-quantization"]], "Quantization": [[115, "quantization"]], "TensorFlow": [[115, "tensorflow"]], "AIMET Weight SVD": [[116, "aimet-weight-svd"]], "AIMET Winnowing": [[117, "aimet-winnowing"]], "Winnowing Overview": [[117, "winnowing-overview"]], "How Winnowing Works": [[117, "how-winnowing-works"]]}, "indexentries": {"load_keras_model_multi_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.load_keras_model_multi_gpu"]], "load_tf_sess_variables_to_keras_single_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.load_tf_sess_variables_to_keras_single_gpu"]], "save_as_tf_module_multi_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.save_as_tf_module_multi_gpu"]], "save_tf_session_single_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.save_tf_session_single_gpu"]], "adaroundparameters (class in aimet_tensorflow.adaround.adaround_weight)": [[36, "aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"], [57, "aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"]], "quantscheme (class in aimet_common.defs)": [[36, "aimet_common.defs.QuantScheme"], [57, "aimet_common.defs.QuantScheme"], [71, "aimet_common.defs.QuantScheme"], [87, "aimet_common.defs.QuantScheme"]], "post_training_percentile (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_percentile"], [57, "aimet_common.defs.QuantScheme.post_training_percentile"], [71, "aimet_common.defs.QuantScheme.post_training_percentile"], [87, "aimet_common.defs.QuantScheme.post_training_percentile"]], "post_training_tf (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_tf"], [57, "aimet_common.defs.QuantScheme.post_training_tf"], [71, "aimet_common.defs.QuantScheme.post_training_tf"], [87, "aimet_common.defs.QuantScheme.post_training_tf"]], "post_training_tf_enhanced (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [57, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [71, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [87, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"]], "training_range_learning_with_tf_enhanced_init (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [57, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [71, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [87, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"]], "training_range_learning_with_tf_init (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [57, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [71, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [87, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"]], "fold_all_batch_norms_to_scale() (in module aimet_tensorflow.keras.batch_norm_fold)": [[37, "aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_tensorflow.keras.bn_reestimation)": [[37, "aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"]], "compressionscheme (class in aimet_common.defs)": [[38, "aimet_common.defs.CompressionScheme"], [61, "aimet_common.defs.CompressionScheme"]], "costmetric (class in aimet_common.defs)": [[38, "aimet_common.defs.CostMetric"], [61, "aimet_common.defs.CostMetric"]], "modelcompressor (class in aimet_tensorflow.keras.compress)": [[38, "aimet_tensorflow.keras.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.ModuleCompRatioPair"], [61, "aimet_tensorflow.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters"], [61, "aimet_tensorflow.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode"]], "auto (aimet_tensorflow.defs.spatialsvdparameters.mode attribute)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"]], "channel_pruning (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.channel_pruning"], [61, "aimet_common.defs.CompressionScheme.channel_pruning"]], "compress_model() (aimet_tensorflow.keras.compress.modelcompressor static method)": [[38, "aimet_tensorflow.keras.compress.ModelCompressor.compress_model"]], "mac (aimet_common.defs.costmetric attribute)": [[38, "aimet_common.defs.CostMetric.mac"], [61, "aimet_common.defs.CostMetric.mac"]], "manual (aimet_tensorflow.defs.spatialsvdparameters.mode attribute)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"]], "memory (aimet_common.defs.costmetric attribute)": [[38, "aimet_common.defs.CostMetric.memory"], [61, "aimet_common.defs.CostMetric.memory"]], "spatial_svd (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.spatial_svd"], [61, "aimet_common.defs.CompressionScheme.spatial_svd"]], "weight_svd (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.weight_svd"], [61, "aimet_common.defs.CompressionScheme.weight_svd"]], "equalize_model() (in module aimet_tensorflow.keras.cross_layer_equalization)": [[39, "aimet_tensorflow.keras.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_tensorflow.keras.layer_output_utils)": [[40, "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil"]], "generate_layer_outputs() (aimet_tensorflow.keras.layer_output_utils.layeroutpututil method)": [[40, "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "prepare_model() (in module aimet_tensorflow.keras.model_preparer)": [[42, "aimet_tensorflow.keras.model_preparer.prepare_model"]], "clssetinfo (class in aimet_tensorflow.keras.cross_layer_equalization)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_tensorflow.keras.cross_layer_equalization)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_tensorflow.keras.cross_layer_equalization.highbiasfold)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold.bias_fold"], [43, "id0"]], "fold_all_batch_norms() (in module aimet_tensorflow.keras.batch_norm_fold)": [[43, "aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_tensorflow.keras.batch_norm_fold)": [[43, "aimet_tensorflow.keras.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_tensorflow.keras.cross_layer_equalization.crosslayerscaling)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_tensorflow.keras.cross_layer_equalization.crosslayerscaling)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_model"]], "quantanalyzer (class in aimet_tensorflow.keras.quant_analyzer)": [[44, "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_tensorflow.keras.quant_analyzer.quantanalyzer method)": [[44, "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer.analyze"]], "quantizationsimmodel (class in aimet_tensorflow.keras.quantsim)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_tensorflow.keras.quantsim.quantizationsimmodel method)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_tensorflow.keras.quantsim.quantizationsimmodel method)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel.export"]], "apply_adaround() (in module aimet_tensorflow.adaround.adaround_weight.adaround)": [[57, "aimet_tensorflow.adaround.adaround_weight.Adaround.apply_adaround"]], "autoquant (class in aimet_tensorflow.auto_quant)": [[58, "aimet_tensorflow.auto_quant.AutoQuant"]], "apply() (aimet_tensorflow.auto_quant.autoquant method)": [[58, "aimet_tensorflow.auto_quant.AutoQuant.apply"]], "set_adaround_params() (aimet_tensorflow.auto_quant.autoquant method)": [[58, "aimet_tensorflow.auto_quant.AutoQuant.set_adaround_params"]], "fold_all_batch_norms_to_scale() (in module aimet_tensorflow.batch_norm_fold)": [[59, "aimet_tensorflow.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_tensorflow.bn_reestimation)": [[59, "aimet_tensorflow.bn_reestimation.reestimate_bn_stats"]], "biascorrectionparams() (in module aimet_tensorflow.bias_correction)": [[60, "aimet_tensorflow.bias_correction.BiasCorrectionParams"]], "quantparams (class in aimet_tensorflow.bias_correction)": [[60, "aimet_tensorflow.bias_correction.QuantParams"]], "analytical_bias_correction_per_layer() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.analytical_bias_correction_per_layer"]], "bias_correction_per_layer() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.bias_correction_per_layer"]], "correct_bias() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.correct_bias"]], "channelpruningparameters (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode"]], "modelcompressor (class in aimet_tensorflow.compress)": [[61, "aimet_tensorflow.compress.ModelCompressor"]], "svd (class in aimet_tensorflow.svd)": [[61, "aimet_tensorflow.svd.Svd"]], "auto (aimet_tensorflow.defs.channelpruningparameters.mode attribute)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode.auto"]], "compress_model() (aimet_tensorflow.compress.modelcompressor static method)": [[61, "aimet_tensorflow.compress.ModelCompressor.compress_model"]], "compress_net() (aimet_tensorflow.svd.svd method)": [[61, "aimet_tensorflow.svd.Svd.compress_net"]], "manual (aimet_tensorflow.defs.channelpruningparameters.mode attribute)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode.manual"]], "equalize_model() (in module aimet_tensorflow.cross_layer_equalization)": [[62, "aimet_tensorflow.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_tensorflow.layer_output_utils)": [[63, "aimet_tensorflow.layer_output_utils.LayerOutputUtil"]], "generate_layer_outputs() (aimet_tensorflow.layer_output_utils.layeroutpututil method)": [[63, "aimet_tensorflow.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "update_keras_bn_ops_trainable_flag() (in module aimet_tensorflow.utils.graph)": [[64, "aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"]], "clssetinfo (class in aimet_tensorflow.cross_layer_equalization)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_tensorflow.cross_layer_equalization)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_tensorflow.cross_layer_equalization.highbiasfold)": [[65, "aimet_tensorflow.cross_layer_equalization.HighBiasFold.bias_fold"], [65, "id0"]], "fold_all_batch_norms() (in module aimet_tensorflow.batch_norm_fold)": [[65, "aimet_tensorflow.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_tensorflow.batch_norm_fold)": [[65, "aimet_tensorflow.batch_norm_fold.fold_given_batch_norms"]], "map_cls_sets_to_new_session() (aimet_tensorflow.cross_layer_equalization.clssetinfo static method)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo.map_cls_sets_to_new_session"]], "scale_cls_sets() (in module aimet_tensorflow.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_tensorflow.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling.scale_model"]], "quantanalyzer (class in aimet_tensorflow.quant_analyzer)": [[66, "aimet_tensorflow.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_tensorflow.quant_analyzer.quantanalyzer method)": [[66, "aimet_tensorflow.quant_analyzer.QuantAnalyzer.analyze"]], "quantizationsimmodel (class in aimet_tensorflow.quantsim)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_tensorflow.quantsim.quantizationsimmodel method)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_tensorflow.quantsim.quantizationsimmodel method)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel.export"]], "visualize_relative_weight_ranges_single_layer() (in module aimet_tensorflow.plotting_utils)": [[69, "aimet_tensorflow.plotting_utils.visualize_relative_weight_ranges_single_layer"]], "visualize_weight_ranges_single_layer() (in module aimet_tensorflow.plotting_utils)": [[69, "aimet_tensorflow.plotting_utils.visualize_weight_ranges_single_layer"]], "adaroundparameters (class in aimet_torch.adaround.adaround_weight)": [[71, "aimet_torch.adaround.adaround_weight.AdaroundParameters"]], "apply_adaround() (in module aimet_torch.adaround.adaround_weight.adaround)": [[71, "aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"]], "check_model_arch() (in module aimet_torch.arch_checker.arch_checker.archchecker)": [[72, "aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"]], "autoquant (class in aimet_torch.auto_quant)": [[73, "aimet_torch.auto_quant.AutoQuant"]], "fold_all_batch_norms_to_scale() (in module aimet_torch.batch_norm_fold)": [[74, "aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_torch.bn_reestimation)": [[74, "aimet_torch.bn_reestimation.reestimate_bn_stats"]], "activationtype (class in aimet_common.defs)": [[75, "aimet_common.defs.ActivationType"]], "convbninfotype (class in aimet_common.bias_correction)": [[75, "aimet_common.bias_correction.ConvBnInfoType"]], "quantparams (class in aimet_torch.quantsim)": [[75, "aimet_torch.quantsim.QuantParams"]], "correct_bias() (in module aimet_torch.bias_correction)": [[75, "aimet_torch.bias_correction.correct_bias"]], "no_activation (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.no_activation"]], "relu (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.relu"]], "relu6 (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.relu6"]], "channelpruningparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode"]], "greedyselectionparameters (class in aimet_common.defs)": [[76, "aimet_common.defs.GreedySelectionParameters"]], "modelcompressor (class in aimet_torch.compress)": [[76, "aimet_torch.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode"]], "tarrankselectionparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.TarRankSelectionParameters"]], "weightsvdparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters"]], "weightsvdparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.AutoModeParams"]], "weightsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.ManualModeParams"]], "weightsvdparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode"]], "auto (aimet_torch.defs.channelpruningparameters.mode attribute)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode.auto"]], "auto (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode.auto"]], "auto (aimet_torch.defs.weightsvdparameters.mode attribute)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode.auto"]], "compress_model() (aimet_torch.compress.modelcompressor static method)": [[76, "aimet_torch.compress.ModelCompressor.compress_model"]], "manual (aimet_torch.defs.channelpruningparameters.mode attribute)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode.manual"]], "manual (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode.manual"]], "manual (aimet_torch.defs.weightsvdparameters.mode attribute)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode.manual"]], "equalize_model() (in module aimet_torch.cross_layer_equalization)": [[77, "aimet_torch.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_torch.layer_output_utils)": [[78, "aimet_torch.layer_output_utils.LayerOutputUtil"]], "namingscheme (class in aimet_torch.layer_output_utils)": [[78, "aimet_torch.layer_output_utils.NamingScheme"]], "onnx (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.ONNX"]], "pytorch (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.PYTORCH"]], "torchscript (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"]], "generate_layer_outputs() (aimet_torch.layer_output_utils.layeroutpututil method)": [[78, "aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "prepare_model() (in module aimet_torch.model_preparer)": [[80, "aimet_torch.model_preparer.prepare_model"]], "adaptermetadata (class in aimet_torch.peft)": [[83, "aimet_torch.peft.AdapterMetaData"]], "peftquantutils (class in aimet_torch.peft)": [[83, "aimet_torch.peft.PeftQuantUtils"]], "disable_lora_adapters() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"]], "enable_adapter_and_load_weights() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"]], "export_adapter_weights() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.export_adapter_weights"]], "freeze_base_model() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.freeze_base_model"]], "freeze_base_model_activation_quantizers() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"]], "freeze_base_model_param_quantizers() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"]], "get_quantized_lora_layer() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"]], "replace_lora_layers_with_quantizable_layers() (aimet_torch.peft method)": [[83, "aimet_torch.peft.replace_lora_layers_with_quantizable_layers"]], "save_lora_weights_after_adaptation() (aimet_torch.peft method)": [[83, "aimet_torch.peft.save_lora_weights_after_adaptation"]], "set_bitwidth_for_lora_adapters() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"]], "track_lora_meta_data() (aimet_torch.peft method)": [[83, "aimet_torch.peft.track_lora_meta_data"]], "clssetinfo (class in aimet_torch.cross_layer_equalization)": [[84, "aimet_torch.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_torch.cross_layer_equalization)": [[84, "aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_torch.cross_layer_equalization.highbiasfold)": [[84, "aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"], [84, "id0"]], "fold_all_batch_norms() (in module aimet_torch.batch_norm_fold)": [[84, "aimet_torch.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_torch.batch_norm_fold)": [[84, "aimet_torch.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[84, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[84, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"]], "callbackfunc (class in aimet_common.utils)": [[85, "aimet_common.utils.CallbackFunc"]], "quantanalyzer (class in aimet_torch.quant_analyzer)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.analyze"]], "check_model_sensitivity_to_quantization() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"]], "enable_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"]], "export_per_layer_encoding_min_max_range() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"]], "export_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"]], "export_per_layer_stats_histogram() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"]], "perform_per_layer_analysis_by_disabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"]], "perform_per_layer_analysis_by_enabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"]], "quantizationsimmodel (class in aimet_torch.quantsim)": [[87, "aimet_torch.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_torch.quantsim.quantizationsimmodel method)": [[87, "aimet_torch.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_torch.quantsim.quantizationsimmodel method)": [[87, "aimet_torch.quantsim.QuantizationSimModel.export"]], "load_checkpoint() (aimet_torch.quantsim method)": [[87, "aimet_torch.quantsim.load_checkpoint"]], "save_checkpoint() (aimet_torch.quantsim method)": [[87, "aimet_torch.quantsim.save_checkpoint"]], "visualizecompression (class in aimet_torch.visualize_serialized_data)": [[88, "aimet_torch.visualize_serialized_data.VisualizeCompression"]], "display_comp_ratio_plot() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[88, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"]], "display_eval_scores() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[88, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"]], "visualize_changes_after_optimization() (in module aimet_torch.visualize_model)": [[89, "aimet_torch.visualize_model.visualize_changes_after_optimization"]], "visualize_relative_weight_ranges_to_identify_problematic_layers() (in module aimet_torch.visualize_model)": [[89, "aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"]], "visualize_weight_ranges() (in module aimet_torch.visualize_model)": [[89, "aimet_torch.visualize_model.visualize_weight_ranges"]]}})