<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AIMET Model Compression &mdash; AI Model Efficiency Toolkit Documentation: ver 1.33.5</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../torch_docs/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.33.5
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/tutorials/quickstart_guide.html">Quickstart Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/examples/ptq.html">Post-Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Feature Descriptions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="adaround.html"> Adaptive Rounding (AdaRound)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AIMET PyTorch API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/quantized_modules.html">Quantized Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/quantizer.html">Quantizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/encoding_analyzer.html">Encoding Analyzers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer.html">MinMaxEncodingAnalyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.html">SqnrEncodingAnalyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.html">PercentileEncodingAnalyzer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html">FakeQuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html">QuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html">quantization.affine</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize.html">Quantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize.html">QuantizeDequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_.html">quantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize.html">quantize_dequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize.html">dequantize</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html">quantization.float</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../torch_docs/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../torch_docs/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">AIMET Model Compression</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/model_compression.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="aimet-model-compression">
<span id="ug-model-compression"></span><h1>AIMET Model Compression<a class="headerlink" href="#aimet-model-compression" title="Permalink to this heading"></a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a></h2>
<p>AIMET provides a model compression library that can be used to reduce a model’s MAC and memory costs with a minimal
drop in accuracy. AIMET supports various compression schemes like Weight SVD, Spatial SVD and Channel Pruning.</p>
<div class="toctree-wrapper compound">
</div>
<p>Please see the <a class="reference internal" href="compression_feature_guidebook.html#ug-comp-guidebook"><span class="std std-ref">Compression Guidebook</span></a> - which includes some practical advice on using the compression features, and how to combine the features</p>
</div>
<div class="section" id="use-case">
<h2>Use Case<a class="headerlink" href="#use-case" title="Permalink to this heading"></a></h2>
<p>AIMET allows user to take a trained model and compress it to desired compression ratio which can be further fine-tuned and exported to a target.
All of the compression schemes in AIMET use a two-step process - Compression ratio selection followed by model
compression.</p>
<img alt="../_images/compression_use_case.PNG" src="../_images/compression_use_case.PNG" />
<p>The following sub-sections explain these steps in more detail.</p>
</div>
<div class="section" id="compression-ratio-selection">
<h2>Compression ratio selection<a class="headerlink" href="#compression-ratio-selection" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
</div>
<ul class="simple">
<li><p><a class="reference internal" href="greedy_compression_ratio_selection.html#ug-greedy-comp-ratio-selection"><span class="std std-ref">Greedy Compression Ratio Selection</span></a>: During this phase, individual layers of the original model are analyzed to determine optimal compression ratios per layer. Currently AIMET supports the Greedy Compression Ratio Selection method.</p></li>
<li><p>Manual Compression Ratio Selection: As an alternative to AIMET automatically selecting optimal compression ratios per layer, the user has a choice to specify compression ratios manually per layer. The suggested procedure would be to use the Greedy Compression Ratio Selection method to get a nominal set of compression ratios first. And then use this as the starting point for manually changing compression ratios for one or more layers.</p></li>
</ul>
<p>To visualize various usage of the compression tool we can use:</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="visualization_compression.html">Visualization</a></li>
</ul>
</div>
</div>
<div class="section" id="model-compression">
<h2>Model Compression<a class="headerlink" href="#model-compression" title="Permalink to this heading"></a></h2>
<p>In this phase, AIMET will apply the compression ratios per layer to create a compressed model.
Currently, AIMET supports the following model compression algorithms.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="weight_svd.html">Weight SVD</a></li>
<li class="toctree-l1"><a class="reference internal" href="spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l1"><a class="reference internal" href="channel_pruning.html">Channel Pruning</a></li>
</ul>
</div>
</div>
<div class="section" id="optional-techniques-to-get-better-compression-results">
<h2>Optional techniques to get better compression results<a class="headerlink" href="#optional-techniques-to-get-better-compression-results" title="Permalink to this heading"></a></h2>
<p>AIMET supports the following techniques that can be optionally used to get better compression results</p>
<ul class="simple">
<li><p>Rank-rounding</p></li>
<li><p>Per-layer fine-tuning</p></li>
</ul>
<div class="section" id="rank-rounding">
<h3>Rank Rounding<a class="headerlink" href="#rank-rounding" title="Permalink to this heading"></a></h3>
<p>Often ML runtime-software like those for Embedded ML accelerators, will prefer the dimensions of layers like Conv2d or FC to be of a certain multiplicity. Matching the expected dimension size will result in optimal runtime for that layer. AIMET techniques like Weight/Spatial SVD or Channel Pruning, try to decompose layers or reduce layers - specifically in terms of output channels and input channels. The rank-rounding feature in AIMET will try and reduce layers to match a user-provided multiplicity. By default this feature is disabled. At present, AIMET allows the user to specify a multiplicity-factor for the entire model, not on a per-layer basis.</p>
<p>Users can make use of this feature to generate more optimal models for running on embedded targets.</p>
</div>
<div class="section" id="per-layer-fine-tuning">
<h3>Per-layer Fine-tuning<a class="headerlink" href="#per-layer-fine-tuning" title="Permalink to this heading"></a></h3>
<p>Given a user-model and desired compression-ratio, the user may sometimes notice a sharp degradation in accuracy after compression but before fine-tuning. One technique that might help the overall compression of such scenarios, is using a feature called per-layer fine-tuning. When this feature is selected, AIMET invokes a user-provided fine-tuning function after compressing every layer that was selected for compression. This is done during the Model Compression phase in the diagram shown above.</p>
<p>Note: The user is responsible for choosing appropriate learning-rates and other training parameters for fine-tuning. Using this feature may require the user to carefully pick the learning rates and learning-rate-decay parameters to be used during fine-tuning.</p>
</div>
</div>
<div class="section" id="faqs">
<h2>FAQs<a class="headerlink" href="#faqs" title="Permalink to this heading"></a></h2>
<ol class="arabic">
<li><p>Which technique is the best technique to use for compression?</p>
<p><em>We see best results when Spatial SVD is performed followed by Channel Pruning.</em></p>
</li>
<li><p>Can we combine the different techniques?</p>
<p><em>Yes, as stated in 1, different techniques can be combined together to get better accuracy. Compression can be combined with Post-training Quantization techniques as well to get a better model for target.</em></p>
</li>
<li><p>How to take a model to target after compression?</p>
<p><em>To take a model to target it needs to be first compressed using the above techniques and then it should be quantized and exported to target</em></p>
</li>
<li><p>Greedy rank selection is very slow. Can something be done to speed it up?</p>
<p><em>Greedy rank selection in itself is not time consuming. The time consuming part is creating the eval-score dictionary. For different experiments, eval-score dictionary can be generated once and then loaded into the searcher. Or, one can reduce the number of candidates over which the eval-score dictionary is created. But lesser the number of candidates, lesser the granularity. To strike a balance the value of 10 candidates was chosen.</em></p>
</li>
<li><p>Is per-layer fine tuning helpful?</p>
<p><em>Per-layer fine tuning is an experimental technique. We have not observed major gains by using it. But one can try out if it works for their model. In practice, we have observed that the best combination is to do say 1 epoch of fine-tuning per-layer and then do say 10-15 epochs of fine-tuning for the entire compressed model at the end.</em></p>
</li>
</ol>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Xiangyu Zhang, Jianhua Zou, Kaiming He, and Jian Sun. “Accelerating Very Deep Convolutional Networks for Classification and Detection.” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943-1955, 1 Oct. 2016.</p></li>
<li><p>Yihui He, Xiangyu Zhang, and Jian Sun. “Channel Pruning for Accelerating Very Deep Neural Networks.” IEEE International Conference on Computer Vision (ICCV), Venice, 2017, pp. 1398-1406.</p></li>
<li><p>Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. “Speeding up Convolutional Neural Networks with Low Rank Expansions.” British Machine Vision Conference, Jan. 2014.</p></li>
<li><p>Andrey Kuzmin, Markus Nagel, Saurabh Pitre, Sandeep Pendyam, Tijmen Blankevoort, Max Welling. “Taxonomy and Evaluation of Structured Compression of Convolutional Neural Networks.”</p></li>
</ol>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>