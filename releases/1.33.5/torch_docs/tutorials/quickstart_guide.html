<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quickstart Guide &mdash; AI Model Efficiency Toolkit Documentation: ver 1.33.5</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
      <link rel="stylesheet" href="../../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../../user_guide/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.33.5
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/model_quantization.html"> Quantization User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_quantization.html#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_quantization.html#aimet-quantization-features">AIMET Quantization Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantization_sim.html"> Quantization Simulation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#quantsim-workflow">QuantSim Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#simulating-quantization-noise">Simulating Quantization Noise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#determining-quantization-parameters-encodings">Determining Quantization Parameters (Encodings)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#quantization-schemes">Quantization Schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#configuring-quantization-simulation-ops">Configuring Quantization Simulation Ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_sim.html#frequently-asked-questions">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantization_aware_training.html"> Quantization-Aware Training (QAT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_aware_training.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_aware_training.html#qat-workflow">QAT workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_aware_training.html#qat-modes">QAT modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantization_aware_training.html#recommendations-for-quantization-aware-training">Recommendations for Quantization-Aware Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/model_quantization.html#post-training-quantization"><span class="hideitem">Post-Training Quantization</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/auto_quant.html">AutoQuant</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/auto_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/auto_quant.html#workflow">Workflow</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/adaround.html">Adaptive Rounding (AdaRound)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/adaround.html#adaround-use-cases">AdaRound Use Cases</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/adaround.html#common-terminology">Common terminology</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/adaround.html#use-cases">Use Cases</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html">Cross-Layer Equalization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/bn_reestimation.html">BN Re-estimation</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/bn_reestimation.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/bn_reestimation.html#workflow">Workflow</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html">Bias Correction [Depricated]</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/model_quantization.html#debugging-analysis-tools"><span class="hideitem">Debugging/Analysis Tools</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quant_analyzer.html">QuantAnalyzer</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/quant_analyzer.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/quant_analyzer.html#requirements">Requirements</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/quant_analyzer.html#detailed-analysis-descriptions">Detailed Analysis Descriptions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/visualization_quant.html">Visualizations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/visualization_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/visualization_quant.html#quantization">Quantization</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../user_guide/visualization_quant.html#pytorch">PyTorch</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../user_guide/visualization_quant.html#tensorflow">TensorFlow</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_quantization.html#aimet-quantization-workflow">AIMET Quantization Workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/model_quantization.html#pytorch"><span class="hideitem">PyTorch</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_model_guidelines.html"> PyTorch Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_quantization.html"> AIMET PyTorch Quantization APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo.ClsSetLayerPairInfo</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html">PEFT LoRA</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_fp_lora_layer()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.quantize_lora_scale_with_fixed_range()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/model_quantization.html#tensorflow"><span class="hideitem">Tensorflow</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_model_guidelines.html"> TensorFlow Model Guidelines</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_model_guidelines.html#aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"><code class="docutils literal notranslate"><span class="pre">update_keras_bn_ops_trainable_flag()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_quantization.html#debugging-guidelines">Debugging Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantization_feature_guidebook.html">Quantization Guidebook</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/model_compression.html"> Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/compression_feature_guidebook.html">Compression Guidebook</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/greedy_compression_ratio_selection.html">Greedy Compression Ratio Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/greedy_compression_ratio_selection.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/greedy_compression_ratio_selection.html#how-it-works">How it works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/greedy_compression_ratio_selection.html#per-layer-exploration">Per-layer Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/greedy_compression_ratio_selection.html#compression-ratio-selection">Compression Ratio Selection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/channel_pruning.html#winnowing">Winnowing</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../user_guide/winnowing.html">Winnowing</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../user_guide/winnowing.html#overview">Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../user_guide/winnowing.html#winnowing-overview">Winnowing Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../user_guide/winnowing.html#how-winnowing-works">How Winnowing Works</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api_docs/index.html"> API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_docs/torch.html">AIMET APIs for PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/torch_quantization.html">PyTorch Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_model_preparer.html#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo.ClsSetLayerPairInfo</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_peft_lora.html">PEFT LoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_fp_lora_layer()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.quantize_lora_scale_with_fixed_range()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_common.defs.GreedySelectionParameters"><code class="docutils literal notranslate"><span class="pre">GreedySelectionParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#tar-selection-parameters">TAR Selection Parameters</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.TarRankSelectionParameters"><code class="docutils literal notranslate"><span class="pre">TarRankSelectionParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_compress.html#aimet_torch.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_eval_scores()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_comp_ratio_plot()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"><code class="docutils literal notranslate"><span class="pre">visualize_relative_weight_ranges_to_identify_problematic_layers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_weight_ranges"><code class="docutils literal notranslate"><span class="pre">visualize_weight_ranges()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_changes_after_optimization"><code class="docutils literal notranslate"><span class="pre">visualize_changes_after_optimization()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme"><code class="docutils literal notranslate"><span class="pre">NamingScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.ONNX"><code class="docutils literal notranslate"><span class="pre">NamingScheme.ONNX</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.PYTORCH"><code class="docutils literal notranslate"><span class="pre">NamingScheme.PYTORCH</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"><code class="docutils literal notranslate"><span class="pre">NamingScheme.TORCHSCRIPT</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_docs/tensorflow.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/tensorflow_model_guidelines.html">TensorFlow Model Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_model_guidelines.html#aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"><code class="docutils literal notranslate"><span class="pre">update_keras_bn_ops_trainable_flag()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/tensorflow_quantization.html">TensorFlow Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/tensorflow_compress.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.Mode"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CostMetric"><code class="docutils literal notranslate"><span class="pre">CostMetric</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CostMetric.mac"><code class="docutils literal notranslate"><span class="pre">CostMetric.mac</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CostMetric.memory"><code class="docutils literal notranslate"><span class="pre">CostMetric.memory</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CompressionScheme"><code class="docutils literal notranslate"><span class="pre">CompressionScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CompressionScheme.channel_pruning"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.channel_pruning</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CompressionScheme.spatial_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.spatial_svd</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_common.defs.CompressionScheme.weight_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.weight_svd</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#code-examples">Code Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#weight-svd-top-level-api">Weight SVD Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.svd.Svd"><code class="docutils literal notranslate"><span class="pre">Svd</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#aimet_tensorflow.svd.Svd.compress_net"><code class="docutils literal notranslate"><span class="pre">Svd.compress_net()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_compress.html#code-examples-for-weight-svd">Code Examples for Weight SVD</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/tensorflow_visualization_quantization.html">TensorFlow Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_visualization_quantization.html#top-level-api-for-visualization-of-weight-tensors">Top-level API for Visualization of Weight tensors</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_visualization_quantization.html#aimet_tensorflow.plotting_utils.visualize_weight_ranges_single_layer"><code class="docutils literal notranslate"><span class="pre">visualize_weight_ranges_single_layer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_visualization_quantization.html#aimet_tensorflow.plotting_utils.visualize_relative_weight_ranges_single_layer"><code class="docutils literal notranslate"><span class="pre">visualize_relative_weight_ranges_single_layer()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_visualization_quantization.html#code-examples-for-visualization-of-weight-tensors">Code Examples for Visualization of Weight tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html">Using AIMET Tensorflow APIs with Keras Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#apis">APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.save_tf_session_single_gpu"><code class="docutils literal notranslate"><span class="pre">save_tf_session_single_gpu()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.load_tf_sess_variables_to_keras_single_gpu"><code class="docutils literal notranslate"><span class="pre">load_tf_sess_variables_to_keras_single_gpu()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.save_as_tf_module_multi_gpu"><code class="docutils literal notranslate"><span class="pre">save_as_tf_module_multi_gpu()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.load_keras_model_multi_gpu"><code class="docutils literal notranslate"><span class="pre">load_keras_model_multi_gpu()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#code-example">Code Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/convert_tf_sess_to_keras.html#utility-functions">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/tensorflow_layer_output_generation.html">Tensorflow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/tensorflow_layer_output_generation.html#aimet_tensorflow.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/tensorflow_layer_output_generation.html#aimet_tensorflow.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/tensorflow_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_docs/keras.html">AIMET APIs for Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/keras_quantization.html">Keras Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_model_preparer.html#aimet_tensorflow.keras.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_model_preparer.html#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_quant_analyzer.html#aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_quant_analyzer.html#aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_adaround.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#aimet_tensorflow.keras.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#custom-datatype-used">Custom Datatype used</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo.ClsSetLayerPairInfo</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#code-example-for-lower-level-apis">Code Example for Lower level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_primitive_apis_cle.html#example-helper-methods-to-perform-cle-in-manual-mode">Example helper methods to perform CLE in manual mode</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_batchnorm_re_estimation.html#limitations">Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/keras_layer_output_generation.html">Keras Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_layer_output_generation.html#aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_layer_output_generation.html#aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/keras_compression.html">Keras Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_compression.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_compression.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.keras.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.keras.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_compression.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_compression.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_compression.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CostMetric"><code class="docutils literal notranslate"><span class="pre">CostMetric</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CostMetric.mac"><code class="docutils literal notranslate"><span class="pre">CostMetric.mac</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CostMetric.memory"><code class="docutils literal notranslate"><span class="pre">CostMetric.memory</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme"><code class="docutils literal notranslate"><span class="pre">CompressionScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme.channel_pruning"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.channel_pruning</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme.spatial_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.spatial_svd</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme.weight_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.weight_svd</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/keras_compression.html#aimet_tensorflow.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/keras_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_docs/onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/onnx_quantization.html">ONNX Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_quantsim.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_cross_layer_equalization.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_adaround.html#adaround-parameters">Adaround Parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_auto_quant.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_quant_analyzer.html"> QuantAnalyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_quant_analyzer.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_quant_analyzer.html#run-specific-utility">Run specific utility</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../api_docs/onnx_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_docs/onnx_layer_output_generation.html">ONNX Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_docs/onnx_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_docs/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/examples.html"> Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html"> Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html#quick-install">Quick Install</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html#release-packages">Release Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/index.html#advanced-installation-instructions">Advanced Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-gpu-packages">Install GPU packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../install/install_host.html#install-gpu-packages-for-pytorch-2-1-or-tensorflow">Install GPU packages for PyTorch 2.1 or TensorFlow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../install/install_host.html#install-gpu-packages-for-pytorch-1-13-or-onnx">Install GPU packages for PyTorch 1.13 or ONNX</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../install/install_host.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../install/install_host.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_docker.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../install/install_docker.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../install/install_docker.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../user_guide/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../user_guide/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Quickstart Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/torch_docs/tutorials/quickstart_guide.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="quickstart-guide">
<span id="tutorials-quickstart-guide"></span><h1>Quickstart Guide<a class="headerlink" href="#quickstart-guide" title="Permalink to this heading"></a></h1>
<p>In this tutorial, we will go through the end-to-end process of using AIMET and PyTorch to create, calibrate, and export
a simple quantized model. Note that this is intended to show the most basic workflow in AIMET. It is <em>not</em> meant to
demonstrate the most state-of-the-art techniques available in AIMET.</p>
<div class="section" id="overall-flow">
<h2>Overall flow<a class="headerlink" href="#overall-flow" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Define the basic floating-point PyTorch model, training, and eval loops</p></li>
<li><p>Prepare the trained model for quantization</p></li>
<li><p>Create quantization simulation (quantsim) model in AIMET to simulate the effects of quantization</p></li>
<li><p>Calibrate the quantsim model on training data and evaluate the quantized accuracy</p></li>
<li><p>Fine-tune the quantized model to improve the quantized accuracy</p></li>
<li><p>Export the quantized model</p></li>
</ol>
</div>
<div class="section" id="pytorch-prerequisites">
<h2>PyTorch prerequisites<a class="headerlink" href="#pytorch-prerequisites" title="Permalink to this heading"></a></h2>
<p>To see clearly what happens inside AIMET, lets first start with some simple PyTorch code for defining, training, and
evaluating a model. The code below is adapted from PyTorchs
<a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html">basic optimization tutorial</a>.
Note that AIMET does not have any special requirement on what these training/eval loops look like.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># 1) Start with some data loaders to train, evaluate, and calibrate the model</span>

<span class="n">cifar10_train_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s1">&#39;/tmp/cifar10&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">cifar10_test_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="s1">&#39;/tmp/cifar10&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">cifar10_train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">cifar10_train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 2) Define a simple model to train on this dataset</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn_2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># 3) Define an evaluation loop for the model</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="mf">100.</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
<p>Now, lets instantiate a network and train for a few epochs on our dataset to establish a baseline floating-point model</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>

<span class="c1"># Send the model to the desired device (optional)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define some loss function and optimizer</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># Train for 4 epochs</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Evaluate the floating-point model</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">fp_accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Floating point accuracy: </span><span class="si">{</span><span class="n">fp_accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>Floating point accuracy: 91.70999908447266
</pre></div>
</div>
</div>
<div class="section" id="prepare-the-floating-point-model-for-quantization">
<h2>Prepare the floating point model for quantization<a class="headerlink" href="#prepare-the-floating-point-model-for-quantization" title="Permalink to this heading"></a></h2>
<p>Before we can (accurately) simulate quantization, there are a couple important steps to take care of:</p>
<div class="section" id="model-preparation">
<h3>1) Model preparation<a class="headerlink" href="#model-preparation" title="Permalink to this heading"></a></h3>
<p>AIMETs quantization simulation tool (<code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code>) expects the floating point model to conform to some
specific guidelines. For example, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code> is only able to quantize math operations performed by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> objects, whereas <code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.nn.functional</span></code> calls will be (incorrectly) ignored.</p>
<p>If we look back at our previous model definition, we see it calls <code class="xref py py-func docutils literal notranslate"><span class="pre">F.relu()</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">F.softmax()</span></code> in the forward
function. Does this mean we need to completely redefine our model to use AIMET? Thankfully, no. AIMET provides the
<code class="xref py py-mod docutils literal notranslate"><span class="pre">model_preparer</span></code> API to transform our incompatible model into a new fully-compatible model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch</span> <span class="kn">import</span> <span class="n">model_preparer</span>

<span class="n">prepared_model</span> <span class="o">=</span> <span class="n">model_preparer</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>

<span class="c1"># Note: This transformation should not change the model&#39;s forward function at all</span>
<span class="n">fp_accuracy_prepared</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">fp_accuracy_prepared</span> <span class="o">==</span> <span class="n">fp_accuracy</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>2024-05-07 14:39:22,747 - root - INFO - AIMET
2024-05-07 14:39:22,806 - ModelPreparer - INFO - Functional         : Adding new module for node: {module_relu}
2024-05-07 14:39:22,806 - ModelPreparer - INFO - Functional         : Adding new module for node: {module_relu_1}
2024-05-07 14:39:22,806 - ModelPreparer - INFO - Functional         : Adding new module for node: {module_softmax}
GraphModule(
  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=12544, out_features=10, bias=True)
  (module_relu): ReLU()
  (module_relu_1): ReLU()
  (module_softmax): Softmax(dim=-1)
)



def forward(self, x):
    conv1 = self.conv1(x);  x = None
    bn_1 = self.bn_1(conv1);  conv1 = None
    module_relu = self.module_relu(bn_1);  bn_1 = None
    conv2 = self.conv2(module_relu);  module_relu = None
    bn_2 = self.bn_2(conv2);  conv2 = None
    module_relu_1 = self.module_relu_1(bn_2);  bn_2 = None
    getattr_1 = module_relu_1.shape
    getitem = getattr_1[0];  getattr_1 = None
    view = module_relu_1.view(getitem, -1);  module_relu_1 = getitem = None
    linear = self.linear(view);  view = None
    module_softmax = self.module_softmax(linear);  linear = None
    return module_softmax

# To see more debug info, please use `graph_module.print_readable()`
</pre></div>
</div>
<p>Note how the prepared model now contains distinct modules for the <code class="xref py py-func docutils literal notranslate"><span class="pre">relu()</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">softmax()</span></code> operations.</p>
</div>
<div class="section" id="batchnorm-fold">
<h3>2) BatchNorm fold<a class="headerlink" href="#batchnorm-fold" title="Permalink to this heading"></a></h3>
<p>When models are executed in a quantized runtime, batchnorm layers are typically folded into the weight and bias of
an adjacent convolution layer whenever possible in order to remove unnecessary computations. To accurately simulate
inference in these runtimes, it is generally a good idea to perform this batchnorm folding on the floating point model
before applying quantization. AIMET provides the <code class="xref py py-mod docutils literal notranslate"><span class="pre">batch_norm_fold</span></code> tool to do this.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch</span> <span class="kn">import</span> <span class="n">batch_norm_fold</span>

<span class="n">sample_input</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">batch_norm_fold</span><span class="o">.</span><span class="n">fold_all_batch_norms</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">,</span> <span class="n">input_shapes</span><span class="o">=</span><span class="n">sample_input</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>GraphModule(
  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn_1): Identity()
  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn_2): Identity()
  (linear): Linear(in_features=12544, out_features=10, bias=True)
  (module_relu): ReLU()
  (module_relu_1): ReLU()
  (module_softmax): Softmax(dim=-1)
)



def forward(self, x):
    conv1 = self.conv1(x);  x = None
    bn_1 = self.bn_1(conv1);  conv1 = None
    module_relu = self.module_relu(bn_1);  bn_1 = None
    conv2 = self.conv2(module_relu);  module_relu = None
    bn_2 = self.bn_2(conv2);  conv2 = None
    module_relu_1 = self.module_relu_1(bn_2);  bn_2 = None
    getattr_1 = module_relu_1.shape
    getitem = getattr_1[0];  getattr_1 = None
    view = module_relu_1.view(getitem, -1);  module_relu_1 = getitem = None
    linear = self.linear(view);  view = None
    module_softmax = self.module_softmax(linear);  linear = None
    return module_softmax

# To see more debug info, please use `graph_module.print_readable()`
</pre></div>
</div>
<p>Note that the model now has <code class="xref py py-class docutils literal notranslate"><span class="pre">Identity</span></code> (passthrough) layers where it previously had <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm2d</span></code> layers. Like the
<code class="xref py py-mod docutils literal notranslate"><span class="pre">model_preparer</span></code> step, this operation should not impact the models accuracy.</p>
</div>
</div>
<div class="section" id="quantize-the-model">
<h2>Quantize the model<a class="headerlink" href="#quantize-the-model" title="Permalink to this heading"></a></h2>
<p>Now, we are ready to use AIMETs <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code> to simulate quantizing the floating point model. This
involves two steps:</p>
<ol class="arabic simple">
<li><p>Add quantizers to simulate quantization noise during the models forward pass</p></li>
<li><p>Calibrate the quantizer encodings (e.g., min/max ranges) on some sample inputs</p></li>
</ol>
<p>Calibration is necessary to determine the range of values each activation quantizer is likely to encounter in the
models forward pass, and should therefore be able to represent. Theoretically, we could pass the entire training
dataset through the model for calibration, but in practice we usually only need about 500-1000 representative samples
to accurately estimate the ranges.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">aimet_torch.v2</span> <span class="k">as</span> <span class="nn">aimet</span>
<span class="kn">from</span> <span class="nn">aimet_torch.v2</span> <span class="kn">import</span> <span class="n">quantsim</span>

<span class="c1"># QuantizationSimModel will convert each nn.Module in prepared_model into a quantized equivalent module and configure the module&#39;s quantizers</span>
<span class="c1"># In this case, we will quantize all parameters to 4 bits and all activations to 8 bits.</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">quantsim</span><span class="o">.</span><span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">,</span>
                                    <span class="n">dummy_input</span><span class="o">=</span><span class="n">sample_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                                    <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>                                <span class="c1"># Simulate 8-bit activations</span>
                                    <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>                                 <span class="c1"># Simulate 4-bit weights</span>

<span class="c1"># Inside the compute_encodings context, quantizers will observe the statistics of the activations passing through them. These statistics will be used</span>
<span class="c1"># to compute properly calibrated encodings upon exiting the context.</span>
<span class="k">with</span> <span class="n">aimet</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>
            <span class="k">break</span>

<span class="c1"># Compare the accuracy before and after quantization:</span>
<span class="n">quantized_accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Floating point model accuracy: </span><span class="si">{</span><span class="n">fp_accuracy</span><span class="si">}</span><span class="s2"> %</span><span class="se">\n</span><span class="s2">&quot;</span>
      <span class="sa">f</span><span class="s2">&quot;Quantized model accuracy: </span><span class="si">{</span><span class="n">quantized_accuracy</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>GraphModule(
  (conv1): QuantizedConv2d(
    1, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
    (param_quantizers): ModuleDict(
      (weight): QuantizeDequantize(shape=[1], bitwidth=4, symmetric=True)
      (bias): None
    )
    (input_quantizers): ModuleList(
      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
    )
    (output_quantizers): ModuleList(
      (0): None
    )
  )
  (bn_1): Identity()
  (module_relu): FakeQuantizedReLU(
    (param_quantizers): ModuleDict()
    (input_quantizers): ModuleList(
      (0): None
    )
    (output_quantizers): ModuleList(
      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
    )
  )
  (conv2): QuantizedConv2d(
    128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)
    (param_quantizers): ModuleDict(
      (weight): QuantizeDequantize(shape=[1], bitwidth=4, symmetric=True)
      (bias): None
    )
    (input_quantizers): ModuleList(
      (0): None
    )
    (output_quantizers): ModuleList(
      (0): None
    )
  )
  (bn_2): Identity()
  (module_relu_1): FakeQuantizedReLU(
    (param_quantizers): ModuleDict()
    (input_quantizers): ModuleList(
      (0): None
    )
    (output_quantizers): ModuleList(
      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
    )
  )
  (linear): QuantizedLinear(
    in_features=12544, out_features=10, bias=True
    (param_quantizers): ModuleDict(
      (weight): QuantizeDequantize(shape=[1], bitwidth=4, symmetric=True)
      (bias): None
    )
    (input_quantizers): ModuleList(
      (0): None
    )
    (output_quantizers): ModuleList(
      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
    )
  )
  (module_softmax): QuantizedSoftmax(
    dim=-1
    (param_quantizers): ModuleDict()
    (input_quantizers): ModuleList(
      (0): None
    )
    (output_quantizers): ModuleList(
      (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
    )
  )
)



def forward(self, x):
    conv1 = self.conv1(x);  x = None
    bn_1 = self.bn_1(conv1);  conv1 = None
    module_relu = self.module_relu(bn_1);  bn_1 = None
    conv2 = self.conv2(module_relu);  module_relu = None
    bn_2 = self.bn_2(conv2);  conv2 = None
    module_relu_1 = self.module_relu_1(bn_2);  bn_2 = None
    getattr_1 = module_relu_1.shape
    getitem = getattr_1[0];  getattr_1 = None
    view = module_relu_1.view(getitem, -1);  module_relu_1 = getitem = None
    linear = self.linear(view);  view = None
    module_softmax = self.module_softmax(linear);  linear = None
    return module_softmax

# To see more debug info, please use `graph_module.print_readable()`
Floating point model accuracy: 91.70999908447266 %
Quantized model accuracy: 91.1500015258789 %
</pre></div>
</div>
<p>Here, we can see that <code class="docutils literal notranslate"><span class="pre">sim.model</span></code> is nothing more than the <code class="docutils literal notranslate"><span class="pre">prepared_model</span></code> with every layer replaced with a
quantized version of the layer. The quantization behavior of each module is determined by the configuration of its
held quantizers.</p>
<p>For example, we can see that <code class="docutils literal notranslate"><span class="pre">sim.model.conv2</span></code> has a 4-bit weight quantizer and an 8-bit output quantizer as specified
during construction. We will discuss more advanced ways to configure these quantizers to optimize performance and
accuracy in a later tutorial.</p>
</div>
<div class="section" id="fine-tune-the-model-with-quantization-aware-training">
<h2>Fine-tune the model with quantization aware training<a class="headerlink" href="#fine-tune-the-model-with-quantization-aware-training" title="Permalink to this heading"></a></h2>
<p>If were not satisfied with our accuracy after applying quantization, there are some steps we can take to further
optimize the quantized accuracy. One such step is quantization aware training (QAT), during which the model is trained
with the fake-quantization ops present.</p>
<p>Lets repeat our floating-point training loop for one more epoch, but this time use the quantized model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define some loss function and optimizer</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># Train for one more epoch on the quantsim model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>


<span class="c1"># Compare the accuracy before and after QAT:</span>
<span class="n">post_QAT_accuracy</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original quantized model accuracy: </span><span class="si">{</span><span class="n">quantized_accuracy</span><span class="si">}</span><span class="s2"> %</span><span class="se">\n</span><span class="s2">&quot;</span>
      <span class="sa">f</span><span class="s2">&quot;Post-QAT model accuracy: </span><span class="si">{</span><span class="n">post_QAT_accuracy</span><span class="si">}</span><span class="s2"> %&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>Original quantized model accuracy: 91.1500015258789 %
Post-QAT model accuracy: 92.05333709716797 %
</pre></div>
</div>
</div>
<div class="section" id="export-the-quantsim-model">
<h2>Export the quantsim model<a class="headerlink" href="#export-the-quantsim-model" title="Permalink to this heading"></a></h2>
<p>Now that we are happy with our quantized models accuracy, we are ready to export the model with its quantization parameters.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">export_path</span> <span class="o">=</span> <span class="s2">&quot;/tmp/&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;fashion_mnist_model&quot;</span>
<span class="n">sample_input</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>

<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">export_path</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">dummy_input</span><span class="o">=</span><span class="n">sample_input</span><span class="p">)</span>
</pre></div>
</div>
<p>This export method will save the model with quantization nodes removed, along with an encodings file containing
quantization parameters for each activation and weight tensor in the model. These artifacts can then be sent to a
quantized runtime such as Qualcomm Neural Processing SDK.</p>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>