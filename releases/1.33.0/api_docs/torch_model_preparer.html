<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model Preparer API &mdash; AI Model Efficiency Toolkit Documentation: ver 1.33.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Validator Utility" href="torch_model_validator.html" />
    <link rel="prev" title="Architecture Checker API" href="torch_architecture_checker.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../user_guide/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.33.0
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../user_guide/model_quantization.html"> Quantization User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#aimet-quantization-features">AIMET Quantization Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_sim.html"> Quantization Simulation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantsim-workflow">QuantSim Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#simulating-quantization-noise">Simulating Quantization Noise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#determining-quantization-parameters-encodings">Determining Quantization Parameters (Encodings)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantization-schemes">Quantization Schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#configuring-quantization-simulation-ops">Configuring Quantization Simulation Ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#frequently-asked-questions">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_aware_training.html"> Quantization-Aware Training (QAT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#qat-workflow">QAT workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#qat-modes">QAT modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#recommendations-for-quantization-aware-training">Recommendations for Quantization-Aware Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#post-training-quantization"><span class="hideitem">Post-Training Quantization</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/auto_quant.html">AutoQuant</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#workflow">Workflow</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/adaround.html">Adaptive Rounding (AdaRound)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#adaround-use-cases">AdaRound Use Cases</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#common-terminology">Common terminology</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#use-cases">Use Cases</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html">Cross-Layer Equalization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/bn_reestimation.html">BN Re-estimation</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#workflow">Workflow</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html">Bias Correction [Depricated]</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#debugging-analysis-tools"><span class="hideitem">Debugging/Analysis Tools</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quant_analyzer.html">QuantAnalyzer</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#requirements">Requirements</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#detailed-analysis-descriptions">Detailed Analysis Descriptions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_quant.html">Visualizations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/visualization_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/visualization_quant.html#quantization">Quantization</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/visualization_quant.html#pytorch">PyTorch</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/visualization_quant.html#tensorflow">TensorFlow</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../user_guide/model_quantization.html#aimet-quantization-workflow">AIMET Quantization Workflow</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../user_guide/model_quantization.html#pytorch"><span class="hideitem">PyTorch</span></a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="torch_model_guidelines.html"> PyTorch Model Guidelines</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="torch_quantization.html"> AIMET PyTorch Quantization APIs</a><ul class="current">
<li class="toctree-l5"><a class="reference internal" href="torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5 current"><a class="current reference internal" href="#"> Model Preparer API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="#code-examples">Code Examples</a></li>
<li class="toctree-l6"><a class="reference internal" href="#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo.ClsSetLayerPairInfo</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html">PEFT LoRA</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#tensorflow"><span class="hideitem">Tensorflow</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_model_guidelines.html"> TensorFlow Model Guidelines</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_model_guidelines.html#aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"><code class="docutils literal notranslate"><span class="pre">update_keras_bn_ops_trainable_flag()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#debugging-guidelines">Debugging Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_feature_guidebook.html">Quantization Guidebook</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/model_compression.html"> Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/compression_feature_guidebook.html">Compression Guidebook</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html">Greedy Compression Ratio Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#how-it-works">How it works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#per-layer-exploration">Per-layer Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#compression-ratio-selection">Compression Ratio Selection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#winnowing">Winnowing</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/winnowing.html">Winnowing</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#overview">Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#winnowing-overview">Winnowing Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#how-winnowing-works">How Winnowing Works</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html"> API Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="torch.html">AIMET APIs for PyTorch</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="torch_quantization.html">PyTorch Model Quantization API</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4 current"><a class="current reference internal" href="#"> Model Preparer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#code-examples">Code Examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo.ClsSetLayerPairInfo</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_peft_lora.html">PEFT LoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_common.defs.GreedySelectionParameters"><code class="docutils literal notranslate"><span class="pre">GreedySelectionParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#tar-selection-parameters">TAR Selection Parameters</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.TarRankSelectionParameters"><code class="docutils literal notranslate"><span class="pre">TarRankSelectionParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_eval_scores()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_comp_ratio_plot()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"><code class="docutils literal notranslate"><span class="pre">visualize_relative_weight_ranges_to_identify_problematic_layers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_weight_ranges"><code class="docutils literal notranslate"><span class="pre">visualize_weight_ranges()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_changes_after_optimization"><code class="docutils literal notranslate"><span class="pre">visualize_changes_after_optimization()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_layer_output_generation.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme"><code class="docutils literal notranslate"><span class="pre">NamingScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.ONNX"><code class="docutils literal notranslate"><span class="pre">NamingScheme.ONNX</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.PYTORCH"><code class="docutils literal notranslate"><span class="pre">NamingScheme.PYTORCH</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"><code class="docutils literal notranslate"><span class="pre">NamingScheme.TORCHSCRIPT</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensorflow.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tensorflow_model_guidelines.html">TensorFlow Model Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_model_guidelines.html#aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"><code class="docutils literal notranslate"><span class="pre">update_keras_bn_ops_trainable_flag()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow_quantization.html">TensorFlow Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow_compress.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.Mode"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ChannelPruningParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CostMetric"><code class="docutils literal notranslate"><span class="pre">CostMetric</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CostMetric.mac"><code class="docutils literal notranslate"><span class="pre">CostMetric.mac</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CostMetric.memory"><code class="docutils literal notranslate"><span class="pre">CostMetric.memory</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CompressionScheme"><code class="docutils literal notranslate"><span class="pre">CompressionScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CompressionScheme.channel_pruning"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.channel_pruning</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CompressionScheme.spatial_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.spatial_svd</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_common.defs.CompressionScheme.weight_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.weight_svd</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#code-examples">Code Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#weight-svd-top-level-api">Weight SVD Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.svd.Svd"><code class="docutils literal notranslate"><span class="pre">Svd</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_compress.html#aimet_tensorflow.svd.Svd.compress_net"><code class="docutils literal notranslate"><span class="pre">Svd.compress_net()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_compress.html#code-examples-for-weight-svd">Code Examples for Weight SVD</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow_visualization_quantization.html">TensorFlow Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_visualization_quantization.html#top-level-api-for-visualization-of-weight-tensors">Top-level API for Visualization of Weight tensors</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_visualization_quantization.html#aimet_tensorflow.plotting_utils.visualize_weight_ranges_single_layer"><code class="docutils literal notranslate"><span class="pre">visualize_weight_ranges_single_layer()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_visualization_quantization.html#aimet_tensorflow.plotting_utils.visualize_relative_weight_ranges_single_layer"><code class="docutils literal notranslate"><span class="pre">visualize_relative_weight_ranges_single_layer()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_visualization_quantization.html#code-examples-for-visualization-of-weight-tensors">Code Examples for Visualization of Weight tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="convert_tf_sess_to_keras.html">Using AIMET Tensorflow APIs with Keras Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="convert_tf_sess_to_keras.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="convert_tf_sess_to_keras.html#apis">APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.save_tf_session_single_gpu"><code class="docutils literal notranslate"><span class="pre">save_tf_session_single_gpu()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.load_tf_sess_variables_to_keras_single_gpu"><code class="docutils literal notranslate"><span class="pre">load_tf_sess_variables_to_keras_single_gpu()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.save_as_tf_module_multi_gpu"><code class="docutils literal notranslate"><span class="pre">save_as_tf_module_multi_gpu()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="convert_tf_sess_to_keras.html#aimet_tensorflow.utils.convert_tf_sess_to_keras.load_keras_model_multi_gpu"><code class="docutils literal notranslate"><span class="pre">load_keras_model_multi_gpu()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="convert_tf_sess_to_keras.html#code-example">Code Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="convert_tf_sess_to_keras.html#utility-functions">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tensorflow_layer_output_generation.html">Tensorflow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="tensorflow_layer_output_generation.html#aimet_tensorflow.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="tensorflow_layer_output_generation.html#aimet_tensorflow.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="tensorflow_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="keras.html">AIMET APIs for Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="keras_quantization.html">Keras Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="keras_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_model_preparer.html#aimet_tensorflow.keras.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_model_preparer.html#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_quant_analyzer.html#aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_quant_analyzer.html#aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_adaround.html#aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_cross_layer_equalization.html#aimet_tensorflow.keras.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#custom-datatype-used">Custom Datatype used</a><ul>
<li class="toctree-l8"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="keras_primitive_apis_cle.html#aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo.ClsSetLayerPairInfo</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#code-example-for-lower-level-apis">Code Example for Lower level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#example-helper-methods-to-perform-cle-in-manual-mode">Example helper methods to perform CLE in manual mode</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_batchnorm_re_estimation.html#aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_batchnorm_re_estimation.html#aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#limitations">Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="keras_layer_output_generation.html">Keras Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="keras_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_layer_output_generation.html#aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_layer_output_generation.html#aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="keras_compression.html">Keras Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CostMetric"><code class="docutils literal notranslate"><span class="pre">CostMetric</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CostMetric.mac"><code class="docutils literal notranslate"><span class="pre">CostMetric.mac</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CostMetric.memory"><code class="docutils literal notranslate"><span class="pre">CostMetric.memory</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme"><code class="docutils literal notranslate"><span class="pre">CompressionScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme.channel_pruning"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.channel_pruning</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme.spatial_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.spatial_svd</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme.weight_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.weight_svd</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx_quantization.html">ONNX Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_quantsim.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#adaround-parameters">Adaround Parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_auto_quant.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_quant_analyzer.html"> QuantAnalyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_quant_analyzer.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_quant_analyzer.html#run-specific-utility">Run specific utility</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx_layer_output_generation.html">ONNX Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/examples.html"> Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html"> Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#quick-install">Quick Install</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#release-packages">Release Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#advanced-installation-instructions">Advanced Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages">Install GPU packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-pytorch-2-1-or-tensorflow">Install GPU packages for PyTorch 2.1 or TensorFlow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-pytorch-1-13-or-onnx">Install GPU packages for PyTorch 1.13 or ONNX</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_docker.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_docker.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../user_guide/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../user_guide/index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../user_guide/model_quantization.html">AIMET Model Quantization</a></li>
          <li class="breadcrumb-item"><a href="torch_quantization.html">AIMET PyTorch Quantization APIs</a></li>
      <li class="breadcrumb-item active">Model Preparer API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api_docs/torch_model_preparer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="torch_architecture_checker.html" class="btn btn-neutral float-left" title="Architecture Checker API" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="torch_model_validator.html" class="btn btn-neutral float-right" title="Model Validator Utility" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="model-preparer-api">
<span id="api-torch-model-preparer"></span><h1>Model Preparer API<a class="headerlink" href="#model-preparer-api" title="Permalink to this heading"></a></h1>
<p>AIMET PyTorch ModelPreparer API uses new graph transformation feature available in PyTorch 1.9+ version and automates
model definition changes required by user. For example, it changes functionals defined in forward pass to
torch.nn.Module type modules for activation and elementwise functions. Also, when torch.nn.Module type modules are reused,
it unrolls into independent modules.</p>
<p>Users are strongly encouraged to use AIMET PyTorch ModelPreparer API first and then use the returned model as input
to all the AIMET Quantization features.</p>
<p>AIMET PyTorch ModelPreparer API requires minimum PyTorch 1.9 version.</p>
<div class="section" id="top-level-api">
<h2>Top-level API<a class="headerlink" href="#top-level-api" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_torch.model_preparer.prepare_model">
<span class="sig-prename descclassname"><span class="pre">aimet_torch.model_preparer.</span></span><span class="sig-name descname"><span class="pre">prepare_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modules_to_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_classes_to_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concrete_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/model_preparer.html#prepare_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.model_preparer.prepare_model" title="Permalink to this definition"></a></dt>
<dd><p>Prepare and modify the pytorch model for AIMET features using torch.FX symbolic tracing API.</p>
<ol class="arabic simple">
<li><p>Replace torch.nn.functional by module of type torch.nn.Module</p></li>
<li><p>Create new independent torch.nn.Module instances for reused/duplicate module</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – pytorch Model to be modified.</p></li>
<li><p><strong>modules_to_exclude</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – List of modules to exclude when tracing.</p></li>
<li><p><strong>module_classes_to_exclude</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]]) – List of module classes to exclude when tracing.</p></li>
<li><p><strong>concrete_args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]) – Allows you to partially specialize your function, whether it’s to remove control flow or
data structures. If the model has control flow, torch.fx won’t be able to trace the model. Check
torch.fx.symbolic_trace API in detail.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">GraphModule</span></code></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Modified pytorch Model</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this heading"></a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">aimet_torch.model_preparer</span> <span class="kn">import</span> <span class="n">prepare_model</span>

</pre></div>
</div>
<p><strong>Example 1: Model with Functional relu</strong></p>
<p>We begin with the following model, which contains two functional relus and relu method inside forward method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ModelWithFunctionalReLU</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Model that uses functional ReLU instead of nn.Modules. Expects input of shape (1, 3, 32, 32) &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ModelWithFunctionalReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
</span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>Run the model preparer API on the model by passing in the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_preparer_functional_example</span><span class="p">():</span>

    <span class="c1"># Load the model and keep in eval() mode</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ModelWithFunctionalReLU</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="c1"># Call to prepare_model API</span>
    <span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>

    <span class="c1"># Compare the outputs of original and transformed model</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">),</span> <span class="n">prepared_model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
</pre></div>
</div>
<p>After that, we get prepared_model, which is functionally same as original model. User can verify this by comparing
the outputs of both models.</p>
<p>prepared_model should have all three functional relus now converted to torch.nn.ReLU modules which satisfy
model guidelines described here <a class="reference internal" href="torch_model_guidelines.html#api-torch-model-guidelines"><span class="std std-ref">Model Guidelines</span></a>.</p>
<p><strong>Example 2: Model with reused torch.nn.ReLU module</strong></p>
<p>We begin with the following model, which contains torch.nn.ReLU module which is used at multiple instances inside
model forward function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ModelWithReusedReLU</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Model that uses single ReLU instances multiple times in the forward. Expects input of shape (1, 3, 32, 32) &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ModelWithReusedReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>Run the model preparer API on the model by passing in the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_preparer_reused_example</span><span class="p">():</span>

    <span class="c1"># Load the model and keep in eval() mode</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ModelWithReusedReLU</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="c1"># Call to prepare_model API</span>
    <span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>

    <span class="c1"># Compare the outputs of original and transformed model</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">),</span> <span class="n">prepared_model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">))</span>
</pre></div>
</div>
<p>After that, we get prepared_model, which is functionally same as original model. User can verify this by comparing
the outputs of both models.</p>
<p>prepared_model should have separate independent torch.nn.Module instances which satisfy model guidelines described
here <a class="reference internal" href="torch_model_guidelines.html#api-torch-model-guidelines"><span class="std std-ref">Model Guidelines</span></a>.</p>
<p><strong>Example 3: Model with elementwise Add</strong></p>
<p>We begin with the following model, which contains elementwise Add operation inside model forward function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ModelWithElementwiseAddOp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ModelWithElementwiseAddOp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="hll">        <span class="n">x</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">x2</span>
</span>        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>Run the model preparer API on the model by passing in the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model_preparer_elementwise_add_example</span><span class="p">():</span>

    <span class="c1"># Load the model and keep in eval() mode</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ModelWithElementwiseAddOp</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)]</span>

    <span class="c1"># Call to prepare_model API</span>
    <span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>

    <span class="c1"># Compare the outputs of original and transformed model</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">input_tensor</span><span class="p">),</span> <span class="n">prepared_model</span><span class="p">(</span><span class="o">*</span><span class="n">input_tensor</span><span class="p">))</span>
</pre></div>
</div>
<p>After that, we get prepared_model, which is functionally same as original model. User can verify this by comparing
the outputs of both models.</p>
</div>
<div class="section" id="limitations-of-torch-fx-symbolic-trace-api">
<h2>Limitations of torch.fx symbolic trace API<a class="headerlink" href="#limitations-of-torch-fx-symbolic-trace-api" title="Permalink to this heading"></a></h2>
<p>Limitations of torch.fx symbolic trace: <a class="reference external" href="https://pytorch.org/docs/stable/fx.html#limitations-of-symbolic-tracing">https://pytorch.org/docs/stable/fx.html#limitations-of-symbolic-tracing</a></p>
<p><strong>1. Dynamic control flow is not supported by torch.fx</strong>
Loops or if-else statement where condition may depend on some of the input values. It can only trace one execution
path and all the other branches that weren’t traced will be ignored. For example, following simple function when traced,
will fail with TraceError saying that ‘symbolically traced variables cannot be used as inputs to control flow’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flag</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">flag</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span>

<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="c1"># Fails!</span>
<span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">concrete_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;flag&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</pre></div>
</div>
<p>Workarounds for this problem:</p>
<ul>
<li><p>Many cases of dynamic control flow can be simply made to static control flow which is supported by torch.fx
symbolic tracing. Static control flow is where loops or if-else statements whose value can’t change
across different model forward passes. Such cases can be traced by removing data dependencies on input values by
passing concrete values to ‘concrete_args’ to specialize your forward functions.</p></li>
<li><p>In truly dynamic control flow, user should wrap such piece of code at model-level scope using torch.fx.wrap API
which will preserve it as a node instead of being traced through:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span>
<span class="k">def</span> <span class="nf">custom_function_not_to_be_traced</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Function which we do not want to be traced, when traced using torch FX API, call to this function will</span>
<span class="sd">    be inserted as call_function, and won&#39;t be traced through &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">+=</span> <span class="n">x</span>
        <span class="n">y</span> <span class="o">+=</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span>
</pre></div>
</div>
</li>
</ul>
<p><strong>2. Non-torch functions which does not use __torch_function__ mechanism is not supported by default in symbolic
tracing.</strong></p>
<p>Workaround for this problem:</p>
<ul>
<li><p>If we do not want to capture them in symbolic tracing then user should use torch.fx.wrap() API at module-level scope:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>
<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">&#39;len&#39;</span><span class="p">)</span>  <span class="c1"># call the API at module-level scope.</span>
<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">&#39;sqrt&#39;</span><span class="p">)</span> <span class="c1"># call the API at module-level scope.</span>

<span class="k">class</span> <span class="nc">ModelWithNonTorchFunction</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ModelWithNonTorchFunction</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ModelWithNonTorchFunction</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model_transformed</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p><strong>3. Customizing the behavior of tracing by overriding the Tracer.is_leaf_module() API</strong></p>
<p>In symbolic tracing, leaf modules appears as node rather than being traced through and all the standard torch.nn modules
are default set of leaf modules. But this behavior can be changed by overriding the Tracer.is_leaf_module() API.</p>
<p>AIMET model preparer API exposes ‘module_to_exclude’ argument which can be used to prevent certain module(s) being
traced through. For example, let’s examine following code snippet where we don’t want to trace CustomModule further:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">CustomModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom</span> <span class="o">=</span> <span class="n">CustomModule</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">CustomModel</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">modules_to_exclude</span><span class="o">=</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">custom</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>
</pre></div>
</div>
<p>In this example, ‘self.custom’ is preserved as node and not being traced through.</p>
<p><strong>4. Tensor constructors are not traceable</strong></p>
<p>For example, let’s examine following code snippet:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="n">Error</span> <span class="n">traceback</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="ne">TypeError</span><span class="p">:</span> <span class="n">arange</span><span class="p">()</span> <span class="n">received</span> <span class="n">an</span> <span class="n">invalid</span> <span class="n">combination</span> <span class="n">of</span> <span class="n">arguments</span> <span class="o">-</span> <span class="n">got</span> <span class="p">(</span><span class="n">Proxy</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">Attribute</span><span class="p">),</span> <span class="n">but</span> <span class="n">expected</span> <span class="n">one</span> <span class="n">of</span><span class="p">:</span>
    <span class="o">*</span> <span class="p">(</span><span class="n">Number</span> <span class="n">end</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">Tensor</span> <span class="n">out</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span> <span class="n">layout</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="n">device</span><span class="p">,</span> <span class="nb">bool</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="nb">bool</span> <span class="n">requires_grad</span><span class="p">)</span>
    <span class="o">*</span> <span class="p">(</span><span class="n">Number</span> <span class="n">start</span><span class="p">,</span> <span class="n">Number</span> <span class="n">end</span><span class="p">,</span> <span class="n">Number</span> <span class="n">step</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">Tensor</span> <span class="n">out</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span> <span class="n">layout</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="n">device</span><span class="p">,</span> <span class="nb">bool</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="nb">bool</span> <span class="n">requires_grad</span><span class="p">)</span>
</pre></div>
</div>
<p>The above snippet is problematic because arguments to torch.arange() are input dependent.
Workaround for this problem:</p>
<ul>
<li><p>use deterministic constructors (hard-coding) so that the value they produce will be embedded as constant in
the graph:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
</pre></div>
</div>
</li>
<li><p>Or use torch.fx.wrap API to wrap torch.arange() and call that instead:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span>
<span class="k">def</span> <span class="nf">do_not_trace_me</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">do_not_trace_me</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="torch_architecture_checker.html" class="btn btn-neutral float-left" title="Architecture Checker API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="torch_model_validator.html" class="btn btn-neutral float-right" title="Model Validator Utility" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>