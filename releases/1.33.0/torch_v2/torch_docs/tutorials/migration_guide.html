<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Migrate to QuantSim v2 &mdash; AI Model Efficiency Toolkit Documentation: ver 1.33.0</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
      <link rel="stylesheet" href="../../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.33.0
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../install/install_host.html">Install in Host Machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/install_docker.html">Install in Docker Container</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quickstart_guide.html">Quickstart Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/ptq.html">Post-Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Feature Descriptions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/adaround.html"> Adaptive Rounding (AdaRound)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AIMET PyTorch API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quantized_modules.html">Quantized Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quantizer.html">Quantizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../encoding_analyzer.html">Encoding Analyzers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer.html">MinMaxEncodingAnalyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.html">SqnrEncodingAnalyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.html">PercentileEncodingAnalyzer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/nn.fake_quantization_mixin.html">FakeQuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/nn.quantization_mixin.html">QuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/quantization/affine/index.html">quantization.affine</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize.html">Quantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize.html">QuantizeDequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_.html">quantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize.html">quantize_dequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize.html">dequantize</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/quantization/float/index.html">quantization.float</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Migrate to QuantSim v2</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/torch_docs/tutorials/migration_guide.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="migrate-to-quantsim-v2">
<span id="tutorials-migration-guide"></span><h1>Migrate to QuantSim v2<a class="headerlink" href="#migrate-to-quantsim-v2" title="Permalink to this heading"></a></h1>
<p>Learn how to migrate your code from QuantSim v1 to QuantSim v2!</p>
<p>Migration to QuantSim v2 enables access to new features, easier debugging, and simpler code that is easier to extend. This guide provides an overview of the migration process and describes the fundamental differences between the two versions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please be advised that QuantSim v2 is an experimental feature whose APIs and behaviors are subject to change.</p>
</div>
<div class="section" id="changes-in-quantsim-v2">
<h2>Changes in QuantSim v2<a class="headerlink" href="#changes-in-quantsim-v2" title="Permalink to this heading"></a></h2>
<p>Before migrating, it is important to understand the behavior and API differences between QuantSim v1 and QuantSim v2. Users can interact with QuantSim through the high level APIs in the same way. Methods like <code class="docutils literal notranslate"><span class="pre">compute_encodings()</span></code> and <code class="docutils literal notranslate"><span class="pre">export()</span></code> will remain the same.</p>
<p>Under the hood, QuantSim v2 has a different set of building blocks and properties than QuantSim v1, as shown below:</p>
<a class="reference internal image-reference" href="../../_images/quantsim2.0.png"><img alt="../../_images/quantsim2.0.png" src="../../_images/quantsim2.0.png" style="width: 800px;" /></a>
</div>
<div class="section" id="migration-process">
<h2>Migration Process<a class="headerlink" href="#migration-process" title="Permalink to this heading"></a></h2>
<p>The migration process includes the following:</p>
<ol class="arabic simple">
<li><p>Update imports of QuantizationSimModel and other features</p></li>
<li><p>Change how internal components of QuantizationSimModel are accessed</p></li>
<li><p>Remove any dependency on deprecated features</p></li>
</ol>
<div class="section" id="imports">
<h3>Imports<a class="headerlink" href="#imports" title="Permalink to this heading"></a></h3>
<p>To migrate to QuantSim v2, your imports should originate from the <code class="xref py py-mod docutils literal notranslate"><span class="pre">aimet_torch.v2</span></code> namespace and be replaced as shown below. If your code does not directly access lower-level components, no further code change is needed.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 38%" />
<col style="width: 47%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>AIMET Classes</p></th>
<th class="head"><p><code class="xref py py-mod docutils literal notranslate"><span class="pre">aimet_torch</span></code></p></th>
<th class="head"><p><code class="xref py py-mod docutils literal notranslate"><span class="pre">aimet_torch.v2</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>QuantSim</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.quantsim.QuantizationSimModel</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.v2.quantsim.quantsim.QuantizationSimModel</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>AdaRound</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.adaround.adaround_weight.AdaRound</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.v2.adaround.AdaRound</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Sequential MSE</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.seq_mse.apply_seq_mse</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.v2.seq_mse.apply_seq_mse</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>QuantAnalyzer</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.quant_analyzer.QuantAnalyzer</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.v2.quant_analyzer.QuantAnalyzer</span></code></p></td>
</tr>
<tr class="row-even"><td><p>AutoQuant</p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.auto_quant.AutoQuant</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.v2.auto_quant.AutoQuant</span></code></p></td>
</tr>
</tbody>
</table>
<p>In QuantSim v2, all implementation code is ported to Python. Users will no longer need to import from <code class="docutils literal notranslate"><span class="pre">aimet_common.libpymo</span></code>. Please refer to the table in <a class="reference internal" href="#deprecated-features"><span class="std std-ref">Deprecated Features</span></a> to migrate these imports.</p>
<p>All the other import statements will stay the same, including but not limited to:</p>
<ul class="simple">
<li><p><code class="code highlight python docutils literal highlight-python"><span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantScheme</span></code></p></li>
<li><p><code class="code highlight python docutils literal highlight-python"><span class="kn">from</span> <span class="nn">aimet_torch.cross_layer_equalization</span> <span class="kn">import</span> <span class="n">equalize_model</span></code></p></li>
<li><p><code class="code highlight python docutils literal highlight-python"><span class="kn">from</span> <span class="nn">aimet_torch.model_preparer</span> <span class="kn">import</span> <span class="n">prepare_model</span></code></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="quantizationsimmodel">
<h3>QuantizationSimModel<a class="headerlink" href="#quantizationsimmodel" title="Permalink to this heading"></a></h3>
<div class="section" id="moving-from-quantwrapper-to-quantized-modules">
<h4>Moving from QuantWrapper to Quantized Modules<a class="headerlink" href="#moving-from-quantwrapper-to-quantized-modules" title="Permalink to this heading"></a></h4>
<p>To enable quantization in QuantSim v1, modules are wrapped with a QuantizeWrapper. These wrapped modules can be accessed as follows:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span> <span class="k">as</span> <span class="n">QuantizationSimModelV1</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModelV1</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">all_quant_wrappers</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">()</span>
<span class="k">for</span> <span class="n">quant_wrapper</span> <span class="ow">in</span> <span class="n">sim</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">quant_wrapper</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>StaticGridQuantWrapper(
    (_module_to_wrap): Linear(in_features=100, out_features=200, bias=True)
)
StaticGridQuantWrapper(
    (_module_to_wrap): ReLU()
)
</pre></div>
</div>
<p>In contrast, QuantSim v2 enables quantization through quantized nn.Modules - modules are no longer wrapped but replaced with a quantized version. For example, a nn.Linear would be replaced with QuantizedLinear, nn.Conv2d would be replace by QuantizedConv2d, and so on. The quantized module definitions can be found under <code class="xref py py-mod docutils literal notranslate"><span class="pre">aimet_torch.v2.nn</span></code>. These quantized modules can be accessed as follows:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch.v2.quantsim.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span> <span class="k">as</span> <span class="n">QuantizationSimModelV2</span>
<span class="n">sim2</span> <span class="o">=</span> <span class="n">QuantizationSimModelV2</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">all_q_modules</span> <span class="o">=</span> <span class="n">sim2</span><span class="o">.</span><span class="n">qmodules</span><span class="p">()</span>
<span class="k">for</span> <span class="n">q_module</span> <span class="ow">in</span> <span class="n">sim2</span><span class="o">.</span><span class="n">qmodules</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">q_module</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>QuantizedLinear(
        in_features=100, out_features=200, bias=True
        (param_quantizers): ModuleDict(
            (weight): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=True)
            (bias): None
        )
        (input_quantizers): ModuleList(
            (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
        )
        (output_quantizers): ModuleList(
            (0): None
        )
)
FakeQuantizedReLU(
    (param_quantizers): ModuleDict()
    (input_quantizers): ModuleList(
        (0): None
    )
    (output_quantizers): ModuleList(
        (0): QuantizeDequantize(shape=[1], bitwidth=8, symmetric=False)
    )
)
</pre></div>
</div>
<p>For more information on Quantized modules, please refer to the API reference guide <a class="reference internal" href="../quantized_modules.html#api-torch-quantized-modules"><span class="std std-ref">here</span></a>.</p>
</div>
<div class="section" id="moving-from-staticgrid-and-learnedgrid-quantizer-to-affine-and-float-quantizer">
<h4>Moving from StaticGrid and LearnedGrid Quantizer to Affine and Float Quantizer<a class="headerlink" href="#moving-from-staticgrid-and-learnedgrid-quantizer-to-affine-and-float-quantizer" title="Permalink to this heading"></a></h4>
<p>In QuantSim v1, we relied on StaticGridQuantizer and LearnedGridQuantizer. For both, floating point quantization could be enabled based on <code class="docutils literal notranslate"><span class="pre">QuantizationDataType</span></code> passed in.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch.tensor_quantizer</span> <span class="kn">import</span> <span class="n">StaticGridPerChannelQuantizers</span>
<span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantizationDataType</span>

<span class="n">fp_quantizer</span> <span class="o">=</span> <span class="n">StaticGridPerChannelQuantizer</span><span class="p">(</span><span class="n">data_type</span> <span class="o">=</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="n">affine_quantizer</span> <span class="o">=</span> <span class="n">StaticGridPerChannelQuantizer</span><span class="p">(</span><span class="n">data_type</span> <span class="o">=</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>However, in QuantSim v2, this functionality is separated into an AffineQuantizer and a FloatQuantizer. Users can access these quantizers and related operations under <cite>aimet_torch.v2.quantization</cite>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">aimet_torch.v2.quantization</span> <span class="k">as</span> <span class="nn">Q</span>

<span class="n">affine_q</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">affine</span><span class="o">.</span><span class="n">Quantize</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bitwidth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">symmetric</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">affine_qdq</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">affine</span><span class="o">.</span><span class="n">QuantizeDequantize</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bitwidth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">symmetric</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">fp_qdq</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">float</span><span class="o">.</span><span class="n">FloatQuantizeDequantize</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</pre></div>
</div>
<p>From the wrapped module (QuantSim v1) or quantized module (QuantSim v2), the attributes to access the quantizers remain consistent: <code class="docutils literal notranslate"><span class="pre">.input_quantizers</span></code> for input quantizers, <code class="docutils literal notranslate"><span class="pre">.output_quantizers</span></code> for output quantizers, and <code class="docutils literal notranslate"><span class="pre">.param_quantizers</span></code> for parameter quantizers.</p>
<p>For more information on Quantizers, please refer to the API reference guide <a class="reference internal" href="../quantizer.html#api-torch-quantizers"><span class="std std-ref">here</span></a>.</p>
</div>
<div class="section" id="code-examples">
<h4>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this heading"></a></h4>
<p><strong>Setup</strong></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="kn">from</span> <span class="nn">aimet_torch.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span> <span class="k">as</span> <span class="n">QuantizationSimModelV1</span>

<span class="n">sim1</span> <span class="o">=</span> <span class="n">QuantizationSimModelV1</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">wrap_linear</span> <span class="o">=</span> <span class="n">sim1</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">linear</span>

<span class="c1"># QuantSim v2</span>
<span class="kn">from</span> <span class="nn">aimet_torch.v2.quantsim.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span> <span class="k">as</span> <span class="n">QuantizationSimModelV2</span>

<span class="n">sim2</span> <span class="o">=</span> <span class="n">QuantizationSimModelV2</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">qlinear</span> <span class="o">=</span> <span class="n">sim2</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">linear</span>
</pre></div>
</div>
<p><strong>Case 1: Manually setting common attributes</strong></p>
<p><em>Bitwidth</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">bitwidth</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bitwidth</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bitwidth</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># QuantSim v2</span>
<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]:</span>
    <span class="n">module</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">bitwidth</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bitwidth</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bitwidth</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
<p><em>Symmetry</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">use_symmetric_encodings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">is_unsigned_symmetric</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">use_strict_symmetric</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">wrap_linear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">use_symmetric_encodings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_unsigned_symmetric</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">use_strict_symmetric</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">wrap_linear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">use_symmetric_encodings</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_unsigned_symmetric</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">use_strict_symmetric</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># QuantSim v2</span>
<span class="c1"># Notes: simplified into two flags</span>
<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">symmetric</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">signed</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">symmetric</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">signed</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">symmetric</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">signed</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p><em>Encoding Data</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="kn">import</span> <span class="nn">libpymo</span>

<span class="k">if</span> <span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">encoding</span><span class="p">:</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TfEncoding</span><span class="p">()</span>
    <span class="n">encoding</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">encoding</span><span class="o">.</span><span class="n">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span>

<span class="k">if</span> <span class="n">wrap_linear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoding</span><span class="p">:</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TfEncoding</span><span class="p">()</span>
    <span class="n">encoding</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">encoding</span><span class="o">.</span><span class="n">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">wrap_linear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span>

<span class="k">if</span> <span class="n">wrap_linear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoding</span><span class="p">:</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TfEncoding</span><span class="p">()</span>
    <span class="n">encoding</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">encoding</span><span class="o">.</span><span class="n">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">wrap_linear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span>

<span class="c1"># QuantSim v2</span>
<span class="c1"># Notes: TfEncoding() is no longer used, encoding min/max are of type torch.nn.Parameter</span>
<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">module</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>

<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">qlinear</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Case 2: Enabling and Disabling Quantization</strong></p>
<p><em>Is quantization enabled?</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="k">if</span> <span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="c1"># QuantSim v2</span>
<span class="c1"># Notes: Quantizers no longer have an &#39;enabled&#39; attribute. If a quantizer is present, it is enabled</span>
<span class="k">if</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p><em>Disabling Quantization</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># QuantSim v2</span>
<span class="c1"># Notes: Quantizers can be disabled by setting them to None OR using the utility API (_remove_input_quantizers, _remove_output_quantizers, _remove_param_quantizers)</span>
<span class="n">qlinear</span><span class="o">.</span><span class="n">param_encodings</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">qlinear</span><span class="o">.</span><span class="n">_remove_param_quantizers</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Enabling Quantization</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># QuantSim v2</span>
<span class="kn">import</span> <span class="nn">aimet_torch.v2.quantization</span> <span class="k">as</span> <span class="nn">Q</span>
<span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span><span class="o">.</span><span class="n">affine</span><span class="o">.</span><span class="n">QuantizeDequantize</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Temporarily disabling Quantization</em></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="k">assert</span> <span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">enabled</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># Run other code here</span>
<span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># QuantSim v2</span>
<span class="k">assert</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span>
<span class="k">with</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">_remove_param_quantizers</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="c1"># Run other code here</span>

<span class="k">assert</span> <span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>Case 3: Freezing encodings</strong></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># QuantSim v1</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">_is_encoding_frozen</span><span class="p">:</span>
    <span class="n">wrap_linear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">freeze_encodings</span><span class="p">()</span>

<span class="c1"># QuantSim v2</span>
<span class="c1"># Notes: There is no longer a concept of &quot;freezing&quot;. Mimicking v1 freezing behavior involves the allow_overwrite and requires_grad_ flag</span>
<span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">allow_overwrite</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># Prevents encodings from being overwritten by AIMET APIs</span>
<span class="n">qlinear</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>   <span class="c1"># Prevents encodings from being learned</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="deprecated-features">
<span id="id1"></span><h3>Deprecated Features<a class="headerlink" href="#deprecated-features" title="Permalink to this heading"></a></h3>
<p>There are some components that are tied to the QuantSim v1 design that are not needed in QuantSim v2. For example, all QuantSim v2 source code will be implemented in Python to provide easier debugging and improved portability. It is not recommended to use libpymo modules with QuantSim 2.0. Below, you can see a list of these features and the recommended migration guideline:</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Component in v1</p></th>
<th class="head"><p>Replacement in v2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>StaticGridQuantWrapper, LearnedGridQuantWrapper</p></td>
<td><p>Quantized nn.Modules</p></td>
</tr>
<tr class="row-odd"><td><p>StaticGridQuantizer, LearnedGridQuantizer</p></td>
<td><p><a class="reference internal" href="../quantizer.html#api-torch-quantizers"><span class="std std-ref">AffineQuantizer</span></a>, <a class="reference internal" href="../quantizer.html#api-torch-quantizers"><span class="std std-ref">FloatQuantizer</span></a></p></td>
</tr>
<tr class="row-even"><td><p>libpymo.EncodingAnalyzerForPython</p></td>
<td><p><a class="reference internal" href="../encoding_analyzer.html#api-torch-encoding-analyzer"><span class="std std-ref">MinMaxEncodingAnalyzer</span></a>, <a class="reference internal" href="../encoding_analyzer.html#api-torch-encoding-analyzer"><span class="std std-ref">SqnrEncodingAnalyzer</span></a>, <a class="reference internal" href="../encoding_analyzer.html#api-torch-encoding-analyzer"><span class="std std-ref">PercentileEncodingAnalyzer</span></a></p></td>
</tr>
<tr class="row-odd"><td><p>libpymo.TfEncoding</p></td>
<td><p>AffineEncoding, FloatEncoding, VectorEncoding</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>