Search.setIndex({"docnames": ["_templates/autosummary/class", "_templates/autosummary/function", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.fake_quantization_mixin", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize", "torch_docs/api/quantization/affine/index", "torch_docs/api/quantization/float/FloatQuantizeDequantize", "torch_docs/api/quantization/float/index", "torch_docs/api/quantization/tensor", "torch_docs/blockwise_quantization", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/migration_guide", "torch_docs/tutorials/quickstart_guide", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/quantsim_2.0_overview", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["_templates/autosummary/class.rst", "_templates/autosummary/function.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.fake_quantization_mixin.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize.rst", "torch_docs/api/quantization/affine/index.rst", "torch_docs/api/quantization/float/FloatQuantizeDequantize.rst", "torch_docs/api/quantization/float/index.rst", "torch_docs/api/quantization/tensor.rst", "torch_docs/blockwise_quantization.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/migration_guide.rst", "torch_docs/tutorials/quickstart_guide.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/quantsim_2.0_overview.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["&lt;no title&gt;", "&lt;no title&gt;", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "FakeQuantizationMixin", "QuantizationMixin", "Quantize", "QuantizeDequantize", "dequantize", "quantize", "quantize_dequantize", "quantization.affine", "FloatQuantizeDequantize", "quantization.float", "quantization.tensor", "Blockwise Quantization", "Encoding Analyzers", "Post-Training Quantization", "MinMaxEncodingAnalyzer", "PercentileEncodingAnalyzer", "SqnrEncodingAnalyzer", "AIMET: AI Model Efficiency Toolkit Documentation", "Quantized Modules", "Quantizers", "Migrate to QuantSim v2", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "QuantSim v2", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"name": [0, 1, 3, 6, 7, 24, 25, 39, 44, 46, 48], "escap": [0, 1], "underlin": [0, 1], "qualcomm": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "innov": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "center": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "inc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "ai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "effici": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "toolkit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "quantsim_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "default_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "json": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "The": [2, 4, 6, 7, 11, 12, 14, 16, 17, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51], "pytorch": [2, 3, 6, 7, 24, 28, 29, 30, 34, 39, 40, 42, 44, 46], "gpu": [2, 3, 38, 46], "pypi": 2, "ar": [2, 6, 7, 8, 9, 14, 17, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51], "avail": [2, 7, 27, 37, 40, 42, 43, 45], "environ": 2, "meet": [2, 29, 32, 33], "follow": [2, 3, 4, 6, 7, 17, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 47, 50, 51], "64": [2, 8, 17, 22, 25, 28], "bit": [2, 14, 17, 27, 28, 30, 38, 43, 44, 46], "intel": 2, "x86": 2, "compat": [2, 17, 27], "processor": 2, "linux": [2, 4], "ubuntu": [2, 4], "22": [2, 4, 27], "04": [2, 4], "lt": [2, 4], "python": [2, 3, 4, 26, 45], "3": [2, 11, 12, 16, 17, 22, 26, 27, 32, 38, 41, 43, 51], "10": [2, 3, 4, 6, 7, 8, 9, 11, 16, 17, 24, 25, 27, 33, 36, 41], "20": [2, 6, 7, 28, 41], "8": [2, 4, 6, 7, 8, 9, 11, 12, 14, 16, 17, 24, 25, 26, 27, 38, 51], "cuda": [2, 4, 27], "12": [2, 11, 17], "0": [2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 17, 21, 22, 24, 25, 26, 27, 28, 32, 33, 37, 42], "torch": [2, 3, 6, 7, 8, 9, 11, 12, 14, 16, 17, 23, 24, 25, 26, 27, 37, 46], "2": [2, 3, 9, 11, 12, 14, 16, 17, 25, 26, 28, 38, 43, 44], "pip": [2, 3, 4, 23], "apt": [2, 3, 4, 23], "get": [2, 3, 4, 28, 31, 38, 49], "liblapack": [2, 3, 4, 23], "python3": [2, 3, 4, 23], "m": [2, 3, 4, 23], "For": [2, 3, 4, 6, 7, 17, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 40, 42, 44, 48, 51], "other": [2, 17, 26, 33, 35, 36, 38, 40, 43, 44, 46], "variant": [2, 4, 28, 29, 30, 39, 40, 41, 44], "latest": [2, 3], "version": [2, 3, 4, 6, 7, 17, 24, 26, 27, 34, 45], "from": [2, 6, 7, 8, 9, 14, 16, 17, 21, 24, 25, 27, 28, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 51], "whl": [2, 3, 4], "file": [2, 3, 4, 17, 27, 38, 40, 41, 44, 46, 49], "host": [2, 3, 4, 46, 48], "http": [2, 3, 4, 32, 39, 46, 48], "github": [2, 3, 4, 32, 46], "com": [2, 3, 4, 46], "quic": [2, 3, 4, 32, 46], "1": [2, 3, 6, 7, 8, 9, 11, 12, 14, 16, 17, 24, 25, 26, 33, 35, 36, 37, 38, 42, 43, 44, 47, 50, 51], "13": [2, 3, 11], "11": [2, 4, 11, 16], "x": [2, 14, 16, 24, 27, 32, 37, 40], "download": [2, 3, 4, 27], "31": [2, 3, 4], "aimet_torch": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 37, 45], "torch_gpu_": 2, "cp38": [2, 4], "linux_x86_64": [2, 3, 4], "cpu": [2, 3, 4, 27, 38, 46], "onli": [2, 3, 4, 11, 12, 16, 17, 24, 27, 30, 35, 38, 40, 41, 42, 46, 51], "torch_cpu_": 2, "tensorflow": [2, 3, 28, 29, 30, 34, 35, 39, 40, 42, 44, 46], "aimet_tensorflow": [2, 3, 4], "tf_gpu_": 2, "tf_cpu_": 2, "onnx": [2, 3, 23, 28, 29, 34, 37, 38, 39, 40, 42, 44], "14": [2, 11, 27], "aimet_onnx": [2, 3, 4], "onnx_gpu_": 2, "onnx_cpu_": 2, "previou": [2, 27, 32, 33, 43], "brows": 2, "each": [2, 3, 4, 6, 7, 17, 24, 25, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 41, 42, 43, 44, 49, 51], "includ": [2, 17, 26, 30, 36, 38, 40, 42, 44, 46], "multipl": [2, 4, 17, 24, 34, 36, 38, 46], "format": [2, 17, 25, 29, 35], "torch_gpu": [2, 3, 4], "torch_cpu": [2, 3, 4], "tf_gpu": [2, 3, 4], "tf_cpu": [2, 3, 4], "onnx_gpu": [2, 3, 4], "onnx_cpu": [2, 3, 4], "package_prefix": 2, "_": [2, 3, 4, 8, 9, 12, 23, 24, 25, 27], "platform": [2, 38], "setup": [2, 26], "bash": [2, 3], "command": [2, 3, 4, 48], "shell": 2, "nvidia": [2, 3, 4], "card": 2, "comput": [2, 4, 6, 7, 14, 17, 21, 22, 27, 28, 36, 37, 38, 39, 40, 44, 48, 51], "capabl": [2, 24, 48, 49], "5": [2, 8, 9, 11, 12, 14, 17, 24, 25, 26, 32, 41, 43], "later": [2, 27], "docker": 2, "To": [2, 24, 26, 27, 30, 33, 36, 37, 40, 42, 43, 44, 45, 48, 49], "us": [2, 4, 6, 7, 8, 9, 16, 17, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 46, 49], "acceler": [2, 23, 34, 36], "train": [2, 23, 28, 29, 30, 34, 36, 43, 44, 46], "modul": [2, 6, 7, 17, 23, 27, 28, 38, 45, 46, 51], "an": [2, 6, 7, 16, 17, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 49, 51], "enabl": [2, 3, 17, 23, 26, 30, 34, 38, 40, 42, 44, 45, 46], "minimum": [2, 11, 12, 24], "driver": [2, 4], "455": 2, "i": [2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51], "alwai": [2, 33], "recommend": [2, 17, 26, 28, 30, 32, 38, 43], "especi": [2, 38, 41, 43], "newer": 2, "both": [2, 11, 12, 17, 23, 24, 26, 38, 39, 41, 42, 43, 44, 45, 47, 51], "cudnn": 2, "more": [2, 17, 23, 24, 26, 27, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49], "interfac": 2, "support": [2, 17, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 50, 51], "There": [2, 26, 28, 37, 39, 41, 48, 49], "two": [2, 17, 24, 26, 27, 33, 34, 36, 38, 39, 40, 41, 44, 47, 48, 49, 50], "wai": [2, 17, 26, 27, 33], "On": [2, 7], "your": [2, 3, 4, 23, 26, 37, 45], "machin": [2, 3, 36], "our": [2, 4, 27, 33, 43, 44], "pre": [2, 3, 4, 34, 39], "built": [2, 3], "develop": [2, 3, 4, 7, 17, 24, 45], "imag": [2, 28, 40], "pleas": [2, 3, 4, 23, 26, 27, 28, 29, 30, 31, 34, 36, 39, 40, 44, 45], "click": 2, "appropri": [2, 3, 4, 6, 7, 17, 24, 32, 33, 36, 43], "link": [2, 28, 29, 30, 39, 40, 44], "contain": [2, 6, 7, 16, 24, 27, 38, 40, 41, 42, 44], "thi": [3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 17, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51], "page": [3, 4, 32, 44, 46], "provid": [3, 4, 7, 14, 17, 23, 24, 26, 27, 28, 32, 33, 36, 38, 39, 40, 42, 43, 44, 45, 48, 49, 51], "instruct": [3, 4, 23], "insid": [3, 6, 7, 24, 27], "variant_str": [3, 4], "ONE": [3, 4], "depend": [3, 4, 16, 26, 32, 33, 38, 42, 46], "desir": [3, 4, 17, 27, 32, 36, 38, 43], "pt113": 3, "tf": [3, 40, 44, 46], "export": [3, 4, 23, 26, 30, 34, 36, 37, 38, 41, 44, 45, 46], "aimet_vari": [3, 4], "one": [3, 17, 24, 27, 31, 36, 41, 42, 46, 47, 50], "workspac": 3, "absolute_path_to_workspac": 3, "docker_image_nam": 3, "artifact": [3, 27], "codelinaro": 3, "org": [3, 4, 39], "dev": [3, 4], "docker_container_nam": 3, "any_nam": 3, "note": [3, 4, 17, 26, 27, 31, 32, 33, 34, 36, 37, 38, 40], "feel": 3, "free": [3, 38, 39, 41], "modifi": [3, 4, 38, 44, 46, 51], "need": [3, 17, 26, 27, 29, 32, 36, 38, 39, 40, 41, 42, 44, 46, 48, 49], "you": [3, 4, 26, 33, 37, 47, 50], "want": 3, "If": [3, 4, 6, 7, 8, 9, 11, 12, 14, 17, 22, 24, 25, 26, 27, 29, 37, 38, 39, 40, 42, 43, 48, 49, 51], "skip": [3, 31], "next": [3, 27, 43], "section": [3, 4, 17, 28, 30, 31, 36, 38, 44], "any_tag": 3, "t": [3, 28], "f": [3, 4, 27], "jenkin": 3, "dockerfil": 3, "ensur": [3, 24, 38, 43], "alreadi": [3, 33, 43], "run": [3, 8, 9, 17, 24, 25, 26, 30, 34, 36, 38, 39, 40, 44, 46, 48], "otherwis": [3, 4, 8, 9, 11, 12, 17, 25, 43], "remov": [3, 26, 27, 31, 34, 44, 51], "exist": [3, 6, 7, 17, 38, 44], "new": [3, 8, 9, 17, 23, 25, 26, 27, 38, 42, 46], "p": 3, "grep": 3, "kill": 3, "rm": 3, "u": [3, 43], "id": [3, 48], "user": [3, 17, 23, 24, 26, 28, 29, 32, 36, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49], "g": [3, 27, 30, 32, 34, 43, 51], "v": [3, 17, 33], "etc": [3, 4, 32, 38], "passwd": 3, "ro": 3, "group": [3, 17, 42, 44], "home": 3, "mnt": 3, "entrypoint": 3, "bin": [3, 4, 22], "w": [3, 51], "hostnam": 3, "abov": [3, 4, 17, 23, 29, 30, 33, 34, 36, 37, 39, 43, 44, 51], "base": [3, 6, 7, 8, 9, 11, 12, 14, 17, 22, 24, 25, 26, 31, 32, 38], "filesystem": 3, "add": [3, 7, 24, 27, 42, 44, 46, 48, 49, 51], "all": [3, 6, 7, 17, 24, 26, 27, 31, 33, 36, 39, 40, 42, 43, 45], "order": [3, 4, 6, 17, 27, 30, 31, 32, 38, 41, 44, 49], "access": [3, 26, 38], "replac": [3, 17, 24, 26, 27, 39, 44], "port": [3, 26, 48], "forward": [3, 6, 7, 8, 9, 24, 25, 27, 37, 40, 43, 46], "done": [3, 8, 9, 25, 31, 36, 42, 44, 51], "visual": [3, 36, 38, 39, 40, 43, 46, 47, 50], "api": [3, 7, 26, 27, 34, 37, 38, 42, 45, 46, 48], "can": [3, 4, 6, 8, 9, 16, 17, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50], "achiev": [3, 17, 28, 32, 33, 47, 50], "port_id": 3, "ani": [3, 4, 7, 17, 26, 27, 28, 29, 42, 46], "number": [3, 6, 7, 11, 12, 14, 17, 22, 24, 28, 33, 34, 36, 41, 44, 46, 48, 51], "through": [3, 4, 24, 26, 27, 39, 40, 44, 45, 48, 49], "method": [3, 4, 6, 7, 17, 24, 26, 27, 33, 36, 38, 43, 44], "go": [3, 4, 27, 45, 48], "project": [3, 4], "identifi": [3, 4, 17, 40, 43, 46, 51], "wish": [3, 4], "should": [3, 4, 6, 7, 17, 24, 26, 27, 32, 36, 42, 48, 51], "32": [3, 4, 8, 25, 43], "sudo": [3, 4], "y": [3, 4, 27, 40], "altern": [3, 4, 17, 36], "we": [3, 4, 17, 24, 26, 27, 33, 36, 38, 39, 42, 43, 44, 45, 49], "tag": [3, 4, 46], "below": [3, 4, 8, 9, 11, 12, 17, 24, 25, 26, 27, 28, 29, 30, 38, 39, 40, 42, 43, 44, 51], "release_tag": [3, 4], "step": [3, 11, 12, 23, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 41, 43, 44], "url": [3, 4, 48], "download_url": [3, 4], "common": [3, 17, 26, 43, 49], "suffix": [3, 4], "wheel_file_suffix": [3, 4], "cp310": [3, 4], "specifi": [3, 4, 8, 9, 11, 12, 14, 17, 25, 27, 29, 36, 42, 44, 49], "pend": [3, 4], "pip3": [3, 4], "h": [3, 4, 50, 51], "These": [3, 4, 24, 26, 27, 29, 30, 31, 32, 37, 38, 39, 40, 43, 44], "assum": [3, 4, 17], "path": [3, 4], "usr": [3, 4], "lib": [3, 4], "dist": [3, 4], "case": [3, 4, 11, 12, 17, 24, 26, 27, 33, 39, 41, 42], "accordingli": [3, 4], "automat": [3, 4, 17, 32, 36, 38, 40, 46], "torch_stabl": [3, 4], "html": [3, 4, 32, 40, 46, 49], "OR": [3, 4, 26], "variabl": [3, 4, 8, 9, 25], "sourc": [3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 43], "envsetup": [3, 4], "sh": [3, 4], "unless": [4, 7, 51], "local": [4, 48], "basic": [4, 23, 27, 45], "requisit": 4, "updat": [4, 25, 26, 38, 39, 41, 44, 46], "upgrad": 4, "ye": [4, 36], "wget": 4, "gnupg2": 4, "have": [4, 7, 17, 26, 27, 33, 36, 38, 39, 40, 43, 44, 45], "set": [4, 6, 7, 17, 21, 24, 25, 26, 28, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 51], "default": [4, 7, 8, 9, 11, 12, 24, 25, 28, 33, 36, 42, 44, 46, 48], "do": [4, 27, 36, 40, 44], "were": [4, 32, 38, 42, 45, 51], "test": 4, "7": [4, 11, 12, 14, 27, 51], "sub": [4, 31, 36, 44, 51], "correspond": [4, 17, 24, 31, 33, 38, 40, 51], "visit": [4, 23, 34], "archiv": 4, "obtain": [4, 31, 32, 40, 44, 45], "correct": [4, 27, 28, 30, 38, 39, 43], "exact": [4, 24, 30], "up": [4, 17, 36, 41, 42, 44, 45, 51], "date": 4, "repo": 4, "ubuntu2204": 4, "x86_64": 4, "pin": 4, "mv": 4, "prefer": [4, 36], "d": [4, 8, 9, 11, 12, 25], "repositori": 4, "600": 4, "local_instal": 4, "local_11": 4, "520": 4, "61": 4, "05": [4, 11, 12, 27], "1_amd64": 4, "deb": 4, "kei": 4, "adv": 4, "fetch": 4, "3bf863cc": 4, "pub": 4, "dpkg": 4, "cp": [4, 32], "var": 4, "keyr": 4, "gpg": 4, "share": [4, 24], "echo": 4, "list": [4, 11, 12, 17, 22, 24, 25, 26, 33, 35, 37, 42], "515": 4, "65": [4, 32], "01": [4, 11, 12, 28], "torch_gpu_pt113": 4, "torch_cpu_pt113": 4, "cp36": 4, "cp36m": 4, "cp37": 4, "cp37m": 4, "py3": 4, "none": [4, 6, 7, 8, 9, 10, 11, 12, 14, 17, 24, 25, 26, 27, 48], "actual": [4, 17, 32, 38], "wheel": 4, "filenam": 4, "": [4, 6, 7, 17, 23, 24, 25, 27, 32, 35, 36, 38, 39, 40, 41, 43, 44, 48, 49, 51], "cat": 4, "reqs_deb_common": 4, "txt": 4, "xarg": 4, "reqs_deb_torch_common": 4, "reqs_deb_onnx_common": 4, "reqs_deb_tf_gpu": 4, "reqs_deb_torch_gpu": 4, "reqs_deb_onnx_gpu": 4, "option": [4, 7, 8, 9, 11, 12, 17, 22, 23, 25, 27, 28, 40, 42, 44, 45, 48], "uninstal": 4, "cach": 4, "dir": 4, "9": [4, 11, 12, 16, 43], "post1": 4, "onnxruntime_v": 4, "c": [4, 32], "import": [4, 7, 8, 9, 11, 12, 14, 16, 17, 23, 24, 25, 27, 30, 31, 43], "print": [4, 6, 7, 11, 12, 24, 26, 27, 38, 40], "__version__": 4, "ln": 4, "gnu": 4, "libjpeg": 4, "so": [4, 24, 26, 37, 40, 48], "chose": 4, "between": [4, 17, 24, 26, 39, 40, 42, 44, 45], "class": [6, 7, 8, 9, 14, 17, 18, 20, 21, 22, 25, 26, 27], "v2": [6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27], "nn": [6, 7, 8, 9, 17, 23, 24, 25, 26, 27, 37, 45, 46], "arg": [6, 7, 11, 12, 16, 17, 24], "kwarg": [6, 7, 11, 12, 16, 24], "mixin": [6, 7, 24], "implement": [6, 7, 24, 26, 37, 43, 45], "fake": [6, 7, 9, 12, 14, 24, 25, 27, 45], "quantiz": [6, 7, 9, 10, 12, 14, 18, 20, 21, 22, 23, 28, 29, 30, 32, 34, 36, 40, 45, 46, 48], "top": [6, 7, 31, 48], "regular": [6, 7, 24, 28, 38, 44], "specif": [6, 17, 27, 28, 29, 30, 32, 34, 36, 37, 38, 39, 42, 46], "input": [6, 7, 8, 9, 11, 12, 14, 17, 24, 25, 26, 27, 31, 36, 40, 42, 44, 47, 48, 50, 51], "output": [6, 7, 8, 9, 11, 17, 24, 25, 26, 27, 31, 36, 39, 40, 42, 44, 46, 47, 50, 51], "paramet": [6, 7, 8, 9, 11, 12, 14, 16, 17, 21, 22, 24, 25, 26, 27, 28, 30, 31, 36, 37, 38, 39, 40, 41, 42, 45, 49], "tensor": [6, 7, 8, 9, 10, 11, 12, 14, 17, 22, 24, 25, 27, 28, 31, 37, 38, 40, 42, 43, 44, 46, 47, 50], "its": [6, 7, 16, 23, 24, 27, 34, 38, 40, 44, 51], "held": [6, 27], "quantizerbas": [6, 7, 24, 25], "object": [6, 7, 16, 17, 22, 24, 25, 27, 30, 38, 41, 44], "dure": [6, 24, 27, 28, 34, 36, 38, 41, 42, 44, 48, 49], "inherit": [6, 24], "layer": [6, 7, 17, 24, 27, 28, 29, 30, 31, 32, 35, 37, 38, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51], "oper": [6, 7, 24, 26, 27, 37, 38, 39, 42, 43], "behav": [6, 7, 24, 43], "exactli": [6, 7, 24, 44], "same": [6, 7, 16, 17, 24, 25, 26, 30, 39, 42, 44, 45, 49], "parent": [6, 7], "A": [6, 17, 22, 24, 32, 38, 40, 41, 42, 43, 44], "initi": [6, 7, 8, 9, 14, 24, 25, 28, 41, 43, 44], "scratch": 6, "syntax": 6, "form": 6, "from_modul": [6, 7], "input_quant": [6, 7, 24, 26, 27], "modulelist": [6, 7, 24, 26, 27], "appli": [6, 7, 8, 9, 11, 12, 17, 24, 25, 27, 28, 29, 30, 33, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49], "type": [6, 7, 8, 9, 16, 17, 22, 24, 25, 26, 38, 40, 42, 44, 48], "output_quant": [6, 7, 24, 26, 27], "param_quant": [6, 7, 17, 24, 26, 27], "moduledict": [6, 7, 24, 26, 27], "map": [6, 7, 11, 12, 16, 17, 24, 40, 42], "associ": [6, 7, 24, 38], "exampl": [6, 7, 8, 9, 11, 12, 14, 16, 17, 24, 25, 27, 28, 32, 33, 34, 38, 40, 42, 44, 46, 51], "qlinear": [6, 7, 24, 26], "fakequantizedlinear": [6, 24], "in_featur": [6, 7, 24, 26, 27], "out_featur": [6, 7, 24, 26, 27], "bia": [6, 7, 14, 26, 27, 28, 31, 38, 39, 42, 43, 46], "fals": [6, 7, 8, 9, 11, 12, 16, 17, 24, 25, 26, 27, 37, 42], "weight": [6, 7, 17, 22, 24, 26, 27, 28, 30, 32, 36, 38, 39, 40, 41, 42, 43, 44, 49], "linear": [6, 7, 17, 24, 26, 27, 30, 31], "true": [6, 7, 8, 9, 14, 16, 17, 22, 24, 25, 26, 27, 37, 42], "abstract": [6, 7, 24, 25], "perform": [6, 7, 8, 9, 17, 24, 25, 27, 29, 30, 31, 32, 33, 36, 38, 39, 40, 41, 43, 45], "logic": [6, 7, 46], "param": [6, 17, 25, 42], "call": [6, 7, 14, 16, 17, 24, 27, 30, 36, 38, 40, 42, 44, 46, 47, 50], "pass": [6, 7, 17, 23, 24, 26, 27, 34, 37, 38, 39, 40, 41, 43, 44, 46, 48], "__quant_init__": [6, 7, 24], "invok": [6, 7, 24, 36, 38, 48, 49], "right": [6, 7, 8, 9, 11, 12, 14, 24, 25, 38, 51], "after": [6, 7, 24, 27, 28, 29, 30, 32, 36, 38, 41, 43, 48, 49], "__init__": [6, 7, 24, 27], "structur": [6, 7, 24, 36], "size": [6, 7, 8, 9, 11, 12, 17, 24, 25, 28, 36, 37, 47, 50], "initializd": [6, 7, 24], "custom": [6, 7, 24, 43, 44, 45], "overridden": [6, 7, 24], "length": [6, 7, 17, 22, 24], "given": [6, 7, 17, 24, 29, 31, 33, 34, 36, 39, 47, 48, 50], "compute_encod": [6, 7, 8, 9, 14, 16, 23, 24, 25, 26, 27, 45], "enter": [6, 7, 24, 29], "context": [6, 7, 24, 27], "observ": [6, 7, 18, 21, 24, 25, 27, 33, 36, 38, 39, 40, 41, 44], "encod": [6, 7, 8, 9, 16, 17, 20, 21, 22, 23, 25, 26, 27, 28, 30, 38, 40, 41, 45, 46], "upon": [6, 7, 24, 27], "exit": [6, 7, 24, 27], "quantizedlinear": [6, 7, 17, 24, 26, 27], "symmetr": [6, 7, 8, 9, 16, 17, 22, 24, 25, 26, 27, 42, 44], "randn": [6, 7, 8, 9, 16, 24, 25], "16": [6, 7, 8, 14, 17, 24, 25, 28], "is_initi": [6, 7, 8, 9, 14, 24, 25], "classmethod": [6, 7], "creat": [6, 7, 23, 24, 27, 28, 30, 36, 37, 38, 41, 44], "instanc": [6, 7, 48], "result": [6, 7, 16, 17, 22, 28, 29, 31, 32, 34, 39, 40, 41, 42, 44], "attribut": [6, 7, 24, 26, 40], "origin": [6, 7, 24, 26, 27, 31, 32, 36, 38, 39, 40, 41, 44, 48], "mai": [6, 7, 16, 17, 24, 28, 32, 36, 38, 39, 40, 42, 43, 44], "assign": [6, 7, 8, 9, 24, 25], "float": [6, 7, 14, 16, 17, 23, 24, 38, 40, 43, 44, 45, 49], "point": [6, 7, 16, 17, 23, 24, 26, 34, 36, 38, 40, 43, 44, 45, 49], "return": [6, 7, 8, 9, 16, 17, 22, 23, 25, 27, 29, 33, 34, 40, 44], "quantized_linear": [6, 7], "module_cl": [6, 7], "decor": [6, 7], "regist": [6, 7, 24, 25], "defin": [6, 17, 24, 27, 37, 38, 40, 42, 44], "featur": [7, 17, 24, 28, 29, 30, 36, 39, 40, 44, 46, 48, 49], "under": [7, 17, 24, 26, 40, 42, 48, 49], "heavi": [7, 17, 24, 48, 49], "chang": [7, 17, 24, 27, 28, 36, 40, 41, 42, 44, 45, 49, 51], "occur": [7, 17, 24], "without": [7, 14, 16, 17, 24, 29, 38, 41, 44, 51], "notic": [7, 17, 24, 36], "futur": [7, 17, 24, 45], "verion": 7, "function": [7, 11, 12, 16, 17, 24, 26, 27, 28, 33, 36, 37, 38, 40, 44, 46, 48, 49], "behavior": [7, 24, 26, 27, 34, 45], "fakequantizationmixin": [7, 23, 24], "abil": [7, 46], "kernel": [7, 17, 24, 31, 45, 47, 50], "which": [7, 8, 9, 11, 12, 16, 17, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 36, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50], "place": [7, 17, 41, 42], "ha": [7, 16, 17, 26, 27, 32, 33, 36, 39, 41, 44, 48, 51], "been": [7, 16, 17, 38, 41, 44, 45, 51], "within": [7, 16, 24, 32, 40, 44], "fall": [7, 33, 42], "back": [7, 16, 27, 42], "equival": [7, 11, 12, 14, 17, 27], "e": [7, 27, 30, 32, 34, 41, 43, 51], "get_kernel": 7, "doe": [7, 24, 26, 27, 33, 35, 38, 43], "retriev": 7, "well": [7, 16, 17, 24, 32, 36, 38, 39, 40, 44, 47], "dequant": [7, 9, 12, 16, 23, 24, 25, 44], "set_kernel": 7, "signatur": [7, 11, 12], "must": [7, 17, 24, 30, 34, 35, 40, 42, 51], "match": [7, 17, 31, 36, 40, 42, 43, 44, 51], "In": [7, 17, 24, 26, 27, 28, 29, 32, 33, 36, 38, 39, 41, 42, 44, 45, 49, 51], "gener": [7, 8, 9, 11, 12, 17, 25, 27, 36, 38, 40, 41, 42, 44], "quantizedtensor": [7, 8, 16, 25], "take": [7, 17, 27, 34, 36, 38, 39, 41, 42, 43, 51], "addit": [7, 17, 29, 38, 41, 42, 46], "keyword": 7, "argument": [7, 14, 17], "output_encod": 7, "onc": [7, 30, 31, 36, 40, 41, 44], "callabl": [7, 17], "underli": [7, 43], "q": [7, 8, 9, 11, 12, 14, 16, 24, 25, 26, 44], "def": [7, 26, 27], "int_multipli": 7, "b": [7, 8, 9, 11, 12, 25], "enc": 7, "affin": [7, 8, 9, 10, 11, 12, 16, 17, 23, 24, 25, 27, 45], "rais": 7, "notimplementederror": 7, "q_output": 7, "quantized_repr": [7, 16], "offset": [7, 8, 9, 10, 11, 12, 17, 22, 25, 38, 40, 41, 44], "dq_output": 7, "scale": [7, 8, 9, 10, 11, 12, 14, 16, 17, 25, 30, 38, 39, 40, 41, 44], "qmult": 7, "quantizedmultipli": [7, 24], "set_default_kernel": 7, "quantized_forward": 7, "cl": [7, 46], "get_default_kernel": 7, "current": [7, 31, 34, 35, 36, 37, 42, 47, 50], "shape": [8, 9, 14, 16, 17, 20, 21, 22, 24, 25, 26, 27, 40], "bitwidth": [8, 9, 11, 12, 14, 16, 17, 24, 25, 26, 27, 30, 38, 43, 44], "encoding_analyz": [8, 9, 14, 18, 20, 21, 22, 25], "block_siz": [8, 9, 10, 11, 12, 17, 25], "precis": [8, 9, 11, 12, 14, 23, 25, 38], "out": [8, 9, 11, 12, 14, 25, 29, 32, 36, 40], "clamp": [8, 9, 11, 12, 14, 25, 44], "left": [8, 9, 11, 12, 14, 25, 33, 51], "lceil": [8, 9, 11, 12, 14, 25], "frac": [8, 9, 11, 12, 14, 25], "rfloor": [8, 9, 11, 12, 14, 25], "qmin": [8, 9, 11, 12, 25, 44], "qmax": [8, 9, 11, 12, 25, 44], "where": [8, 9, 11, 12, 14, 24, 25, 27, 30, 33, 40, 41, 47, 50, 51], "deriv": [8, 9, 11, 12, 24, 25], "learnabl": [8, 9, 25], "theta_": [8, 9, 25], "min": [8, 9, 20, 22, 24, 25, 26, 27, 40, 44], "max": [8, 9, 14, 20, 22, 24, 25, 26, 27, 36, 39, 40, 44], "block": [8, 9, 11, 12, 17, 25, 26, 45], "begin": [8, 9, 11, 12, 25, 41, 42], "pmatrix": [8, 9, 11, 12, 25], "b_0": [8, 9, 11, 12, 25], "b_1": [8, 9, 11, 12, 17, 25], "cdot": [8, 9, 11, 12, 25], "b_": [8, 9, 11, 12, 25], "end": [8, 9, 11, 12, 25, 27, 36], "equat": [8, 9, 11, 12, 17, 25, 44], "further": [8, 9, 11, 12, 16, 17, 25, 26, 27, 31, 34, 36, 38, 42], "out_": [8, 9, 11, 12, 25], "j_0": [8, 9, 11, 12, 25], "j_": [8, 9, 11, 12, 25], "input_": [8, 9, 11, 12, 25], "scale_": [8, 9, 11, 12, 25], "i_0": [8, 9, 11, 12, 25], "i_": [8, 9, 11, 12, 25], "offset_": [8, 9, 11, 12, 25], "text": [8, 9, 11, 12, 25], "quad": [8, 9, 11, 12, 25, 44], "forall_": [8, 9, 11, 12, 25], "leq": [8, 9, 11, 12, 25], "i_d": [8, 9, 11, 12, 25], "lfloor": [8, 9, 11, 12, 14, 25], "j_d": [8, 9, 11, 12, 25], "b_d": [8, 9, 11, 12, 25], "tupl": [8, 9, 11, 12, 17, 22, 25], "int": [8, 9, 11, 12, 14, 17, 22, 25, 26], "bool": [8, 9, 11, 12, 17, 22, 25], "asymmetr": [8, 9, 22, 25, 42, 44], "encodinganalyz": [8, 9, 14, 18, 25], "analyz": [8, 9, 20, 21, 22, 23, 24, 25, 29, 31, 36, 37, 40, 44, 45, 48, 49], "calibr": [8, 9, 17, 20, 21, 22, 23, 24, 25, 27, 38, 40, 41, 43, 44], "absolut": [8, 9, 25], "cannot": [8, 9, 25], "until": [8, 9, 25, 29], "properli": [8, 9, 25, 27], "statist": [8, 9, 14, 24, 25, 27, 30, 38, 40, 49], "manual": [8, 9, 25, 26, 29, 36], "valu": [8, 9, 11, 12, 14, 16, 17, 21, 22, 25, 27, 28, 33, 36, 38, 39, 40, 41, 44, 47, 49, 50], "see": [8, 9, 24, 25, 26, 27, 31, 33, 34, 36, 38, 42, 43, 44, 47, 48, 49, 50], "129": [8, 25, 37], "255": [8, 16, 25], "122": [8, 25], "192": [8, 25], "106": [8, 25], "94": [8, 25], "145": [8, 25], "181": [8, 25], "144": [8, 25], "194": [8, 25], "74": [8, 25], "86": [8, 25], "150": [8, 25], "33": [8, 25], "103": [8, 25], "37": [8, 25], "111": [8, 25], "237": [8, 25], "218": [8, 25], "49": [8, 25], "155": [8, 25], "179": [8, 25], "66": [8, 25, 32], "89": [8, 25], "110": [8, 25], "17": [8, 22, 25], "36": [8, 25], "83": [8, 25], "grad_fn": [8, 9, 16, 25], "aliasbackward0": [8, 9, 16, 25], "ones_lik": [8, 9, 25], "187": [8, 25], "186": [8, 25], "131": [8, 25], "203": [8, 25], "80": [8, 25], "143": [8, 25], "152": [8, 25], "226": [8, 25], "55": [8, 25], "172": [8, 25], "207": [8, 25], "146": [8, 25], "216": [8, 25], "238": [8, 25], "141": [8, 25], "178": [8, 25], "188": [8, 25], "63": [8, 25], "59": [8, 25], "19": [8, 25], "162": [8, 25], "30": [8, 25], "109": [8, 25], "overlin": [9, 12, 25], "qdq": [9, 14, 25], "dequantizedtensor": [9, 16, 25], "2771": [9, 25], "3038": [9, 25], "0819": [9, 25], "9700": [9, 25], "9487": [9, 25], "1307": [9, 25], "7894": [9, 25], "1709": [9, 25], "2212": [9, 25], "7741": [9, 25], "0295": [9, 25], "2265": [9, 25], "0564": [9, 25], "6177": [9, 25], "0386": [9, 25], "0176": [9, 25], "6054": [9, 25], "8836": [9, 25], "1232": [9, 25], "8229": [9, 25], "5540": [9, 25], "3992": [9, 25], "2363": [9, 25], "2546": [9, 25], "0036": [9, 25], "2355": [9, 25], "1741": [9, 25], "6079": [9, 25], "6247": [9, 25], "0115": [9, 25], "2458": [9, 25], "9157": [9, 25], "4694": [9, 25], "0639": [9, 25], "2568": [9, 25], "0680": [9, 25], "6695": [9, 25], "7932": [9, 25], "1889": [9, 25], "0158": [9, 25], "5695": [9, 25], "5220": [9, 25], "1977": [9, 25], "4475": [9, 25], "0424": [9, 25], "1128": [9, 25], "8796": [9, 25], "1060": [9, 25], "5897": [9, 25], "6196": [9, 25], "9961": [9, 25], "0549": [9, 25], "6431": [9, 25], "0039": [9, 25], "8706": [9, 25], "4706": [9, 25], "2353": [9, 25], "8078": [9, 25], "3451": [9, 25], "1176": [9, 25], "4549": [9, 25], "0471": [9, 25], "5255": [9, 25], "4157": [9, 25], "0784": [9, 25], "5333": [9, 12, 25], "1647": [9, 25], "2118": [9, 25], "2196": [9, 25], "9176": [9, 25], "9490": [9, 25], "7765": [9, 25], "4784": [9, 25], "6039": [9, 25], "3137": [9, 25], "3216": [9, 25], "8000": [9, 12, 25], "4392": [9, 25], "4863": [9, 25], "overload": [11, 12], "sign": [11, 12, 26, 44], "rceil": [11, 12], "posit": [11, 12], "integ": [11, 12, 17, 28, 38, 40], "rang": [11, 12, 21, 22, 27, 28, 30, 33, 38, 39, 40, 41, 43, 44, 46, 49], "over": [11, 12, 22, 24, 28, 33, 36, 49], "neg": [11, 12, 17, 24], "num_step": [11, 12, 22], "num": [11, 12], "_step": [11, 12], "maximum": [11, 12, 14, 22, 24], "arang": [11, 12], "start": [11, 12, 27, 28, 33, 36, 42, 44], "0000e": [11, 12], "5000e": [11, 12], "02": [11, 12], "1921e": [11, 12], "08": [11, 12], "4": [11, 12, 16, 17, 26, 27, 30, 33, 38, 51], "6": [11, 12, 17, 41], "00": [11, 12], "0500e": [11, 12], "1000e": [11, 12], "1500e": [11, 12], "2000e": [11, 12], "2500e": [11, 12], "15": [11, 12, 36, 41], "0000": [12, 16], "0667": 12, "1333": 12, "2000": [12, 16], "2667": 12, "3333": 12, "4000": [12, 16], "4667": 12, "6000": [12, 16], "6667": 12, "7333": 12, "8667": 12, "9333": 12, "exponent_bit": [14, 17], "mantissa_bit": [14, 17], "dtype": [14, 16, 17, 26], "simul": [14, 17, 23, 24, 27, 34, 38, 41, 45, 46], "cast": [14, 24], "expon": [14, 17], "mantissa": [14, 17], "x_c": 14, "log_2": 14, "ieee": [14, 36, 39], "standard": [14, 24], "represent": [14, 16], "_max": 14, "mutual": [14, 17], "exclus": [14, 17], "repres": [14, 16, 24, 25, 27, 33, 38, 39, 40, 41, 44], "determin": [14, 17, 24, 27, 29, 32, 36, 38, 39, 40], "dynam": [14, 39, 44, 46, 49], "finer": [14, 17, 45], "8998": 14, "0947": 14, "0891": 14, "1727": 14, "unlik": 14, "affinequant": [14, 26], "floatquant": [14, 26], "is_bfloat16": 14, "8984": 14, "0859": 14, "1729": 14, "minmaxencodinganalyz": [14, 23, 26], "float16": [14, 17, 26], "is_float16": 14, "8994": 14, "0889": 14, "alia": 14, "hold": [16, 17, 24, 42], "store": [16, 17], "along": [16, 17, 27, 41, 44], "encodingbas": [16, 25], "inform": [16, 26, 38, 40], "necessari": [16, 17, 27, 48], "real": 16, "self": [16, 22, 27], "produc": [16, 17, 22, 33, 40, 45, 48], "rtype": 16, "57": 16, "312": 16, "153": 16, "205": 16, "set_rang": 16, "128": [16, 17, 27], "127": 16, "x_q": 16, "26": 16, "23": 16, "x_dq": 16, "3000": 16, "equal": [16, 17, 22, 24, 28, 29, 32, 33, 37, 38, 40, 49], "data": [16, 17, 23, 26, 27, 28, 30, 35, 38, 39, 40, 41, 43, 44], "abl": [16, 27, 28, 48, 49], "carri": 16, "gradient": 16, "thu": 16, "autograd": 16, "allow": [16, 17, 24, 29, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 48], "backpropag": 16, "requires_grad": 16, "38": [16, 36], "28": 16, "40": 16, "int8": [16, 41, 44, 49], "subsequ": [16, 37, 39, 41, 42], "about": [16, 27, 45], "wa": [16, 31, 36, 42], "With": [16, 45], "convert": [16, 27, 29, 38, 49], "loss": [16, 23, 27, 28, 34, 38, 40, 44], "39": [16, 27], "51": 16, "521": 16, "41": 16, "quant_dequ": 16, "quantizedequant": [16, 17, 23, 24, 25, 26, 27], "x_qdq": 16, "52": 16, "68": 16, "97": 16, "uint8": 16, "when": [17, 21, 23, 24, 27, 28, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51], "also": [17, 31, 32, 33, 38, 40, 42, 43, 44, 46, 48, 49, 51], "known": [17, 33, 34], "like": [17, 23, 26, 27, 34, 36, 38, 40, 41, 42, 45, 48], "grid": [17, 45], "counterpart": [17, 24], "process": [17, 22, 23, 27, 29, 34, 36, 38, 39, 44, 45], "particular": [17, 38, 42], "choos": [17, 31, 32, 36], "come": [17, 41, 44], "cover": [17, 30, 42, 44], "whole": [17, 44], "split": [17, 22, 24], "describ": [17, 26, 38, 39, 43, 44], "sever": [17, 24, 32], "pro": 17, "con": 17, "per": [17, 22, 24, 30, 38, 39, 40, 42, 43, 44, 46], "entir": [17, 27, 33, 36], "collect": [17, 31, 40], "singl": [17, 28, 39], "benefit": [17, 28], "less": [17, 22, 24, 31, 33], "storag": 17, "space": 17, "drawback": 17, "outlier": [17, 40, 44], "affect": [17, 30, 42, 51], "channel": [17, 24, 30, 32, 33, 35, 36, 39, 40, 42, 43, 44, 46, 47, 49, 50, 51], "individu": [17, 30, 31, 32, 33, 36, 38, 40, 43], "typic": [17, 27, 32, 38, 40, 41, 42, 44, 48], "dimens": [17, 24, 36, 43, 47, 50], "compar": [17, 27, 40, 41, 49], "would": [17, 26, 32, 36, 42, 46, 48], "influenc": 17, "resid": [17, 46], "chunk": 17, "across": [17, 39, 40], "improv": [17, 26, 27, 32, 38, 41, 43, 49], "granular": [17, 36, 43, 44, 45, 49], "found": [17, 26, 41, 44, 45], "isol": 17, "optim": [17, 27, 28, 29, 34, 36, 38, 41, 44, 45, 46, 48], "cost": [17, 33, 36, 41], "increas": [17, 33, 39, 42], "favor": 17, "possibl": [17, 27, 40, 42, 43], "similarli": [17, 43], "lead": [17, 28, 30, 39, 43, 44], "better": [17, 28, 29, 38, 39, 41], "accuraci": [17, 23, 27, 28, 29, 32, 33, 34, 36, 38, 39, 40, 41, 43, 44, 46, 49, 51], "activ": [17, 24, 27, 38, 40, 41, 42, 43, 44], "runtim": [17, 23, 27, 32, 34, 36, 38, 40, 42, 44, 46], "part": [17, 36, 38, 39, 40], "basi": [17, 33, 36], "instanti": [17, 27, 41, 48], "relationship": 17, "being": [17, 26], "rule": [17, 42], "most": [17, 27, 42], "long": 17, "b_2": 17, "b_n": 17, "s_1": 17, "s_2": 17, "s_n": 17, "satisfi": [17, 27, 29], "n": [17, 27, 46], "word": 17, "evenli": 17, "divid": [17, 24, 41], "valid": [17, 29, 38, 46], "sinc": [17, 30, 32, 33, 44], "divis": 17, "permit": 17, "essenti": [17, 23], "invalid": 17, "combin": [17, 29, 32, 36, 38, 39], "though": [17, 42], "3d": 17, "final": [17, 31, 32, 33, 41, 43, 48], "infer": [17, 23, 27, 30, 32, 34, 39, 41, 44, 46], "while": [17, 24, 28, 33, 37, 38, 41, 43, 44, 45, 48], "arbitrari": 17, "experiment": [17, 26, 36, 42, 45], "purpos": [17, 42], "restrict": [17, 37], "constraint": 17, "still": [17, 38, 43], "themselv": [17, 41], "code": [17, 27, 28, 45], "show": [17, 23, 27, 34, 39, 43], "how": [17, 24, 26, 27, 36, 39, 40, 43, 44, 45], "configur": [17, 27, 32, 35, 46], "convolut": [17, 27, 30, 32, 36, 43], "sim": [17, 23, 26, 27, 41, 44], "conv_1": 17, "refer": [17, 26, 28, 29, 30, 34, 38, 40, 41, 42, 44, 45], "quantizedconv2d": [17, 24, 26, 27], "work": [17, 30, 36, 37, 39, 42], "too": 17, "linear_1": 17, "scheme": [17, 29, 30, 33, 36, 40], "lower": [17, 26, 33, 38, 43], "adjust": [17, 30, 31, 32, 38, 39, 43], "thei": [17, 42, 45, 48], "lie": 17, "higher": [17, 22, 30, 33, 41, 43], "leverag": 17, "than": [17, 26, 27, 35, 41, 48], "due": [17, 38, 39], "fact": 17, "expans": [17, 36], "factor": [17, 22, 32, 36, 39], "fashion": 17, "groupedblockquantizedequant": 17, "introduc": [17, 38, 42, 44], "decompressed_bw": 17, "expand": [17, 24], "greater": [17, 24], "block_group": 17, "togeth": [17, 36], "As": [17, 29, 31, 32, 33, 36, 38, 39, 40, 44, 47, 50], "except": 17, "make": [17, 24, 33, 36, 37, 38, 44, 45], "easier": [17, 26, 45], "quantsim": [17, 23, 38, 41, 42, 46], "config_util": 17, "set_blockwise_quantization_for_weight": 17, "quantizationsimmodel": [17, 23, 27, 28, 30], "consist": [17, 26, 29, 44, 51], "either": [17, 34, 44], "whose": [17, 26, 39, 42, 45, 51], "union": 17, "arrai": 17, "in_channel": [17, 27], "out_channel": [17, 27], "conv": [17, 35, 42, 46, 47, 50, 51], "input_channel": 17, "conv2d": [17, 24, 26, 27, 31, 36, 46, 51], "conv2": [17, 27], "linear1": 17, "dim": [17, 27], "lambda": 17, "isinst": 17, "util": [17, 26, 27, 30, 38], "certain": [17, 36, 37, 38, 42], "Of": 17, "signific": [17, 43], "second": [17, 24, 42], "subset": [17, 28, 30, 40, 51], "switch": 17, "docstr": 17, "instead": [17, 38, 39], "differ": [17, 26, 31, 33, 36, 38, 39, 41, 42, 43, 44, 45], "ex": 17, "4d": 17, "2d": 17, "handl": 17, "requir": [17, 27, 28, 30, 32, 36, 38, 39, 42, 44], "time": [17, 27, 29, 36, 37, 41, 48], "mention": 17, "assist": [17, 48, 49], "transform": [17, 27, 46], "set_activation_quantizers_to_float": 17, "set_grouped_blockwise_quantization_for_weight": 17, "decompress": 17, "bw": 17, "experi": [17, 36, 45], "similar": [17, 39, 41, 44], "addition": 17, "effect": [17, 24, 27, 30, 38, 40, 42, 44], "larger": [17, 47, 50], "reduc": [17, 24, 31, 36, 39, 43, 46, 51], "write": 17, "snippet": 17, "encoding_vers": 17, "exported_model": 17, "dummy_input": [17, 27], "present": [17, 26, 27, 36, 39], "techniqu": [20, 21, 22, 23, 27, 28, 29, 31, 32, 34, 38, 40, 41, 43, 44, 45, 46, 47, 50], "num_bin": [21, 22], "2048": [21, 22], "percentil": 21, "100": [21, 26, 27], "set_percentil": 21, "clip": [21, 22, 42, 44], "largest": 21, "smallest": 21, "50": [21, 32], "indic": [21, 24, 32, 51], "asymmetric_delta_candid": 22, "symmetric_delta_candid": 22, "101": 22, "offset_candid": 22, "21": 22, "max_parallel": 22, "gamma": 22, "sqnr": [22, 44], "calcul": [22, 24, 33, 39, 40, 44], "histogram": [22, 38, 40, 44, 46], "delta": [22, 44], "search": [22, 33, 41, 42], "mode": [22, 25, 37, 38, 42], "paral": 22, "memori": [22, 32, 36, 47, 50, 51], "usag": [22, 23, 32, 36, 43], "faster": [22, 28, 34, 41], "nois": [22, 27, 38, 39, 40, 41, 42], "compute_encodings_from_stat": 22, "stat": 22, "is_symmetr": [22, 42], "lowest": 22, "expect": [22, 27, 36, 38, 40], "_histogram": 22, "els": [22, 27, 39], "tool": [23, 27, 36, 39, 49, 51], "compress": [23, 31, 34, 46, 47, 49, 50, 51], "deploi": [23, 44], "edg": [23, 34], "devic": [23, 27, 44], "fix": [23, 34, 38, 43, 44, 46], "post": [23, 27, 28, 29, 34, 36, 41, 44, 46], "fine": [23, 32, 34, 38, 41, 44], "tune": [23, 32, 34, 38, 41, 44], "minim": [23, 34, 36, 38, 44], "incur": [23, 34, 40], "pictur": [23, 31, 34], "high": [23, 26, 28, 30, 32, 33, 34, 39, 43, 45, 46, 49], "level": [23, 26, 30, 32, 33, 34, 38, 43, 45, 48], "view": [23, 27, 28, 29, 30, 34, 37, 39, 40, 44, 48], "workflow": [23, 27, 32, 34], "low": [23, 28, 30, 36, 38, 39, 43, 45], "recov": [23, 34, 43, 44], "lost": [23, 34], "via": [23, 32, 34, 44], "torchscript": 23, "target": [23, 30, 32, 33, 34, 36, 38, 43, 44, 46], "neural": [23, 27, 29, 32, 34, 36, 38, 41, 43, 44, 50], "sdk": [23, 27, 34], "instal": [23, 46], "sample_input": [23, 27], "sampl": [23, 24, 27, 31, 38, 39, 40, 41, 44], "data_load": [23, 27], "sample_output": 23, "out_dir": 23, "quantized_model": 23, "quickstart": 23, "guid": [23, 26, 32, 39, 43, 45, 46], "depth": [23, 32, 43], "adapt": [23, 27, 28, 38, 40, 46], "round": [23, 24, 28, 38, 40, 44], "adaround": [23, 26, 29, 38, 43, 45, 46], "sqnrencodinganalyz": [23, 26], "percentileencodinganalyz": [23, 26], "quantizationmixin": [23, 24], "quantize_dequant": 23, "product": [23, 34], "technologi": [23, 34], "subsidiari": [23, 34], "network": [24, 27, 29, 32, 33, 36, 38, 41, 43, 44, 48, 50], "aimet": [24, 26, 27, 34, 37, 42, 45], "serv": [24, 48], "drop": [24, 29, 32, 36, 39, 40, 41, 43, 44], "nativ": 24, "state": [24, 27, 36], "superset": 24, "mean": [24, 27, 31, 42, 44], "extens": 24, "coverag": 24, "limit": [24, 26, 35], "tabl": [24, 26, 33, 37, 48], "full": [24, 50], "basequantizationmixin": 24, "respons": [24, 36], "control": [24, 44, 45], "descript": [24, 37], "dict": [24, 25], "By": [24, 36, 42, 44], "index": [24, 32, 46], "respect": [24, 40], "per_channel_quant": [24, 42], "elementwis": [24, 46], "multipli": [24, 32], "qmul": 24, "some": [24, 26, 27, 28, 32, 33, 36, 37, 38, 39, 41, 43, 44], "sens": 24, "qadd": 24, "quantizedadd": 24, "befor": [24, 26, 27, 28, 29, 30, 36, 38, 41, 48, 49], "first": [24, 27, 32, 36, 38, 41, 48], "disabl": [24, 26, 33, 36, 40, 42, 44], "them": [24, 26, 27, 28, 51], "calibration_data_load": 24, "adaptiveavgpool1d": 24, "fakequantizedadaptiveavgpool1d": 24, "adaptiveavgpool2d": 24, "fakequantizedadaptiveavgpool2d": 24, "adaptiveavgpool3d": 24, "fakequantizedadaptiveavgpool3d": 24, "adaptivemaxpool1d": 24, "fakequantizedadaptivemaxpool1d": 24, "adaptivemaxpool2d": 24, "fakequantizedadaptivemaxpool2d": 24, "adaptivemaxpool3d": 24, "fakequantizedadaptivemaxpool3d": 24, "alphadropout": 24, "fakequantizedalphadropout": 24, "avgpool1d": 24, "fakequantizedavgpool1d": 24, "avgpool2d": 24, "fakequantizedavgpool2d": 24, "avgpool3d": 24, "fakequantizedavgpool3d": 24, "batchnorm1d": 24, "fakequantizedbatchnorm1d": 24, "batchnorm2d": [24, 27], "fakequantizedbatchnorm2d": 24, "batchnorm3d": 24, "fakequantizedbatchnorm3d": 24, "celu": 24, "fakequantizedcelu": 24, "channelshuffl": 24, "fakequantizedchannelshuffl": 24, "constantpad1d": 24, "fakequantizedconstantpad1d": 24, "constantpad2d": 24, "fakequantizedconstantpad2d": 24, "constantpad3d": 24, "fakequantizedconstantpad3d": 24, "conv1d": [24, 46], "fakequantizedconv1d": 24, "quantizedconv1d": 24, "fakequantizedconv2d": 24, "conv3d": 24, "fakequantizedconv3d": 24, "quantizedconv3d": 24, "convtranspose1d": [24, 46], "fakequantizedconvtranspose1d": 24, "convtranspose2d": 24, "fakequantizedconvtranspose2d": 24, "convtranspose3d": 24, "fakequantizedconvtranspose3d": 24, "crossmaplrn2d": 24, "fakequantizedcrossmaplrn2d": 24, "dropout": 24, "fakequantizeddropout": 24, "dropout2d": 24, "fakequantizeddropout2d": 24, "dropout3d": 24, "fakequantizeddropout3d": 24, "elu": 24, "fakequantizedelu": 24, "featurealphadropout": 24, "fakequantizedfeaturealphadropout": 24, "flatten": 24, "fakequantizedflatten": 24, "fold": [24, 28, 29, 30, 38, 39, 40, 46], "fakequantizedfold": 24, "fractionalmaxpool2d": 24, "fakequantizedfractionalmaxpool2d": 24, "fractionalmaxpool3d": 24, "fakequantizedfractionalmaxpool3d": 24, "gelu": 24, "fakequantizedgelu": 24, "quantizedgelu": 24, "glu": 24, "fakequantizedglu": 24, "groupnorm": 24, "fakequantizedgroupnorm": 24, "hardshrink": 24, "fakequantizedhardshrink": 24, "hardsigmoid": 24, "fakequantizedhardsigmoid": 24, "hardswish": 24, "fakequantizedhardswish": 24, "hardtanh": 24, "fakequantizedhardtanh": 24, "ident": [24, 27], "fakequantizedident": 24, "instancenorm1d": 24, "fakequantizedinstancenorm1d": 24, "instancenorm2d": 24, "fakequantizedinstancenorm2d": 24, "instancenorm3d": 24, "fakequantizedinstancenorm3d": 24, "lppool1d": 24, "fakequantizedlppool1d": 24, "lppool2d": 24, "fakequantizedlppool2d": 24, "layernorm": 24, "fakequantizedlayernorm": 24, "quantizedlayernorm": 24, "leakyrelu": 24, "fakequantizedleakyrelu": 24, "localresponsenorm": 24, "fakequantizedlocalresponsenorm": 24, "logsigmoid": 24, "fakequantizedlogsigmoid": 24, "logsoftmax": 24, "fakequantizedlogsoftmax": 24, "maxpool1d": 24, "fakequantizedmaxpool1d": 24, "maxpool2d": 24, "fakequantizedmaxpool2d": 24, "maxpool3d": 24, "fakequantizedmaxpool3d": 24, "maxunpool1d": 24, "fakequantizedmaxunpool1d": 24, "maxunpool2d": 24, "fakequantizedmaxunpool2d": 24, "maxunpool3d": 24, "fakequantizedmaxunpool3d": 24, "mish": 24, "fakequantizedmish": 24, "prelu": 24, "fakequantizedprelu": 24, "pixelshuffl": 24, "fakequantizedpixelshuffl": 24, "pixelunshuffl": 24, "fakequantizedpixelunshuffl": 24, "rrelu": 24, "fakequantizedrrelu": 24, "relu": [24, 26, 27, 39, 42, 51], "fakequantizedrelu": [24, 26, 27], "relu6": [24, 39], "fakequantizedrelu6": 24, "reflectionpad1d": 24, "fakequantizedreflectionpad1d": 24, "reflectionpad2d": 24, "fakequantizedreflectionpad2d": 24, "replicationpad1d": 24, "fakequantizedreplicationpad1d": 24, "replicationpad2d": 24, "fakequantizedreplicationpad2d": 24, "replicationpad3d": 24, "fakequantizedreplicationpad3d": 24, "selu": 24, "fakequantizedselu": 24, "silu": 24, "fakequantizedsilu": 24, "sigmoid": 24, "fakequantizedsigmoid": 24, "quantizedsigmoid": 24, "softmax": [24, 27], "fakequantizedsoftmax": 24, "quantizedsoftmax": [24, 27], "softmax2d": 24, "fakequantizedsoftmax2d": 24, "softmin": 24, "fakequantizedsoftmin": 24, "softplu": 24, "fakequantizedsoftplu": 24, "softshrink": 24, "fakequantizedsoftshrink": 24, "softsign": 24, "fakequantizedsoftsign": 24, "syncbatchnorm": 24, "fakequantizedsyncbatchnorm": 24, "tanh": 24, "fakequantizedtanh": 24, "tanhshrink": 24, "fakequantizedtanhshrink": 24, "threshold": [24, 29], "fakequantizedthreshold": 24, "unflatten": 24, "fakequantizedunflatten": 24, "unfold": 24, "fakequantizedunfold": 24, "upsampl": [24, 37], "fakequantizedupsampl": 24, "upsamplingbilinear2d": 24, "fakequantizedupsamplingbilinear2d": 24, "upsamplingnearest2d": 24, "fakequantizedupsamplingnearest2d": 24, "zeropad2d": 24, "fakequantizedzeropad2d": 24, "bceloss": 24, "fakequantizedbceloss": 24, "bcewithlogitsloss": 24, "fakequantizedbcewithlogitsloss": 24, "bilinear": [24, 37], "fakequantizedbilinear": 24, "ctcloss": 24, "fakequantizedctcloss": 24, "cosinesimilar": 24, "fakequantizedcosinesimilar": 24, "crossentropyloss": [24, 27], "fakequantizedcrossentropyloss": 24, "hingeembeddingloss": 24, "fakequantizedhingeembeddingloss": 24, "huberloss": 24, "fakequantizedhuberloss": 24, "kldivloss": 24, "fakequantizedkldivloss": 24, "l1loss": 24, "fakequantizedl1loss": 24, "mseloss": 24, "fakequantizedmseloss": 24, "multilabelmarginloss": 24, "fakequantizedmultilabelmarginloss": 24, "multilabelsoftmarginloss": 24, "fakequantizedmultilabelsoftmarginloss": 24, "multimarginloss": 24, "fakequantizedmultimarginloss": 24, "nllloss": 24, "fakequantizednllloss": 24, "nllloss2d": 24, "fakequantizednllloss2d": 24, "pairwisedist": 24, "fakequantizedpairwisedist": 24, "poissonnllloss": 24, "fakequantizedpoissonnllloss": 24, "smoothl1loss": 24, "fakequantizedsmoothl1loss": 24, "softmarginloss": 24, "fakequantizedsoftmarginloss": 24, "cosineembeddingloss": 24, "fakequantizedcosineembeddingloss": 24, "gaussiannllloss": 24, "fakequantizedgaussiannllloss": 24, "marginrankingloss": 24, "fakequantizedmarginrankingloss": 24, "tripletmarginloss": 24, "fakequantizedtripletmarginloss": 24, "tripletmarginwithdistanceloss": 24, "fakequantizedtripletmarginwithdistanceloss": 24, "embed": [24, 36, 43], "fakequantizedembed": 24, "embeddingbag": 24, "fakequantizedembeddingbag": 24, "gru": [24, 46], "fakequantizedgru": 24, "rnn": [24, 46], "fakequantizedrnn": 24, "grucel": 24, "fakequantizedgrucel": 24, "rnncell": 24, "fakequantizedrnncel": 24, "lstm": [24, 46], "fakequantizedlstm": 24, "lstmcell": 24, "fakequantizedlstmcel": 24, "adaptivelogsoftmaxwithloss": 24, "fakequantizedadaptivelogsoftmaxwithloss": 24, "aimet_op": 24, "fakequantizedcast": 24, "depthtospacedcrmod": 24, "fakequantizeddepthtospacedcrmod": 24, "onehot": 24, "fakequantizedonehot": 24, "exponenti": 24, "fakequantizedexponenti": 24, "erf": 24, "fakequantizederf": 24, "sqrt": 24, "fakequantizedsqrt": 24, "log": [24, 40], "fakequantizedlog": 24, "ab": [24, 39], "fakequantizedab": 24, "fakequantizedneg": 24, "elementwiseceil": 24, "fakequantizedelementwiseceil": 24, "elementwisefloor": 24, "fakequantizedelementwisefloor": 24, "sin": 24, "fakequantizedsin": 24, "co": 24, "fakequantizedco": 24, "asin": 24, "fakequantizedasin": 24, "atan": 24, "fakequantizedatan": 24, "fakequantizedround": 24, "logicalnot": 24, "fakequantizedlogicalnot": 24, "nonzero": 24, "fakequantizednonzero": 24, "elementwiseunarysign": 24, "fakequantizedelementwiseunarysign": 24, "rsqrt": 24, "fakequantizedrsqrt": 24, "squar": [24, 44], "fakequantizedsquar": 24, "fakequantizedmean": 24, "sum": [24, 27], "fakequantizedsum": 24, "prod": 24, "fakequantizedprod": 24, "argmin": 24, "fakequantizedargmin": 24, "argmax": [24, 27], "fakequantizedargmax": 24, "gather": 24, "fakequantizedgath": 24, "reshap": 24, "fakequantizedreshap": 24, "roialign": 24, "fakequantizedroialign": 24, "permut": 24, "fakequantizedpermut": 24, "indexselect": 24, "fakequantizedindexselect": 24, "topk": 24, "fakequantizedtopk": 24, "tile": 24, "fakequantizedtil": 24, "norm": [24, 28, 30, 38, 39, 40], "fakequantizednorm": 24, "cumsum": 24, "fakequantizedcumsum": 24, "interpol": [24, 33], "fakequantizedinterpol": 24, "normal": [24, 30, 40], "pad": [24, 27], "fakequantizedpad": 24, "fakequantizedshap": 24, "fakequantizedexpand": 24, "stridedslic": 24, "fakequantizedstridedslic": 24, "matmul": [24, 46], "fakequantizedmatmul": 24, "fakequantizedadd": 24, "fakequantizedmultipli": 24, "subtract": 24, "fakequantizedsubtract": 24, "quantizedsubtract": 24, "fakequantizeddivid": 24, "floordivid": 24, "fakequantizedfloordivid": 24, "fakequantizedgreat": 24, "fakequantizedless": 24, "greaterequ": 24, "fakequantizedgreaterequ": 24, "lessequ": 24, "fakequantizedlessequ": 24, "notequ": 24, "fakequantizednotequ": 24, "fakequantizedequ": 24, "remaind": 24, "fakequantizedremaind": 24, "fmod": 24, "fakequantizedfmod": 24, "pow": 24, "fakequantizedpow": 24, "customsilu": 24, "fakequantizedcustomsilu": 24, "fakequantizedmaximum": 24, "fakequantizedmax": 24, "fakequantizedminimum": 24, "fakequantizedmin": 24, "bmm": 24, "fakequantizedbmm": 24, "logicalor": 24, "fakequantizedlogicalor": 24, "logicaland": 24, "fakequantizedlogicaland": 24, "customgath": 24, "fakequantizedcustomgath": 24, "gathernd": 24, "fakequantizedgathernd": 24, "baddbmm": 24, "fakequantizedbaddbmm": 24, "addmm": 24, "fakequantizedaddmm": 24, "scatternd": 24, "fakequantizedscatternd": 24, "dynamicconv2d": 24, "fakequantizeddynamicconv2d": 24, "scatterel": 24, "fakequantizedscatterel": 24, "batchnorm": [24, 29, 39, 51], "fakequantizedbatchnorm": 24, "fakequantizedaimetgroupnorm": 24, "nonmaxsuppress": 24, "fakequantizednonmaxsuppress": 24, "fakequantizedsplit": 24, "concat": [24, 46], "fakequantizedconcat": 24, "fakequantizedwher": 24, "maskedfil": 24, "fakequantizedmaskedfil": 24, "allow_overwrit": [25, 26], "allow_overwit": 25, "flag": [25, 26], "get_encod": 25, "get_legacy_encod": 25, "register_quantization_paramet": 25, "set_legacy_encod": 25, "learn": [26, 30, 36, 38, 41, 44, 45, 46], "v1": [26, 45], "debug": [26, 27, 43, 45], "simpler": 26, "extend": [26, 45], "overview": 26, "fundament": 26, "advis": [26, 38, 42, 45], "subject": [26, 45], "understand": [26, 38, 42, 48, 49], "interact": 26, "remain": [26, 33, 38, 39, 44], "hood": 26, "build": [26, 45], "properti": 26, "shown": [26, 28, 36, 39, 40, 43], "intern": [26, 36, 38, 39, 42], "compon": [26, 45], "namespac": [26, 45], "directli": [26, 40, 44], "adaround_weight": 26, "sequenti": [26, 42, 43, 45], "mse": [26, 40, 44, 45], "seq_ms": 26, "apply_seq_ms": 26, "quantanalyz": [26, 38, 45, 46], "quant_analyz": 26, "autoqu": [26, 38, 41, 46], "auto_qu": 26, "longer": [26, 38, 41], "libpymo": 26, "statement": [26, 37], "stai": 26, "quantschem": [26, 29], "cross_layer_equ": [26, 37], "equalize_model": [26, 37], "model_prepar": [26, 27], "prepare_model": [26, 27], "wrap": 26, "quantizewrapp": 26, "quantizationsimmodelv1": 26, "all_quant_wrapp": 26, "quant_wrapp": 26, "staticgridquantwrapp": 26, "_module_to_wrap": 26, "200": 26, "contrast": 26, "definit": [26, 27, 38], "quantizationsimmodelv2": 26, "sim2": 26, "all_q_modul": 26, "qmodul": 26, "q_modul": 26, "here": [26, 27, 32, 41, 48], "reli": 26, "staticgridquant": 26, "learnedgridquant": 26, "could": [26, 27, 31, 51], "quantizationdatatyp": 26, "tensor_quant": 26, "staticgridperchannelquant": 26, "fp_quantiz": 26, "data_typ": 26, "affine_quant": 26, "howev": [26, 38, 39, 41, 42, 44], "separ": [26, 30, 40, 43, 46], "relat": [26, 40, 44], "affine_q": 26, "affine_qdq": 26, "fp_qdq": 26, "floatquantizedequant": 26, "sim1": 26, "wrap_linear": 26, "symmetri": 26, "use_symmetric_encod": 26, "is_unsigned_symmetr": 26, "use_strict_symmetr": 26, "simplifi": 26, "tfencod": 26, "copy_": 26, "_remove_input_quant": 26, "_remove_output_quant": 26, "_remove_param_quant": 26, "param_encod": 26, "temporarili": 26, "assert": [26, 27], "freez": [26, 28], "_is_encoding_frozen": 26, "freeze_encod": 26, "concept": 26, "mimick": 26, "involv": [26, 27, 38, 43, 45], "requires_grad_": 26, "prevent": [26, 31], "overwritten": 26, "ti": 26, "design": [26, 39, 45], "portabl": [26, 45], "It": [26, 27, 30, 33, 38, 39, 42, 48, 49, 51], "guidelin": [26, 27, 28, 32, 41], "learnedgridquantwrapp": 26, "encodinganalyzerforpython": 26, "affineencod": 26, "floatencod": 26, "vectorencod": 26, "tutori": 27, "simpl": [27, 38, 51], "intend": [27, 32], "meant": 27, "demonstr": 27, "art": 27, "eval": [27, 33, 36, 48], "loop": [27, 43], "evalu": [27, 29, 33, 36, 38, 40, 41, 44, 48], "clearli": 27, "what": [27, 44, 48], "happen": 27, "let": 27, "special": 27, "look": [27, 48], "torchvis": 27, "is_avail": 27, "loader": [27, 28], "cifar10_train_data": 27, "dataset": [27, 38, 39, 44], "fashionmnist": 27, "tmp": 27, "cifar10": 27, "totensor": 27, "cifar10_test_data": 27, "train_load": 27, "dataload": [27, 40], "batch_siz": 27, "shuffl": 27, "test_load": 27, "super": 27, "conv1": 27, "kernel_s": 27, "stride": 27, "bn_1": 27, "256": [27, 40], "bn_2": 27, "total": [27, 33, 44], "now": [27, 38, 45, 46, 51], "few": [27, 32, 38, 43, 44], "epoch": [27, 34, 36, 38, 41], "establish": 27, "baselin": [27, 33, 41], "send": 27, "loss_fn": 27, "adam": 27, "lr": 27, "1e": [27, 41], "batch_idx": 27, "enumer": [27, 30], "backward": 27, "zero_grad": 27, "fp_accuraci": 27, "91": 27, "70999908447266": 27, "accur": 27, "coupl": [27, 28], "care": 27, "conform": 27, "math": 27, "wherea": [27, 44], "incorrectli": 27, "ignor": 27, "complet": [27, 30, 43], "redefin": 27, "thankfulli": 27, "incompat": 27, "fulli": [27, 35], "prepared_model": 27, "fp_accuracy_prepar": 27, "2024": 27, "07": 27, "747": 27, "root": 27, "info": [27, 46], "806": 27, "modelprepar": 27, "ad": [27, 35, 38, 42, 46], "node": [27, 41, 44], "module_relu": 27, "module_relu_1": 27, "module_softmax": 27, "graphmodul": 27, "ep": 27, "momentum": 27, "track_running_stat": 27, "12544": 27, "getattr_1": 27, "getitem": 27, "graph_modul": 27, "print_read": 27, "distinct": 27, "execut": [27, 33, 48], "adjac": [27, 42], "whenev": 27, "unnecessari": [27, 51], "good": [27, 28], "idea": 27, "batch_norm_fold": 27, "iter": [27, 28, 39], "fold_all_batch_norm": 27, "input_shap": 27, "passthrough": 27, "previous": 27, "had": 27, "impact": [27, 33, 43], "readi": [27, 43], "encount": 27, "therefor": [27, 32, 39], "theoret": 27, "practic": [27, 36], "usual": [27, 41], "500": [27, 28, 39, 40], "1000": [27, 28, 39, 40], "estim": [27, 38, 39], "default_output_bw": 27, "default_param_bw": 27, "idx": 27, "break": 27, "quantized_accuraci": 27, "1500015258789": 27, "noth": 27, "everi": [27, 33, 36, 41, 49], "construct": [27, 37], "discuss": [27, 32, 43, 44], "advanc": [27, 45], "re": [27, 38], "One": [27, 32, 36, 47], "qat": [27, 28, 30, 34, 38, 43, 44, 46], "op": [27, 38, 42, 46], "repeat": [27, 31], "post_qat_accuraci": 27, "92": 27, "05333709716797": 27, "happi": 27, "export_path": 27, "model_nam": 27, "fashion_mnist_model": 27, "save": [27, 29, 44, 49], "sent": 27, "nearest": 28, "figur": [28, 33, 43, 51], "illustr": [28, 33, 38, 47, 50], "smaller": [28, 34, 43, 47, 50], "unlabel": [28, 38, 40, 44], "far": 28, "decid": [28, 48], "whether": [28, 41], "awai": 28, "closer": 28, "fp32": [28, 34, 39, 40, 41, 43, 44], "width": [28, 43, 44, 47, 50, 51], "bc": 28, "bnf": 28, "batch": [28, 30, 38, 39, 40], "cle": [28, 38, 43, 46], "cross": [28, 29, 37, 38, 40, 49], "hbf": 28, "awar": [28, 30, 34, 38, 43, 44], "don": 28, "But": [28, 36], "benefici": [28, 40, 41], "consid": [28, 33, 38, 43], "help": [28, 33, 36, 38, 39, 40, 43, 48, 49], "Not": [28, 33], "hyper": [28, 41], "expos": 28, "stabl": 28, "mani": [28, 39, 44], "often": [28, 29, 36, 41], "approxim": [28, 32, 39, 40], "1024": [28, 37], "10000": 28, "moder": 28, "least": [28, 31], "beta": 28, "warm": 28, "period": 28, "kera": [28, 30, 34, 38, 39, 40, 42, 44, 46], "offer": 29, "suit": 29, "sequenc": [29, 30, 37, 42], "try": [29, 31, 33, 36, 38, 43], "variou": [29, 32, 36, 38, 43, 44, 46, 49], "error": [29, 38, 41, 43, 44], "prone": 29, "consum": [29, 36], "amount": [29, 42], "toler": [29, 32], "soon": 29, "reach": [29, 32], "stop": 29, "summari": 29, "autom": [29, 38], "prepar": [29, 38, 46], "check": [29, 38, 41, 43], "friendli": [29, 38, 39], "denot": 29, "select": [29, 32, 40, 44, 48, 51], "best": [29, 32, 36, 38, 44], "preprat": 29, "mainli": 29, "three": [29, 32, 49], "stage": 29, "effort": 29, "manner": 29, "fail": [29, 37, 38], "goal": 29, "small": [30, 34, 38], "preceed": 30, "pcq": [30, 40], "veri": [30, 32, 36, 40, 49, 51], "NOT": [30, 51], "scenario": [30, 36, 38, 51], "decreas": 30, "main": [30, 42, 46, 49], "issu": [30, 34, 37, 43, 46, 48, 49], "depthwis": [30, 46], "oscil": 30, "quant": 30, "flow": [30, 38, 41, 43, 44], "diagram": [30, 33, 36, 44, 47, 50], "explain": [31, 36, 39, 44, 51], "occurr": 31, "detail": [31, 33, 34, 36, 38, 43, 44, 48, 49], "ratio": [31, 32, 48], "magnitud": 31, "matrix": 31, "upstream": [31, 51], "gain": [31, 36], "presenc": 31, "connect": [31, 35, 50], "residu": 31, "sometim": [31, 36, 39, 40], "attempt": [31, 38, 39], "close": [31, 32, 44], "prior": [31, 38, 40], "random": [31, 40], "regress": 31, "document": [32, 34, 45, 46], "svd": [32, 33, 35, 36, 46], "spatial": [32, 33, 35, 36, 46], "ssvd": 32, "prune": [32, 33, 35, 36, 46, 51], "accumul": 32, "mac": [32, 36, 47, 50], "reduct": 32, "uncompress": 32, "algorithm": [32, 33, 36, 43, 51], "overal": [32, 36, 43], "latenc": 32, "bandwidth": 32, "vari": [32, 33, 39, 49], "architectur": 32, "io": [32, 46], "At": [32, 36, 45], "half": 32, "unknown": 32, "apriori": 32, "cssvd": 32, "tri": [32, 38], "75": 32, "pick": [32, 33, 36], "2b": 32, "rel": [32, 38, 43, 49], "avoid": 32, "larg": [32, 41, 47, 50], "2a": 32, "revisit": 32, "ccp": 32, "resnet": 32, "csvd": 32, "assess": 33, "sensit": [33, 38, 40, 43, 44, 46], "applic": [33, 37], "find": [33, 38, 40, 41, 44], "sure": [33, 37], "highest": 33, "dictionari": [33, 36, 42], "column": 33, "captur": 33, "predefin": 33, "candid": [33, 36], "unmodifi": 33, "score": [33, 36, 48], "last": [33, 35, 43], "monoton": 33, "fit": 33, "strict": [33, 42, 44], "procedur": [33, 36], "curv": 33, "core": 33, "constant": [33, 38], "met": 33, "binari": 33, "solut": [33, 41, 43], "quickli": 33, "suggest": [33, 36, 39], "lesser": [33, 36], "drstical": 33, "softwar": [34, 36], "framework": [34, 38, 42, 44], "meta": [34, 38], "h5": [34, 38], "hw": 34, "ptq": [34, 38, 40, 41], "redund": 34, "dilat": 35, "modules_to_ignor": 35, "depthwiseconv2d": 35, "librari": 36, "guidebook": [36, 38], "advic": 36, "greedi": [36, 48], "phase": [36, 38], "choic": [36, 44], "nomin": 36, "And": 36, "ml": [36, 38, 39, 48, 49], "those": 36, "fc": 36, "decompos": [36, 47, 50], "term": [36, 47, 48, 49, 50], "sharp": 36, "degrad": 36, "might": [36, 40], "rate": [36, 41], "carefulli": 36, "decai": 36, "slow": 36, "someth": [36, 48], "speed": [36, 39, 46], "itself": [36, 44, 47, 50], "load": 36, "searcher": 36, "Or": 36, "strike": 36, "balanc": 36, "chosen": 36, "major": [36, 45], "sai": 36, "xiangyu": 36, "zhang": 36, "jianhua": 36, "zou": 36, "kaim": 36, "he": 36, "jian": 36, "sun": 36, "deep": 36, "classif": 36, "detect": 36, "transact": 36, "pattern": 36, "analysi": [36, 43], "intellig": 36, "vol": 36, "pp": 36, "1943": 36, "1955": 36, "oct": 36, "2016": 36, "yihui": 36, "confer": [36, 39], "vision": [36, 39], "iccv": [36, 39], "venic": 36, "2017": 36, "1398": 36, "1406": 36, "jaderberg": 36, "andrea": 36, "vedaldi": 36, "andrew": 36, "zisserman": 36, "british": 36, "jan": 36, "2014": 36, "andrei": 36, "kuzmin": 36, "marku": [36, 39], "nagel": [36, 39], "saurabh": 36, "pitr": 36, "sandeep": 36, "pendyam": 36, "tijmen": [36, 39], "blankevoort": [36, 39], "taxonomi": 36, "graph": [37, 38, 44, 48], "successfulli": 37, "potenti": [37, 40, 48, 49], "workaround": 37, "primit": 37, "around": 37, "rewrit": 37, "slice": 37, "written": [37, 38], "caus": [37, 43, 44], "align_corn": 37, "deconvolut": 37, "deeplabv3": 37, "address": [37, 43, 48], "releas": [37, 45], "hardwar": [38, 39, 44], "predict": 38, "oppos": [38, 42], "advantag": 38, "No": 38, "pipelin": [38, 41, 43, 44], "suffici": [38, 40, 41, 44], "even": 38, "fast": 38, "easi": [38, 40], "gap": 38, "insert": [38, 44], "robust": 38, "account": [38, 41, 43], "trainabl": 38, "bias": 38, "reflect": [38, 44], "integr": 38, "standalon": 38, "consecut": [38, 39], "bn": [38, 46], "deprec": 38, "prep": 38, "accord": [38, 41, 42, 44], "align": 38, "retri": 38, "continu": [38, 39, 41, 43], "warn": 38, "hand": 38, "satisfactori": [38, 43], "bring": 38, "onto": 38, "thing": 38, "item": 38, "checkpoint": 38, "pb": 38, "trial": 38, "seem": 38, "off": [38, 39, 42], "bat": 38, "becom": 39, "paper": 39, "2019": 39, "arxiv": 39, "1906": 39, "04721": 39, "surround": 39, "highlight": [39, 48, 49], "big": 39, "discrep": 39, "accept": [39, 43], "wide": 39, "varianc": 39, "seen": [39, 40], "significantli": 39, "quantizaion": 39, "distribut": [39, 43, 44], "did": 39, "shift": 39, "empir": 39, "analyt": [39, 48, 49], "extract": 39, "bottleneck": [39, 43], "hybrid": 39, "approach": [39, 44], "mart": 39, "van": 39, "baalen": 39, "seoul": 39, "octob": 39, "hotspot": 40, "analys": 40, "callback": [40, 44], "plot": 40, "pretrain": [40, 41, 44], "dummi": 40, "label": [40, 41], "metric": [40, 44], "rune": 40, "doc": [40, 42, 48], "situat": 40, "pinpoint": 40, "culprit": 40, "again": [40, 41, 48], "per_layer_quant_en": 40, "per_layer_quant_dis": 40, "axi": 40, "track": 40, "min_max_rang": 40, "folder": 40, "enhanc": [40, 44], "toss": 40, "displai": [40, 48, 49], "activations_pdf": 40, "weights_pdf": 40, "monitor": 40, "contribut": [40, 43], "read": 40, "per_layer_mse_loss": 40, "mitig": [41, 44], "hyperparamet": 41, "accompani": 41, "throughout": [41, 42, 45, 49], "aid": 41, "converg": 41, "schedul": 41, "placement": 42, "fuse": [42, 44], "six": 42, "overrul": 42, "turn": 42, "op_typ": 42, "empti": 42, "is_output_quant": 42, "is_quant": 42, "strict_symmetr": 42, "unsigned_symmetr": 42, "omit": 42, "altogeth": 42, "asid": 42, "govern": 42, "unsign": [42, 44], "gemm": 42, "is_input_quant": 42, "recogn": [42, 44], "keep": [42, 43], "convent": 42, "preced": 42, "supergroup": [42, 46], "made": [42, 45], "op_list": 42, "member": 42, "branch": 42, "config": [42, 46], "entri": 42, "string": 42, "model_input": 42, "whatev": 42, "earlier": 42, "model_output": 42, "diagnost": 43, "strictli": 43, "insight": [43, 48, 49], "why": 43, "underperform": 43, "tackl": 43, "chart": 43, "saniti": 43, "ofth": 43, "independ": 43, "kept": 43, "convers": 43, "toward": 43, "wise": 43, "uneven": 43, "vanilla": 43, "global": 43, "restor": 43, "rest": 43, "inner": 43, "token": 43, "bert": 43, "reveal": 43, "problemat": [43, 49], "problem": 43, "resort": 43, "revert": 43, "power": [43, 45], "ultim": 44, "copi": 44, "ingest": 44, "feed": 44, "000": 44, "yield": 44, "dequantiz": 44, "hook": 44, "intercept": 44, "four": 44, "zero": [44, 46], "vice": 44, "versa": 44, "textrm": 44, "dfrac": 44, "strong": 44, "excess": 44, "signal": 44, "satur": 44, "erro": 44, "static": 44, "alongsid": 44, "ones": 44, "just": [44, 48, 51], "non": 44, "intermedi": 44, "welcom": 45, "motiv": 45, "clean": 45, "ground": 45, "maintain": 45, "familiar": 45, "newli": 45, "flexibl": 45, "transpar": 45, "redesign": 45, "yet": 45, "mainlin": 45, "compris": 45, "dispatch": 45, "easili": 45, "move": 45, "uphold": 45, "migrat": 45, "navig": 45, "blockwis": 45, "slim": 46, "backslash": 46, "user_guid": 46, "api_doc": 46, "quantizablemultiheadattent": 46, "kyuykim": 46, "multi": 46, "mangal": 46, "geunle": 46, "bug": 46, "correctli": 46, "leaf": 46, "klhsieh": 46, "akhobar": 46, "multiheadattent": 46, "ashvkuma": 46, "mha": 46, "pdf": 46, "fp16": 46, "minor": 46, "stand": [46, 47, 50], "adaptiveround": 46, "recurr": 46, "packag": 46, "decomposit": [47, 50], "singular": [47, 50], "\ud835\udc5a": [47, 50], "\ud835\udc5b": [47, 50], "\u210e": [47, 50], "\ud835\udc64": [47, 50], "give": [47, 50], "height": [47, 50, 51], "\ud835\udc58": [47, 50], "k": 47, "rank": [47, 50], "degre": [47, 50], "progress": [48, 49], "computation": [48, 49], "task": [48, 49], "websocket": 48, "tell": 48, "listen": 48, "rather": 48, "5006": 48, "compress_model": 48, "visualizecompress": 48, "display_eval_scor": 48, "display_comp_ratio_plot": 48, "directori": 49, "lot": 49, "anoth": [50, 51], "lose": 51, "much": 51, "explicitli": 51, "pictori": 51, "volum": 51, "hxwx8": 51, "hxwx5": 51, "simpli": 51, "propag": 51, "That": 51, "teh": 51, "green": 51, "color": 51, "side": 51, "action": 51, "taken": 51, "pink": 51, "orang": 51}, "objects": {"aimet_torch.v2.nn": [[6, 0, 1, "", "FakeQuantizationMixin"], [7, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.FakeQuantizationMixin": [[6, 1, 1, "", "__quant_init__"], [6, 1, 1, "", "compute_encodings"], [6, 1, 1, "", "forward"], [6, 1, 1, "", "from_module"], [6, 1, 1, "", "implements"], [6, 2, 1, "", "input_quantizers"], [6, 2, 1, "", "output_quantizers"], [6, 2, 1, "", "param_quantizers"]], "aimet_torch.v2.nn.QuantizationMixin": [[7, 1, 1, "", "__quant_init__"], [7, 1, 1, "", "compute_encodings"], [7, 1, 1, "", "forward"], [7, 1, 1, "", "from_module"], [7, 1, 1, "", "get_default_kernel"], [7, 1, 1, "", "get_kernel"], [7, 1, 1, "", "implements"], [7, 2, 1, "", "input_quantizers"], [7, 2, 1, "", "output_quantizers"], [7, 2, 1, "", "param_quantizers"], [7, 1, 1, "", "set_default_kernel"], [7, 1, 1, "", "set_kernel"]], "aimet_torch.v2.nn.base": [[24, 0, 1, "", "BaseQuantizationMixin"]], "aimet_torch.v2.nn.base.BaseQuantizationMixin": [[24, 1, 1, "", "__quant_init__"], [24, 1, 1, "", "compute_encodings"], [24, 1, 1, "", "forward"], [24, 2, 1, "", "input_quantizers"], [24, 2, 1, "", "output_quantizers"], [24, 2, 1, "", "param_quantizers"]], "aimet_torch.v2.quantization": [[13, 3, 0, "-", "affine"], [15, 3, 0, "-", "float"]], "aimet_torch.v2.quantization.affine": [[8, 0, 1, "", "Quantize"], [9, 0, 1, "", "QuantizeDequantize"], [10, 4, 1, "", "dequantize"], [11, 4, 1, "", "quantize"], [12, 4, 1, "", "quantize_dequantize"]], "aimet_torch.v2.quantization.affine.Quantize": [[8, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.QuantizeDequantize": [[9, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer": [[25, 0, 1, "", "Quantize"], [25, 0, 1, "", "QuantizeDequantize"], [25, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[25, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[25, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[25, 1, 1, "", "allow_overwrite"], [25, 1, 1, "", "compute_encodings"], [25, 1, 1, "", "get_encoding"], [25, 1, 1, "", "get_legacy_encodings"], [25, 1, 1, "", "is_initialized"], [25, 1, 1, "", "register_quantization_parameter"], [25, 1, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization.encoding_analyzer": [[18, 0, 1, "", "EncodingAnalyzer"], [20, 0, 1, "", "MinMaxEncodingAnalyzer"], [21, 0, 1, "", "PercentileEncodingAnalyzer"], [22, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer": [[21, 1, 1, "", "set_percentile"]], "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer": [[22, 1, 1, "", "compute_encodings_from_stats"]], "aimet_torch.v2.quantization.float": [[14, 0, 1, "", "FloatQuantizeDequantize"], [14, 0, 1, "", "QuantizeDequantize"]], "aimet_torch.v2.quantization.tensor": [[16, 0, 1, "", "DequantizedTensor"], [16, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "quantize"], [16, 1, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "quantize"], [16, 1, 1, "", "quantized_repr"]], "aimet_torch.v2.quantsim.config_utils": [[17, 4, 1, "", "set_activation_quantizers_to_float"], [17, 4, 1, "", "set_blockwise_quantization_for_weights"], [17, 4, 1, "", "set_grouped_blockwise_quantization_for_weights"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:attribute", "3": "py:module", "4": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "module", "Python module"], "4": ["py", "function", "Python function"]}, "titleterms": {"aimet": [2, 3, 4, 23, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51], "instal": [2, 3, 4, 34], "quick": 2, "releas": [2, 3, 4, 34, 46], "packag": [2, 3, 4], "system": 2, "requir": [2, 40], "advanc": 2, "instruct": 2, "docker": 3, "set": 3, "variant": [3, 18], "us": [3, 28, 36, 38, 45, 48], "prebuilt": 3, "imag": 3, "build": 3, "local": 3, "start": [3, 23, 34, 48], "contain": 3, "from": [3, 4, 26], "pypi": [3, 4], "environ": [3, 4], "setup": [3, 4], "prerequisit": [4, 27], "gpu": 4, "pytorch": [4, 23, 27, 37, 38, 49], "2": [4, 27, 46], "1": [4, 27, 46], "tensorflow": [4, 38, 49], "13": [4, 46], "onnx": 4, "common": [4, 28], "debian": 4, "torch": 4, "replac": 4, "pillow": 4, "simd": 4, "onnxruntim": 4, "post": [4, 19, 38, 39], "step": 4, "fakequantizationmixin": 6, "quantizationmixin": 7, "quantiz": [8, 11, 13, 15, 16, 17, 19, 24, 25, 26, 27, 38, 39, 41, 42, 43, 44, 49], "quantizedequant": [9, 14], "dequant": 10, "quantize_dequant": 12, "affin": [13, 26], "class": [13, 16, 24], "function": 13, "floatquantizedequant": 14, "float": [15, 26, 27], "tensor": 16, "blockwis": 17, "low": 17, "power": 17, "lpbq": 17, "top": [17, 24, 25], "level": [17, 24, 25], "api": [17, 23, 24, 25, 28, 29, 30, 39, 40, 44], "export": [17, 27], "encod": [18, 24, 44], "analyz": 18, "train": [19, 27, 38, 39, 41], "minmaxencodinganalyz": 20, "percentileencodinganalyz": 21, "sqnrencodinganalyz": 22, "ai": [23, 34], "model": [23, 27, 34, 36, 37, 38], "effici": [23, 34], "toolkit": [23, 34], "document": 23, "get": [23, 34, 36], "exampl": [23, 26], "featur": [23, 26, 32, 34, 38, 43, 45], "descript": [23, 40], "modul": [24, 26], "configur": [24, 42, 44], "comput": 24, "migrat": 26, "quantsim": [26, 27, 44, 45], "v2": [26, 45], "chang": 26, "process": 26, "import": 26, "quantizationsimmodel": 26, "move": 26, "quantwrapp": 26, "staticgrid": 26, "learnedgrid": 26, "code": 26, "deprec": 26, "quickstart": 27, "guid": [27, 34], "overal": [27, 31], "flow": [27, 39], "prepar": 27, "point": 27, "batchnorm": 27, "fold": 27, "fine": [27, 36], "tune": [27, 36], "awar": [27, 41], "adaround": 28, "case": [28, 36, 38], "terminologi": 28, "autoqu": 29, "overview": [29, 30, 33, 34, 36, 39, 40, 41, 42, 44, 45, 48, 49, 51], "workflow": [29, 30, 38, 41, 44], "bn": 30, "re": 30, "estim": 30, "channel": 31, "prune": 31, "procedur": 31, "select": [31, 33, 36], "winnow": [31, 51], "weight": [31, 50], "reconstruct": 31, "compress": [32, 33, 36, 48], "guidebook": [32, 43], "greedi": 33, "ratio": [33, 36], "how": [33, 42, 48, 51], "work": [33, 51], "per": [33, 36], "layer": [33, 36, 39], "explor": 33, "user": [34, 39], "inform": 34, "toc": 34, "tree": 34, "known": 35, "issu": 35, "option": 36, "techniqu": [36, 39], "better": 36, "result": 36, "rank": 36, "round": 36, "faq": [36, 39], "refer": [36, 39], "guidelin": [37, 38], "debug": 38, "analysi": [38, 40], "tool": [38, 48], "cross": 39, "equal": 39, "quantanalyz": 40, "detail": 40, "qat": 41, "mode": 41, "recommend": 41, "simul": [42, 44], "file": 42, "structur": 42, "individu": 42, "section": 42, "nois": 44, "determin": 44, "paramet": 44, "scheme": 44, "op": 44, "frequent": 44, "ask": 44, "question": 44, "new": 45, "note": 46, "22": 46, "0": 46, "21": 46, "20": 46, "19": 46, "py37": 46, "18": 46, "17": 46, "16": 46, "14": 46, "spatial": 47, "svd": [47, 50], "visual": [48, 49], "design": 48, "bokeh": 48, "server": 48, "session": 48}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"AIMET Installation": [[2, "aimet-installation"]], "Quick Install": [[2, "quick-install"]], "Release Packages": [[2, "release-packages"]], "System Requirements": [[2, "system-requirements"]], "Advanced Installation Instructions": [[2, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[3, "aimet-installation-in-docker"]], "Set variant": [[3, "set-variant"]], "Use prebuilt docker image": [[3, "use-prebuilt-docker-image"]], "Build docker image locally": [[3, "build-docker-image-locally"]], "Start docker container": [[3, "start-docker-container"]], "Install AIMET packages": [[3, "install-aimet-packages"], [4, "install-aimet-packages"]], "From PyPI": [[3, "from-pypi"], [4, "from-pypi"]], "From Release Package": [[3, "from-release-package"], [4, "from-release-package"]], "Environment setup": [[3, "environment-setup"], [4, "environment-setup"]], "AIMET Installation and Setup": [[4, "aimet-installation-and-setup"]], "Install prerequisite packages": [[4, "install-prerequisite-packages"]], "Install GPU packages": [[4, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or TensorFlow": [[4, "install-gpu-packages-for-pytorch-2-1-or-tensorflow"]], "Install GPU packages for PyTorch 1.13 or ONNX": [[4, "install-gpu-packages-for-pytorch-1-13-or-onnx"]], "Install common debian packages": [[4, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[4, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[4, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[4, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[4, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[4, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[4, "post-installation-steps"]], "FakeQuantizationMixin": [[6, "fakequantizationmixin"]], "QuantizationMixin": [[7, "quantizationmixin"]], "Quantize": [[8, "quantize"]], "QuantizeDequantize": [[9, "quantizedequantize"], [14, "quantizedequantize"]], "dequantize": [[10, "dequantize"]], "quantize": [[11, "quantize"]], "quantize_dequantize": [[12, "quantize-dequantize"]], "quantization.affine": [[13, "module-aimet_torch.v2.quantization.affine"]], "Classes": [[13, "classes"], [16, "classes"]], "Functions": [[13, "functions"]], "FloatQuantizeDequantize": [[14, "floatquantizedequantize"]], "quantization.float": [[15, "module-aimet_torch.v2.quantization.float"]], "quantization.tensor": [[16, "quantization-tensor"]], "Blockwise Quantization": [[17, "blockwise-quantization"]], "Low Power Blockwise Quantization (LPBQ)": [[17, "low-power-blockwise-quantization-lpbq"]], "Top Level API": [[17, "top-level-api"]], "Export": [[17, "export"]], "Encoding Analyzers": [[18, "encoding-analyzers"]], "Variants": [[18, "variants"]], "Post-Training Quantization": [[19, "post-training-quantization"], [38, "post-training-quantization"]], "MinMaxEncodingAnalyzer": [[20, "minmaxencodinganalyzer"]], "PercentileEncodingAnalyzer": [[21, "percentileencodinganalyzer"]], "SqnrEncodingAnalyzer": [[22, "sqnrencodinganalyzer"]], "AIMET: AI Model Efficiency Toolkit Documentation": [[23, "aimet-ai-model-efficiency-toolkit-documentation"]], "Getting Started": [[23, "getting-started"], [34, "getting-started"]], "Examples": [[23, null]], "Feature Descriptions": [[23, null]], "AIMET PyTorch API": [[23, null]], "Quantized Modules": [[24, "quantized-modules"]], "Top-level API": [[24, "top-level-api"], [25, "top-level-api"]], "Configuration": [[24, "configuration"]], "Computing Encodings": [[24, "computing-encodings"]], "Quantized Module Classes": [[24, "quantized-module-classes"]], "Quantizers": [[25, "quantizers"]], "Migrate to QuantSim v2": [[26, "migrate-to-quantsim-v2"]], "Changes in QuantSim v2": [[26, "changes-in-quantsim-v2"]], "Migration Process": [[26, "migration-process"]], "Imports": [[26, "imports"]], "QuantizationSimModel": [[26, "quantizationsimmodel"]], "Moving from QuantWrapper to Quantized Modules": [[26, "moving-from-quantwrapper-to-quantized-modules"]], "Moving from StaticGrid and LearnedGrid Quantizer to Affine and Float Quantizer": [[26, "moving-from-staticgrid-and-learnedgrid-quantizer-to-affine-and-float-quantizer"]], "Code Examples": [[26, "code-examples"]], "Deprecated Features": [[26, "deprecated-features"]], "Quickstart Guide": [[27, "quickstart-guide"]], "Overall flow": [[27, "overall-flow"]], "PyTorch prerequisites": [[27, "pytorch-prerequisites"]], "Prepare the floating point model for quantization": [[27, "prepare-the-floating-point-model-for-quantization"]], "1) Model preparation": [[27, "model-preparation"]], "2) BatchNorm fold": [[27, "batchnorm-fold"]], "Quantize the model": [[27, "quantize-the-model"]], "Fine-tune the model with quantization aware training": [[27, "fine-tune-the-model-with-quantization-aware-training"]], "Export the quantsim model": [[27, "export-the-quantsim-model"]], "AIMET AdaRound": [[28, "aimet-adaround"]], "AdaRound Use Cases": [[28, "adaround-use-cases"]], "Common terminology": [[28, "common-terminology"]], "Use Cases": [[28, "use-cases"], [38, "use-cases"]], "AdaRound API": [[28, "adaround-api"]], "AIMET AutoQuant": [[29, "aimet-autoquant"]], "Overview": [[29, "overview"], [30, "overview"], [33, "overview"], [34, "overview"], [36, "overview"], [39, "overview"], [40, "overview"], [41, "overview"], [42, "overview"], [44, "overview"], [45, "overview"], [48, "overview"], [49, "overview"], [51, "overview"]], "Workflow": [[29, "workflow"], [30, "workflow"]], "AutoQuant API": [[29, "autoquant-api"]], "AIMET BN Re-estimation": [[30, "aimet-bn-re-estimation"]], "BN Re-estimation API": [[30, "bn-re-estimation-api"]], "AIMET Channel Pruning": [[31, "aimet-channel-pruning"]], "Overall Procedure": [[31, "overall-procedure"]], "Channel Selection": [[31, "channel-selection"]], "Winnowing": [[31, "winnowing"]], "Weight Reconstruction": [[31, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[32, "aimet-compression-features-guidebook"]], "AIMET Greedy Compression Ratio Selection": [[33, "aimet-greedy-compression-ratio-selection"]], "How it works": [[33, "how-it-works"]], "Per-layer Exploration": [[33, "per-layer-exploration"]], "Compression Ratio Selection": [[33, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[34, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[34, "features"]], "Release Information": [[34, "release-information"]], "Installation Guide": [[34, "installation-guide"]], "toc tree": [[34, "toc-tree"]], "AIMET Known Issues": [[35, "aimet-known-issues"]], "AIMET Model Compression": [[36, "aimet-model-compression"]], "Use Case": [[36, "use-case"]], "Compression ratio selection": [[36, "compression-ratio-selection"]], "Model Compression": [[36, "model-compression"]], "Optional techniques to get better compression results": [[36, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[36, "rank-rounding"]], "Per-layer Fine-tuning": [[36, "per-layer-fine-tuning"]], "FAQs": [[36, "faqs"], [39, "faqs"]], "References": [[36, "references"], [39, "references"]], "Model Guidelines for PyTorch": [[37, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[38, "aimet-model-quantization"]], "AIMET Quantization Features": [[38, "aimet-quantization-features"]], "Debugging/Analysis Tools": [[38, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[38, "aimet-quantization-workflow"]], "PyTorch": [[38, "pytorch"], [49, "pytorch"]], "Tensorflow": [[38, "tensorflow"]], "Debugging Guidelines": [[38, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[39, "aimet-post-training-quantization-techniques"]], "User Flow": [[39, "user-flow"]], "Cross-Layer Equalization API": [[39, "cross-layer-equalization-api"]], "AIMET QuantAnalyzer": [[40, "aimet-quantanalyzer"]], "Requirements": [[40, "requirements"]], "Detailed Analysis Descriptions": [[40, "detailed-analysis-descriptions"]], "QuantAnalyzer API": [[40, "quantanalyzer-api"]], "AIMET Quantization Aware Training": [[41, "aimet-quantization-aware-training"]], "QAT workflow": [[41, "qat-workflow"]], "QAT modes": [[41, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[41, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[42, "quantization-simulation-configuration"]], "Configuration File Structure": [[42, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[42, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[43, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[44, "aimet-quantization-simulation"]], "QuantSim Workflow": [[44, "quantsim-workflow"]], "Simulating Quantization Noise": [[44, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[44, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[44, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[44, "configuring-quantization-simulation-ops"]], "Quantization Simulation APIs": [[44, "quantization-simulation-apis"]], "Frequently Asked Questions": [[44, "frequently-asked-questions"]], "QuantSim v2": [[45, "quantsim-v2"]], "Using QuantSim v2": [[45, "using-quantsim-v2"]], "New Features": [[45, "new-features"]], "AIMET Release Notes": [[46, "aimet-release-notes"]], "1.22.2": [[46, "id1"]], "1.22.1": [[46, "id2"]], "1.22.0": [[46, "id3"]], "1.21.0": [[46, "id4"]], "1.20.0": [[46, "id5"]], "1.19.1.py37": [[46, "py37"]], "1.19.1": [[46, "id6"]], "1.18.0.py37": [[46, "id7"]], "1.18.0": [[46, "id8"]], "1.17.0.py37": [[46, "id9"]], "1.17.0": [[46, "id10"]], "1.16.2.py37": [[46, "id11"]], "1.16.2": [[46, "id12"]], "1.16.1.py37": [[46, "id13"]], "1.16.1": [[46, "id14"]], "1.16.0": [[46, "id15"]], "1.14.0": [[46, "id16"]], "1.13.0": [[46, "id17"]], "AIMET Spatial SVD": [[47, "aimet-spatial-svd"]], "AIMET Visualization": [[48, "aimet-visualization"]], "Design": [[48, "design"]], "Compression": [[48, "compression"]], "Starting a Bokeh Server Session:": [[48, "starting-a-bokeh-server-session"]], "How to use the tool": [[48, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[49, "aimet-visualization-for-quantization"]], "Quantization": [[49, "quantization"]], "TensorFlow": [[49, "tensorflow"]], "AIMET Weight SVD": [[50, "aimet-weight-svd"]], "AIMET Winnowing": [[51, "aimet-winnowing"]], "Winnowing Overview": [[51, "winnowing-overview"]], "How Winnowing Works": [[51, "how-winnowing-works"]]}, "indexentries": {"fakequantizationmixin (class in aimet_torch.v2.nn)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.from_module"]], "implements() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"]], "quantizationmixin (class in aimet_torch.v2.nn)": [[7, "aimet_torch.v2.nn.QuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.from_module"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[7, "aimet_torch.v2.nn.QuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[7, "aimet_torch.v2.nn.QuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[7, "aimet_torch.v2.nn.QuantizationMixin.param_quantizers"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "quantize (class in aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.Quantize"]], "forward() (aimet_torch.v2.quantization.affine.quantize method)": [[8, "aimet_torch.v2.quantization.affine.Quantize.forward"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine)": [[9, "aimet_torch.v2.quantization.affine.QuantizeDequantize"]], "forward() (aimet_torch.v2.quantization.affine.quantizedequantize method)": [[9, "aimet_torch.v2.quantization.affine.QuantizeDequantize.forward"]], "dequantize() (in module aimet_torch.v2.quantization.affine)": [[10, "aimet_torch.v2.quantization.affine.dequantize"]], "quantize() (in module aimet_torch.v2.quantization.affine)": [[11, "aimet_torch.v2.quantization.affine.quantize"]], "quantize_dequantize() (in module aimet_torch.v2.quantization.affine)": [[12, "aimet_torch.v2.quantization.affine.quantize_dequantize"]], "aimet_torch.v2.quantization.affine": [[13, "module-aimet_torch.v2.quantization.affine"]], "module": [[13, "module-aimet_torch.v2.quantization.affine"], [15, "module-aimet_torch.v2.quantization.float"]], "floatquantizedequantize (class in aimet_torch.v2.quantization.float)": [[14, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.float)": [[14, "aimet_torch.v2.quantization.float.QuantizeDequantize"]], "aimet_torch.v2.quantization.float": [[15, "module-aimet_torch.v2.quantization.float"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "set_activation_quantizers_to_float() (in module aimet_torch.v2.quantsim.config_utils)": [[17, "aimet_torch.v2.quantsim.config_utils.set_activation_quantizers_to_float"]], "set_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[17, "aimet_torch.v2.quantsim.config_utils.set_blockwise_quantization_for_weights"]], "set_grouped_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[17, "aimet_torch.v2.quantsim.config_utils.set_grouped_blockwise_quantization_for_weights"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[18, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[20, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[21, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "set_percentile() (aimet_torch.v2.quantization.encoding_analyzer.percentileencodinganalyzer method)": [[21, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.set_percentile"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[22, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "compute_encodings_from_stats() (aimet_torch.v2.quantization.encoding_analyzer.sqnrencodinganalyzer method)": [[22, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.compute_encodings_from_stats"]], "basequantizationmixin (class in aimet_torch.v2.nn.base)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"]], "input_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[24, "aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[25, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "allow_overwrite() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[25, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})