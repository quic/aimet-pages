Search.setIndex({"docnames": ["Examples/onnx/quantization/adaround", "Examples/onnx/quantization/cle", "Examples/onnx/quantization/quantsim", "Examples/tensorflow/compression/channel_pruning", "Examples/tensorflow/compression/spatial_svd", "Examples/tensorflow/compression/spatial_svd_channel_pruning", "Examples/tensorflow/quantization/adaround", "Examples/tensorflow/quantization/autoquant", "Examples/tensorflow/quantization/bn_reestimation", "Examples/tensorflow/quantization/cle_bc", "Examples/tensorflow/quantization/keras/adaround", "Examples/tensorflow/quantization/keras/autoquant", "Examples/tensorflow/quantization/keras/bn_reestimation", "Examples/tensorflow/quantization/keras/keras_transformer_qat", "Examples/tensorflow/quantization/keras/model_preparer", "Examples/tensorflow/quantization/keras/qat", "Examples/tensorflow/quantization/keras/qat_range_learning", "Examples/tensorflow/quantization/keras/quant_analyzer", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq", "Examples/tensorflow/quantization/keras/quantsim_cle", "Examples/tensorflow/quantization/qat", "Examples/tensorflow/quantization/qat_range_learning", "Examples/tensorflow/quantization/quant_analyzer", "Examples/torch/compression/channel_pruning", "Examples/torch/compression/spatial_svd", "Examples/torch/compression/spatial_svd_channel_pruning", "Examples/torch/quantization/adaround", "Examples/torch/quantization/autoquant", "Examples/torch/quantization/bn_reestimation", "Examples/torch/quantization/cle_bc", "Examples/torch/quantization/qat", "Examples/torch/quantization/qat_range_learning", "Examples/torch/quantization/quant_analyzer", "api_docs/convert_tf_sess_to_keras", "api_docs/index", "api_docs/keras", "api_docs/keras_adaround", "api_docs/keras_batchnorm_re_estimation", "api_docs/keras_compression", "api_docs/keras_cross_layer_equalization", "api_docs/keras_layer_output_generation", "api_docs/keras_model_guidelines", "api_docs/keras_model_preparer", "api_docs/keras_primitive_apis_cle", "api_docs/keras_quant_analyzer", "api_docs/keras_quantization", "api_docs/keras_quantsim", "api_docs/onnx", "api_docs/onnx_adaround", "api_docs/onnx_auto_quant", "api_docs/onnx_cross_layer_equalization", "api_docs/onnx_layer_output_generation", "api_docs/onnx_quant_analyzer", "api_docs/onnx_quantization", "api_docs/onnx_quantsim", "api_docs/quantization_encoding_specification", "api_docs/tensorflow", "api_docs/tensorflow_adaround", "api_docs/tensorflow_auto_quant", "api_docs/tensorflow_batchnorm_re_estimation", "api_docs/tensorflow_bias_correction", "api_docs/tensorflow_compress", "api_docs/tensorflow_cross_layer_equalization", "api_docs/tensorflow_layer_output_generation", "api_docs/tensorflow_model_guidelines", "api_docs/tensorflow_primitive_apis_cle", "api_docs/tensorflow_quant_analyzer", "api_docs/tensorflow_quantization", "api_docs/tensorflow_quantsim", "api_docs/tensorflow_visualization_quantization", "api_docs/torch", "api_docs/torch_adaround", "api_docs/torch_architecture_checker", "api_docs/torch_auto_quant", "api_docs/torch_batchnorm_re_estimation", "api_docs/torch_bias_correction", "api_docs/torch_compress", "api_docs/torch_cross_layer_equalization", "api_docs/torch_layer_output_generation", "api_docs/torch_model_guidelines", "api_docs/torch_model_preparer", "api_docs/torch_model_validator", "api_docs/torch_multi_gpu", "api_docs/torch_peft_lora", "api_docs/torch_primitive_apis_cle", "api_docs/torch_quant_analyzer", "api_docs/torch_quantization", "api_docs/torch_quantsim", "api_docs/torch_visualization_compression", "api_docs/torch_visualization_quantization", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.fake_quantization_mixin", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize", "torch_docs/api/quantization/affine/index", "torch_docs/api/quantization/float/FloatQuantizeDequantize", "torch_docs/api/quantization/float/index", "torch_docs/api/quantization/tensor", "torch_docs/blockwise_quantization", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/migration_guide", "torch_docs/tutorials/quickstart_guide", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/examples", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/quantsim_2.0_overview", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["Examples/onnx/quantization/adaround.ipynb", "Examples/onnx/quantization/cle.ipynb", "Examples/onnx/quantization/quantsim.ipynb", "Examples/tensorflow/compression/channel_pruning.ipynb", "Examples/tensorflow/compression/spatial_svd.ipynb", "Examples/tensorflow/compression/spatial_svd_channel_pruning.ipynb", "Examples/tensorflow/quantization/adaround.ipynb", "Examples/tensorflow/quantization/autoquant.ipynb", "Examples/tensorflow/quantization/bn_reestimation.ipynb", "Examples/tensorflow/quantization/cle_bc.ipynb", "Examples/tensorflow/quantization/keras/adaround.ipynb", "Examples/tensorflow/quantization/keras/autoquant.ipynb", "Examples/tensorflow/quantization/keras/bn_reestimation.ipynb", "Examples/tensorflow/quantization/keras/keras_transformer_qat.ipynb", "Examples/tensorflow/quantization/keras/model_preparer.ipynb", "Examples/tensorflow/quantization/keras/qat.ipynb", "Examples/tensorflow/quantization/keras/qat_range_learning.ipynb", "Examples/tensorflow/quantization/keras/quant_analyzer.ipynb", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq.ipynb", "Examples/tensorflow/quantization/keras/quantsim_cle.ipynb", "Examples/tensorflow/quantization/qat.ipynb", "Examples/tensorflow/quantization/qat_range_learning.ipynb", "Examples/tensorflow/quantization/quant_analyzer.ipynb", "Examples/torch/compression/channel_pruning.ipynb", "Examples/torch/compression/spatial_svd.ipynb", "Examples/torch/compression/spatial_svd_channel_pruning.ipynb", "Examples/torch/quantization/adaround.ipynb", "Examples/torch/quantization/autoquant.ipynb", "Examples/torch/quantization/bn_reestimation.ipynb", "Examples/torch/quantization/cle_bc.ipynb", "Examples/torch/quantization/qat.ipynb", "Examples/torch/quantization/qat_range_learning.ipynb", "Examples/torch/quantization/quant_analyzer.ipynb", "api_docs/convert_tf_sess_to_keras.rst", "api_docs/index.rst", "api_docs/keras.rst", "api_docs/keras_adaround.rst", "api_docs/keras_batchnorm_re_estimation.rst", "api_docs/keras_compression.rst", "api_docs/keras_cross_layer_equalization.rst", "api_docs/keras_layer_output_generation.rst", "api_docs/keras_model_guidelines.rst", "api_docs/keras_model_preparer.rst", "api_docs/keras_primitive_apis_cle.rst", "api_docs/keras_quant_analyzer.rst", "api_docs/keras_quantization.rst", "api_docs/keras_quantsim.rst", "api_docs/onnx.rst", "api_docs/onnx_adaround.rst", "api_docs/onnx_auto_quant.rst", "api_docs/onnx_cross_layer_equalization.rst", "api_docs/onnx_layer_output_generation.rst", "api_docs/onnx_quant_analyzer.rst", "api_docs/onnx_quantization.rst", "api_docs/onnx_quantsim.rst", "api_docs/quantization_encoding_specification.rst", "api_docs/tensorflow.rst", "api_docs/tensorflow_adaround.rst", "api_docs/tensorflow_auto_quant.rst", "api_docs/tensorflow_batchnorm_re_estimation.rst", "api_docs/tensorflow_bias_correction.rst", "api_docs/tensorflow_compress.rst", "api_docs/tensorflow_cross_layer_equalization.rst", "api_docs/tensorflow_layer_output_generation.rst", "api_docs/tensorflow_model_guidelines.rst", "api_docs/tensorflow_primitive_apis_cle.rst", "api_docs/tensorflow_quant_analyzer.rst", "api_docs/tensorflow_quantization.rst", "api_docs/tensorflow_quantsim.rst", "api_docs/tensorflow_visualization_quantization.rst", "api_docs/torch.rst", "api_docs/torch_adaround.rst", "api_docs/torch_architecture_checker.rst", "api_docs/torch_auto_quant.rst", "api_docs/torch_batchnorm_re_estimation.rst", "api_docs/torch_bias_correction.rst", "api_docs/torch_compress.rst", "api_docs/torch_cross_layer_equalization.rst", "api_docs/torch_layer_output_generation.rst", "api_docs/torch_model_guidelines.rst", "api_docs/torch_model_preparer.rst", "api_docs/torch_model_validator.rst", "api_docs/torch_multi_gpu.rst", "api_docs/torch_peft_lora.rst", "api_docs/torch_primitive_apis_cle.rst", "api_docs/torch_quant_analyzer.rst", "api_docs/torch_quantization.rst", "api_docs/torch_quantsim.rst", "api_docs/torch_visualization_compression.rst", "api_docs/torch_visualization_quantization.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.fake_quantization_mixin.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize.rst", "torch_docs/api/quantization/affine/index.rst", "torch_docs/api/quantization/float/FloatQuantizeDequantize.rst", "torch_docs/api/quantization/float/index.rst", "torch_docs/api/quantization/tensor.rst", "torch_docs/blockwise_quantization.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/migration_guide.rst", "torch_docs/tutorials/quickstart_guide.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/examples.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/quantsim_2.0_overview.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["Adaptive Rounding (AdaRound)", "Cross-Layer Equalization (CLE)", "Quantization Simulation", "Model Compression Using Channel Pruning", "Model compression Using Spatial SVD", "Model Compression Using Spatial SVD Followed by Channel Pruning", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Adaptive Rounding (Adaround)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Quantization-Aware Training with a Keras Transformer Model", "Keras Model Preparer", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Quantsim and Adaround - Per Channel Quantization (PCQ)", "Cross-Layer Equalization (CLE) with QuantSim", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Model compression using Channel Pruning", "Model compression using Spatial SVD", "Model compression using Spatial SVD followed by Channel Pruning", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Using AIMET Tensorflow APIs with Keras Models", "Welcome to AI Model Efficiency Toolkit API Docs!", "AIMET Keras APIs", "AIMET Keras AdaRound API", "AIMET Keras BatchNorm Re-estimation APIs", "AIMET Keras Compression API", "AIMET Keras Cross Layer Equalization APIs", "AIMET Keras Layer Output Generation API", "Keras Model Guidelines", "Model Preparer API", "AIMET Keras Cross Layer Equalization Primitive API", "AIMET Keras Quant Analyzer API", "AIMET Keras Quantization APIs", "AIMET Keras Quantization SIM API", "AIMET ONNX APIs", "AIMET ONNX AdaRound API", "AIMET ONNX AutoQuant API", "AIMET ONNX Cross Layer Equalization APIs", "AIMET ONNX Layer Output Generation API", "AIMET ONNX Quant Analyzer API", "AIMET ONNX Quantization APIs", "AIMET ONNX Quantization SIM API", "Encoding Format Specification", "AIMET TensorFlow APIs", "AIMET TensorFlow AdaRound API", "AIMET TensorFlow AutoQuant API", "AIMET TensorFlow BatchNorm Re-estimation APIs", "AIMET TensorFlow Bias Correction API", "AIMET TensorFlow Compression API", "AIMET TensorFlow Cross Layer Equalization APIs", "AIMET Tensorflow Layer Output Generation API", "TensorFlow Model Guidelines", "AIMET TensorFlow Cross Layer Equalization Primitive API", "AIMET Tensorflow Quant Analyzer API", "AIMET TensorFlow Quantization APIs", "AIMET TensorFlow Quantization SIM API", "AIMET Visualization for Quantization for TensorFlow API", "AIMET PyTorch APIs", "AIMET PyTorch AdaRound API", "Architecture Checker API", "AIMET PyTorch AutoQuant API", "AIMET PyTorch BatchNorm Re-estimation APIs", "AIMET PyTorch Bias Correction API", "AIMET PyTorch Compression API", "AIMET PyTorch Cross Layer Equalization APIs", "AIMET PyTorch Layer Output Generation API", "PyTorch Model Guidelines", "Model Preparer API", "Model Validator Utility", "PyTorch Multi-GPU support", "PEFT LoRA", "AIMET PyTorch Cross Layer Equalization Primitive API", "AIMET PyTorch Quant Analyzer API", "AIMET PyTorch Quantization APIs", "AIMET PyTorch Quantization SIM API", "AIMET Visualization Compression API", "AIMET Visualization for Quantization API", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "FakeQuantizationMixin", "QuantizationMixin", "Quantize", "QuantizeDequantize", "dequantize", "quantize", "quantize_dequantize", "quantization.affine", "FloatQuantizeDequantize", "quantization.float", "quantization.tensor", "Blockwise Quantization", "Encoding Analyzers", "Post-Training Quantization", "MinMaxEncodingAnalyzer", "PercentileEncodingAnalyzer", "SqnrEncodingAnalyzer", "AIMET: AI Model Efficiency Toolkit Documentation", "Quantized Modules", "Quantizers", "Migrate to QuantSim v2", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Examples", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "QuantSim v2", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"show": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48, 57, 58, 59, 62, 68, 69, 71, 72, 73, 74, 77, 81, 83, 85, 87, 89, 105, 111, 115, 123, 128, 132], "work": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 46, 48, 54, 59, 66, 68, 71, 81, 82, 87, 105, 118, 121, 125, 126, 128, 131], "code": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 105, 115, 116, 134], "how": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48, 54, 55, 57, 58, 59, 62, 68, 71, 72, 73, 74, 75, 77, 81, 83, 85, 87, 105, 112, 114, 115, 121, 125, 128, 129, 132, 133, 134], "us": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 90, 92, 94, 95, 96, 97, 104, 105, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132, 133, 135, 138], "aimet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 41, 42, 55, 64, 72, 79, 80, 81, 82, 83, 112, 114, 115, 123, 126, 131, 134], "perform": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 17, 18, 19, 22, 23, 24, 25, 26, 29, 32, 33, 36, 37, 39, 44, 48, 50, 52, 55, 57, 58, 59, 60, 61, 62, 64, 66, 68, 71, 72, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 89, 94, 95, 96, 97, 105, 112, 113, 115, 117, 118, 119, 120, 122, 125, 127, 128, 129, 130, 132, 134], "featur": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 41, 42, 43, 45, 50, 55, 64, 65, 71, 77, 79, 80, 81, 82, 84, 86, 87, 95, 105, 112, 116, 117, 118, 121, 125, 128, 129, 133, 135, 137, 138], "typic": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 58, 71, 87, 105, 115, 120, 127, 129, 130, 131, 133, 137], "nearest": [0, 1, 6, 9, 10, 13, 15, 16, 18, 19, 26, 29, 44, 46, 54, 58, 60, 66, 68, 73, 75, 87, 116], "techniqu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 38, 39, 45, 48, 49, 50, 53, 57, 58, 60, 61, 62, 67, 71, 73, 75, 76, 77, 85, 86, 108, 109, 110, 111, 115, 116, 117, 119, 120, 123, 127, 129, 130, 132, 133, 134, 135, 136, 139], "achiev": [0, 3, 4, 5, 6, 7, 8, 10, 16, 18, 23, 24, 25, 26, 27, 38, 61, 76, 91, 105, 116, 120, 122, 136, 139], "when": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 46, 50, 55, 61, 64, 66, 76, 77, 79, 80, 85, 86, 87, 105, 109, 111, 112, 115, 116, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 138, 140], "weight": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 38, 42, 43, 44, 45, 46, 52, 53, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 71, 75, 81, 83, 84, 85, 86, 87, 89, 94, 95, 105, 110, 112, 114, 115, 116, 118, 120, 125, 127, 128, 129, 130, 131, 132, 133, 138], "valu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 52, 55, 57, 58, 61, 65, 66, 71, 75, 76, 78, 80, 83, 84, 85, 87, 96, 97, 99, 100, 102, 104, 105, 109, 110, 113, 115, 116, 122, 125, 127, 128, 129, 130, 133, 136, 138, 139], "integ": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 85, 87, 99, 100, 105, 116, 127, 129], "optim": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 44, 45, 46, 49, 53, 54, 57, 61, 67, 71, 72, 73, 76, 86, 87, 88, 89, 105, 115, 116, 117, 123, 125, 127, 130, 133, 134, 135, 137], "loss": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 36, 44, 46, 52, 57, 66, 71, 85, 87, 104, 111, 115, 116, 123, 127, 129, 133], "function": [0, 1, 3, 4, 5, 6, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 95, 99, 100, 104, 105, 112, 114, 115, 116, 122, 125, 126, 127, 129, 133, 135, 137, 138], "unlabel": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 49, 52, 54, 58, 66, 68, 71, 73, 85, 87, 116, 127, 129, 133], "data": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 43, 44, 46, 48, 49, 52, 54, 57, 58, 61, 65, 66, 68, 71, 73, 74, 75, 76, 80, 82, 83, 85, 87, 88, 104, 105, 111, 114, 115, 116, 118, 124, 127, 128, 129, 130, 132, 133], "decid": [0, 1, 2, 6, 10, 18, 23, 24, 25, 26, 29, 30, 31, 32, 116, 137], "whether": [0, 1, 2, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 45, 51, 61, 63, 78, 80, 81, 86, 116, 130], "specif": [0, 6, 7, 8, 10, 11, 12, 14, 18, 20, 21, 26, 28, 30, 31, 38, 42, 46, 60, 61, 68, 76, 87, 94, 105, 115, 116, 117, 118, 120, 123, 125, 126, 127, 128, 131, 135], "closer": [0, 6, 10, 18, 26, 116], "farther": [0, 6, 26], "one": [0, 3, 4, 5, 6, 9, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 43, 55, 60, 61, 64, 65, 68, 71, 72, 80, 81, 83, 84, 87, 91, 105, 112, 115, 119, 121, 125, 130, 131, 135, 136, 139], "abl": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42, 80, 81, 85, 104, 115, 116, 137, 138], "while": [0, 1, 3, 4, 5, 6, 9, 10, 13, 16, 18, 19, 23, 24, 25, 26, 29, 38, 58, 61, 71, 76, 83, 105, 112, 116, 122, 126, 127, 130, 132, 133, 134, 137], "low": [0, 3, 4, 5, 6, 9, 10, 18, 23, 25, 26, 29, 111, 116, 118, 125, 127, 128, 132, 134], "bit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 55, 68, 71, 85, 90, 102, 105, 115, 116, 118, 127, 132, 133, 135], "width": [0, 1, 2, 6, 10, 18, 26, 28, 29, 30, 31, 32, 55, 85, 116, 132, 133, 136, 139, 140], "cover": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 105, 118, 131, 133], "follow": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 50, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 105, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 129, 130, 131, 133, 134, 136, 139, 140], "instanti": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 79, 82, 83, 105, 115, 130, 137], "fake": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 71, 87, 94, 95, 97, 100, 102, 112, 113, 115, 134], "op": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 33, 38, 43, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 81, 87, 115, 127, 131, 135], "insert": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 71, 80, 87, 127, 133], "simuat": [0, 1, 6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31], "get": [0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 23, 24, 25, 33, 38, 40, 43, 51, 60, 61, 62, 63, 65, 68, 69, 72, 76, 78, 80, 83, 87, 89, 90, 91, 92, 116, 119, 127, 138], "score": [0, 1, 2, 8, 12, 15, 16, 27, 28, 38, 58, 61, 71, 73, 76, 85, 88, 122, 125, 137], "post": [0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 45, 53, 54, 55, 58, 67, 68, 73, 86, 111, 115, 116, 117, 123, 125, 130, 133, 135], "finetun": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 54, 59, 68, 87], "design": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 81, 114, 128, 134], "state": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 64, 112, 115, 125], "art": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 115], "result": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 42, 44, 58, 61, 66, 71, 73, 76, 85, 87, 94, 95, 104, 105, 110, 116, 117, 119, 120, 123, 128, 129, 130, 131, 133], "For": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 51, 52, 54, 57, 58, 59, 61, 62, 63, 68, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 87, 89, 90, 91, 92, 94, 95, 105, 111, 112, 114, 115, 116, 119, 120, 121, 122, 123, 124, 125, 127, 129, 131, 133, 137, 140], "rel": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 38, 61, 69, 76, 89, 120, 127, 132, 138], "friendli": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 117, 127, 128], "like": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 39, 42, 43, 62, 71, 77, 84, 87, 105, 111, 114, 115, 123, 125, 127, 129, 130, 131, 134, 137], "resnet18": [0, 1, 2, 7, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 59, 71, 73, 74, 77, 84, 85, 87, 88, 89], "also": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 44, 46, 52, 55, 57, 58, 60, 66, 68, 71, 73, 79, 80, 85, 87, 91, 92, 105, 119, 120, 121, 122, 127, 129, 131, 132, 133, 135, 137, 138, 140], "some": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 38, 42, 43, 45, 46, 61, 65, 68, 71, 76, 80, 84, 86, 87, 89, 91, 92, 112, 114, 115, 116, 120, 122, 125, 126, 127, 128, 130, 132, 133], "paramet": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 40, 42, 43, 44, 45, 46, 52, 53, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 99, 100, 102, 104, 105, 109, 110, 112, 113, 114, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130, 131, 134, 138], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 52, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 90, 91, 92, 94, 95, 96, 97, 102, 105, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 137, 138, 140], "deliber": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "chosen": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 121, 125], "have": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 50, 52, 55, 61, 65, 66, 71, 72, 77, 78, 80, 81, 85, 87, 89, 92, 95, 105, 114, 115, 122, 125, 127, 128, 129, 132, 133, 134], "execut": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 73, 80, 88, 115, 121, 122, 137], "more": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 43, 44, 46, 48, 49, 50, 52, 55, 57, 58, 60, 61, 62, 65, 66, 68, 71, 72, 73, 75, 76, 77, 81, 84, 85, 87, 90, 105, 111, 112, 114, 115, 119, 120, 121, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 138], "quickli": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 122], "reli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 114], "imagenet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 54, 58, 59, 60, 62, 65, 68, 69, 71, 74, 75, 87, 121], "task": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 137, 138], "imag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 58, 66, 73, 75, 85, 90, 116, 121, 129], "classif": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 125], "If": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 41, 42, 43, 46, 55, 57, 58, 60, 61, 62, 64, 65, 66, 68, 71, 73, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 99, 100, 102, 105, 110, 112, 113, 114, 115, 117, 126, 127, 128, 129, 131, 132, 137, 138, 140], "you": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 58, 61, 64, 68, 71, 76, 80, 82, 87, 91, 92, 114, 121, 122, 126, 136, 139], "alreadi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 87, 91, 122, 132], "version": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 71, 80, 87, 90, 91, 92, 94, 95, 105, 112, 114, 115, 121, 123, 134], "readili": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "avail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 39, 62, 71, 73, 80, 85, 87, 90, 95, 115, 126, 129, 131, 132, 134], "otherwis": [0, 6, 26, 58, 81, 83, 87, 91, 92, 96, 97, 99, 100, 105, 113, 132], "download": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 90, 91, 92, 115], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 109, 112, 113, 115, 116, 119, 120, 121, 122, 126, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140], "appropri": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 71, 76, 84, 87, 90, 92, 94, 95, 105, 112, 120, 121, 122, 125, 132], "locat": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 121], "e": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 45, 46, 52, 54, 55, 57, 66, 68, 71, 75, 85, 87, 95, 115, 118, 120, 123, 130, 132, 140], "g": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 71, 85, 87, 91, 115, 118, 120, 123, 132, 140], "http": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 80, 90, 91, 92, 120, 121, 128, 135, 137], "net": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 121], "org": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 80, 91, 92, 121, 128], "challeng": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "lsvrc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "2012": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "index": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 73, 85, 112, 120, 135], "php": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 121], "note1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 43, 44, 46, 48, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 90, 91, 92, 94, 95, 99, 100, 102, 104, 105, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 139, 140], "dataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48, 49, 52, 54, 66, 68, 71, 73, 74, 85, 115, 121, 129], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 42, 43, 44, 45, 48, 53, 54, 55, 57, 58, 61, 66, 67, 68, 71, 72, 73, 81, 83, 85, 86, 87, 88, 91, 92, 95, 102, 105, 111, 112, 114, 115, 116, 120, 121, 122, 125, 127, 128, 129, 131, 132, 133, 134, 137, 138, 140], "characterist": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "subfold": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "sampl": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 46, 52, 54, 55, 57, 58, 60, 61, 65, 66, 68, 71, 73, 75, 85, 87, 111, 112, 115, 119, 127, 128, 129, 130, 133], "val": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "valid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 44, 52, 54, 61, 62, 65, 66, 68, 71, 75, 76, 85, 86, 87, 105, 117, 127, 135], "pleas": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 44, 46, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 66, 68, 71, 73, 74, 75, 76, 77, 81, 83, 85, 87, 90, 92, 111, 114, 115, 116, 119, 121, 123, 125, 129, 133, 134], "see": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 42, 46, 48, 49, 50, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 77, 85, 87, 96, 97, 112, 113, 114, 115, 119, 122, 123, 125, 127, 131, 132, 133, 136, 137, 138, 139], "descript": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 112, 126], "detail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 61, 71, 80, 87, 91, 92, 119, 121, 122, 123, 125, 127, 132, 133, 137, 138], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 38, 43, 44, 46, 52, 58, 61, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 87, 88, 89, 94, 105, 110, 112, 120, 127, 129, 130, 131, 132, 133], "subdirectori": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "per": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 44, 52, 55, 59, 61, 65, 66, 74, 76, 78, 83, 85, 87, 105, 110, 112, 118, 127, 128, 129, 131, 132, 133, 135], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 40, 41, 42, 43, 44, 46, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 75, 76, 78, 79, 80, 81, 83, 84, 85, 87, 88, 94, 95, 96, 97, 102, 105, 106, 108, 109, 110, 113, 114, 115], "file": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 44, 46, 57, 58, 61, 64, 66, 68, 71, 72, 73, 75, 76, 83, 85, 87, 88, 90, 91, 92, 105, 115, 127, 129, 130, 133, 135, 138], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 43, 55, 57, 61, 65, 69, 71, 72, 75, 76, 81, 84, 85, 87, 88, 89, 91, 92, 94, 95, 105, 112, 113, 115, 119, 120, 121, 122, 127, 128, 129, 130, 131, 132, 133, 138, 140], "note2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "To": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 42, 46, 48, 49, 50, 57, 58, 60, 61, 62, 68, 71, 73, 75, 76, 77, 83, 85, 87, 90, 112, 114, 115, 118, 121, 122, 125, 126, 129, 131, 132, 133, 134, 137, 138], "speed": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 71, 76, 83, 125, 128, 135], "up": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 44, 46, 52, 57, 61, 64, 66, 68, 71, 76, 83, 85, 87, 92, 105, 125, 130, 131, 133, 134, 140], "mai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 55, 71, 73, 80, 83, 87, 91, 92, 94, 95, 104, 105, 112, 116, 120, 125, 127, 128, 129, 131, 132, 133], "reduc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 83, 105, 112, 119, 125, 128, 132, 135, 140], "subset": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 44, 52, 60, 65, 66, 85, 105, 116, 118, 129, 140], "entir": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 60, 61, 66, 76, 83, 85, 105, 115, 122, 125], "ilsvrc2012": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "ha": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 43, 44, 50, 52, 57, 60, 64, 65, 66, 71, 72, 76, 77, 80, 81, 83, 84, 85, 87, 89, 95, 104, 105, 114, 115, 120, 121, 122, 125, 128, 130, 133, 137, 140], "1000": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 52, 54, 58, 66, 68, 71, 73, 75, 76, 85, 87, 115, 116, 128, 129], "50": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 68, 76, 109, 120], "But": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 80, 87, 116, 125], "purpos": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 105, 131], "run": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 42, 44, 45, 46, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 63, 66, 68, 72, 73, 74, 76, 78, 80, 81, 87, 91, 92, 96, 97, 105, 112, 113, 114, 118, 123, 125, 127, 128, 129, 133, 135, 137], "could": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 71, 79, 85, 87, 114, 115, 119, 140], "exercis": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "left": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 96, 97, 99, 100, 102, 113, 122, 140], "reader": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "necessari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 58, 61, 71, 73, 76, 85, 87, 104, 105, 115, 137], "edit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 54, 55, 65, 68, 71, 87], "cell": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "below": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 39, 40, 41, 42, 43, 50, 51, 55, 60, 61, 62, 63, 65, 66, 71, 77, 78, 79, 83, 91, 92, 96, 97, 99, 100, 105, 112, 113, 114, 115, 117, 118, 127, 128, 131, 132, 133, 140], "specifi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 46, 55, 58, 61, 66, 68, 71, 76, 85, 87, 89, 91, 92, 96, 97, 99, 100, 102, 105, 113, 115, 117, 125, 131, 133, 138], "directori": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 40, 44, 58, 61, 63, 66, 69, 73, 76, 78, 83, 85, 89, 121, 138], "where": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 46, 55, 57, 58, 61, 68, 71, 76, 79, 80, 83, 87, 96, 97, 99, 100, 102, 112, 113, 115, 118, 122, 129, 130, 136, 139, 140], "save": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 43, 44, 46, 51, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 76, 78, 83, 84, 85, 87, 89, 115, 117, 133, 138], "dataset_dir": [0, 1, 2, 7, 9, 10, 11, 12, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38], "path": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 44, 46, 51, 57, 58, 61, 63, 66, 68, 71, 73, 75, 76, 78, 80, 83, 85, 87, 88, 92, 121], "replac": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 54, 59, 62, 65, 68, 71, 74, 75, 80, 83, 84, 87, 91, 105, 112, 114, 115, 128, 133], "real": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 58, 73, 104], "loop": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 80, 115, 132], "doe": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 42, 44, 50, 52, 57, 61, 66, 76, 77, 79, 80, 85, 95, 112, 114, 115, 122, 124, 127, 132], "ani": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 41, 42, 43, 44, 45, 46, 52, 61, 65, 66, 68, 71, 74, 76, 79, 80, 81, 84, 85, 86, 87, 91, 95, 105, 114, 115, 116, 117, 121, 131, 135], "limit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 64, 112, 114, 124], "written": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 126, 127], "Not": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 82, 83, 85, 116, 122], "realli": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 40, 42, 51, 52, 58, 59, 61, 63, 71, 72, 74, 75, 78, 80, 81, 83, 85, 87, 89, 91, 92, 105, 112, 114, 115, 122, 125, 127, 128, 131, 132, 133, 134, 138], "later": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 87, 90, 115], "modifi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 43, 46, 51, 65, 80, 83, 84, 87, 91, 92, 127, 133, 135, 140], "user": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 41, 42, 43, 44, 45, 52, 54, 55, 59, 61, 64, 65, 66, 74, 76, 79, 80, 82, 84, 86, 88, 89, 91, 105, 111, 112, 114, 116, 117, 120, 121, 125, 127, 129, 130, 131, 132, 133, 134, 135, 137, 138], "quantizationsim": [0, 1, 2, 6, 7, 8, 9, 10, 11, 13, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 71, 82], "which": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 42, 43, 45, 51, 52, 55, 57, 60, 61, 63, 66, 68, 71, 72, 75, 76, 78, 80, 81, 83, 84, 86, 87, 89, 91, 92, 95, 96, 97, 99, 100, 104, 105, 110, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 139], "still": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 41, 105, 127, 132], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 51, 52, 54, 55, 57, 60, 61, 62, 63, 65, 66, 68, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 96, 97, 104, 105, 111, 112, 113, 114, 115, 117, 118, 120, 122, 123, 125, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139], "place": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 46, 60, 62, 65, 66, 68, 71, 75, 77, 84, 87, 95, 105, 130, 131], "origin": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 42, 51, 61, 63, 68, 76, 78, 80, 87, 94, 95, 112, 114, 115, 119, 120, 125, 127, 128, 129, 130, 133, 137], "do": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 42, 46, 68, 71, 80, 82, 83, 89, 92, 115, 125, 129, 133], "infer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 45, 46, 49, 52, 53, 54, 55, 57, 67, 68, 71, 86, 87, 105, 111, 115, 118, 120, 123, 128, 130, 133, 135], "put": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "interfac": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 90], "method": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 40, 46, 58, 61, 63, 64, 68, 75, 78, 80, 87, 94, 95, 105, 112, 114, 115, 122, 125, 127, 132, 133], "should": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 46, 48, 49, 52, 54, 55, 58, 60, 61, 64, 66, 68, 71, 73, 76, 78, 79, 80, 83, 85, 86, 87, 94, 95, 105, 112, 114, 115, 120, 125, 131, 137, 140], "your": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 49, 54, 59, 68, 71, 74, 75, 80, 81, 87, 90, 91, 92, 111, 114, 121, 126, 134], "exist": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 71, 87, 91, 94, 95, 105, 127, 133], "routin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 71, 87], "import": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 89, 92, 95, 96, 97, 99, 100, 102, 104, 105, 111, 112, 113, 115, 118, 119, 132], "torch": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 94, 95, 96, 97, 99, 100, 102, 104, 105, 111, 112, 113, 114, 115, 121, 126, 135], "onnxruntim": [0, 1, 2, 49, 51, 52], "ort": [0, 1, 2, 49], "common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 58, 61, 68, 83, 87, 91, 105, 114, 132, 138], "image_net_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59], "util": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 43, 44, 46, 57, 58, 59, 60, 64, 65, 66, 68, 72, 73, 83, 84, 87, 88, 105, 114, 115, 118, 121, 127], "image_net_evalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 66], "imagenetevalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 66], "image_net_data_load": [0, 1, 2, 23, 25, 26, 28, 29, 30, 31, 32], "imagenetdataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32], "imagenetdatapipelin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59, 71, 74, 75, 87], "staticmethod": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 80], "def": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 41, 42, 43, 44, 46, 48, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 87, 88, 89, 95, 114, 115], "get_val_dataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 71, 75, 87], "return": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 94, 95, 96, 97, 104, 105, 110, 111, 113, 115, 117, 122, 123, 129, 133], "data_load": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 48, 49, 54, 68, 71, 73, 75, 76, 87, 111, 115], "image_s": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 66, 73], "batch_siz": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 44, 49, 52, 54, 57, 58, 60, 61, 66, 68, 71, 73, 76, 85, 87, 115], "is_train": [0, 1, 2, 23, 25, 26, 28, 29, 30, 31, 32], "fals": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 46, 51, 54, 55, 57, 58, 60, 61, 63, 64, 66, 68, 72, 73, 75, 76, 80, 81, 83, 87, 94, 95, 96, 97, 99, 100, 104, 105, 112, 113, 114, 115, 126, 131], "num_work": [0, 1, 2, 23, 24, 25, 26, 28, 29, 30, 31, 32], "sess": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 38, 58, 59, 60, 61, 62, 65, 68, 69], "inferencesess": [0, 1, 2, 49, 51, 52], "float": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 44, 46, 49, 52, 55, 57, 58, 61, 66, 68, 71, 73, 75, 76, 85, 87, 94, 95, 102, 104, 105, 111, 112, 127, 129, 132, 133, 134, 138], "given": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 39, 43, 46, 55, 58, 60, 61, 62, 64, 65, 68, 69, 71, 73, 74, 76, 77, 84, 87, 94, 95, 105, 112, 117, 119, 122, 123, 125, 128, 136, 137, 139], "its": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 42, 69, 94, 95, 104, 111, 112, 115, 121, 123, 127, 129, 133, 140], "top": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 60, 94, 95, 119, 137], "param": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 38, 39, 43, 44, 46, 48, 49, 52, 54, 57, 60, 61, 65, 66, 68, 71, 73, 76, 83, 85, 87, 88, 94, 105, 113, 131], "iter": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 38, 44, 49, 52, 57, 60, 61, 66, 71, 73, 76, 85, 115, 116, 128], "none": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 42, 43, 44, 46, 48, 49, 51, 52, 54, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 87, 88, 89, 94, 95, 96, 97, 98, 99, 100, 102, 105, 112, 113, 114, 115, 137], "go": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 59, 71, 74, 87, 91, 92, 115, 121, 134, 137], "load": [0, 1, 2, 13, 33, 40, 43, 46, 51, 59, 60, 62, 63, 64, 65, 68, 69, 71, 74, 75, 76, 78, 80, 81, 83, 87, 125], "pretrain": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59, 71, 73, 74, 77, 84, 85, 87, 88, 89, 129, 130, 133], "torchvis": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 73, 74, 77, 84, 85, 87, 88, 89, 115], "similarli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 105, 132], "instead": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 71, 79, 80, 81, 87, 105, 127, 128], "differ": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 38, 58, 61, 71, 73, 76, 80, 83, 85, 87, 91, 92, 105, 114, 119, 121, 122, 125, 127, 128, 130, 131, 132, 133, 134], "framework": [0, 1, 2, 34, 54, 123, 127, 131, 133], "altogeth": [0, 1, 2, 131], "input_shap": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 39, 41, 44, 49, 52, 54, 58, 59, 60, 61, 62, 65, 69, 71, 73, 75, 76, 77, 80, 84, 85, 87, 88, 115], "224": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 44, 46, 49, 52, 54, 58, 59, 60, 61, 62, 65, 66, 69, 71, 73, 75, 77, 78, 84, 85, 87, 88, 89], "shape": [0, 1, 2, 12, 13, 14, 18, 26, 28, 29, 30, 31, 32, 33, 41, 42, 61, 72, 76, 77, 80, 81, 83, 84, 96, 97, 102, 104, 105, 108, 109, 110, 112, 113, 114, 115, 129], "channel": [0, 1, 2, 9, 15, 16, 19, 24, 26, 28, 29, 30, 31, 32, 38, 55, 59, 69, 72, 74, 83, 85, 89, 105, 112, 118, 120, 121, 122, 124, 125, 128, 129, 131, 132, 133, 135, 136, 138, 139, 140], "x": [0, 1, 2, 10, 13, 14, 17, 18, 22, 26, 28, 29, 30, 31, 32, 38, 41, 42, 46, 64, 68, 72, 79, 80, 81, 90, 102, 104, 112, 115, 120, 126, 129], "height": [0, 1, 2, 13, 26, 28, 29, 30, 31, 32, 136, 139, 140], "dummy_input": [0, 1, 2, 26, 27, 28, 29, 30, 31, 32, 37, 40, 49, 51, 52, 54, 71, 72, 73, 77, 78, 79, 83, 84, 85, 87, 105, 115], "randn": [0, 1, 2, 27, 46, 49, 52, 54, 71, 73, 80, 81, 85, 87, 94, 95, 96, 97, 104, 112, 113], "filenam": [0, 1, 2, 15, 16, 46, 57, 61, 68, 71, 83, 87], "resnet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 38, 58, 59, 120], "18": [0, 1, 2], "pt_model": [0, 1, 2], "true": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 43, 46, 48, 55, 60, 61, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 80, 81, 83, 84, 85, 87, 88, 89, 94, 95, 96, 97, 102, 104, 105, 110, 112, 113, 114, 115, 126, 131], "export": [0, 1, 2, 6, 9, 10, 13, 18, 20, 21, 26, 29, 30, 31, 40, 44, 46, 51, 52, 54, 55, 59, 63, 66, 68, 71, 74, 78, 79, 83, 85, 87, 91, 92, 111, 114, 118, 121, 123, 125, 126, 127, 130, 133, 134, 135], "eval": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 44, 49, 52, 57, 58, 61, 66, 71, 73, 75, 76, 77, 80, 82, 84, 85, 87, 88, 89, 115, 122, 125, 137], "export_param": [0, 1, 2], "do_constant_fold": [0, 1, 2], "input_nam": [0, 1, 2, 87], "input": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 33, 38, 40, 41, 42, 44, 49, 51, 52, 54, 58, 59, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 87, 94, 95, 96, 97, 99, 100, 102, 105, 112, 113, 114, 115, 119, 125, 129, 131, 133, 136, 137, 139, 140], "output_nam": [0, 1, 2, 87], "output": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 38, 41, 42, 44, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 72, 73, 75, 79, 80, 81, 83, 85, 86, 87, 89, 94, 95, 96, 97, 99, 105, 112, 113, 114, 115, 119, 125, 128, 129, 131, 133, 135, 136, 139, 140], "dynamic_ax": [0, 1, 2], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140], "load_model": [0, 1, 2, 40], "cpu": [0, 1, 2, 3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 61, 71, 73, 74, 78, 80, 84, 87, 89, 90, 91, 115, 127, 135], "cuda": [0, 1, 2, 3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 73, 74, 75, 76, 85, 87, 88, 90, 91, 92, 115], "devic": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 40, 51, 63, 71, 73, 74, 75, 78, 80, 83, 84, 87, 88, 89, 111, 115, 133], "environ": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 90, 121], "chang": [0, 1, 2, 3, 4, 5, 8, 9, 12, 13, 15, 16, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 45, 55, 71, 73, 79, 80, 83, 86, 87, 89, 95, 105, 112, 115, 116, 125, 129, 130, 131, 133, 134, 138, 140], "logic": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32, 94, 95, 135], "forc": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32], "placement": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32, 131], "need": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 41, 42, 43, 46, 52, 55, 61, 63, 65, 71, 75, 76, 78, 82, 83, 84, 85, 87, 91, 92, 105, 114, 115, 117, 120, 125, 127, 128, 129, 130, 131, 133, 135, 137, 138], "cudnn_conv_algo_search": [0, 1, 2], "fix": [0, 1, 2, 55, 81, 111, 123, 127, 132, 133, 135], "default": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 44, 46, 57, 58, 60, 61, 66, 68, 71, 73, 75, 76, 80, 85, 87, 91, 92, 95, 96, 97, 99, 100, 112, 113, 116, 122, 125, 131, 133, 135, 137], "avoid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 46, 52, 71, 79, 85, 87, 120], "everi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 44, 52, 57, 63, 66, 71, 78, 85, 87, 115, 122, 125, 130, 138], "cudaexecutionprovid": [0, 1, 2], "get_available_provid": [0, 1, 2], "cpuexecutionprovid": [0, 1, 2], "use_cuda": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 48, 51, 54, 57, 60, 61, 63, 66, 68, 71, 74, 76, 87], "els": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 43, 49, 74, 80, 81, 110, 115, 128], "let": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 71, 80, 87, 115], "session": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 36, 38, 49, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 88], "point": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 42, 43, 44, 45, 52, 53, 55, 66, 67, 75, 83, 84, 85, 86, 87, 94, 95, 104, 105, 111, 112, 114, 123, 125, 127, 129, 132, 133, 134, 138], "32": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 33, 36, 41, 42, 44, 49, 55, 57, 58, 61, 66, 71, 72, 80, 81, 87, 91, 92, 96, 113, 132], "print": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 49, 61, 68, 71, 72, 73, 76, 80, 81, 87, 92, 94, 95, 99, 100, 112, 114, 115, 127, 129], "befor": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 40, 41, 42, 43, 45, 49, 51, 60, 63, 64, 65, 71, 73, 78, 84, 86, 87, 89, 112, 114, 115, 116, 117, 118, 125, 127, 130, 137, 138], "quantizationsimmodel": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 37, 40, 43, 46, 48, 51, 54, 57, 59, 63, 68, 71, 74, 78, 83, 85, 87, 105, 111, 115, 116, 118], "batchnorm": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 39, 42, 43, 45, 50, 58, 62, 64, 65, 72, 73, 75, 77, 84, 89, 112, 117, 128, 140], "bn": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 37, 43, 60, 62, 64, 65, 67, 75, 84, 86, 127, 135], "These": [0, 1, 2, 6, 9, 10, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 33, 36, 46, 57, 58, 68, 73, 87, 92, 112, 114, 115, 117, 118, 119, 120, 126, 127, 128, 129, 132, 133], "adjac": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 115, 131], "convolut": [0, 1, 2, 3, 4, 5, 6, 9, 10, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 38, 42, 43, 61, 65, 72, 105, 115, 118, 120, 125, 132], "cannot": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 72, 80, 81, 96, 97, 113], "thei": [0, 1, 2, 3, 4, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 43, 61, 65, 80, 84, 86, 105, 131, 134, 137], "why": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 132], "On": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 55, 90, 95], "runtim": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 46, 54, 55, 61, 68, 71, 76, 87, 105, 111, 115, 120, 123, 125, 127, 129, 131, 133, 135], "tflite": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "snapdragon": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "neural": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 111, 115, 117, 120, 123, 125, 127, 130, 132, 133, 139], "process": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 38, 40, 51, 61, 63, 68, 71, 78, 87, 88, 105, 110, 111, 115, 117, 123, 125, 127, 128, 133, 134], "sdk": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 111, 115, 123], "etc": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 55, 61, 64, 71, 87, 91, 92, 120, 127], "practic": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 115, 125], "so": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 44, 46, 52, 57, 61, 66, 68, 71, 76, 80, 81, 82, 85, 87, 92, 112, 114, 126, 129, 137], "sec": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "speedup": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "sinc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 54, 71, 83, 87, 105, 118, 120, 122, 133], "unnecessari": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 115, 140], "perspect": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "mathemat": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 79], "equival": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 32, 71, 79, 87, 95, 99, 100, 102, 105, 115], "produc": [0, 1, 2, 6, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 55, 73, 80, 104, 105, 110, 122, 129, 134, 137], "same": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 40, 42, 51, 57, 63, 71, 73, 78, 80, 81, 83, 85, 87, 94, 95, 104, 105, 112, 113, 114, 118, 128, 131, 133, 134, 138], "howev": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 41, 42, 61, 71, 76, 87, 114, 127, 128, 130, 131, 133], "increas": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 23, 25, 26, 29, 30, 31, 38, 61, 76, 89, 105, 122, 128, 131], "rang": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 26, 27, 28, 29, 30, 42, 44, 52, 59, 66, 68, 69, 71, 73, 74, 80, 85, 87, 89, 99, 100, 109, 110, 115, 116, 118, 121, 122, 127, 128, 129, 130, 132, 133, 135, 138], "tensor": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 40, 42, 45, 46, 53, 54, 55, 57, 60, 66, 67, 68, 71, 72, 73, 76, 77, 78, 79, 80, 83, 84, 85, 86, 87, 94, 95, 96, 97, 98, 99, 100, 102, 105, 110, 112, 113, 115, 116, 119, 126, 127, 129, 131, 132, 133, 135, 136, 139], "neg": [0, 1, 2, 6, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 99, 100, 105, 112], "impact": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 115, 122, 132], "especi": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 90, 127, 130, 132], "int8": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 104, 130, 133, 138], "lower": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 105, 114, 122, 127, 132], "precis": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 55, 71, 96, 97, 99, 100, 102, 111, 113, 127], "want": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 40, 43, 46, 51, 58, 63, 65, 66, 68, 71, 78, 80, 84, 86, 87, 91], "target": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40, 42, 46, 49, 51, 54, 55, 59, 61, 63, 68, 71, 74, 76, 78, 83, 87, 111, 118, 120, 122, 123, 125, 127, 132, 133, 135], "behavior": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 80, 95, 112, 114, 115, 123, 134], "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 38, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 80, 83, 85, 87, 114, 115, 120, 121, 130, 137], "call": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 37, 38, 39, 41, 42, 43, 52, 55, 58, 61, 62, 65, 71, 76, 77, 80, 84, 85, 87, 94, 95, 102, 104, 105, 112, 115, 118, 125, 127, 129, 131, 133, 135, 136, 139], "aimet_onnx": [0, 1, 2, 48, 49, 50, 51, 52, 54, 90, 92], "batch_norm_fold": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 37, 43, 59, 60, 65, 74, 84, 89, 115], "fold_all_batch_norms_to_weight": [0, 1, 2], "_": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 33, 36, 40, 42, 43, 44, 51, 52, 54, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 73, 78, 85, 96, 97, 100, 111, 112, 113, 115], "now": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 42, 71, 80, 81, 87, 115, 127, 134, 135, 140], "basic": [0, 1, 2, 8, 9, 12, 13, 15, 16, 19, 20, 21, 28, 29, 30, 31, 71, 87, 92, 111, 115, 134], "mean": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 45, 59, 71, 74, 87, 89, 112, 115, 119, 131, 133], "graph": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 55, 57, 58, 60, 61, 62, 64, 65, 68, 69, 71, 72, 80, 84, 87, 88, 126, 127, 133, 137], "configur": [0, 1, 2, 6, 8, 9, 12, 13, 15, 16, 20, 21, 26, 28, 29, 30, 31, 36, 44, 55, 57, 58, 71, 73, 75, 83, 85, 87, 105, 115, 120, 124, 135], "them": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 46, 52, 60, 66, 71, 80, 81, 83, 85, 87, 112, 114, 115, 116, 140], "few": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 87, 115, 120, 127, 132, 133], "explain": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 71, 87, 119, 125, 128, 133, 140], "quant_schem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 54, 55, 57, 66, 68, 71, 73, 75, 85, 87], "set": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 42, 43, 48, 49, 54, 55, 57, 58, 60, 61, 64, 65, 68, 71, 73, 76, 80, 81, 83, 84, 85, 87, 92, 94, 95, 105, 109, 112, 113, 114, 116, 120, 122, 123, 125, 126, 128, 129, 130, 131, 132, 133, 134, 140], "quantschem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 54, 57, 58, 59, 66, 68, 71, 73, 74, 75, 85, 87, 114, 117], "post_training_tf_enhanc": [0, 1, 2, 6, 8, 9, 12, 13, 15, 17, 19, 20, 22, 26, 28, 29, 30, 32, 36, 44, 46, 52, 55, 57, 58, 66, 68, 71, 73, 75, 85, 87], "support": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 19, 20, 21, 22, 28, 29, 30, 31, 33, 34, 38, 39, 41, 42, 44, 46, 54, 57, 58, 61, 62, 64, 66, 68, 71, 75, 76, 79, 80, 85, 87, 90, 105, 119, 120, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 139, 140], "option": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 43, 44, 46, 49, 57, 58, 60, 61, 66, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 85, 87, 89, 92, 95, 96, 97, 99, 100, 105, 110, 111, 113, 115, 116, 121, 129, 131, 133, 134, 137], "tf_enhanc": [0, 1, 2, 8, 9, 12, 13, 15, 19, 20, 28, 29, 30, 46, 60, 68, 75], "tf": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 75, 85, 91, 129, 133, 135], "quant": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 28, 29, 30, 31, 36, 45, 46, 54, 57, 60, 68, 71, 75, 86, 87, 118], "scheme": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 36, 38, 44, 46, 54, 57, 58, 60, 61, 66, 68, 71, 73, 75, 76, 78, 85, 87, 105, 117, 118, 122, 125, 129], "enum": [0, 1, 2, 8, 9, 12, 13, 15, 19, 20, 28, 29, 30, 38, 61, 75, 76], "post_training_tf": [0, 1, 2, 8, 9, 10, 12, 13, 15, 18, 19, 20, 28, 29, 30, 36, 44, 46, 54, 55, 57, 58, 66, 68, 71, 75, 85, 87], "default_activation_bw": [0, 1, 2, 48, 52, 54], "8": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 36, 43, 44, 46, 48, 52, 54, 55, 57, 58, 61, 66, 68, 71, 73, 75, 76, 80, 81, 83, 85, 87, 88, 90, 92, 94, 95, 96, 97, 99, 100, 102, 104, 105, 112, 113, 114, 115, 127, 140], "essenti": [0, 1, 2, 8, 9, 12, 13, 15, 16, 19, 20, 21, 28, 29, 30, 31, 105, 111], "ask": [0, 1, 2, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 28, 29, 30, 31, 32], "all": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 37, 39, 41, 42, 43, 46, 52, 55, 59, 61, 62, 65, 66, 68, 71, 74, 75, 76, 80, 81, 83, 84, 85, 87, 89, 91, 94, 95, 105, 112, 114, 115, 119, 122, 125, 128, 129, 131, 132, 134], "activ": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 41, 42, 43, 44, 46, 52, 54, 55, 60, 65, 66, 68, 71, 72, 75, 79, 80, 83, 84, 85, 87, 105, 112, 115, 127, 129, 130, 131, 132, 133], "default_param_bw": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 48, 52, 54, 57, 58, 66, 68, 71, 85, 87, 115], "In": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 49, 52, 55, 58, 61, 64, 71, 72, 73, 76, 79, 80, 81, 85, 86, 87, 95, 105, 112, 114, 115, 116, 117, 120, 122, 125, 127, 128, 130, 131, 133, 134, 138, 140], "case": [0, 2, 13, 14, 17, 22, 32, 44, 49, 52, 55, 58, 65, 73, 79, 80, 81, 83, 85, 92, 99, 100, 105, 112, 114, 115, 122, 128, 130, 131], "custom": [0, 2, 13, 16, 27, 42, 46, 55, 80, 94, 95, 112, 121, 132, 133, 134], "compil": [0, 2, 11, 12, 13, 17, 33, 44, 46], "via": [0, 2, 42, 111, 120, 123, 133], "user_onnx_lib": [0, 2], "custom_op1": [0, 2], "custom_op2": [0, 2], "There": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 78, 81, 87, 90, 114, 116, 126, 128, 130, 137, 138], "other": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 61, 65, 79, 80, 84, 87, 90, 105, 114, 122, 124, 125, 127, 129, 132, 133, 135], "check": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 42, 44, 45, 51, 52, 63, 66, 72, 78, 79, 80, 81, 85, 86, 87, 117, 127, 130, 132], "api": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 41, 79, 82, 91, 95, 114, 115, 116, 117, 121, 123, 126, 127, 129, 131, 134, 135, 137], "document": [0, 1, 2, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 34, 83, 88, 90, 120, 121, 123, 134, 135], "refer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 60, 71, 75, 78, 83, 86, 87, 105, 114, 116, 121, 123, 127, 129, 130, 131, 133, 134], "copi": [0, 4, 5, 6, 26, 29, 30, 31, 42, 46, 87, 89, 121, 133], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "quantsim": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 20, 21, 26, 28, 29, 30, 31, 36, 40, 46, 48, 51, 52, 54, 57, 59, 63, 68, 71, 73, 74, 75, 78, 83, 85, 87, 105, 111, 121, 127, 130, 131, 135], "deepcopi": [0, 89], "even": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 127], "though": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 105, 131], "ad": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 55, 61, 68, 71, 81, 83, 87, 115, 124, 127, 131, 135], "node": [0, 1, 2, 6, 8, 9, 10, 12, 13, 18, 20, 21, 26, 29, 30, 31, 46, 61, 68, 71, 72, 79, 80, 87, 115, 130, 133], "readi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 46, 68, 71, 87, 115, 132], "yet": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 134], "find": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 43, 61, 65, 71, 75, 81, 84, 87, 89, 122, 127, 129, 130, 133], "scale": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 37, 39, 43, 50, 55, 59, 62, 65, 71, 74, 77, 84, 87, 95, 96, 97, 98, 99, 100, 102, 104, 105, 113, 118, 127, 128, 129, 130, 133], "offset": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 44, 52, 55, 66, 71, 85, 87, 95, 96, 97, 98, 99, 100, 105, 110, 113, 127, 129, 130, 133], "pass": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 40, 42, 43, 44, 46, 48, 51, 52, 54, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 87, 94, 95, 105, 111, 112, 114, 115, 123, 126, 127, 128, 129, 130, 132, 133, 135, 137], "through": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 61, 71, 75, 80, 85, 87, 89, 112, 114, 115, 128, 129, 133, 134, 137, 138], "collect": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 73, 85, 87, 105, 119, 129], "statist": [0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 37, 38, 44, 45, 52, 59, 61, 66, 67, 69, 71, 74, 76, 85, 86, 87, 89, 96, 97, 102, 112, 113, 115, 118, 127, 129, 138], "calcul": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 46, 57, 58, 61, 65, 66, 68, 71, 73, 84, 87, 110, 112, 122, 128, 129, 133], "sometim": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 87, 119, 125, 128, 129], "calibr": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 44, 48, 52, 54, 66, 68, 71, 85, 87, 96, 97, 105, 108, 109, 110, 111, 112, 113, 115, 127, 129, 130, 132, 133], "simpli": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 44, 46, 52, 57, 66, 68, 71, 80, 85, 87, 140], "fairli": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "simpl": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 36, 44, 52, 57, 61, 66, 71, 76, 80, 85, 87, 115, 127, 140], "loader": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 44, 52, 54, 66, 68, 71, 74, 75, 85, 87, 115, 116], "extract": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 128], "don": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 80, 83, 87, 116], "t": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 71, 80, 82, 83, 87, 91, 116], "metric": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 44, 46, 61, 71, 76, 87, 129, 133], "just": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 66, 71, 87, 133, 137, 140], "ignor": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 60, 61, 62, 65, 71, 75, 76, 80, 87, 115], "pointer": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "regard": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "veri": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 71, 87, 118, 120, 125, 129, 138, 140], "small": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 71, 87, 118, 123, 127], "percentag": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "1m": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "onli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 41, 46, 48, 51, 52, 54, 60, 61, 63, 64, 68, 71, 72, 75, 78, 79, 80, 82, 84, 85, 87, 90, 91, 92, 99, 100, 104, 105, 112, 115, 118, 124, 127, 129, 130, 131, 135, 140], "500": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 49, 71, 76, 87, 115, 116, 128, 129], "It": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 39, 42, 43, 44, 49, 52, 55, 61, 62, 65, 66, 71, 76, 80, 84, 85, 87, 114, 115, 118, 121, 122, 127, 128, 131, 137, 138, 140], "benefici": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 116, 129, 130], "well": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 52, 61, 66, 71, 72, 81, 83, 85, 87, 95, 104, 105, 112, 120, 125, 127, 128, 129, 133, 136], "distribut": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 33, 38, 61, 71, 76, 87, 128, 132, 133], "look": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 42, 60, 71, 87, 115, 137], "definit": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 45, 79, 80, 83, 86, 114, 115, 127], "extrem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "scenario": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 118, 125, 127, 140], "dark": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "light": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "pictur": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 111, 119, 123], "captur": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 40, 51, 63, 71, 78, 80, 87, 122], "night": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87], "might": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 55, 71, 87, 125, 129], "give": [0, 1, 2, 6, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 87, 136, 139], "ideal": [0, 1, 2, 4, 5, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 71, 87], "mani": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 80, 116, 128, 133], "wai": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 61, 76, 78, 87, 90, 105, 114, 115, 121, 122], "pass_calibration_data": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 48, 54, 68, 71, 87], "get_input": [0, 1, 2], "name": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 16, 17, 20, 21, 22, 32, 33, 38, 40, 42, 51, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 75, 78, 83, 85, 87, 91, 92, 94, 95, 112, 113, 128, 133, 135, 137], "batch_cntr": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 49], "input_data": [0, 1, 2, 26, 28, 29, 30, 31, 32, 36, 49, 54, 57, 61, 66, 68, 71, 87], "target_data": [0, 1, 2, 26, 28, 29, 30, 31, 32, 71, 87], "inputs_batch": [0, 1, 2, 26, 28, 29, 30, 31, 32, 71, 87], "numpi": [0, 1, 2, 7, 8, 14, 33, 36, 38, 44, 46, 49, 52, 54, 57, 58, 61, 66], "break": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 38, 49, 54, 68, 71, 87, 115], "abov": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 44, 52, 57, 61, 66, 71, 76, 80, 82, 85, 87, 91, 92, 105, 111, 117, 118, 121, 122, 123, 125, 126, 128, 132, 133, 140], "subsequ": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 71, 87, 104, 126, 128, 130, 131], "compute_encod": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 36, 46, 54, 57, 68, 71, 87, 94, 95, 96, 97, 102, 104, 111, 112, 113, 114, 115, 134], "forward_pass_callback": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 57, 66, 68, 85, 87], "forward_pass_callback_arg": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 46, 48, 68, 71, 87], "first": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 45, 60, 61, 71, 80, 86, 112, 115, 120, 125, 127, 130, 137], "u": [0, 1, 2, 6, 8, 9, 10, 13, 18, 20, 21, 26, 29, 30, 31, 71, 91, 132], "saw": [0, 1, 2, 6, 8, 9, 10, 18, 20, 21, 26, 29, 30, 31], "describ": [0, 6, 10, 18, 26, 46, 55, 68, 71, 80, 87, 105, 114, 127, 128, 132, 133], "over": [0, 42, 49, 61, 73, 76, 85, 99, 100, 110, 112, 116, 122, 125, 138], "learn": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 36, 37, 38, 39, 46, 48, 49, 50, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 77, 85, 87, 114, 118, 121, 125, 127, 130, 133, 134, 135], "vector": [0, 6, 10, 18, 26, 71], "compli": [0, 26, 29, 30, 31, 32, 71, 87], "signatur": [0, 3, 4, 5, 23, 24, 25, 36, 38, 44, 49, 52, 57, 61, 66, 76, 85, 95, 99, 100], "expect": [0, 3, 4, 5, 8, 12, 23, 24, 25, 28, 38, 41, 43, 44, 46, 48, 52, 54, 58, 60, 61, 65, 66, 68, 71, 72, 76, 80, 81, 84, 85, 87, 110, 115, 125, 127, 129], "num_batch": [0, 1, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 22, 26, 27, 28, 29, 32, 36, 44, 48, 49, 52, 57, 58, 59, 66, 71, 73, 74, 85], "number": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 37, 38, 42, 44, 46, 52, 57, 58, 59, 61, 66, 68, 71, 74, 75, 76, 80, 85, 87, 91, 94, 95, 99, 100, 102, 105, 110, 112, 116, 122, 123, 125, 130, 133, 135, 137, 140], "around": [0, 6, 10, 13, 18, 26, 44, 52, 54, 58, 66, 68, 71, 85, 87, 126], "2000": [0, 6, 7, 9, 10, 11, 18, 26, 27, 29, 49, 58, 71, 73, 100, 104], "size": [0, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 18, 26, 42, 46, 54, 58, 60, 61, 66, 68, 71, 72, 73, 81, 85, 87, 94, 95, 96, 97, 99, 100, 105, 112, 113, 116, 125, 126, 136, 139], "translat": [0, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 71], "64": [0, 6, 10, 18, 26, 41, 42, 44, 52, 54, 58, 66, 68, 71, 85, 87, 90, 96, 105, 110, 113, 116], "default_num_iter": [0, 6, 10, 18, 26, 27, 36, 48, 57, 71], "10000": [0, 6, 7, 10, 11, 18, 26, 36, 57, 71, 116], "strongli": [0, 6, 10, 18, 26, 42, 71, 80], "recommend": [0, 2, 6, 10, 14, 18, 26, 27, 38, 42, 44, 52, 61, 66, 71, 72, 76, 85, 90, 105, 114, 116, 118, 120, 127, 132], "o": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 61, 68, 76], "adaround_weight": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 49, 57, 58, 71, 73, 114], "adaroundparamet": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 49, 57, 58, 71, 73], "satisfi": [0, 27, 80, 105, 115, 117], "requir": [0, 2, 3, 4, 5, 14, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 36, 37, 38, 39, 42, 43, 44, 46, 48, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 91, 92, 105, 115, 116, 118, 120, 125, 127, 128, 131, 133], "deriv": [0, 55, 96, 97, 99, 100, 112, 113], "form": [0, 17, 22, 32, 33, 42, 94, 121], "arrai": [0, 8, 105], "__init__": [0, 14, 27, 41, 42, 58, 72, 73, 76, 79, 80, 81, 94, 95, 112, 115], "self": [0, 14, 27, 41, 42, 58, 61, 72, 73, 76, 79, 80, 81, 104, 110, 115], "_torch_data_load": 0, "_iter": 0, "__iter__": 0, "__next__": 0, "next": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 43, 65, 71, 83, 84, 87, 91, 115, 132], "__len__": [0, 27, 73, 85], "len": [0, 13, 27, 38, 49, 71, 73, 80], "forward_fn": [0, 8, 12, 28, 48, 71, 74], "makedir": [0, 3, 4, 5, 8, 9, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31], "exist_ok": [0, 3, 4, 5, 8, 9, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31], "ada_model": [0, 6, 10, 18, 26], "apply_adaround": [0, 6, 10, 18, 26, 36, 48, 57, 71], "filename_prefix": [0, 6, 8, 9, 10, 12, 18, 19, 20, 21, 26, 28, 29, 30, 31, 36, 46, 57, 68, 71, 83, 87], "default_quant_schem": [0, 6, 10, 18, 26, 36, 57, 58, 71], "after": [0, 1, 3, 4, 6, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 36, 37, 43, 49, 57, 59, 60, 62, 65, 71, 73, 74, 80, 81, 84, 85, 87, 89, 94, 95, 112, 115, 116, 117, 118, 120, 125, 127, 130, 132, 137, 138], "again": [0, 1, 3, 4, 5, 6, 9, 10, 18, 19, 23, 24, 25, 26, 29, 129, 130, 137], "note": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 31, 42, 43, 44, 46, 49, 50, 51, 52, 54, 58, 61, 65, 66, 68, 73, 76, 77, 82, 83, 84, 85, 87, 91, 92, 105, 114, 115, 119, 120, 122, 123, 125, 126, 127, 129], "two": [0, 1, 3, 4, 5, 6, 9, 10, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 42, 43, 60, 61, 65, 76, 80, 81, 84, 90, 105, 112, 114, 115, 122, 123, 125, 127, 128, 129, 130, 133, 136, 137, 138, 139], "thing": [0, 6, 10, 18, 26, 127], "understand": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 114, 127, 131, 137, 138], "biwidth": [0, 6, 10, 18, 26], "must": [0, 6, 10, 12, 13, 15, 16, 17, 18, 22, 26, 32, 42, 61, 71, 95, 105, 112, 118, 123, 124, 129, 131, 140], "bitwidth": [0, 6, 10, 18, 26, 44, 46, 55, 57, 58, 66, 68, 71, 73, 75, 83, 85, 87, 96, 97, 99, 100, 102, 104, 105, 112, 113, 114, 115, 118, 127, 132, 133], "wa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40, 51, 55, 61, 63, 71, 76, 78, 83, 104, 119, 125, 131], "freez": [0, 6, 10, 18, 26, 36, 57, 71, 83, 114, 116], "set_and_freeze_param_encod": [0, 6, 10, 18, 26, 36, 48, 57, 71], "been": [0, 3, 4, 5, 6, 7, 10, 11, 12, 13, 18, 19, 23, 24, 25, 26, 27, 42, 71, 81, 89, 95, 104, 105, 127, 130, 133, 134, 140], "down": [0, 1, 6, 9, 10, 18, 19, 26, 29, 55, 71], "base": [0, 6, 7, 8, 10, 11, 12, 18, 26, 27, 28, 36, 37, 48, 54, 57, 60, 61, 68, 71, 83, 85, 87, 91, 94, 95, 96, 97, 99, 100, 102, 105, 110, 112, 113, 114, 119, 120, 127], "initi": [0, 6, 10, 16, 17, 18, 20, 21, 22, 26, 30, 31, 32, 36, 57, 60, 68, 71, 87, 94, 95, 96, 97, 102, 112, 113, 116, 130, 132, 133], "intern": [0, 6, 7, 10, 11, 13, 14, 18, 26, 42, 66, 68, 71, 73, 87, 114, 125, 127, 128, 131], "NOT": [0, 6, 10, 18, 26, 71, 118, 140], "frozen": [0, 6, 10, 18, 26, 71], "alter": [0, 6, 10, 18, 26, 71], "reflect": [0, 6, 26, 127, 133], "encoding_path": [0, 6, 7, 10, 11, 18, 26, 27, 36, 49, 57, 58, 71, 73], "join": [0, 6, 10, 15, 16, 18, 26, 27, 61, 68, 76, 88], "newli": [0, 6, 26, 134], "updat": [0, 3, 4, 5, 6, 8, 9, 10, 14, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 55, 59, 60, 62, 64, 65, 71, 72, 87, 88, 92, 113, 114, 121, 127, 128, 130, 133, 135], "depend": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 61, 80, 91, 92, 104, 114, 120, 121, 122, 127, 131, 135], "observ": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 89, 94, 95, 106, 109, 112, 113, 115, 122, 125, 127, 128, 129, 130, 133], "slight": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31], "gain": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31, 119, 125], "serv": [0, 6, 26, 44, 49, 52, 58, 73, 85, 112, 137], "try": [0, 3, 4, 5, 6, 7, 9, 10, 11, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31, 38, 61, 72, 76, 88, 117, 119, 122, 125, 127, 132], "workflow": [0, 6, 26, 111, 115, 120, 123], "against": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 44, 52, 58, 66, 85, 89], "choic": [0, 1, 3, 4, 5, 6, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 44, 55, 125, 133], "plai": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31], "best": [0, 3, 4, 5, 6, 7, 9, 10, 11, 18, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 58, 73, 117, 120, 125, 127, 133], "step": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 43, 49, 59, 64, 65, 71, 73, 74, 80, 83, 85, 87, 99, 100, 111, 115, 116, 117, 118, 119, 120, 122, 125, 127, 128, 130, 132, 133], "would": [0, 3, 4, 5, 6, 8, 9, 10, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 39, 42, 62, 71, 77, 87, 105, 114, 120, 125, 131, 135, 137], "take": [0, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 43, 58, 61, 71, 76, 84, 87, 95, 105, 115, 123, 125, 127, 128, 130, 131, 132, 140], "without": [0, 6, 7, 9, 10, 11, 13, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 46, 68, 71, 83, 87, 95, 102, 104, 105, 112, 117, 127, 130, 133, 140], "resnet18_after_adaround": [0, 6, 26], "illustr": [0, 6, 10, 18, 26, 68, 87, 116, 122, 127, 136, 139], "invok": [0, 6, 10, 18, 26, 33, 36, 38, 43, 45, 57, 60, 61, 62, 65, 71, 76, 85, 86, 87, 94, 95, 112, 125, 127, 137, 138], "As": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 79, 87, 105, 117, 119, 120, 122, 125, 127, 128, 129, 133, 136, 139], "indic": [0, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 27, 38, 43, 55, 60, 61, 64, 65, 73, 76, 109, 112, 120, 140], "make": [0, 6, 8, 10, 12, 13, 14, 18, 26, 28, 33, 37, 41, 43, 45, 59, 60, 64, 65, 79, 82, 86, 105, 112, 122, 125, 126, 127, 133, 134], "faster": [0, 3, 4, 5, 6, 7, 10, 11, 12, 18, 23, 24, 25, 26, 27, 110, 116, 123, 130], "hope": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "addit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 59, 87, 95, 105, 117, 127, 130, 131, 135], "resourc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "doc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 80, 83, 129, 131, 137], "know": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "qat": [0, 1, 6, 9, 10, 13, 18, 19, 26, 29, 37, 54, 57, 59, 68, 71, 74, 82, 86, 115, 116, 118, 121, 123, 127, 132, 133, 135], "showcas": [1, 9, 17, 19, 22, 29, 32], "appli": [1, 3, 4, 5, 8, 9, 12, 13, 19, 23, 24, 25, 27, 28, 29, 36, 38, 39, 43, 45, 48, 57, 58, 61, 62, 65, 71, 73, 75, 76, 81, 84, 86, 89, 94, 95, 96, 97, 99, 100, 105, 112, 113, 115, 116, 117, 118, 121, 122, 125, 127, 128, 130, 131, 132, 133, 134, 135, 137, 138], "aim": [1, 3, 4, 5, 8, 9, 12, 19, 23, 24, 25, 28, 29, 37], "improv": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 34, 68, 71, 87, 105, 114, 115, 120, 127, 130, 132, 138], "help": [1, 3, 4, 5, 6, 7, 9, 17, 19, 20, 21, 22, 29, 32, 62, 65, 72, 81, 83, 87, 89, 116, 122, 125, 127, 128, 129, 132, 137, 138], "recov": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 111, 123, 132, 133], "sensit": [1, 9, 19, 29, 44, 45, 52, 53, 66, 67, 85, 86, 122, 127, 129, 132, 133, 135], "oppos": [1, 9, 19, 29, 127, 131], "about": [1, 8, 9, 14, 19, 28, 29, 36, 38, 39, 43, 46, 48, 49, 50, 54, 55, 57, 58, 60, 61, 62, 65, 68, 71, 73, 75, 76, 77, 84, 85, 87, 104, 115, 134], "free": [1, 3, 4, 5, 8, 9, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 87, 91, 127, 128, 130], "bia": [1, 8, 12, 19, 39, 43, 50, 62, 65, 67, 72, 77, 80, 81, 83, 84, 86, 94, 95, 102, 114, 115, 116, 119, 127, 128, 131, 132, 135], "correct": [1, 10, 18, 19, 27, 32, 43, 65, 67, 71, 73, 84, 86, 92, 115, 116, 118, 127, 128, 132], "paper": [1, 9, 19, 29, 128], "iccv": [1, 9, 19, 29, 125, 128], "2019": [1, 9, 19, 29, 128], "arxiv": [1, 9, 19, 29, 128], "ab": [1, 9, 19, 29, 112, 128], "1906": [1, 9, 19, 29, 128], "04721": [1, 9, 19, 29, 128], "norm": [1, 9, 19, 29, 43, 59, 65, 72, 74, 84, 112, 116, 118, 127, 128, 129], "conv": [1, 3, 4, 5, 6, 7, 8, 9, 12, 19, 20, 21, 22, 29, 33, 37, 43, 57, 59, 60, 61, 65, 71, 74, 75, 80, 84, 89, 105, 124, 131, 135, 136, 139, 140], "immedi": [1, 9, 19, 27, 29], "consecut": [1, 9, 19, 29, 43, 65, 83, 84, 127, 128], "correspond": [1, 3, 4, 5, 6, 7, 8, 9, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 33, 36, 37, 40, 43, 57, 59, 60, 63, 65, 71, 74, 78, 83, 84, 85, 87, 90, 91, 92, 105, 112, 119, 122, 127, 129, 140], "high": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 39, 43, 50, 62, 65, 77, 84, 111, 114, 116, 118, 120, 122, 123, 128, 132, 134, 135, 138], "perhap": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "sai": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 80, 125], "upto": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "trainingmod": [1, 2], "preserv": [1, 2, 3, 4, 5, 23, 24, 25, 80], "current": [1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 42, 46, 61, 65, 66, 68, 72, 76, 81, 82, 95, 119, 123, 124, 125, 126, 131, 136, 139], "comput": [1, 3, 4, 5, 7, 10, 12, 13, 17, 18, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 38, 40, 44, 46, 51, 52, 54, 55, 57, 58, 61, 63, 66, 68, 71, 73, 76, 78, 82, 83, 85, 87, 90, 92, 94, 95, 102, 105, 109, 110, 115, 116, 125, 126, 127, 128, 129, 133, 137, 140], "And": [1, 2, 9, 10, 15, 16, 18, 19, 20, 21, 29, 30, 31, 43, 65, 84, 125], "default_output_bw": [1, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 57, 58, 66, 68, 71, 85, 87, 115], "encod": [1, 3, 4, 5, 7, 10, 11, 12, 13, 18, 26, 27, 29, 30, 31, 36, 40, 44, 46, 48, 51, 52, 54, 57, 58, 59, 63, 66, 68, 71, 73, 74, 78, 82, 83, 85, 87, 94, 95, 96, 97, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 118, 127, 129, 130, 134, 135], "5": [1, 3, 4, 5, 6, 9, 13, 18, 20, 21, 23, 24, 25, 29, 30, 31, 33, 38, 48, 49, 59, 61, 73, 74, 76, 80, 83, 87, 88, 90, 96, 97, 99, 100, 102, 105, 112, 113, 114, 120, 130, 132], "suffici": [1, 9, 19, 29, 127, 129, 130, 133], "rounding_mod": [1, 9, 10, 13, 15, 16, 18, 19, 29, 44, 46, 54, 66, 68, 73, 87], "round": [1, 9, 18, 19, 29, 36, 38, 44, 45, 46, 53, 57, 58, 60, 61, 66, 67, 68, 73, 75, 76, 86, 87, 111, 112, 116, 121, 127, 129, 133], "mode": [1, 3, 4, 5, 6, 7, 9, 19, 20, 21, 22, 23, 24, 25, 29, 33, 38, 39, 46, 50, 58, 61, 62, 68, 73, 75, 76, 77, 80, 82, 84, 87, 88, 110, 113, 126, 127, 131], "possibl": [1, 7, 9, 11, 14, 19, 27, 29, 41, 42, 46, 68, 73, 79, 81, 87, 105, 115, 129, 131, 132], "stochast": [1, 9, 19, 29, 44, 46, 58, 60, 66, 68, 75, 87], "bias": [1, 9, 19, 29, 127], "interestingli": [1, 9, 19, 29], "procedur": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 122, 125], "cl": [1, 9, 19, 29, 43, 62, 65, 84, 95, 135], "skip": [1, 9, 19, 29, 33, 39, 62, 71, 73, 75, 91, 119], "hba": [1, 9, 19, 29], "absorpt": [1, 9, 19, 29], "cross_layer_equ": [1, 9, 19, 29, 39, 43, 50, 60, 62, 65, 77, 84, 89, 114, 126], "equalize_model": [1, 9, 19, 29, 39, 50, 60, 62, 77, 89, 114, 126], "add": [2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 31, 41, 42, 46, 55, 66, 68, 79, 80, 81, 83, 87, 91, 95, 112, 115, 131, 133, 135, 137, 138, 140], "train": [2, 3, 14, 27, 33, 34, 36, 37, 38, 42, 44, 45, 52, 53, 54, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 71, 73, 74, 76, 82, 85, 86, 90, 111, 116, 117, 118, 121, 123, 125, 132, 133, 135], "ml": [2, 13, 15, 16, 20, 21, 30, 31, 34, 87, 125, 127, 128, 137, 138], "order": [2, 3, 4, 5, 8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 41, 43, 45, 64, 65, 79, 81, 84, 86, 87, 91, 92, 94, 105, 115, 118, 119, 120, 127, 130, 133, 138], "estim": [2, 45, 67, 86, 115, 127, 128], "deploi": [2, 111, 133], "acceler": [2, 13, 15, 16, 20, 21, 30, 31, 61, 76, 87, 90, 111, 123, 125], "awar": [2, 37, 45, 59, 68, 74, 82, 116, 118, 121, 123, 127, 132, 133], "adaround": [2, 49, 53, 58, 73, 111, 114, 117, 121, 127, 132, 134, 135], "cross": [2, 45, 53, 58, 60, 67, 73, 75, 82, 86, 89, 116, 117, 121, 126, 127, 128, 129, 138], "equal": [2, 14, 45, 53, 58, 60, 67, 73, 75, 82, 86, 89, 104, 105, 110, 112, 116, 117, 120, 121, 122, 126, 127, 128, 129, 138], "emploi": [2, 30, 31, 71, 87], "act": [2, 15, 16, 19, 85], "regular": [2, 3, 4, 5, 13, 23, 24, 25, 36, 46, 57, 68, 71, 87, 94, 95, 112, 116, 127, 133], "automat": [2, 27, 38, 43, 61, 65, 76, 84, 91, 92, 105, 120, 125, 127, 129, 135], "regist": [2, 94, 95, 112, 113], "oper": [2, 14, 38, 42, 60, 61, 65, 79, 80, 81, 94, 95, 112, 114, 115, 126, 127, 128, 131, 132], "quantizationsimul": 2, "exampl": [3, 13, 14, 27, 41, 72, 79, 81, 82, 83, 94, 95, 96, 97, 99, 100, 102, 104, 105, 112, 113, 115, 116, 120, 122, 123, 127, 129, 131, 133, 135, 140], "brief": [3, 4, 5, 23, 24, 25], "introduct": [3, 4, 5, 23, 24, 25], "guid": [3, 4, 5, 7, 9, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 38, 61, 76, 111, 114, 120, 121, 128, 132, 134, 135], "spatial": [3, 23, 33, 120, 121, 122, 124, 125, 135], "svd": [3, 23, 33, 120, 121, 122, 124, 125, 135], "decomposit": [3, 4, 5, 23, 24, 25, 61, 136, 139], "gener": [3, 4, 5, 9, 13, 15, 16, 23, 24, 25, 29, 34, 46, 55, 61, 68, 72, 83, 95, 96, 97, 99, 100, 105, 113, 115, 121, 125, 127, 129, 130, 131, 133], "layer": [3, 4, 5, 7, 13, 22, 23, 24, 25, 33, 36, 37, 38, 41, 42, 44, 45, 46, 52, 53, 57, 58, 59, 61, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 81, 82, 83, 85, 86, 87, 88, 89, 94, 95, 105, 112, 115, 116, 117, 118, 119, 120, 121, 124, 126, 127, 128, 129, 131, 132, 133, 135, 136, 137, 138, 139, 140], "conv2d": [3, 4, 5, 12, 13, 18, 23, 24, 25, 33, 42, 43, 55, 60, 61, 65, 69, 72, 80, 81, 84, 105, 112, 114, 115, 119, 125, 135, 140], "decompos": [3, 4, 5, 23, 24, 25, 125, 136, 139], "singl": [3, 4, 5, 17, 18, 22, 23, 24, 25, 32, 33, 36, 44, 52, 57, 61, 66, 76, 80, 82, 85, 105, 116, 128], "split": [3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 58, 105, 110, 112], "flattend": [3, 4, 5, 23, 24, 25], "2d": [3, 4, 5, 18, 23, 24, 25, 105], "matrix": [3, 4, 5, 18, 23, 24, 25, 119], "singular": [3, 4, 5, 23, 24, 25, 61, 136, 139], "discard": [3, 4, 5, 23, 24, 25, 52, 66, 85], "least": [3, 4, 5, 23, 24, 25, 116, 119], "signific": [3, 4, 5, 23, 24, 25, 105, 132], "diagon": [3, 4, 5, 23, 24, 25], "matric": [3, 4, 5, 23, 24, 25], "combin": [3, 4, 5, 7, 11, 23, 24, 25, 27, 75, 80, 105, 117, 120, 125, 127, 128], "back": [3, 4, 5, 23, 24, 25, 33, 71, 82, 87, 95, 104, 115, 131], "separ": [3, 4, 5, 20, 21, 23, 24, 25, 30, 31, 42, 43, 46, 57, 68, 71, 80, 81, 84, 87, 114, 118, 129, 132, 135], "magnitud": [3, 4, 5, 23, 24, 25, 119], "feed": [3, 4, 5, 13, 14, 23, 24, 25, 42, 133], "dimens": [3, 4, 5, 23, 24, 25, 105, 112, 125, 132, 136, 139], "reconstruct": [3, 4, 5, 23, 24, 25, 36, 57, 61, 71], "minim": [3, 4, 5, 15, 16, 20, 21, 23, 24, 25, 30, 31, 36, 57, 61, 68, 71, 87, 111, 123, 125, 127, 133], "distanc": [3, 4, 5, 23, 24, 25], "both": [3, 4, 5, 16, 19, 20, 21, 23, 24, 25, 30, 31, 42, 55, 71, 80, 85, 87, 90, 99, 100, 105, 111, 112, 114, 127, 128, 130, 131, 132, 133, 134, 136, 140], "structur": [3, 4, 5, 17, 23, 24, 25, 32, 55, 60, 80, 94, 95, 112, 125], "mac": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88, 120, 125, 136, 139], "memori": [3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 38, 61, 76, 83, 110, 120, 125, 136, 139, 140], "either": [3, 4, 5, 6, 10, 18, 19, 23, 24, 25, 26, 34, 38, 43, 60, 61, 71, 76, 79, 83, 105, 123, 133], "epoch": [3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 46, 59, 61, 74, 76, 87, 115, 123, 125, 127, 130], "close": [3, 4, 5, 23, 24, 25, 57, 60, 62, 65, 68, 69, 119, 120, 133], "folder": [3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 24, 25, 30, 31, 32, 64, 89, 129], "pipelin": [3, 13, 40, 51, 59, 63, 68, 73, 74, 78, 87, 127, 130, 132, 133], "num_comp_ratio_candid": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "num_eval_iter": [3, 4, 5, 23, 24, 25], "convert": [3, 4, 5, 6, 7, 8, 9, 19, 20, 21, 22, 33, 41, 42, 43, 65, 80, 104, 115, 117, 127, 138], "tfrecord": [3, 4, 5, 6, 7, 8, 9, 15, 16, 20, 21, 22, 26, 61, 66, 68], "contain": [3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 24, 25, 32, 43, 55, 61, 63, 65, 72, 76, 80, 81, 85, 90, 94, 95, 104, 112, 115, 127, 129, 130, 131, 133], "start": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 33, 36, 38, 42, 57, 58, 59, 61, 62, 63, 65, 66, 68, 71, 76, 80, 81, 87, 99, 100, 115, 116, 121, 122, 125, 131, 133], "label": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 20, 21, 22, 27, 38, 44, 52, 58, 66, 68, 71, 73, 85, 87, 129, 130], "tfrecords_dir": [3, 4, 5, 6, 8, 9, 20, 21, 22], "dir": [3, 4, 5, 7, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 92], "disabl": [3, 4, 5, 6, 7, 9, 20, 21, 23, 25, 33, 44, 66, 83, 85, 87, 112, 114, 122, 125, 129, 131, 133], "log": [3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 20, 21, 22, 36, 57, 81, 112, 129], "info": [3, 4, 5, 6, 7, 9, 20, 21, 22, 43, 60, 65, 72, 75, 81, 84, 115, 135], "level": [3, 4, 5, 6, 7, 9, 13, 20, 21, 22, 39, 60, 62, 77, 111, 114, 118, 120, 122, 123, 127, 132, 134, 137], "eager": [3, 4, 5, 6, 7, 9, 20, 21, 22], "verbos": [3, 4, 5, 6, 7, 9, 20, 21, 22], "displai": [3, 4, 5, 6, 7, 9, 13, 20, 21, 22, 121, 129, 137, 138], "erorr": [3, 4, 5, 9, 20, 21], "tensorflow": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 32, 34, 36, 38, 39, 40, 41, 43, 44, 46, 90, 91, 118, 121, 123, 124, 131, 133, 135], "messag": [3, 4, 5, 6, 7, 9, 20, 21, 22, 61], "error": [3, 4, 5, 6, 7, 8, 9, 11, 20, 21, 22, 42, 61, 68, 73, 80, 117, 127, 130, 132, 133], "critic": [3, 4, 5, 6, 7, 9, 20, 21, 22], "tf_cpp_min_log_level": [3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 20, 21, 22], "todo": [3, 4, 5, 9, 20, 21], "compat": [3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 20, 21, 22, 33, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 79, 90, 105, 115], "v1": [3, 4, 5, 6, 7, 8, 9, 15, 16, 20, 21, 22, 33, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 114, 134], "abhijit": [3, 4], "disable_eager_execut": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 58], "set_verbos": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22], "type": [3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 17, 20, 21, 22, 23, 24, 25, 27, 30, 31, 33, 36, 37, 38, 39, 43, 44, 46, 52, 57, 58, 59, 61, 62, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 85, 87, 89, 94, 95, 96, 97, 104, 105, 110, 112, 113, 114, 127, 129, 131, 133, 137], "list": [3, 4, 5, 6, 8, 9, 12, 14, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 42, 43, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 71, 74, 75, 76, 77, 78, 80, 84, 85, 87, 89, 92, 99, 100, 105, 110, 112, 113, 114, 122, 124, 126, 131], "image_net_train": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 29, 30, 31], "imagenettrain": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 29, 30, 31], "format_bgr": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "int": [3, 4, 5, 6, 7, 8, 9, 11, 12, 17, 20, 21, 22, 23, 24, 25, 27, 36, 37, 38, 44, 46, 49, 55, 57, 58, 59, 60, 61, 66, 68, 71, 73, 74, 75, 76, 83, 85, 87, 96, 97, 99, 100, 102, 105, 110, 113, 114], "bool": [3, 4, 5, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 43, 46, 60, 61, 64, 65, 66, 68, 73, 75, 76, 80, 83, 84, 87, 96, 97, 99, 100, 105, 110, 113], "maximum": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 32, 36, 57, 58, 71, 87, 99, 100, 102, 110, 112], "training_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "keras_learning_phas": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "data_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66, 68], "input_1": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 60, 61, 62, 65, 66], "validation_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "update_ops_nam": [3, 4, 5, 6, 8, 9, 20, 21, 59], "str": [3, 4, 5, 6, 8, 9, 14, 20, 21, 33, 38, 40, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 73, 75, 78, 79, 80, 83, 85, 87, 89], "learning_r": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 30, 31, 59, 74, 87], "decay_step": [3, 4, 5, 6, 8, 9, 20, 21, 59], "mostli": [3, 4, 5, 6, 8, 9, 20, 21, 25], "move": [3, 4, 5, 6, 8, 9, 20, 21, 82, 134], "averag": [3, 4, 5, 6, 8, 9, 20, 21], "graphkei": [3, 4, 5, 6, 8, 9, 20, 21, 22], "update_op": [3, 4, 5, 6, 8, 9, 20, 21, 22], "alwai": [3, 4, 5, 6, 8, 9, 20, 21, 61, 90, 122], "dure": [3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 42, 57, 61, 65, 68, 71, 76, 87, 88, 94, 112, 115, 116, 123, 125, 127, 130, 131, 133, 137, 138], "rate": [3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 42, 87, 125, 130], "adjust": [3, 4, 5, 6, 7, 8, 9, 20, 21, 29, 36, 57, 58, 71, 72, 87, 105, 118, 119, 120, 127, 128, 132], "decai": [3, 4, 5, 6, 8, 9, 20, 21, 125], "trainer": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 30, 31, 38, 61, 76, 121], "num_epoch": [3, 4, 5, 6, 8, 9, 20, 21], "resnet50": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 33, 38, 39, 43, 44, 46, 58, 59, 60, 62, 65, 69], "kera": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 34, 42, 56, 58, 59, 60, 61, 62, 64, 65, 69, 118, 121, 123, 127, 131, 133, 135], "covert": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22], "clear_sess": [3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 33, 36, 59, 60, 62, 65, 69], "releas": [3, 4, 5, 6, 7, 9, 20, 21, 22, 121, 126, 134], "global": [3, 4, 5, 6, 7, 9, 20, 21, 22, 132], "clutter": [3, 4, 5, 6, 7, 9, 20, 21, 22], "old": [3, 4, 5, 6, 7, 9, 20, 21, 22], "By": [3, 4, 5, 6, 8, 9, 12, 20, 21, 22, 26, 28, 29, 30, 31, 37, 38, 42, 58, 61, 76, 83, 112, 125, 131, 133], "train_op": [3, 4, 5, 6, 9, 20, 21, 22], "fold": [3, 4, 5, 7, 22, 37, 39, 43, 50, 58, 59, 62, 65, 67, 72, 73, 74, 77, 84, 86, 89, 112, 116, 117, 118, 127, 128, 129, 135], "applic": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 33, 38, 39, 43, 44, 46, 55, 58, 59, 60, 61, 62, 65, 69, 84, 122, 126], "backend": [3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 33, 36, 58, 59, 60, 62, 65, 69], "allow": [3, 4, 5, 6, 7, 9, 11, 13, 20, 21, 22, 27, 38, 40, 42, 45, 46, 51, 53, 55, 58, 61, 63, 67, 76, 78, 79, 80, 86, 87, 104, 105, 112, 117, 123, 125, 127, 129, 130, 131, 132, 133, 134, 135, 137], "easili": [3, 4, 5, 6, 7, 9, 20, 21, 22, 61, 76, 134], "read": [3, 4, 5, 6, 7, 9, 20, 21, 22, 129], "eventu": [3, 4, 5, 6, 7, 9, 20, 21, 22], "aimet_tensorflow": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 90, 92], "update_keras_bn_ops_trainable_flag": [3, 4, 5, 6, 7, 9, 20, 21, 22, 58, 64], "load_save_path": [3, 4, 5, 6, 7, 9, 20, 21, 22, 58, 64], "trainabl": [3, 4, 5, 6, 9, 16, 20, 21, 22, 31, 64, 68, 127], "add_image_net_computational_nodes_in_graph": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "an": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 42, 44, 46, 52, 54, 55, 57, 58, 59, 60, 61, 62, 66, 68, 71, 73, 74, 75, 76, 77, 79, 80, 81, 85, 87, 90, 94, 95, 104, 105, 111, 112, 113, 114, 115, 116, 117, 119, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 134, 138, 140], "softmax": [3, 4, 5, 6, 7, 9, 13, 14, 20, 21, 22, 33, 42, 57, 60, 61, 62, 65, 112, 115], "add_computational_nodes_in_graph": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "get_sess": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 58, 59, 60, 62, 65, 69], "creat": [3, 4, 5, 7, 11, 13, 17, 22, 32, 33, 36, 38, 42, 43, 44, 46, 49, 51, 52, 57, 58, 59, 61, 64, 65, 66, 68, 71, 73, 74, 76, 80, 82, 83, 84, 85, 87, 89, 94, 95, 111, 112, 115, 116, 118, 125, 126, 127, 130, 133], "within": [3, 4, 5, 6, 7, 9, 13, 21, 33, 95, 104, 112, 120, 129, 133], "images_class": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "identifi": [3, 4, 5, 6, 7, 9, 20, 21, 22, 75, 81, 91, 92, 105, 121, 129, 132, 135, 140], "input_op_nam": [3, 4, 5, 6, 7, 8, 9, 20, 21, 33, 38, 58, 59, 60, 61, 62, 65], "output_op_nam": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 38, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68], "starting_op_nam": [3, 4, 5, 6, 7, 9, 20, 21, 22, 57, 58, 59, 63, 68], "append": [3, 4, 5, 8, 43, 65, 76], "test": [3, 4, 5, 6, 7, 9, 12, 13, 14, 20, 21, 22, 44, 52, 59, 66, 68, 72, 74, 85, 92], "is_gpu_avail": [3, 4, 5, 6, 7, 9, 20, 21, 22], "cuda_onli": [3, 4, 5, 6, 7, 9, 20, 21, 22], "": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 39, 41, 42, 43, 44, 46, 49, 52, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 68, 71, 74, 75, 76, 80, 84, 85, 87, 89, 92, 94, 95, 105, 111, 112, 113, 115, 120, 124, 125, 127, 128, 129, 130, 132, 133, 137, 138, 140], "determin": [3, 4, 5, 8, 13, 23, 24, 25, 27, 36, 38, 44, 46, 52, 55, 57, 61, 62, 65, 66, 68, 71, 76, 85, 87, 102, 105, 112, 115, 117, 120, 125, 127, 128, 129], "fp32": [3, 4, 5, 12, 13, 22, 23, 24, 25, 32, 40, 44, 51, 63, 66, 78, 85, 116, 123, 128, 129, 130, 132, 133], "defin": [3, 4, 5, 9, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 41, 42, 44, 45, 49, 52, 55, 57, 58, 61, 64, 66, 71, 73, 76, 79, 80, 81, 85, 86, 87, 94, 105, 112, 115, 126, 127, 129, 131, 133], "target_comp_ratio": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "desir": [3, 4, 5, 23, 24, 25, 38, 46, 52, 61, 68, 76, 85, 87, 91, 105, 115, 120, 125, 127, 132], "compess": [3, 4, 5], "ratio": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88, 119, 120, 137], "denot": [3, 4, 5, 23, 24, 25, 38, 117], "20": [3, 4, 5, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 36, 38, 42, 55, 57, 61, 71, 87, 90, 94, 95, 116, 130], "80": [3, 4, 5, 38, 96, 113], "pre": [3, 4, 5, 15, 16, 40, 51, 63, 78, 90, 91, 92, 121, 123, 128], "9": [3, 4, 5, 23, 25, 26, 29, 30, 31, 32, 38, 61, 71, 80, 83, 87, 92, 99, 100, 104, 132], "10": [3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 36, 38, 41, 42, 43, 46, 57, 60, 61, 68, 74, 76, 80, 81, 83, 87, 88, 90, 91, 92, 94, 95, 96, 97, 99, 104, 105, 112, 113, 115, 122, 125, 130], "part": [3, 4, 5, 23, 24, 25, 42, 44, 49, 52, 58, 66, 73, 82, 85, 105, 125, 127, 128, 129], "variou": [3, 4, 5, 7, 11, 17, 22, 23, 24, 25, 27, 32, 38, 61, 76, 117, 120, 125, 127, 132, 133, 135, 138], "measur": [3, 4, 5, 23, 24, 25, 27, 38, 61, 76, 85], "tri": [3, 4, 5, 23, 24, 25, 120, 127], "33": [3, 4, 5, 23, 24, 25, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "66": [3, 4, 5, 23, 24, 25, 96, 113, 120], "00": [3, 4, 5, 23, 24, 25, 99, 100], "higher": [3, 4, 5, 23, 24, 25, 61, 71, 76, 105, 110, 118, 122, 130, 132], "candid": [3, 4, 5, 23, 24, 25, 38, 39, 60, 61, 62, 76, 122, 125], "granular": [3, 4, 5, 13, 23, 24, 25, 38, 61, 76, 105, 125, 132, 133, 134, 138], "time": [3, 4, 5, 7, 11, 17, 22, 23, 24, 25, 27, 32, 38, 43, 55, 61, 65, 76, 80, 81, 105, 115, 117, 125, 126, 130, 137], "taken": [3, 4, 5, 23, 24, 25, 42, 140], "complet": [3, 4, 5, 7, 11, 22, 23, 24, 25, 27, 38, 115, 118, 132], "modules_to_ignor": [3, 4, 5, 23, 24, 25, 38, 61, 76, 85, 88, 124], "interact": [3, 4, 5, 23, 24, 25, 114], "too": [3, 4, 5, 23, 24, 25, 105], "choss": [3, 4, 5, 23, 24, 25], "auto": [3, 4, 5, 23, 24, 25, 34, 38, 39, 43, 50, 55, 61, 62, 65, 76, 77, 84, 88], "analysi": [3, 4, 5, 13, 23, 24, 25, 27, 38, 44, 52, 61, 66, 76, 85, 125, 132], "much": [3, 4, 5, 7, 11, 16, 21, 23, 24, 25, 31, 140], "altern": [3, 4, 5, 23, 24, 25, 92, 105, 125], "manual": [3, 4, 5, 7, 11, 23, 24, 25, 33, 38, 55, 61, 76, 84, 96, 97, 113, 114, 117, 125], "retriev": [3, 4, 5, 23, 25, 95], "those": [3, 4, 5, 14, 16, 21, 23, 24, 25, 31, 52, 85, 125], "num_reconstruction_sampl": [3, 4, 5, 23, 25, 61, 76], "last": [3, 4, 5, 122, 124, 132], "stage": [3, 4, 5, 117], "map": [3, 4, 5, 7, 10, 11, 12, 14, 15, 16, 18, 22, 44, 46, 55, 58, 65, 81, 83, 94, 95, 99, 100, 104, 105, 112, 129, 131], "linear": [3, 4, 5, 37, 43, 57, 59, 60, 65, 71, 74, 80, 81, 83, 84, 89, 94, 95, 105, 112, 114, 115, 118, 119], "regress": [3, 4, 5, 119], "attempt": [3, 4, 5, 119, 127, 128], "done": [3, 4, 5, 8, 14, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 41, 91, 96, 97, 113, 119, 125, 131, 133, 140], "random": [3, 4, 5, 14, 27, 33, 36, 42, 44, 46, 49, 52, 54, 57, 58, 61, 66, 73, 119, 129], "ridicul": [3, 4, 5, 23, 25], "enabl": [3, 4, 5, 16, 18, 21, 23, 25, 31, 34, 38, 44, 59, 61, 66, 68, 74, 76, 83, 85, 90, 91, 105, 111, 114, 118, 123, 127, 129, 131, 133, 134, 135], "allow_custom_downsample_op": [3, 4, 5, 23, 25, 61, 76], "flag": [3, 4, 5, 23, 25, 43, 60, 64, 65, 73, 80, 87, 113, 114], "downsampl": [3, 4, 5, 23, 25], "consid": [3, 4, 5, 13, 23, 25, 65, 72, 116, 122, 127, 132], "bandwidth": [3, 4, 5, 23, 25, 120], "overhead": [3, 4, 5, 23, 25], "trade": [3, 4, 5, 23, 25, 36, 57, 71], "off": [3, 4, 5, 23, 25, 36, 46, 57, 68, 71, 87, 127, 128, 131], "suggest": [3, 4, 5, 23, 25, 46, 87, 122, 125, 128], "eval_callback": [3, 4, 5, 7, 11, 12, 17, 22, 23, 24, 25, 27, 32, 33, 38, 44, 49, 52, 58, 61, 66, 73, 76, 85, 88], "function_nam": [3, 4, 5, 23, 24, 25], "eval_iter": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "batch": [3, 4, 5, 7, 8, 11, 12, 22, 23, 24, 25, 28, 36, 37, 38, 40, 43, 44, 52, 54, 57, 58, 59, 60, 61, 63, 65, 66, 68, 71, 72, 74, 78, 84, 85, 87, 116, 118, 127, 128, 129], "choos": [3, 4, 5, 23, 24, 25, 66, 68, 87, 89, 105, 119, 120, 125], "enough": [3, 4, 5, 23, 24, 25, 72], "trust": [3, 4, 5, 23, 24, 25], "callback": [3, 4, 5, 13, 15, 16, 17, 22, 23, 24, 25, 32, 38, 44, 46, 49, 52, 58, 61, 66, 68, 73, 76, 85, 87, 129, 133], "invoc": [3, 4, 5, 23, 24, 25], "compress_schem": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "cost_metr": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "actual": [3, 4, 5, 8, 9, 12, 14, 20, 21, 28, 30, 31, 40, 44, 49, 51, 52, 58, 63, 66, 71, 73, 78, 82, 85, 87, 105, 120, 127], "greedi": [3, 4, 5, 125, 137], "select": [3, 4, 5, 36, 57, 60, 71, 87, 89, 90, 91, 92, 117, 120, 129, 133, 137, 140], "among": [3, 4, 5, 71], "reach": [3, 4, 5, 7, 11, 27, 117, 120], "previou": [3, 4, 5, 9, 29, 38, 43, 61, 76, 84, 115, 120, 122, 132], "rule": [3, 4, 5, 46, 66, 68, 105, 131], "thumb": [3, 4, 5], "found": [3, 4, 5, 14, 33, 43, 84, 105, 114, 130, 133, 134], "compressionschem": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "costmetr": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "greedyselectionparamet": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "channelpruningparamet": [3, 5, 23, 25, 61, 76], "decim": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "greedy_param": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "get_operation_by_nam": [3, 4, 5, 6, 8, 9, 20, 21, 22, 33, 60, 61, 65, 68, 69], "conv1_conv": [3, 4, 5, 69], "auto_param": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "automodeparam": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88], "greedy_select_param": [3, 4, 5, 23, 24, 25, 38, 61, 76], "data_set": [3, 5, 6, 9, 10, 18, 36, 57, 60, 61], "channel_prun": [3, 5, 23, 25, 38, 61, 76], "modelcompressor": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88], "compress_model": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 88, 137], "relev": [3, 4, 5, 23, 24, 25], "our": [3, 4, 5, 8, 9, 12, 13, 15, 16, 19, 20, 23, 24, 25, 28, 37, 52, 83, 85, 90, 92, 115, 122, 132, 133], "new": [3, 5, 6, 9, 10, 14, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 32, 41, 42, 43, 55, 62, 65, 71, 79, 80, 83, 87, 91, 96, 97, 105, 111, 113, 114, 115, 127, 131, 135], "final": [3, 5, 8, 12, 13, 15, 16, 17, 22, 28, 32, 38, 42, 61, 76, 81, 88, 105, 119, 120, 122, 130, 132, 137], "compressed_sess": [3, 4, 33], "comp_stat": [3, 4, 23, 24], "working_dir": [3, 4, 5, 33, 61], "fell": [3, 4, 5, 23, 24, 25], "sharpli": [3, 4, 5, 23, 24, 25], "15": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 87, 99, 100, 125, 130], "job": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 87], "hyper": [3, 4, 5, 8, 9, 12, 13, 20, 21, 23, 24, 25, 28, 30, 31, 87, 116, 130], "search": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 34, 36, 57, 71, 87, 110, 122, 130, 131], "good": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 42, 83, 87, 115, 116], "end": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 36, 37, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 80, 81, 85, 87, 96, 97, 99, 100, 113, 115, 125], "drop": [3, 4, 5, 7, 8, 11, 12, 13, 15, 16, 20, 21, 23, 24, 25, 27, 28, 30, 31, 58, 61, 87, 112, 117, 120, 125, 128, 129, 130, 132, 133], "factor": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 43, 65, 84, 87, 105, 110, 120, 125, 128], "feel": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 87, 91], "fit": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 38, 46, 61, 76, 87, 122], "reduced_": [3, 4, 5], "accordingli": [3, 4, 5, 58, 92], "compr_graph_all_ops_nam": [3, 4, 5], "get_oper": [3, 4, 5], "update_ops_name_after_cp": [3, 4, 5], "op_nam": [3, 4, 5], "1e": [3, 4, 5, 13, 14, 20, 21, 42, 68, 72, 115, 130], "finetu": [3, 4, 5, 23, 24, 25], "ofcours": [3, 4, 5, 9, 20, 21, 23, 24, 25, 29, 30, 31], "graph_sav": [3, 4, 5, 6, 60, 65, 68], "save_model_to_meta": [3, 4, 5], "meta_path": [3, 4, 5], "finetuned_model": [3, 4, 5, 23, 24], "quantiz": [3, 4, 5, 7, 11, 14, 23, 24, 25, 27, 34, 35, 36, 37, 40, 42, 44, 47, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 66, 70, 71, 73, 74, 78, 79, 80, 82, 83, 85, 94, 95, 97, 98, 100, 102, 106, 108, 109, 110, 111, 116, 117, 118, 120, 121, 123, 125, 129, 134, 135, 137], "pytorch": [4, 5, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 72, 80, 81, 89, 90, 91, 94, 95, 112, 118, 121, 123, 129, 131, 133, 135], "repres": [4, 5, 17, 22, 23, 24, 25, 32, 36, 38, 42, 44, 46, 52, 55, 57, 58, 60, 61, 66, 68, 76, 79, 83, 85, 87, 102, 104, 112, 113, 115, 122, 127, 128, 129, 130, 133], "spatialsvdparamet": [4, 5, 24, 25, 33, 38, 61, 76, 88], "spatial_svd": [4, 5, 24, 25, 33, 38, 61, 76, 88], "comp_accuraci": 4, "ssvd_compressed_sess": 5, "ssvd_comp_stat": [5, 25], "ssvd_finetuned_model": [5, 25], "further": [5, 25, 34, 62, 65, 80, 96, 97, 99, 100, 104, 105, 113, 114, 115, 119, 123, 125, 127, 131], "similar": [5, 16, 21, 25, 31, 83, 105, 128, 130, 133], "out": [5, 7, 11, 14, 25, 42, 44, 45, 46, 52, 53, 66, 67, 68, 80, 83, 85, 86, 87, 96, 97, 99, 100, 102, 113, 117, 120, 125, 129], "ssvd_cp_compressed_sess": 5, "cp_comp_stat": [5, 25], "ok": [5, 25], "fine": [6, 7, 8, 9, 13, 15, 16, 20, 21, 30, 31, 34, 38, 46, 61, 68, 76, 83, 87, 111, 120, 123, 127, 130, 133], "tune": [6, 7, 8, 9, 13, 15, 16, 20, 21, 30, 31, 34, 38, 46, 61, 68, 76, 83, 87, 111, 120, 123, 127, 130, 133], "fold_all_batch_norm": [6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 43, 60, 65, 84, 89, 115], "bn_folded_sess": [6, 9, 20, 21], "maintain": [6, 49, 134], "fresh": 6, "save_and_load_graph": [6, 60, 65], "bn_folded_sess_copi": 6, "With": [6, 14, 16, 17, 21, 22, 31, 32, 104, 134], "enhanc": [6, 16, 17, 21, 22, 31, 32, 44, 54, 66, 68, 83, 85, 129, 133], "input_label_tensor": [6, 8, 9, 20, 21, 22], "get_tensor_by_nam": [6, 7, 8, 9, 20, 21, 22, 57, 58, 68], "train_tensor": [6, 8, 9, 20, 21, 22, 68], "train_tensors_dict": [6, 8, 9, 20, 21, 22], "dict": [6, 8, 9, 20, 21, 22, 38, 43, 46, 60, 61, 65, 75, 76, 78, 79, 80, 83, 84, 85, 87, 112, 113], "fromkei": [6, 8, 9, 20, 21, 22], "eval_output": [6, 8, 9, 20, 21, 22], "top1": [6, 8, 9, 20, 21, 22, 27, 38], "acc": [6, 8, 9, 11, 12, 13, 17, 20, 21, 22, 44], "input_label": [6, 8, 9, 20, 21, 22], "input_label_tensors_dict": [6, 8, 9, 20, 21, 22], "zip": [6, 8, 9, 20, 21, 22, 38, 44, 58], "feed_dict": [6, 7, 8, 9, 20, 21, 22, 57, 58, 63, 68], "as_default": [6, 7, 8, 9, 20, 21, 22, 58, 60, 61, 62, 65, 68, 69], "ensur": [6, 18, 78, 91, 112, 127, 132], "prior": [6, 26, 29, 30, 31, 119, 127, 129], "num_iter": [6, 7, 11, 38], "offer": [7, 11, 27, 52, 68, 85, 117], "suit": [7, 11, 27, 117], "network": [7, 11, 13, 14, 18, 27, 42, 61, 68, 112, 115, 117, 120, 122, 125, 127, 130, 132, 133, 137, 139], "often": [7, 11, 116, 117, 125, 130], "sequenc": [7, 11, 13, 27, 72, 117, 118, 126, 131], "better": [7, 8, 11, 18, 28, 72, 89, 105, 116, 117, 127, 128, 130], "prone": [7, 11, 117], "consum": [7, 11, 19, 27, 55, 117, 125], "analyz": [7, 11, 27, 38, 45, 53, 61, 67, 76, 86, 96, 97, 108, 109, 110, 111, 112, 113, 117, 119, 125, 126, 129, 133, 134, 137, 138], "amount": [7, 11, 17, 22, 27, 32, 117, 131], "toler": [7, 11, 27, 117, 120], "soon": [7, 11, 117], "threshold": [7, 11, 61, 112, 117], "stop": [7, 11, 36, 57, 71, 117], "autom": [7, 11, 26, 29, 30, 31, 32, 45, 71, 79, 80, 86, 87, 117, 127], "input_tensor_nam": [7, 58], "output_tensor_nam": [7, 58], "section": [7, 9, 11, 12, 27, 29, 72, 81, 91, 92, 105, 116, 118, 119, 121, 125, 127, 133], "eval_dataset_s": [7, 11, 12, 27, 49, 58, 73], "5000": [7, 11, 27, 49, 58, 73], "calibration_dataset_s": [7, 11, 27, 49, 58, 73], "_create_sampled_data_load": [7, 11, 27, 73], "_sampled_dataset": [7, 58], "_create_sampled_dataset": [7, 58], "num_sampl": [7, 11, 12, 27, 44, 58, 73], "_graph": [7, 22, 58], "shuffle_buffer_s": [7, 58], "300": [7, 58], "buffer": [7, 58], "shuffle_se": [7, 58], "22222": [7, 58], "shuffl": [7, 10, 18, 33, 38, 58, 76, 115], "buffer_s": [7, 58], "seed": [7, 58, 76], "object": [7, 11, 12, 15, 16, 17, 22, 26, 29, 30, 31, 32, 33, 36, 40, 44, 46, 49, 51, 52, 57, 58, 59, 61, 63, 66, 68, 73, 76, 78, 83, 85, 87, 94, 95, 104, 105, 110, 112, 113, 115, 118, 127, 130, 133], "eval_dataset": [7, 11, 12, 44, 58, 73], "image_dataset": [7, 44, 58], "lambda": [7, 10, 11, 12, 13, 14, 18, 22, 44, 105], "unlabeled_dataset": [7, 11, 12, 17, 22, 44, 58, 66, 73], "argument": [7, 11, 12, 17, 22, 32, 33, 36, 40, 44, 46, 51, 52, 57, 58, 61, 63, 66, 68, 71, 78, 80, 85, 87, 95, 102, 105], "whole": [7, 11, 12, 58, 105, 133], "np": [7, 8, 14, 33, 36, 38, 42, 44, 46, 49, 52, 54, 57, 58, 61, 65, 66], "iterate_tf_dataset": [7, 58], "sampled_dataset": [7, 11, 12, 17, 58], "global_variables_initi": [7, 57, 58, 61], "input_tensor": [7, 10, 18, 19, 33, 42, 54, 57, 58, 68, 80], "output_tensor": [7, 33, 57, 58], "num_correct_predict": [7, 58, 73], "prob": [7, 58], "predict": [7, 17, 38, 40, 44, 58, 61, 73, 127], "argmax": [7, 58, 73, 112, 115], "axi": [7, 17, 22, 32, 55, 58, 129], "sum": [7, 27, 38, 58, 73, 112, 115], "allowed_accuracy_drop": [7, 11, 27, 49, 58, 73], "convei": [7, 11], "seri": [7, 11, 27, 87], "auto_qu": [7, 11, 27, 49, 58, 73, 114], "01": [7, 11, 27, 36, 49, 57, 58, 71, 73, 92, 99, 100, 116], "shown": [7, 11, 17, 22, 32, 43, 65, 79, 82, 83, 114, 116, 125, 128, 129, 132], "adaround_dataset_s": [7, 11, 27, 49, 58, 73], "adaround_dataset": [7, 11, 58], "adaround_param": [7, 11, 27, 49, 58, 73], "set_adaround_param": [7, 11, 27, 49, 58, 73], "associ": [7, 11, 17, 22, 32, 36, 43, 57, 58, 60, 61, 73, 81, 94, 95, 112, 127], "eval_scor": [7, 11, 38, 61, 76, 85], "cle": [7, 11, 27, 39, 60, 62, 77, 82, 86, 116, 121, 127, 132, 135], "standalon": [7, 11, 27, 72, 127], "fashion": [7, 11, 18, 27, 105], "counter": [8, 12, 28, 45, 46, 68, 87], "potenti": [8, 12, 28, 43, 45, 65, 72, 126, 129, 137, 138], "instabl": [8, 12, 28, 45], "batchnrom": [8, 28], "varianc": [8, 12, 28, 45, 128], "recalcul": [8, 12, 28, 37], "stabl": [8, 12, 28, 37, 80, 116], "rather": [8, 12, 28, 37, 80, 137], "than": [8, 12, 13, 28, 37, 38, 43, 55, 61, 65, 71, 72, 76, 80, 81, 84, 87, 105, 114, 115, 124, 130, 137], "noisi": [8, 12, 28, 37], "compar": [8, 12, 13, 14, 15, 16, 17, 22, 28, 32, 61, 72, 80, 89, 105, 115, 129, 130, 138], "focu": [8, 28], "itself": [8, 17, 22, 28, 32, 51, 125, 133, 136, 139], "inform": [8, 28, 43, 55, 61, 65, 75, 81, 84, 104, 114, 127, 129], "accuraci": [8, 12, 13, 17, 22, 27, 28, 32, 34, 36, 38, 40, 46, 49, 51, 57, 58, 61, 63, 68, 71, 73, 76, 78, 83, 87, 105, 111, 115, 116, 117, 120, 122, 123, 125, 127, 128, 129, 130, 132, 133, 135, 138, 140], "line": [8, 54, 59, 68, 69, 71, 74, 75, 87, 89, 121], "difficult": 8, "model_sess_bn_mut": 8, "easier": [8, 105, 114, 134], "bn_mutabl": 8, "modify_sess_bn_mut": 8, "training_tf_placehold": 8, "unlik": [8, 28, 102], "script": [8, 28], "didn": [8, 28], "becaus": [8, 14, 28, 42, 80], "present": [8, 14, 28, 34, 72, 78, 81, 83, 105, 114, 115, 125, 128], "statatist": [8, 28], "json": [8, 12, 17, 19, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "default_config_per_channel": [8, 12], "is_output_quant": [8, 12, 131], "is_quant": [8, 12, 131], "is_symmetr": [8, 12, 55, 110, 131], "strict_symmetr": [8, 12, 131], "unsigned_symmetr": [8, 12, 131], "per_channel_quant": [8, 12, 18, 55, 112, 131], "op_typ": [8, 12, 131], "squeez": [8, 12], "pad": [8, 12, 42, 72, 80, 81, 112, 115], "supergroup": [8, 12, 131, 135], "op_list": [8, 12, 131], "relu": [8, 12, 13, 14, 41, 42, 43, 55, 62, 65, 72, 75, 79, 80, 81, 84, 112, 114, 115, 128, 131, 140], "clip": [8, 12, 109, 110, 131, 133], "gemm": [8, 12, 131], "model_input": [8, 12, 81, 131], "is_input_quant": [8, 12, 131], "model_output": [8, 12, 131], "config_file_path": 8, "tmp": [8, 12, 17, 22, 32, 44, 58, 66, 73, 85, 115], "open": [8, 12], "w": [8, 12, 85, 91, 140], "f": [8, 12, 15, 16, 27, 49, 73, 80, 81, 91, 115], "dump": [8, 12], "training_range_learning_with_tf_init": [8, 12, 16, 21, 28, 31, 36, 57, 68, 71, 87], "config_fil": [8, 12, 17, 18, 22, 32, 44, 46, 52, 66, 68, 73, 75, 85, 87], "5e": [8, 24, 25, 28, 30, 31, 59, 74, 87], "7": [8, 12, 24, 25, 28, 30, 31, 43, 59, 73, 74, 83, 87, 91, 92, 99, 100, 102, 115, 140], "finetuned_accuraci": [8, 28, 30, 31], "helper": [8, 12, 28, 58, 60, 64, 73], "reestimate_bn_stat": [8, 12, 28, 37, 59, 74], "full": [8, 12, 28, 38, 41, 45, 64, 79, 86, 112, 139], "100": [8, 12, 28, 37, 58, 59, 61, 68, 73, 74, 109, 114, 115], "adapt": [8, 12, 18, 28, 45, 67, 74, 83, 86, 111, 115, 116, 121, 127, 129, 135], "forward": [8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 44, 46, 52, 66, 68, 71, 72, 74, 79, 80, 81, 82, 84, 85, 87, 91, 94, 95, 96, 97, 112, 113, 115, 126, 129, 132, 135], "yield": [8, 12, 28, 52, 66, 71, 74, 85, 133], "directli": [8, 12, 16, 28, 37, 49, 82, 85, 114, 129, 133], "bn_reestim": [8, 12, 28, 37, 59, 74], "real_input": 8, "vstack": 8, "from_tensor_slic": [8, 36, 37, 44, 57, 58, 61, 66], "bn_re_restimation_dataset": [8, 59], "start_op_nam": [8, 9, 22, 59, 60, 62, 65, 66], "bn_re_estimation_dataset": [8, 37, 59], "bn_num_batch": [8, 37, 59], "finetuned_accuracy_bn_reestim": [8, 28], "far": [8, 12, 28, 116], "effici": [8, 12, 28, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "fold_all_batch_norms_to_scal": [8, 12, 28, 37, 59, 74], "resnet50_after_qat": [8, 20], "lead": [9, 29, 44, 52, 66, 85, 105, 116, 118, 128, 132, 133], "shift": [9, 29, 67, 86, 128], "training_range_learning_with_tf_enhanced_init": [9, 16, 21, 31, 36, 57, 71, 87], "aimet_cl": [9, 19], "cle_applied_sess": 9, "under": [9, 29, 39, 62, 95, 105, 112, 114, 121, 129, 131, 137, 138], "hood": [9, 29, 114], "correct_bia": [9, 29, 60, 75], "num_quant_sampl": [9, 29, 60, 75], "num_bias_correct_sampl": [9, 29, 60, 75], "bias_correct": [9, 29, 60, 75], "aimet_bc": 9, "quant_param": [9, 60, 75], "quantparam": [9, 29, 60, 75], "quant_mod": [9, 60], "round_mod": [9, 29, 60, 75], "ops_to_ignor": [9, 60], "bias_correction_param": [9, 60], "biascorrectionparam": [9, 60], "56": 9, "16": [9, 12, 15, 16, 29, 36, 38, 46, 54, 55, 57, 68, 71, 80, 83, 87, 94, 95, 96, 102, 105, 112, 113, 116], "after_bc_sess": 9, "biascorrect": [9, 60], "bias_correct_param": [9, 60], "resnet50_after_qat_range_learn": [9, 21], "smaller": [10, 18, 71, 72, 116, 123, 132, 136, 139], "awai": [10, 18, 116], "image_net_dataset": [10, 11, 12, 17, 18, 19], "imagenetdataset": [10, 11, 12, 17, 18, 19], "get_val_dataset": [10, 11, 12, 17, 18, 19], "include_top": [10, 18, 19], "pool": [10, 12, 18, 19], "rest": [10, 15, 16, 18, 19, 33, 132], "sim": [10, 12, 13, 18, 26, 27, 36, 37, 48, 49, 57, 59, 71, 73, 74, 75, 82, 83, 85, 105, 111, 114, 115, 130, 133], "progbar": [10, 15, 16, 18, 19], "preprocess_input": [10, 15, 16, 18, 19, 33, 38], "sim_model": [10, 15, 16, 17, 18, 19, 26, 28, 29, 30, 31, 32, 71, 87], "tf_dataset": [10, 18, 19], "progbar_stat_upd": [10, 15, 16, 18, 19], "preprocess": [10, 13, 18, 38], "image_dataset_from_directori": [10, 18, 38], "ada_round_data": [10, 18], "label_mod": [10, 18, 38], "categor": [10, 18, 38], "image_width": [10, 18], "image_height": [10, 18], "y": [10, 17, 18, 22, 32, 46, 68, 80, 91, 92, 115, 129], "fo": [10, 18, 71], "r": [10, 18, 71, 83, 85], "Of": [10, 18, 105], "cours": [10, 18], "resnet50_after_adaround": 10, "quick": [10, 14, 18, 121], "dictionari": [11, 12, 14, 38, 61, 76, 85, 87, 88, 122, 125, 131], "adam": [11, 12, 13, 15, 16, 17, 44, 46, 68, 115], "categoricalcrossentropi": [11, 12, 17, 44], "categoricalaccuraci": [11, 12, 17, 44], "thi": [12, 13, 14, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 89, 91, 92, 94, 95, 96, 97, 99, 100, 102, 104, 105, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140], "notebook": [12, 13, 14], "i": [12, 13, 14, 33, 34, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 99, 100, 102, 105, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140], "6": [12, 13, 14, 36, 42, 49, 57, 61, 71, 73, 80, 83, 87, 99, 100, 105, 130], "simul": [12, 13, 15, 16, 32, 40, 45, 46, 51, 53, 55, 60, 63, 67, 68, 71, 75, 78, 79, 82, 83, 86, 87, 102, 105, 111, 112, 115, 123, 127, 130, 134, 135], "train_dataset_s": 12, "re_estimation_dataset_s": 12, "train_dataset": 12, "re_estimation_dataset": 12, "built": [12, 13, 90, 91], "sequenti": [12, 13, 14, 41, 42, 114, 131, 132, 134], "subclass": [12, 13, 33, 41, 42], "incompat": [12, 13, 115], "therefor": [12, 13, 14, 83, 115, 120, 128], "conv1": [12, 23, 24, 25, 33, 42, 72, 76, 79, 80, 81, 84, 88, 115], "fuse": [12, 131, 133], "maxpooling2d": 12, "conv2": [12, 42, 55, 76, 79, 80, 84, 105, 115], "flatten": [12, 80, 112], "dens": [12, 13, 14, 41, 42, 43], "functional_model": [12, 13, 14], "baselin": [12, 13, 27, 115, 122, 130], "loss_fn": [12, 115], "qsim": [12, 37], "posit": [12, 13, 14, 42, 99, 100], "quantized_callback": [12, 13, 15, 16], "tensorboard": [12, 13, 15, 16], "log_dir": [12, 13, 15, 16], "histori": [12, 13, 15, 16], "validation_data": [12, 13, 15, 16], "reestim": [12, 37], "mnist_after_bn_re_estimation_qat_range_learn": 12, "standard": [13, 15, 16, 20, 21, 30, 31, 80, 87, 89, 102, 112], "1": [13, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140], "dataset": [13, 33, 36, 37, 38, 44, 49, 52, 54, 57, 58, 59, 60, 61, 66, 68, 71, 73, 74, 75, 85, 87, 115, 121, 127, 128, 133], "2": [13, 33, 36, 38, 42, 43, 46, 49, 54, 57, 58, 59, 61, 64, 68, 71, 72, 73, 74, 76, 78, 80, 81, 83, 84, 85, 87, 90, 91, 97, 99, 100, 102, 104, 105, 113, 114, 116, 127, 132, 133], "3": [13, 33, 36, 38, 39, 43, 44, 46, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 89, 90, 99, 100, 104, 105, 110, 114, 115, 120, 127, 130, 132, 140], "evalu": [13, 27, 33, 36, 38, 44, 46, 52, 54, 57, 58, 61, 62, 65, 66, 71, 73, 76, 85, 87, 88, 115, 117, 121, 122, 125, 127, 129, 130, 133, 137], "4": [13, 17, 22, 23, 32, 33, 36, 37, 43, 44, 49, 52, 57, 58, 59, 61, 66, 71, 73, 74, 75, 76, 80, 83, 84, 85, 87, 99, 100, 104, 105, 114, 115, 118, 122, 127, 140], "imdb": 13, "sentiment": 13, "vocab_s": [13, 14, 42], "20000": [13, 14, 42], "20k": 13, "word": [13, 105], "maxlen": [13, 14, 42], "200": [13, 14, 27, 42, 114], "movi": 13, "review": 13, "x_train": [13, 33, 37], "y_train": [13, 33], "x_val": 13, "y_val": 13, "load_data": 13, "num_word": 13, "pad_sequ": 13, "embed_dim": [13, 14, 42], "embed": [13, 14, 42, 80, 87, 112, 125, 132], "token": [13, 14, 42, 132], "num_head": [13, 14, 42], "attent": [13, 14, 42], "head": [13, 14, 42], "ff_dim": [13, 14, 42], "hidden": [13, 14, 42], "insid": [13, 14, 38, 42, 80, 91, 94, 95, 112, 115], "delta": [13, 14, 42, 44, 52, 66, 85, 110, 133], "input_dim": [13, 14, 42], "output_dim": [13, 14, 42], "block": [13, 73, 96, 97, 99, 100, 105, 113, 114, 134], "multiheadattent": [13, 14, 42, 135], "key_dim": [13, 14, 42], "dropout": [13, 14, 42, 112], "layernorm": [13, 14, 42, 112], "epsilon": [13, 14, 42], "globalaveragepooling1d": [13, 14, 42], "functional_callback": 13, "histogram_freq": 13, "sparse_categorical_crossentropi": 13, "128": [13, 66, 80, 104, 105, 115], "wrap": [13, 15, 16, 17, 19, 22, 32, 80, 114], "wrapper": [13, 19, 26, 29, 30, 31, 36, 44, 52, 57, 61, 66, 76, 85], "effect": [13, 15, 16, 20, 21, 30, 31, 36, 37, 46, 57, 59, 68, 71, 74, 83, 87, 105, 112, 115, 118, 127, 129, 131, 133], "visual": [13, 17, 22, 32, 34, 38, 56, 61, 70, 76, 91, 125, 127, 128, 129, 132, 135, 136, 139], "right": [13, 27, 94, 95, 96, 97, 99, 100, 102, 112, 113, 127, 140], "multi": [13, 33, 65, 86, 135], "encount": [13, 115], "access": [13, 26, 29, 30, 31, 91, 114, 127], "mha": [13, 135], "accur": [13, 115], "clone_lay": 13, "clone": [13, 121], "diagram": [13, 118, 122, 125, 133, 136, 139], "m": [13, 90, 91, 92, 111, 121], "convert_to_pb": [13, 46], "onc": [13, 15, 16, 20, 21, 23, 24, 25, 29, 30, 31, 41, 79, 81, 83, 87, 95, 118, 119, 125, 129, 130, 133], "inspect": 13, "1024": [13, 54, 68, 71, 87, 116, 126], "artifact": [13, 15, 16, 40, 51, 63, 69, 78, 91, 115], "3000": [13, 104], "model_after_qat": [13, 15, 16], "anoth": [13, 16, 21, 31, 83, 87, 139, 140], "most": [13, 105, 115, 131], "complex": [13, 36, 44, 46, 52, 57, 66, 68, 85, 87], "elementari": 13, "logdir": 13, "summari": [13, 69, 89, 117], "vanilla": [13, 16, 21, 27, 31, 132], "tool": [14, 44, 66, 85, 111, 115, 125, 128, 138, 140], "sequanti": 14, "build": [14, 42, 114, 134], "dicuss": 14, "text": [14, 42, 96, 97, 99, 100, 113], "transform": [14, 26, 27, 29, 30, 31, 32, 42, 71, 73, 80, 87, 105, 115, 135], "tokenandpositionembed": [14, 42], "transformerblock": [14, 42], "super": [14, 42, 72, 80, 81, 115], "att": [14, 42], "ffn": [14, 42], "layernorm1": [14, 42], "layernorm2": [14, 42], "dropout1": [14, 42], "dropout2": [14, 42], "kwarg": [14, 42, 94, 95, 99, 100, 104, 112], "attn_output": [14, 42], "out1": [14, 42], "ffn_output": [14, 42], "token_emb": [14, 42], "pos_emb": [14, 42], "random_input": [14, 42], "embedding_lay": [14, 42], "transformer_block": [14, 42], "token_and_position_embed": 14, "re": [14, 33, 45, 67, 86, 115, 121, 127], "symmetr": [14, 55, 83, 94, 95, 96, 97, 104, 105, 110, 112, 113, 114, 115, 131, 133], "model_prepar": [14, 26, 28, 29, 30, 31, 32, 42, 44, 71, 74, 80, 85, 87, 114, 115], "prepare_model": [14, 26, 28, 29, 30, 31, 32, 42, 44, 71, 74, 80, 85, 87, 114, 115], "input_lay": [14, 42], "begin": [14, 42, 72, 80, 81, 96, 97, 99, 100, 113, 130, 131], "unwrap": 14, "ident": [14, 41, 79, 112, 115], "total": [14, 38, 115, 122, 133], "get_weight": 14, "represent": [14, 55, 102, 104], "reorder": 14, "get_original_models_weights_in_functional_model_ord": 14, "original_model": [14, 42], "class_nam": [14, 38], "ndarrai": [14, 43, 63, 65, 84], "arg": [14, 87, 94, 95, 99, 100, 104, 105, 112], "lookup": 14, "remov": [14, 37, 59, 74, 80, 91, 114, 115, 119, 123, 133, 140], "match": [14, 36, 40, 44, 51, 52, 57, 61, 63, 66, 76, 78, 85, 87, 95, 105, 119, 125, 129, 131, 132, 133, 140], "original_model_weight": 14, "pop": 14, "weight_nam": 14, "kei": [14, 16, 21, 31, 43, 55, 60, 65, 84, 92], "functional_model_weight_ord": 14, "enumer": [14, 36, 38, 57, 61, 71, 76, 78, 87, 115, 118], "sort": 14, "weights_in_correct_ord": 14, "item": [14, 17, 22, 32, 49, 127], "weight_info": 14, "assert": [14, 80, 114, 115], "count_param": 14, "output_shap": 14, "textclassif": 14, "what": [14, 115, 133, 137], "architectur": [14, 68, 86, 120], "model_weights_in_correct_ord": 14, "assert_array_equ": 14, "modelprepar": [14, 26, 29, 30, 31, 32, 37, 42, 71, 80, 87, 115], "arthmet": [14, 42], "experss": [14, 42], "tfoplambda": [14, 42], "ressembl": 14, "conv_1": [14, 42, 105], "conv_2": [14, 42], "becuas": [14, 42, 51], "rais": [14, 42, 61, 68, 95], "except": [14, 17, 22, 32, 42, 105], "hopefulli": [14, 19], "min": [15, 16, 18, 44, 52, 55, 66, 68, 85, 89, 96, 97, 108, 110, 112, 113, 114, 115, 129, 133], "max": [15, 16, 18, 44, 52, 55, 66, 68, 85, 89, 96, 97, 102, 108, 110, 112, 113, 114, 115, 125, 128, 129, 133], "keep": [15, 20, 21, 30, 31, 80, 87, 131, 132], "constant": [15, 20, 21, 30, 31, 49, 58, 73, 80, 87, 122, 127], "assign": [15, 16, 55, 83, 94, 95, 96, 97, 112, 113], "dataset_train": [15, 16], "dataset_valid": [15, 16], "respect": [15, 16, 41, 61, 89, 112, 129], "glob": [15, 16], "decode_exampl": [15, 16], "decod": [15, 16], "parse_single_exampl": [15, 16], "fixedlenfeatur": [15, 16], "int64": [15, 16], "string": [15, 16, 55, 131], "image_data": [15, 16], "cast": [15, 16, 102, 112], "int32": [15, 16], "decode_jpeg": [15, 16], "get_imagenet_dataset": [15, 16], "dataset_path": [15, 16], "split_nam": [15, 16], "num_parallel_read": [15, 16], "tfrecorddataset": [15, 16], "glob_nam": [15, 16], "tf_record_fil": [15, 16], "num_parallel_cal": [15, 16], "being": [15, 16, 19, 38, 41, 43, 55, 61, 76, 79, 80, 81, 84, 85, 105, 114], "categorical_crossentropi": [15, 16, 46], "hyperparamet": [15, 16, 130], "henc": 16, "jointli": [16, 20, 21, 30, 31], "ye": [16, 92, 125], "due": [16, 34, 42, 67, 81, 86, 105, 127, 128], "restrict": [16, 105, 126], "prevent": [16, 72, 80, 114, 119], "mention": [16, 105], "continu": [16, 21, 31, 42, 81, 87, 127, 128, 130, 132], "benefit": [16, 21, 31, 55, 105, 116], "analys": [17, 22, 32, 129], "respond": [17, 22, 32], "One": [17, 22, 26, 29, 30, 31, 32, 44, 46, 60, 66, 68, 115, 120, 125, 136], "second": [17, 22, 32, 42, 58, 71, 105, 112, 131], "anyth": [17, 22, 32], "tupl": [17, 22, 32, 33, 36, 37, 38, 40, 43, 44, 46, 52, 57, 58, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 87, 96, 97, 99, 100, 105, 110, 113], "dummi": [17, 22, 32, 36, 46, 48, 57, 71, 72, 73, 77, 78, 84, 85, 87, 129], "val_dataset": 17, "callbackfunc": [17, 22, 32, 44, 52, 66, 85], "exactli": [17, 22, 32, 58, 94, 95, 112, 133], "multipl": [17, 22, 32, 38, 61, 65, 68, 72, 76, 77, 78, 80, 81, 84, 87, 88, 92, 105, 112, 123, 125, 127, 135], "eval_func": [17, 38, 61, 88], "v": [17, 22, 32, 36, 57, 71, 91, 105, 122], "demonstr": [17, 22, 32, 115], "quant_analyz": [17, 22, 32, 44, 52, 66, 85, 114], "enable_per_layer_mse_loss": [17, 32, 44, 52, 85], "track": [17, 22, 32, 83, 129], "minimum": [17, 22, 32, 36, 57, 71, 80, 87, 89, 90, 99, 100, 112], "histogram": [17, 22, 32, 44, 52, 66, 69, 85, 89, 110, 127, 129, 133, 135], "seen": [17, 22, 32, 128, 129], "results_dir": [17, 22, 32, 44, 52, 58, 66, 69, 73, 85, 89], "html": [17, 22, 32, 80, 85, 120, 129, 135, 138], "plot": [17, 22, 32, 69, 89, 129], "per_layer_quant_en": [17, 32, 129], "per_layer_quant_dis": [17, 32, 129], "min_max_rang": [17, 22, 32, 129], "activations_pdf": [17, 22, 32, 129], "name_": [17, 32, 85], "index_0": [17, 32], "index_1": [17, 32], "index_n": [17, 32], "weights_pdf": [17, 22, 32, 129], "layer1": [17, 32, 43, 65, 84], "param_name_": [17, 22, 32, 85], "channel_index_0": [17, 22, 32], "channel_index_1": [17, 22, 32], "channel_index_n": [17, 32], "layer2": [17, 32, 43, 65, 84], "layern": [17, 32], "per_layer_mse_loss": [17, 32, 129], "sub": [17, 22, 32, 72, 92, 119, 125, 133, 140], "basi": [18, 55, 105, 122, 125], "between": [18, 36, 38, 43, 57, 61, 65, 66, 71, 73, 76, 78, 84, 85, 87, 92, 105, 112, 114, 128, 129, 131, 133, 134], "imagin": 18, "filter": [18, 42], "kernel": [18, 95, 105, 112, 119, 134, 136, 139], "28": [18, 76, 104], "were": [18, 27, 30, 31, 40, 43, 51, 55, 63, 65, 71, 78, 83, 84, 87, 92, 120, 127, 131, 134, 140], "entireti": [18, 42], "contrast": [18, 42, 114], "repeat": [18, 58, 83, 115, 119], "uniqu": 18, "attribut": [18, 42, 80, 83, 94, 95, 112, 114, 129], "conv2d_lay": 18, "kernel_s": [18, 42, 72, 80, 81, 115], "snpe": [18, 19], "qnn": [18, 19], "config": [18, 46, 66, 68, 85, 131, 135], "style": 18, "mismatch": 18, "togeth": [18, 105, 125], "pcq_quantsim_config": 18, "tell": [18, 137], "did": [18, 128], "resnet50_pcq_adaround": 18, "mimic": 19, "cle_applied_model": [19, 39], "yaml": 19, "h5": [19, 40, 123, 127], "savedmodel": 19, "protobuff": 19, "safe": 19, "resnet50_after_cl": 19, "Then": [20, 21, 30, 31, 36, 52, 57, 71, 85, 87], "meta": [20, 33, 61, 63, 68, 83, 123, 127], "No": [22, 75, 81, 127], "func": [22, 85], "func_callback_arg": [22, 52, 66, 85], "data_pipelin": 22, "per_op_quant_en": 22, "per_op_quant_dis": 22, "quant_op_name0": 22, "quant_op_name1": 22, "quant_op_namen": 22, "op1": 22, "channel_index_x": 22, "op2": 22, "channel_index_i": 22, "opn": 22, "channel_index_z": 22, "per_op_mse_loss": 22, "nn": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 76, 79, 80, 81, 82, 84, 85, 87, 94, 95, 96, 97, 105, 111, 112, 113, 114, 115, 126, 134, 135], "modul": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 41, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 87, 89, 90, 94, 95, 105, 111, 115, 116, 127, 134, 135, 140], "gpu": [23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 60, 61, 66, 68, 76, 78, 86, 90, 91, 127, 135], "learning_rate_schedul": [23, 24, 25, 28, 30, 31, 74, 87], "schedul": [23, 24, 25, 28, 30, 31, 130], "max_epoch": [23, 24, 25, 28, 30, 31], "is_avail": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 74, 115], "aimet_torch": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 126, 134], "compressed_model": [23, 24, 38, 61, 76], "15e": [23, 25], "prune": [24, 38, 120, 121, 122, 124, 125, 135, 140], "ssvd_compressed_model": 25, "ssvd_cp_compressed_model": 25, "ssvd_cp_finetuned_model": 25, "certain": [26, 29, 30, 31, 32, 71, 79, 80, 85, 87, 105, 125, 126, 127, 131], "guidelin": [26, 29, 30, 31, 32, 34, 45, 48, 54, 56, 58, 68, 71, 80, 86, 114, 115, 116, 120, 130], "rand": [26, 28, 29, 30, 31, 32, 33, 36, 44, 57, 58, 61, 66, 72, 78, 81], "modif": [26, 29, 30, 31], "made": [26, 29, 30, 31, 80, 131, 134], "overrid": [26, 29, 30, 31, 61, 80, 87], "no_grad": [26, 27, 29, 30, 31, 32, 71, 81, 87], "ptq": [27, 58, 73, 123, 127, 129, 130], "success": 27, "care": [27, 115], "non": [27, 72, 80, 133], "expert": 27, "effort": [27, 58, 73, 117], "known": [27, 81, 105, 122, 123], "heurist": [27, 61], "cumul": 27, "until": [27, 58, 73, 96, 97, 113, 117], "val_transform": 27, "compos": [27, 73], "centercrop": 27, "totensor": [27, 73, 115], "normal": [27, 43, 72, 112, 118, 129], "485": 27, "456": 27, "406": 27, "std": 27, "229": 27, "225": 27, "imagenet_dataset": 27, "imagefold": 27, "root": [27, 91, 92, 115], "eaxmpl": 27, "tqdm": 27, "subsetrandomsampl": [27, 73], "in_eval_mod": 27, "get_devic": 27, "_dataset": [27, 73], "logit": 27, "topk": [27, 49, 112], "k": [27, 136], "view_a": 27, "unlabeleddatasetwrapp": [27, 73], "__getitem__": [27, 73], "unlabeled_imagenet_dataset": 27, "unlabeled_imagenet_data_load": 27, "initial_accuraci": [27, 49, 73], "run_infer": [27, 49, 73], "predefin": [27, 122], "empir": [27, 60, 128], "adaround_data_load": [27, 49, 73], "furhter": 27, "optimized_accuraci": [27, 49, 73], "train_load": [28, 74, 76, 115], "images_dir": 28, "resnet18_after_qat": [28, 30, 31], "bc_param": 29, "weight_bw": [29, 75], "act_bw": [29, 75], "resnet18_after_cle_bc": 29, "matter": 32, "involv": [33, 114, 115, 127, 132, 134], "four": [33, 133], "convert_tf_sess_to_kera": 33, "save_tf_session_single_gpu": 33, "sourc": [33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 132], "variabl": [33, 38, 42, 61, 76, 80, 91, 92, 96, 97, 113, 121], "load_tf_sess_variables_to_keras_single_gpu": 33, "compressed_op": 33, "save_session_graph_and_vari": 33, "creation": 33, "compress": [33, 34, 35, 56, 70, 111, 119, 121, 123, 135, 136, 138, 139, 140], "isol": [33, 105], "strategi": 33, "save_as_tf_module_multi_gpu": 33, "loading_path": 33, "saving_path": 33, "load_keras_model_multi_gpu": 33, "funetun": 33, "instanc": [33, 61, 80, 81, 87, 94, 95, 137], "moblinetv1": 33, "convert_tf_session_to_keras_model": 33, "mirroredstrategi": 33, "get_sess_from_keras_model": 33, "mobilnetv1": 33, "compress_sess": 33, "mobilenet": 33, "act_softmax": 33, "saved_model_single_gpu": 33, "correspnd": 33, "set_learning_phas": 33, "saved_model_multi_gpu": 33, "scope": [33, 80], "vgg16": [33, 61], "modulecompratiopair": [33, 38, 61, 76], "compressible_op": 33, "layer_a": 33, "list_of_module_comp_ratio_pair": [33, 38, 61, 76], "manual_param": [33, 61, 76], "manualmodeparam": [33, 38, 61, 76], "pylint": 33, "unus": 33, "to_categor": [33, 46], "rmsprop": 33, "mse": [33, 44, 52, 66, 85, 114, 129, 133, 134], "qualcomm": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "innov": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "center": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "inc": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "ai": [33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "toolkit": [33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "quantsim_config": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "default_config": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "softwar": [34, 123, 125], "dramat": 34, "lost": [34, 111, 123], "At": [34, 120, 125, 134], "onnx": [34, 55, 78, 79, 83, 87, 90, 91, 111, 121, 123, 126, 127, 131], "link": [34, 90, 121], "debug": [34, 35, 36, 40, 47, 51, 55, 56, 57, 61, 63, 70, 78, 114, 115, 132, 134], "codebas": 34, "sphinx": 34, "page": [34, 91, 92, 120, 133, 135], "model": [35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140], "default_reg_param": [36, 57, 71], "default_beta_rang": [36, 57, 71], "default_warm_start": [36, 57, 71], "datasetv2": [36, 37, 57, 60, 61], "beta": [36, 57, 71, 116], "anneal": [36, 57, 71], "start_beta": [36, 57, 71], "end_beta": [36, 57, 71], "warm": [36, 57, 71, 116], "period": [36, 57, 71, 116], "zero": [36, 57, 60, 71, 83, 133, 135], "post_training_percentil": [36, 57, 71, 87], "percentil": [36, 57, 71, 87, 109], "absolut": [36, 57, 61, 71, 76, 87, 96, 97, 113], "nois": [36, 57, 67, 71, 86, 87, 110, 115, 127, 128, 129, 130, 131], "aimetlogg": [36, 57], "test_model": [36, 57], "keras_model": [36, 57], "dummy_forward_pass": [36, 57], "intend": [36, 44, 52, 55, 57, 61, 66, 76, 85, 115, 120], "Or": [36, 44, 46, 52, 57, 66, 68, 78, 80, 85, 87, 125], "someth": [36, 44, 46, 52, 57, 66, 68, 85, 87, 125, 137], "apply_adaround_exampl": [36, 48, 57], "set_level_for_all_area": [36, 57], "dataset_s": [36, 57, 66], "possible_batch": [36, 57], "w4a8": [36, 57], "param_bw": [36, 57, 71, 73, 83], "output_bw": [36, 57, 71, 73, 83], "adarounded_model": [36, 71], "adarounded_sess": [36, 57], "grid": [36, 57, 71, 105, 134], "handl": [37, 59, 73, 74, 105], "undo": [37, 59, 74], "upon": [37, 59, 74, 94, 95, 112, 115], "batch_norm": [37, 43, 59, 65, 74, 84], "qcquantizewrapp": [37, 74], "pair": [37, 38, 43, 61, 65, 74, 75, 76, 84], "got": [37, 65, 74, 80, 84], "prepar": [37, 41, 44, 45, 49, 52, 58, 66, 71, 73, 79, 83, 85, 86, 87, 117, 127, 135], "overal": [38, 61, 71, 76, 87, 120, 125, 132], "algorithm": [38, 55, 60, 61, 76, 120, 122, 125, 132, 140], "pick": [38, 42, 43, 60, 61, 65, 76, 120, 122, 125], "tweak": [38, 43, 61, 65, 76, 83, 84], "compressor": [38, 61, 76], "static": [38, 42, 61, 65, 76, 80, 133], "visualization_url": [38, 61, 76, 88], "callabl": [38, 58, 61, 68, 71, 73, 74, 76, 80, 85, 95, 105], "cost": [38, 61, 76, 105, 122, 125, 130], "url": [38, 61, 76, 88, 91, 92, 121, 137], "appear": [38, 43, 61, 65, 72, 76, 80, 81, 84], "compressionstat": [38, 61, 76], "use_monotonic_fit": [38, 61, 76], "saved_eval_scores_dict": [38, 61, 76, 88], "express": [38, 61, 76], "comp": [38, 61, 76], "greater": [38, 43, 61, 65, 76, 84, 105, 112], "monoton": [38, 61, 76, 122], "pickl": [38, 61, 76], "experi": [38, 61, 76, 105, 125, 134], "union": [38, 40, 42, 43, 46, 61, 62, 63, 65, 68, 71, 72, 73, 75, 76, 77, 78, 84, 85, 87, 105], "rank": [38, 61, 76, 83, 136, 139], "noth": [38, 61, 76, 115], "space": [38, 61, 76, 105], "weight_svd": [38, 61, 76], "comp_ratio": [38, 61, 76], "decode_predict": 38, "aimet_common_def": 38, "aimet_tensorflow_def": 38, "get_eval_func": 38, "50000": 38, "func_wrapp": 38, "validation_d": 38, "inp_data": 38, "img": 38, "pred": [38, 49], "cnt": 38, "b": [38, 59, 74, 83, 95, 96, 97, 99, 100, 113], "aimet_spatial_svd": 38, "evalfunct": 38, "driver": [38, 90, 92], "stat": [38, 61, 74, 76, 110], "three": [39, 62, 80, 117, 120, 138], "comprehens": [39, 62], "detect": [39, 62, 125], "shall": [39, 55, 62], "rtype": [39, 42, 43, 104], "cross_layer_equalization_auto": [39, 62, 77], "individu": [39, 43, 62, 65, 77, 85, 105, 118, 119, 120, 122, 125, 127, 129, 132], "intermedi": [40, 51, 63, 72, 78, 87, 133], "accord": [40, 51, 63, 78, 127, 130, 131, 133], "comparison": [40, 51, 63, 78], "amongst": [40, 51, 63, 78], "miss": [40, 42, 51, 55, 63, 78, 81], "issu": [40, 42, 51, 63, 72, 78, 81, 118, 123, 126, 132, 135, 137, 138], "layer_output_util": [40, 51, 63, 78], "layeroutpututil": [40, 51, 63, 78], "save_dir": 40, "keraslayeroutput": 40, "implement": [40, 44, 46, 49, 52, 58, 63, 66, 73, 78, 85, 87, 94, 95, 112, 114, 126, 132, 134], "constructor": [40, 43, 60, 61, 63, 75, 78, 79, 80, 84, 87], "generate_layer_output": [40, 51, 63, 78], "input_batch": [40, 51, 63, 78], "disk": [40, 63, 78], "obtain": [40, 43, 51, 52, 55, 60, 63, 65, 78, 84, 92, 119, 120, 129, 133, 134], "aimet_export_artifact": [40, 51, 63, 78], "sake": [40, 51, 63, 78], "simplic": [40, 51, 63, 78], "mandatori": [40, 51, 63, 78], "load_encodings_to_sim": [40, 51, 63, 78], "construct": [40, 51, 61, 63, 72, 78, 91, 92, 115, 126], "properli": [40, 51, 63, 78, 96, 97, 113, 115], "get_pre_processed_input": [40, 51, 63, 78], "fp32_layer_output_util": [40, 51, 63, 78], "fp32_layer_output": [40, 51, 63, 78], "quantsim_layer_output_util": [40, 51, 63, 78], "quantsim_layer_output": [40, 51, 63, 78], "sever": [41, 45, 64, 79, 81, 86, 105, 112, 120], "encourag": [41, 42, 45, 79, 80, 86], "format": [41, 43, 46, 57, 60, 61, 65, 68, 71, 83, 85, 87, 105, 113, 117, 124], "get_model": 41, "mix": [41, 60], "reus": [41, 79, 80, 81], "had": [41, 79, 115], "x2": [41, 79, 80], "relu2": [41, 42, 79, 81], "manditori": 42, "submodul": [42, 79], "inherit": [42, 94, 112], "pure": [42, 79], "inputlay": 42, "portion": 42, "get_text_classificaiton_model": 42, "model_preparer_two_subclassed_lay": 42, "get_subclass_model_with_functional_lay": 42, "sigmoid": [42, 80, 112], "binary_classifi": 42, "myfunctionalmodel": 42, "my_functional_model": 42, "classifi": 42, "model_preparer_subclassed_model_with_functional_lay": 42, "resembl": 42, "piec": [42, 80], "python": [42, 61, 68, 87, 90, 91, 92, 114, 134], "caus": [42, 126, 132, 133], "trace": [42, 79], "symbol": 42, "touch": 42, "static_patch_count": 42, "guarante": 42, "verifi": [42, 80], "furthermor": 42, "resu": 42, "resblock": 42, "twice": 42, "bad": 42, "bn1": [42, 72, 81, 84], "bn2": 42, "relu1": [42, 79, 81], "plug": [43, 65, 84], "conv2dtranspos": 43, "depthwiseconv2d": [43, 124], "crosslayersc": [43, 60, 65, 84], "scale_model": [43, 65, 84], "clssetinfo": [43, 65], "highbiasfold": [43, 60, 65, 84], "bias_fold": [43, 65, 84], "cls_set_info_list": [43, 65, 84], "bn_layer": [43, 84], "sigma": [43, 65, 84], "element": [43, 55, 65, 84], "model_transform_util": 43, "replace_relu6_with_relu": 43, "cross_layer_equalization_auto_stepwis": [43, 65], "relu6": [43, 62, 65, 75, 84, 112, 128], "model_for_cl": 43, "folded_pair": [43, 65, 84], "bn_dict": [43, 84], "conv_or_linear": 43, "group": [43, 65, 91, 105, 131, 133], "fold_given_batch_norm": [43, 60, 65, 84], "layer_pair": [43, 65, 84], "conv_linear": 43, "is_batch_norm_second": 43, "scale_cls_set": [43, 65, 84], "cls_set": [43, 65, 84], "cls_pair_1": [43, 65, 84], "cls_pair_2": [43, 65, 84], "hold": [43, 65, 75, 84, 104, 105, 112, 131], "along": [43, 60, 65, 83, 84, 104, 105, 115, 130, 133], "depth": [43, 84, 111, 120, 132], "wise": [43, 76, 84, 85, 132], "clssetlayerpairinfo": [43, 65, 84], "scale_factor": [43, 65, 84], "relu_activation_between_lay": [43, 65, 84], "relat": [43, 60, 61, 62, 65, 75, 76, 84, 114, 129, 133], "whose": [43, 63, 78, 80, 84, 105, 114, 128, 131, 134, 140], "cross_layer_equalization_manu": [43, 65, 84], "get_example_layer_pairs_resnet50_for_fold": 43, "consecutive_layer_list": [43, 65, 84], "get_consecutive_layer_list_from_resnet50_for_sc": [43, 65], "scaling_factor_list": [43, 65, 84], "format_info_for_high_bias_fold": [43, 65], "conv_op_1": [43, 65], "bn_op_1": [43, 65], "conv_op_2": [43, 65], "bn_op_2": [43, 65], "conv_op_3": [43, 65], "bn_op_3": [43, 65], "11": [43, 55, 83, 90, 91, 92, 99, 104], "bn_op": [43, 65], "upstream": [43, 65, 119, 140], "downstream": [43, 55, 65], "usag": [43, 55, 64, 65, 81, 83, 87, 110, 111, 120, 121, 125, 132], "conv_op": [43, 65, 69], "bn_op_with_meta": [43, 65], "_fold_upstream_flag": [43, 65], "boolean": [43, 65], "is_relu_activation_in_cls_set": [43, 65], "fill": [43, 65, 87], "create_cls_set_info_list": [43, 65], "quantanalyz": [44, 52, 53, 66, 67, 85, 114, 127, 134, 135], "pdf": [44, 66, 85, 135], "scalar": [44, 52, 58, 66, 85], "hotspot": [44, 66, 85, 129], "31": [44, 57, 58, 61, 71, 72, 75, 85, 87, 91, 92], "toi": 44, "256": [44, 52, 66, 85, 115, 129], "num_class": [44, 46, 58, 73], "ey": 44, "label_dataset": [44, 58], "own": [44, 49, 52, 54, 58, 59, 66, 68, 71, 73, 74, 75, 85, 87], "goal": [44, 49, 52, 58, 73, 85, 117], "action": [44, 52, 54, 59, 66, 68, 71, 74, 75, 85, 87, 140], "prepared_model": [44, 71, 80, 85, 87, 115], "forward_pass_callback_fn": [44, 52, 66, 85], "eval_callback_fn": [44, 52, 66, 85], "approxim": [44, 52, 66, 85, 116, 120, 128, 129], "quant_analyzer_result": [44, 52, 66, 85], "abil": [45, 53, 67, 86, 95, 135], "hardwar": [45, 53, 67, 86, 89, 127, 128, 133], "in_plac": [46, 87], "default_data_typ": [46, 68, 87], "quantizationdatatyp": [46, 68, 87, 114], "mechan": [46, 80, 87], "custom_object": 46, "store": [46, 57, 60, 65, 68, 71, 83, 87, 104, 105], "pth": [46, 68, 76, 78, 83, 87], "prefix": [46, 57, 61, 68, 71, 83, 87], "quantize_model": [46, 54, 68], "dummy_x": 46, "dummy_i": 46, "randint": [46, 58], "lr": [46, 115], "001": 46, "write": [48, 54, 68, 71, 87, 105], "ada_rounded_model": 48, "math": [49, 115], "auto_quant_v2": [49, 73], "onnx_model": [49, 50, 52, 54], "dummy_data": [49, 52, 54], "astyp": [49, 52, 54], "float32": [49, 52, 54], "Its": 49, "fed": 49, "unlabelled_data_load": 49, "ceil": [49, 71], "num_of_sampl": 49, "evaldataload": 49, "acc_top1": 49, "acc_top5": 49, "batch_avg_top_1_5": 49, "4f": [49, 73], "happen": [50, 77, 115], "dummy_input_dict": 51, "serializetostr": 51, "dir_path": [51, 63, 78], "interest": [52, 85], "create_quantsim_and_encod": 52, "unlabeled_data_load": [52, 73, 85], "_get_unlabled_data_load": [52, 85], "unlabeled_dataset_iter": [52, 73, 85], "autoqu": [53, 67, 86, 114, 121, 127, 130, 135], "unifi": [53, 67, 86], "integr": [53, 58, 67, 73, 82, 83, 86, 127], "max_batch_count": [54, 68, 71, 87], "current_batch_count": [54, 68, 71, 87], "use_symmetric_encod": [54, 114], "forward_pass_funct": 54, "syntax": [55, 94], "usabl": 55, "xx": 55, "yy": 55, "zz": 55, "major": [55, 125, 134], "revis": 55, "minor": [55, 135], "patch": 55, "substanti": 55, "fulli": [55, 61, 115, 124], "bug": [55, 135], "backward": [55, 84, 115], "assum": [55, 73, 92, 105], "activation_encod": 55, "tensor_nam": 55, "param_encod": [55, 114], "constraint": [55, 105], "depict": 55, "6086959838867188": 55, "109158515930176": 55, "114": 55, "018501389771699905": 55, "21": [55, 110], "558866932988167": 55, "12636379897594452": 55, "12": [55, 90, 91, 92, 99, 105], "010530316270887852": 55, "06318144500255585": 55, "06268782913684845": 55, "127": [55, 104], "0004936049808748066": 55, "fc1": [55, 80], "05589814856648445": 55, "05546144023537636": 55, "0004367042565718293": 55, "184721499681473": 55, "10788747668266296": 55, "0089906234367221": 55, "conv2d_1": [55, 61], "1020304188132286": 55, "10380396991968155": 55, "008650330936207491": 55, "readvariableop": [55, 68], "1462666392326355": 55, "1451239287853241": 55, "126": 55, "0011427081098743512": 55, "08333279937505722": 55, "08268175274133682": 55, "0006510374592799766": 55, "includ": [55, 58, 73, 87, 105, 114, 118, 125, 127, 129, 131, 133, 135], "field": 55, "dtype": [55, 80, 83, 102, 104, 105, 114], "datatyp": 55, "snippet": [55, 80, 105], "highlight": [55, 128, 137, 138], "quantizer_arg": 55, "activation_bitwidth": 55, "param_bitwidth": 55, "popul": [55, 60], "broken": 55, "occur": [55, 61, 68, 95, 105, 112], "who": 55, "knowledg": 55, "default_config_fil": [57, 58, 71], "conv2d_input": 57, "reset_default_graph": [57, 63, 68], "init": [57, 61, 83], "get_default_graph": 57, "default_rounding_mod": 58, "manner": [58, 73, 117], "meet": [58, 73, 90, 117, 120, 122], "datasetv1": [58, 59, 66], "unless": [58, 75, 92, 95, 140], "n": [58, 85, 105, 115, 135], "andoutput": 58, "fp32_sess": 58, "cache_id": [58, 73], "explicitli": [58, 140], "preced": [59, 74, 131], "var": [59, 74, 92], "load_fp32_model": [59, 74], "imagenetpipelin": [59, 74], "quant_sim": [59, 74, 87], "main": [60, 118, 131, 135, 138], "reference_model": 60, "conv_bn_dict": [60, 75], "perform_only_empirical_bias_corr": [60, 75], "convbninfotyp": 60, "find_all_convs_bn_with_activ": 60, "nest": 60, "graphsearchutil": [60, 65], "biasutil": [60, 65], "bias_correction_empir": 60, "biascorrectparam": 60, "fc1000": [60, 62, 65], "_new_sess": 60, "analyt": [60, 128, 137, 138], "bias_correction_empirical_analyt": 60, "bias_correction_after_cl": 60, "sess_after_cl": 60, "bias_correction_per_lay": 60, "corrected_model": 60, "layer_name_to_be_correct": 60, "analytical_bias_correction_per_lay": 60, "preceeding_bn_layer_info": 60, "is_first_conv": 60, "bc": [60, 116], "preceed": [60, 118], "bias_correction_single_layer_empir": 60, "initialize_model_with_bia": 60, "example_conv_lay": 60, "res2a_branch2a": [60, 65], "bias_correction_single_layer_analyt": 60, "convs_bn_activation_info_dict": 60, "sure": [60, 122, 126], "preceding_bn_layer_info": 60, "tar": 61, "train_model": [61, 76], "train_flag": [61, 76], "channels_last": 61, "downsamplelay": 61, "upsamplelay": 61, "teh": [61, 140], "evaluate_model": [61, 76], "honor": [61, 76], "obvious": [61, 76], "spatial_svd_auto_mod": [61, 76], "block1_conv1": 61, "compr_model_sess": 61, "pretti": [61, 76], "spatial_svd_manual_mod": [61, 76], "block1_conv2": 61, "channel_pruning_auto_mod": [61, 76], "channel_pruning_manual_mod": [61, 76], "block1_conv2_op": 61, "block2_conv2_op": 61, "block2_conv2": 61, "checkpoint": [61, 68, 87, 127], "output_fil": 61, "svd_graph": 61, "svd_type": 61, "num_lay": 61, "layer_rank": 61, "num_rank": 61, "no_evalu": 61, "layer_selection_threshold": 61, "connect": [61, 119, 124, 139], "balanc": [61, 125], "multipli": [61, 112, 120], "accumul": [61, 120], "footprint": 61, "ssvd": [61, 120], "length": [61, 94, 95, 105, 110, 112], "compression_point": 61, "valueerror": [61, 68], "compress_net": 61, "eval_nam": 61, "run_graph": 61, "evaluate_graph": [61, 68], "default_eval_func": [61, 68], "error_margin": 61, "avg": 61, "graph_ev": [61, 68], "prototyp": 61, "accept": [61, 128, 132], "degrad": [61, 125], "invalid": [61, 80, 105], "runtimeerror": 61, "tfrecord_gener": 61, "tf_gen": [61, 68], "mnistpars": [61, 68], "weight_svd_auto_mod": [61, 76], "alloc": [61, 68], "wish": [61, 68, 91, 92], "tfrecordgener": [61, 68], "mnist": [61, 68, 76], "parser": [61, 68], "mnist_sav": [61, 68], "95": 61, "pretty_print": 61, "weight_svd_manual_mod": [61, 76], "matmul_1": 61, "connectedgraph": [62, 65, 81], "hbf": [62, 65, 116], "new_sess": 62, "wherein": [63, 78], "saver": 63, "import_meta_graph": 63, "restor": [63, 87, 132], "trainbl": 64, "recompil": 64, "temp": 64, "clean": [64, 134], "recurr": [64, 135], "rnn": [64, 112, 135], "lstm": [64, 112, 135], "graph_util": 65, "after_relu_replace_sess": 65, "find_and_replace_relu6_with_relu": 65, "after_bn_fold_sess": 65, "after_cls_sess": 65, "after_hbf_sess": 65, "updated_sess": 65, "map_cls_sets_to_new_sess": 65, "tf_names_op_dict": 65, "get_layer_pairs_resnet50_for_fold": 65, "after_fold_sess": 65, "graph_search": 65, "bn2a_branch2a": 65, "cond": 65, "fusedbatchnorm_1": 65, "res2a_branch2b": 65, "bn2a_branch2b": 65, "res2a_branch2c": 65, "bn2a_branch2c": 65, "conv1_op": 65, "conv1_depthwise_op": 65, "conv1_pointwise_op": 65, "temp_cl": 65, "model_start_op_nam": 66, "model_output_op_nam": 66, "learnt": 68, "orig_sess": 68, "quantisim": 68, "tutori": [68, 115], "load_model_from_meta": 68, "reshape_input": 68, "dense_1": 68, "biasadd": 68, "trainingextens": [68, 87], "src": [68, 87], "quantization_aware_training_range_learn": 68, "parser2": 68, "generator2": 68, "cross_entropi": 68, "xent": 68, "train_step": 68, "simultan": 68, "fc1_w": 68, "matmul": [68, 112, 135], "perf": 68, "ce": 68, "adamoptim": 68, "tempadam": 68, "initialize_uninitialized_var": 68, "read_data_set": 68, "one_hot": 68, "next_batch": 68, "plotting_util": 69, "visualize_weight_ranges_single_lay": 69, "scatter": [69, 89], "bokeh": [69, 88, 89], "visualize_relative_weight_ranges_single_lay": 69, "publish": [69, 88, 89], "visualizing_weight_ranges_for_single_lay": 69, "visualiza": 69, "visualizing_relative_weight_ranges_for_single_lay": 69, "experiment": [71, 72, 73, 85, 87, 105, 114, 125, 131, 134], "v2": [71, 73, 85, 87, 94, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115], "namespac": [71, 73, 85, 87, 114, 134], "visit": [71, 73, 85, 87, 92, 111, 123], "overview": [71, 73, 85, 87, 114], "param_bw_override_list": 71, "ignore_quant_ops_list": 71, "pars": [71, 84, 87], "affect": [71, 105, 118, 131, 140], "commonli": 71, "10k": 71, "15k": 71, "get_train_dataload": [71, 74], "quantized_resnet18": [71, 87], "arch_check": 72, "archcheck": 72, "check_model_arch": 72, "result_dir": 72, "_node_check_dict": 72, "record": [72, 85], "fail": [72, 80, 81, 117, 126, 127], "arch_checker_report": 72, "dotted_name_op": 72, "nodeerrorreportobject": 72, "archcheckerreport": 72, "condit": [72, 80, 81], "less": [72, 105, 110, 112, 119, 122], "modelwithnotenoughchannel": 72, "prelu": [72, 112], "stride": [72, 80, 81, 115], "batchnorm2d": [72, 81, 84, 112, 115], "example_check_for_number_of_conv_channel": 72, "fewer": 72, "logger": [72, 81], "_check_conv_channel_32_bas": 72, "_check_conv_channel_larger_than_32": 72, "layer_nam": [72, 85], "modelwithprelu": 72, "prelu1": 72, "example_check_for_non_performant_activ": 72, "num_paramet": 72, "_activation_check": 72, "modelwithnonfoldablebn": 72, "foldabl": 72, "avg_pool1": 72, "avgpool2d": [72, 112], "example_check_for_standalone_bn": 72, "averagepool": 72, "ep": [72, 115], "05": [72, 92, 99, 100, 115], "momentum": [72, 115], "affin": [72, 83, 95, 96, 97, 98, 99, 100, 104, 105, 111, 112, 113, 115, 134], "track_running_stat": [72, 115], "_check_batch_norm_fold": 72, "strict_valid": 73, "model_prepare_requir": 73, "id": [73, 88, 91, 137], "cach": [73, 92], "hen": 73, "proce": 73, "unid": 73, "unintuit": 73, "_subset_sampl": 73, "sampler": 73, "fp32_model": 73, "fakedata": 73, "eval_data_load": 73, "dim": [73, 105, 115], "deprec": [73, 127], "dummy_input_on_cpu": 73, "dummy_input_on_gpu": 73, "layers_to_ignor": 75, "remain": [75, 114, 122, 127, 128, 133], "calc": 75, "corr": 75, "irrespect": 75, "fact": [75, 105], "elig": 75, "input_bn": 75, "output_bn": 75, "in_activation_typ": 75, "no_activ": 75, "out_activation_typ": 75, "hode": 75, "mobilenetv2": [75, 84], "512": 75, "module_prop_dict": 75, "find_all_conv_bn_with_activ": 75, "weightsvdparamet": 76, "tarrankselectionparamet": 76, "num_rank_indic": 76, "rank_select_schem": 76, "select_param": 76, "rankselectschem": 76, "mnist_trained_on_gpu": 76, "rank_select": 76, "mnist_torch_model": 76, "dataloadermnist": 76, "_layer_db": 76, "ture": 76, "batch_callback": 76, "spatial_svd_auto_mode_with_layerwise_finetun": 76, "torchscript": [78, 87, 111], "naming_schem": 78, "namingschem": 78, "onnx_export_arg": [78, 87], "onnxexportapiarg": [78, 87], "consist": [78, 105, 114, 117, 133, 140], "numer": 78, "onnx_util": 78, "pythonpath": [78, 121], "successfulli": [78, 126], "map_loc": 78, "model_torch": 78, "convers": [79, 132], "onnx_file_nam": 79, "jit": 79, "traceabl": [79, 80], "stateless": 79, "former": 79, "retrain": 79, "whenev": [79, 115], "image_rgb": 79, "rgb_output": 79, "image_bw": 79, "bw_output": 79, "rgb": 79, "bw": [79, 83, 87, 105], "elementwis": [80, 112, 135], "unrol": 80, "independ": [80, 132], "modules_to_exclud": 80, "module_classes_to_exclud": 80, "concrete_arg": 80, "duplic": 80, "exclud": [80, 81, 85], "partial": 80, "special": [80, 115], "control": [80, 112, 133, 134], "flow": [80, 82, 86, 118, 127, 130, 132, 133], "won": 80, "symbolic_trac": 80, "graphmodul": [80, 115], "modelwithfunctionalrelu": 80, "9216": 80, "fc2": 80, "model_preparer_functional_exampl": 80, "allclos": 80, "modelwithreusedrelu": 80, "model_preparer_reused_exampl": 80, "modelwithelementwiseaddop": 80, "x1": 80, "model_preparer_elementwise_add_exampl": 80, "dynam": [80, 102, 128, 133, 135, 138], "statement": [80, 114, 126], "branch": [80, 121, 131], "weren": 80, "traceerror": 80, "workaround": [80, 126], "problem": [80, 132], "across": [80, 83, 105, 128, 129], "Such": 80, "concret": 80, "truli": 80, "custom_function_not_to_be_trac": 80, "call_funct": 80, "__torch_function__": 80, "sqrt": [80, 112], "modelwithnontorchfunct": 80, "model_transform": 80, "tracer": 80, "is_leaf_modul": 80, "leaf": [80, 135], "expos": [80, 116], "module_to_exclud": 80, "examin": 80, "custommodul": 80, "softplu": [80, 112], "custommodel": 80, "arang": [80, 99, 100], "traceback": 80, "typeerror": 80, "receiv": 80, "proxi": 80, "layout": 80, "pin_memori": 80, "requires_grad": [80, 104], "problemat": [80, 132, 138], "determinist": 80, "hard": 80, "do_not_trace_m": 80, "share": [81, 92, 112], "modelwithreusednod": 81, "inplac": 81, "2592": 81, "view": [81, 111, 115, 123, 126, 137], "model_valid": 81, "modelvalid": 81, "validate_example_model": 81, "validate_model": 81, "validate_for_reused_modul": 81, "0x7f127685a598": 81, "resolv": 81, "warn": [81, 127], "redefin": [81, 115], "distinct": [81, 115], "rewrit": [81, 126], "modelwithoutreusednod": 81, "rerun": 81, "0x7ff577373598": 81, "validate_for_missing_modul": 81, "0x7ff5703eff28": 81, "modelwithfunctionallinear": 81, "0x7f9dd9bd90d0": 81, "matmul_8": 81, "reason": 81, "op_type_map": 81, "recogn": [81, 131, 133], "functional_op": 81, "modelwithoutfunctionallinear": 81, "parallel": 82, "dataparallel": [82, 86], "doesn": 82, "forth": 82, "larg": [83, 120, 130, 136, 139], "librari": [83, 125], "huggingfac": 83, "alon": 83, "loraconfig": 83, "get_peft_model": 83, "lora_config": 83, "lora_alpha": 83, "lora_dropout": 83, "target_modul": 83, "replace_lora_layers_with_quantizable_lay": 83, "alpha": 83, "track_lora_meta_data": 83, "meta_data": 83, "tmp_dir": 83, "convinplacelinear": 83, "peftquantutil": 83, "peft_util": 83, "name_to_module_dict": 83, "disable_lora_adapt": 83, "recomput": 83, "freeze_base_model_param_quant": 83, "tmpdir": 83, "export_model": [83, 87], "filename_prefix_encod": [83, 87], "base_encod": 83, "enable_adapter_and_load_weight": 83, "lora_weights_after_adaptation_for_adapter1": 83, "safetensor": 83, "use_safetensor": 83, "lora_modul": 83, "get_quantized_lora_lay": 83, "param_quant": [83, 94, 95, 105, 112, 114, 115], "quantizedequant": [83, 104, 105, 111, 112, 113, 114, 115], "base_model": 83, "adapter1": 83, "export_adapter_weight": 83, "adapter1_weight": 83, "configr": 83, "adaptermetadata": 83, "lora_a": 83, "lora_b": 83, "replaced_module_typ": 83, "adapater_name_to_meta_data": 83, "track_meta_data": 83, "pt": 83, "adapter_weights_path": 83, "bin": [83, 91, 92, 110], "onnx_model_path": 83, "freeze_base_model": 83, "freeze_base_model_activation_quant": 83, "vice": [83, 133], "versa": [83, 133], "set_bitwidth_for_lora_adapt": 83, "conv1d": [84, 112, 135], "convtranspose2d": [84, 112], "batchnorm1d": [84, 112], "cross_layer_equalization_auto_step_by_step": 84, "conv_bn": 84, "replace_modules_of_type1_with_type2": 84, "layer_list": 84, "clspairinfo": 84, "depthwis": [84, 118, 135], "cross_layer_equalization_depthwise_lay": 84, "encapsul": 85, "check_model_sensitivity_to_quant": 85, "perform_per_layer_analysis_by_enabling_quant_wrapp": 85, "occurr": [85, 119], "perform_per_layer_analysis_by_disabling_quant_wrapp": 85, "export_per_layer_encoding_min_max_rang": 85, "esults_dir": 85, "pcq": [85, 118, 129], "wrapped_module_nam": 85, "param_nam": 85, "export_per_layer_stats_histogram": 85, "ctivations_pdf": 85, "eights_pdf": 85, "am": 85, "channel_index": 85, "export_per_layer_mse_loss": 85, "tap": 85, "checker": 86, "concern": 86, "peft": 86, "lora": 86, "save_checkpoint": 87, "file_path": 87, "load_checkpoint": 87, "quant_sim_model": 87, "propagate_encod": 87, "export_to_torchscript": 87, "use_embedded_encod": 87, "opset_vers": 87, "enable_onnx_check": 87, "entri": [87, 131], "data_typ": [87, 114], "fakequ": 87, "forward_pass_arg": 87, "quatiz": 87, "unction": 87, "visualize_serialized_data": 88, "visualizecompress": [88, 137], "server": [88, 121], "tabl": [88, 112, 114, 121, 122, 126, 137], "display_eval_scor": [88, 137], "saved_eval_scores_dict_path": 88, "display_comp_ratio_plot": [88, 137], "comp_ratio_list_path": 88, "pkl": 88, "start_bokeh_server_sess": 88, "model_compression_with_visu": 88, "65": [88, 92, 120], "resnet18_eval_scor": 88, "comp_ratios_file_path": 88, "greedy_selection_comp_ratios_list": 88, "eval_scores_path": 88, "compression_visu": 88, "termin": [88, 121], "visualize_model": 89, "visualize_relative_weight_ranges_to_identify_problematic_lay": 89, "selected_lay": 89, "figur": [89, 116, 122, 132, 140], "visualize_weight_rang": 89, "deviat": 89, "visualize_changes_after_optim": 89, "old_model": 89, "new_model": 89, "visualize_changes_in_model_after_and_before_cl": 89, "visualiz": 89, "model_copi": 89, "visualize_weight_ranges_model": 89, "usual": [89, 115, 130], "visualize_relative_weight_ranges_model": 89, "pypi": 90, "intel": 90, "x86": 90, "processor": 90, "linux": [90, 92], "ubuntu": [90, 92], "22": [90, 92, 115], "04": [90, 92], "lt": [90, 92], "pip": [90, 91, 92, 111, 121], "apt": [90, 91, 92, 111], "liblapack": [90, 91, 92, 111], "python3": [90, 91, 92, 111, 121], "variant": [90, 92, 130, 133], "latest": [90, 91], "whl": [90, 91, 92], "host": [90, 91, 92, 135, 137], "github": [90, 91, 92, 120, 121, 135], "com": [90, 91, 92, 121, 135], "quic": [90, 91, 92, 120, 121, 135], "cu118": [90, 91, 92], "cp310": [90, 91, 92], "manylinux_2_34_x86_64": [90, 91, 92], "13": [90, 91, 99], "cu117": 90, "14": [90, 99, 115], "older": 90, "brows": [90, 91, 92], "platform": [90, 127], "setup": [90, 114], "bash": [90, 91], "command": [90, 91, 92, 121, 137], "shell": 90, "nvidia": [90, 91, 92], "card": 90, "capabl": [90, 112, 137, 138], "docker": 90, "455": 90, "newer": 90, "cudnn": 90, "machin": [90, 91, 125], "develop": [90, 91, 92, 95, 105, 112, 134], "click": 90, "instruct": [91, 92, 111, 121], "variant_str": 91, "ONE": 91, "pt113": 91, "aimet_vari": 91, "workspac": [91, 121], "absolute_path_to_workspac": [91, 121], "docker_image_nam": 91, "codelinaro": 91, "dev": [91, 92], "docker_container_nam": 91, "any_nam": 91, "any_tag": 91, "jenkin": 91, "dockerfil": 91, "p": 91, "grep": 91, "kill": 91, "rm": 91, "passwd": 91, "ro": 91, "home": 91, "mnt": 91, "entrypoint": 91, "hostnam": 91, "filesystem": 91, "port": [91, 114, 137], "port_id": 91, "project": [91, 92], "tip": [91, 92], "post1": [91, 92], "prepend": [91, 92], "sudo": [91, 92, 121], "wheel": [91, 92], "tag": [91, 92, 121, 135], "ex": [91, 92, 105], "release_tag": [91, 92, 121], "download_url": [91, 92], "extens": [91, 92, 112, 121], "wheel_file_nam": [91, 92], "usr": [91, 92], "lib": [91, 92], "dist": [91, 92], "envsetup": [91, 92], "sh": [91, 92], "pend": [92, 121], "pip3": 92, "h": [92, 121, 139, 140], "local": [92, 137], "requisit": 92, "upgrad": 92, "wget": 92, "gnupg2": 92, "archiv": 92, "exact": [92, 112, 118], "date": 92, "repo": [92, 121], "ubuntu2204": 92, "x86_64": 92, "pin": 92, "mv": 92, "prefer": [92, 125], "d": [92, 96, 97, 99, 100, 113], "repositori": 92, "600": 92, "local_instal": 92, "local_11": 92, "520": 92, "61": 92, "1_amd64": 92, "deb": 92, "adv": 92, "fetch": 92, "3bf863cc": 92, "pub": 92, "dpkg": 92, "cp": [92, 120], "keyr": 92, "gpg": 92, "echo": 92, "515": 92, "cat": 92, "reqs_deb_common": 92, "txt": 92, "xarg": 92, "reqs_deb_torch_common": 92, "reqs_deb_onnx_common": 92, "reqs_deb_tf_gpu": 92, "reqs_deb_torch_gpu": 92, "reqs_deb_onnx_gpu": 92, "uninstal": 92, "onnxruntime_v": 92, "c": [92, 120], "__version__": 92, "ln": 92, "gnu": 92, "libjpeg": 92, "chose": 92, "mixin": [94, 95, 112], "held": [94, 115], "quantizerbas": [94, 95, 112, 113], "behav": [94, 95, 112, 132], "parent": [94, 95], "scratch": 94, "from_modul": [94, 95], "input_quant": [94, 95, 112, 114, 115], "modulelist": [94, 95, 112, 114, 115], "output_quant": [94, 95, 112, 114, 115], "moduledict": [94, 95, 112, 114, 115], "qlinear": [94, 95, 112, 114], "fakequantizedlinear": [94, 112], "in_featur": [94, 95, 112, 114, 115], "out_featur": [94, 95, 112, 114, 115], "abstract": [94, 95, 112, 113], "__quant_init__": [94, 95, 112], "initializd": [94, 95, 112], "overridden": [94, 95, 112], "enter": [94, 95, 112, 117], "context": [94, 95, 112, 115], "exit": [94, 95, 112, 115], "quantizedlinear": [94, 95, 105, 112, 114, 115], "is_initi": [94, 95, 96, 97, 102, 112, 113], "classmethod": [94, 95], "quantized_linear": [94, 95], "module_cl": [94, 95], "decor": [94, 95], "heavi": [95, 105, 112, 137, 138], "notic": [95, 105, 112, 125], "futur": [95, 105, 112, 134], "verion": 95, "fakequantizationmixin": [95, 111, 112], "fall": [95, 122, 131], "get_kernel": 95, "dequant": [95, 97, 100, 104, 111, 112, 113, 133], "set_kernel": 95, "quantizedtensor": [95, 96, 104, 113], "keyword": 95, "output_encod": 95, "underli": [95, 132], "q": [95, 96, 97, 99, 100, 102, 104, 112, 113, 114, 133], "int_multipli": 95, "enc": 95, "notimplementederror": 95, "q_output": 95, "quantized_repr": [95, 104], "dq_output": 95, "qmult": 95, "quantizedmultipli": [95, 112], "set_default_kernel": 95, "quantized_forward": 95, "get_default_kernel": 95, "encoding_analyz": [96, 97, 102, 106, 108, 109, 110, 113], "block_siz": [96, 97, 98, 99, 100, 105, 113], "clamp": [96, 97, 99, 100, 102, 113, 133], "lceil": [96, 97, 99, 100, 102, 113], "frac": [96, 97, 99, 100, 102, 113], "rfloor": [96, 97, 99, 100, 102, 113], "qmin": [96, 97, 99, 100, 113, 133], "qmax": [96, 97, 99, 100, 113, 133], "learnabl": [96, 97, 113], "theta_": [96, 97, 113], "pmatrix": [96, 97, 99, 100, 113], "b_0": [96, 97, 99, 100, 113], "b_1": [96, 97, 99, 100, 105, 113], "cdot": [96, 97, 99, 100, 113], "b_": [96, 97, 99, 100, 113], "equat": [96, 97, 99, 100, 105, 113, 133], "out_": [96, 97, 99, 100, 113], "j_0": [96, 97, 99, 100, 113], "j_": [96, 97, 99, 100, 113], "input_": [96, 97, 99, 100, 113], "scale_": [96, 97, 99, 100, 113], "i_0": [96, 97, 99, 100, 113], "i_": [96, 97, 99, 100, 113], "offset_": [96, 97, 99, 100, 113], "quad": [96, 97, 99, 100, 113, 133], "forall_": [96, 97, 99, 100, 113], "leq": [96, 97, 99, 100, 113], "i_d": [96, 97, 99, 100, 113], "lfloor": [96, 97, 99, 100, 102, 113], "j_d": [96, 97, 99, 100, 113], "b_d": [96, 97, 99, 100, 113], "asymmetr": [96, 97, 110, 113, 131, 133], "encodinganalyz": [96, 97, 102, 106, 113], "129": [96, 113, 126], "255": [96, 104, 113], "122": [96, 113], "192": [96, 113], "106": [96, 113], "94": [96, 113], "145": [96, 113], "181": [96, 113], "144": [96, 113], "194": [96, 113], "74": [96, 113], "86": [96, 113], "150": [96, 113], "103": [96, 113], "37": [96, 113], "111": [96, 113], "237": [96, 113], "218": [96, 113], "49": [96, 113], "155": [96, 113], "179": [96, 113], "89": [96, 113], "110": [96, 113], "17": [96, 110, 113], "36": [96, 113], "83": [96, 113], "grad_fn": [96, 97, 104, 113], "aliasbackward0": [96, 97, 104, 113], "ones_lik": [96, 97, 113], "187": [96, 113], "186": [96, 113], "131": [96, 113], "203": [96, 113], "143": [96, 113], "152": [96, 113], "226": [96, 113], "55": [96, 113], "172": [96, 113], "207": [96, 113], "146": [96, 113], "216": [96, 113], "238": [96, 113], "141": [96, 113], "178": [96, 113], "188": [96, 113], "63": [96, 113], "59": [96, 113], "19": [96, 113], "162": [96, 113], "30": [96, 113], "109": [96, 113], "overlin": [97, 100, 113], "qdq": [97, 102, 113], "dequantizedtensor": [97, 104, 113], "2771": [97, 113], "3038": [97, 113], "0819": [97, 113], "9700": [97, 113], "9487": [97, 113], "1307": [97, 113], "7894": [97, 113], "1709": [97, 113], "2212": [97, 113], "7741": [97, 113], "0295": [97, 113], "2265": [97, 113], "0564": [97, 113], "6177": [97, 113], "0386": [97, 113], "0176": [97, 113], "6054": [97, 113], "8836": [97, 113], "1232": [97, 113], "8229": [97, 113], "5540": [97, 113], "3992": [97, 113], "2363": [97, 113], "2546": [97, 113], "0036": [97, 113], "2355": [97, 113], "1741": [97, 113], "6079": [97, 113], "6247": [97, 113], "0115": [97, 113], "2458": [97, 113], "9157": [97, 113], "4694": [97, 113], "0639": [97, 113], "2568": [97, 113], "0680": [97, 113], "6695": [97, 113], "7932": [97, 113], "1889": [97, 113], "0158": [97, 113], "5695": [97, 113], "5220": [97, 113], "1977": [97, 113], "4475": [97, 113], "0424": [97, 113], "1128": [97, 113], "8796": [97, 113], "1060": [97, 113], "5897": [97, 113], "6196": [97, 113], "9961": [97, 113], "0549": [97, 113], "6431": [97, 113], "0039": [97, 113], "8706": [97, 113], "4706": [97, 113], "2353": [97, 113], "8078": [97, 113], "3451": [97, 113], "1176": [97, 113], "4549": [97, 113], "0471": [97, 113], "5255": [97, 113], "4157": [97, 113], "0784": [97, 113], "5333": [97, 100, 113], "1647": [97, 113], "2118": [97, 113], "2196": [97, 113], "9176": [97, 113], "9490": [97, 113], "7765": [97, 113], "4784": [97, 113], "6039": [97, 113], "3137": [97, 113], "3216": [97, 113], "8000": [97, 100, 113], "4392": [97, 113], "4863": [97, 113], "overload": [99, 100], "sign": [99, 100, 114, 133], "rceil": [99, 100], "num_step": [99, 100, 110], "num": [99, 100], "_step": [99, 100], "0000e": [99, 100], "5000e": [99, 100], "02": [99, 100], "1921e": [99, 100], "08": [99, 100], "0500e": [99, 100], "1000e": [99, 100], "1500e": [99, 100], "2000e": [99, 100], "2500e": [99, 100], "0000": [100, 104], "0667": 100, "1333": 100, "2667": 100, "3333": 100, "4000": [100, 104], "4667": 100, "6000": [100, 104], "6667": 100, "7333": 100, "8667": 100, "9333": 100, "exponent_bit": [102, 105], "mantissa_bit": [102, 105], "expon": [102, 105], "mantissa": [102, 105], "x_c": 102, "log_2": 102, "ieee": [102, 125, 128], "_max": 102, "mutual": [102, 105], "exclus": [102, 105], "finer": [102, 105, 134], "8998": 102, "0947": 102, "0891": 102, "1727": 102, "affinequant": [102, 114], "floatquant": [102, 114], "is_bfloat16": 102, "8984": 102, "0859": 102, "1729": 102, "minmaxencodinganalyz": [102, 111, 114], "float16": [102, 105, 114], "is_float16": 102, "8994": 102, "0889": 102, "alia": 102, "encodingbas": [104, 113], "57": 104, "312": 104, "153": 104, "205": 104, "set_rang": 104, "x_q": 104, "26": 104, "23": 104, "x_dq": 104, "carri": 104, "gradient": 104, "thu": 104, "autograd": 104, "backpropag": 104, "38": [104, 125], "40": 104, "39": [104, 115], "51": 104, "521": 104, "41": 104, "quant_dequ": 104, "x_qdq": 104, "52": 104, "68": 104, "97": 104, "uint8": 104, "counterpart": [105, 112], "particular": [105, 127, 131], "come": [105, 130, 133], "pro": 105, "con": 105, "storag": 105, "drawback": 105, "outlier": [105, 129, 133], "influenc": 105, "resid": [105, 135], "chunk": 105, "favor": 105, "relationship": 105, "long": 105, "b_2": 105, "b_n": 105, "s_1": 105, "s_2": 105, "s_n": 105, "evenli": 105, "divid": [105, 112, 130], "divis": 105, "permit": 105, "3d": 105, "arbitrari": 105, "themselv": [105, 130], "quantizedconv2d": [105, 112, 114, 115], "linear_1": 105, "lie": 105, "leverag": 105, "expans": [105, 125], "groupedblockquantizedequant": 105, "introduc": [105, 127, 131, 133], "decompressed_bw": 105, "expand": [105, 112], "block_group": 105, "config_util": 105, "set_blockwise_quantization_for_weight": 105, "in_channel": [105, 115], "out_channel": [105, 115], "input_channel": 105, "linear1": 105, "isinst": 105, "switch": 105, "docstr": 105, "4d": 105, "assist": [105, 137, 138], "set_activation_quantizers_to_float": 105, "set_grouped_blockwise_quantization_for_weight": 105, "decompress": 105, "addition": 105, "larger": [105, 136, 139], "encoding_vers": 105, "exported_model": 105, "num_bin": [109, 110], "2048": [109, 110], "set_percentil": 109, "largest": 109, "smallest": 109, "asymmetric_delta_candid": 110, "symmetric_delta_candid": 110, "101": 110, "offset_candid": 110, "max_parallel": 110, "gamma": 110, "sqnr": [110, 133], "paral": 110, "compute_encodings_from_stat": 110, "lowest": 110, "_histogram": 110, "edg": [111, 123], "incur": [111, 123, 129], "instal": [111, 135], "sample_input": [111, 115], "sample_output": 111, "out_dir": 111, "quantized_model": 111, "quickstart": 111, "sqnrencodinganalyz": [111, 114], "percentileencodinganalyz": [111, 114], "quantizationmixin": [111, 112], "quantize_dequant": 111, "product": [111, 123], "technologi": [111, 123], "subsidiari": [111, 123], "nativ": 112, "superset": 112, "coverag": 112, "basequantizationmixin": 112, "respons": [112, 125], "qmul": 112, "sens": 112, "qadd": 112, "quantizedadd": 112, "calibration_data_load": 112, "adaptiveavgpool1d": 112, "fakequantizedadaptiveavgpool1d": 112, "adaptiveavgpool2d": 112, "fakequantizedadaptiveavgpool2d": 112, "adaptiveavgpool3d": 112, "fakequantizedadaptiveavgpool3d": 112, "adaptivemaxpool1d": 112, "fakequantizedadaptivemaxpool1d": 112, "adaptivemaxpool2d": 112, "fakequantizedadaptivemaxpool2d": 112, "adaptivemaxpool3d": 112, "fakequantizedadaptivemaxpool3d": 112, "alphadropout": 112, "fakequantizedalphadropout": 112, "avgpool1d": 112, "fakequantizedavgpool1d": 112, "fakequantizedavgpool2d": 112, "avgpool3d": 112, "fakequantizedavgpool3d": 112, "fakequantizedbatchnorm1d": 112, "fakequantizedbatchnorm2d": 112, "batchnorm3d": 112, "fakequantizedbatchnorm3d": 112, "celu": 112, "fakequantizedcelu": 112, "channelshuffl": 112, "fakequantizedchannelshuffl": 112, "constantpad1d": 112, "fakequantizedconstantpad1d": 112, "constantpad2d": 112, "fakequantizedconstantpad2d": 112, "constantpad3d": 112, "fakequantizedconstantpad3d": 112, "fakequantizedconv1d": 112, "quantizedconv1d": 112, "fakequantizedconv2d": 112, "conv3d": 112, "fakequantizedconv3d": 112, "quantizedconv3d": 112, "convtranspose1d": [112, 135], "fakequantizedconvtranspose1d": 112, "fakequantizedconvtranspose2d": 112, "convtranspose3d": 112, "fakequantizedconvtranspose3d": 112, "crossmaplrn2d": 112, "fakequantizedcrossmaplrn2d": 112, "fakequantizeddropout": 112, "dropout2d": 112, "fakequantizeddropout2d": 112, "dropout3d": 112, "fakequantizeddropout3d": 112, "elu": 112, "fakequantizedelu": 112, "featurealphadropout": 112, "fakequantizedfeaturealphadropout": 112, "fakequantizedflatten": 112, "fakequantizedfold": 112, "fractionalmaxpool2d": 112, "fakequantizedfractionalmaxpool2d": 112, "fractionalmaxpool3d": 112, "fakequantizedfractionalmaxpool3d": 112, "gelu": 112, "fakequantizedgelu": 112, "quantizedgelu": 112, "glu": 112, "fakequantizedglu": 112, "groupnorm": 112, "fakequantizedgroupnorm": 112, "hardshrink": 112, "fakequantizedhardshrink": 112, "hardsigmoid": 112, "fakequantizedhardsigmoid": 112, "hardswish": 112, "fakequantizedhardswish": 112, "hardtanh": 112, "fakequantizedhardtanh": 112, "fakequantizedident": 112, "instancenorm1d": 112, "fakequantizedinstancenorm1d": 112, "instancenorm2d": 112, "fakequantizedinstancenorm2d": 112, "instancenorm3d": 112, "fakequantizedinstancenorm3d": 112, "lppool1d": 112, "fakequantizedlppool1d": 112, "lppool2d": 112, "fakequantizedlppool2d": 112, "fakequantizedlayernorm": 112, "quantizedlayernorm": 112, "leakyrelu": 112, "fakequantizedleakyrelu": 112, "localresponsenorm": 112, "fakequantizedlocalresponsenorm": 112, "logsigmoid": 112, "fakequantizedlogsigmoid": 112, "logsoftmax": 112, "fakequantizedlogsoftmax": 112, "maxpool1d": 112, "fakequantizedmaxpool1d": 112, "maxpool2d": 112, "fakequantizedmaxpool2d": 112, "maxpool3d": 112, "fakequantizedmaxpool3d": 112, "maxunpool1d": 112, "fakequantizedmaxunpool1d": 112, "maxunpool2d": 112, "fakequantizedmaxunpool2d": 112, "maxunpool3d": 112, "fakequantizedmaxunpool3d": 112, "mish": 112, "fakequantizedmish": 112, "fakequantizedprelu": 112, "pixelshuffl": 112, "fakequantizedpixelshuffl": 112, "pixelunshuffl": 112, "fakequantizedpixelunshuffl": 112, "rrelu": 112, "fakequantizedrrelu": 112, "fakequantizedrelu": [112, 114, 115], "fakequantizedrelu6": 112, "reflectionpad1d": 112, "fakequantizedreflectionpad1d": 112, "reflectionpad2d": 112, "fakequantizedreflectionpad2d": 112, "replicationpad1d": 112, "fakequantizedreplicationpad1d": 112, "replicationpad2d": 112, "fakequantizedreplicationpad2d": 112, "replicationpad3d": 112, "fakequantizedreplicationpad3d": 112, "selu": 112, "fakequantizedselu": 112, "silu": 112, "fakequantizedsilu": 112, "fakequantizedsigmoid": 112, "quantizedsigmoid": 112, "fakequantizedsoftmax": 112, "quantizedsoftmax": [112, 115], "softmax2d": 112, "fakequantizedsoftmax2d": 112, "softmin": 112, "fakequantizedsoftmin": 112, "fakequantizedsoftplu": 112, "softshrink": 112, "fakequantizedsoftshrink": 112, "softsign": 112, "fakequantizedsoftsign": 112, "syncbatchnorm": 112, "fakequantizedsyncbatchnorm": 112, "tanh": 112, "fakequantizedtanh": 112, "tanhshrink": 112, "fakequantizedtanhshrink": 112, "fakequantizedthreshold": 112, "unflatten": 112, "fakequantizedunflatten": 112, "unfold": 112, "fakequantizedunfold": 112, "upsampl": [112, 126], "fakequantizedupsampl": 112, "upsamplingbilinear2d": 112, "fakequantizedupsamplingbilinear2d": 112, "upsamplingnearest2d": 112, "fakequantizedupsamplingnearest2d": 112, "zeropad2d": 112, "fakequantizedzeropad2d": 112, "bceloss": 112, "fakequantizedbceloss": 112, "bcewithlogitsloss": 112, "fakequantizedbcewithlogitsloss": 112, "bilinear": [112, 126], "fakequantizedbilinear": 112, "ctcloss": 112, "fakequantizedctcloss": 112, "cosinesimilar": 112, "fakequantizedcosinesimilar": 112, "crossentropyloss": [112, 115], "fakequantizedcrossentropyloss": 112, "hingeembeddingloss": 112, "fakequantizedhingeembeddingloss": 112, "huberloss": 112, "fakequantizedhuberloss": 112, "kldivloss": 112, "fakequantizedkldivloss": 112, "l1loss": 112, "fakequantizedl1loss": 112, "mseloss": 112, "fakequantizedmseloss": 112, "multilabelmarginloss": 112, "fakequantizedmultilabelmarginloss": 112, "multilabelsoftmarginloss": 112, "fakequantizedmultilabelsoftmarginloss": 112, "multimarginloss": 112, "fakequantizedmultimarginloss": 112, "nllloss": 112, "fakequantizednllloss": 112, "nllloss2d": 112, "fakequantizednllloss2d": 112, "pairwisedist": 112, "fakequantizedpairwisedist": 112, "poissonnllloss": 112, "fakequantizedpoissonnllloss": 112, "smoothl1loss": 112, "fakequantizedsmoothl1loss": 112, "softmarginloss": 112, "fakequantizedsoftmarginloss": 112, "cosineembeddingloss": 112, "fakequantizedcosineembeddingloss": 112, "gaussiannllloss": 112, "fakequantizedgaussiannllloss": 112, "marginrankingloss": 112, "fakequantizedmarginrankingloss": 112, "tripletmarginloss": 112, "fakequantizedtripletmarginloss": 112, "tripletmarginwithdistanceloss": 112, "fakequantizedtripletmarginwithdistanceloss": 112, "fakequantizedembed": 112, "embeddingbag": 112, "fakequantizedembeddingbag": 112, "gru": [112, 135], "fakequantizedgru": 112, "fakequantizedrnn": 112, "grucel": 112, "fakequantizedgrucel": 112, "rnncell": 112, "fakequantizedrnncel": 112, "fakequantizedlstm": 112, "lstmcell": 112, "fakequantizedlstmcel": 112, "adaptivelogsoftmaxwithloss": 112, "fakequantizedadaptivelogsoftmaxwithloss": 112, "aimet_op": 112, "fakequantizedcast": 112, "depthtospacedcrmod": 112, "fakequantizeddepthtospacedcrmod": 112, "onehot": 112, "fakequantizedonehot": 112, "exponenti": 112, "fakequantizedexponenti": 112, "erf": 112, "fakequantizederf": 112, "fakequantizedsqrt": 112, "fakequantizedlog": 112, "fakequantizedab": 112, "fakequantizedneg": 112, "elementwiseceil": 112, "fakequantizedelementwiseceil": 112, "elementwisefloor": 112, "fakequantizedelementwisefloor": 112, "sin": 112, "fakequantizedsin": 112, "co": 112, "fakequantizedco": 112, "asin": 112, "fakequantizedasin": 112, "atan": 112, "fakequantizedatan": 112, "fakequantizedround": 112, "logicalnot": 112, "fakequantizedlogicalnot": 112, "nonzero": 112, "fakequantizednonzero": 112, "elementwiseunarysign": 112, "fakequantizedelementwiseunarysign": 112, "rsqrt": 112, "fakequantizedrsqrt": 112, "squar": [112, 133], "fakequantizedsquar": 112, "fakequantizedmean": 112, "fakequantizedsum": 112, "prod": 112, "fakequantizedprod": 112, "argmin": 112, "fakequantizedargmin": 112, "fakequantizedargmax": 112, "gather": 112, "fakequantizedgath": 112, "reshap": 112, "fakequantizedreshap": 112, "roialign": 112, "fakequantizedroialign": 112, "permut": 112, "fakequantizedpermut": 112, "indexselect": 112, "fakequantizedindexselect": 112, "fakequantizedtopk": 112, "tile": 112, "fakequantizedtil": 112, "fakequantizednorm": 112, "cumsum": 112, "fakequantizedcumsum": 112, "interpol": [112, 122], "fakequantizedinterpol": 112, "fakequantizedpad": 112, "fakequantizedshap": 112, "fakequantizedexpand": 112, "stridedslic": 112, "fakequantizedstridedslic": 112, "fakequantizedmatmul": 112, "fakequantizedadd": 112, "fakequantizedmultipli": 112, "subtract": 112, "fakequantizedsubtract": 112, "quantizedsubtract": 112, "fakequantizeddivid": 112, "floordivid": 112, "fakequantizedfloordivid": 112, "fakequantizedgreat": 112, "fakequantizedless": 112, "greaterequ": 112, "fakequantizedgreaterequ": 112, "lessequ": 112, "fakequantizedlessequ": 112, "notequ": 112, "fakequantizednotequ": 112, "fakequantizedequ": 112, "remaind": 112, "fakequantizedremaind": 112, "fmod": 112, "fakequantizedfmod": 112, "pow": 112, "fakequantizedpow": 112, "customsilu": 112, "fakequantizedcustomsilu": 112, "fakequantizedmaximum": 112, "fakequantizedmax": 112, "fakequantizedminimum": 112, "fakequantizedmin": 112, "bmm": 112, "fakequantizedbmm": 112, "logicalor": 112, "fakequantizedlogicalor": 112, "logicaland": 112, "fakequantizedlogicaland": 112, "customgath": 112, "fakequantizedcustomgath": 112, "gathernd": 112, "fakequantizedgathernd": 112, "baddbmm": 112, "fakequantizedbaddbmm": 112, "addmm": 112, "fakequantizedaddmm": 112, "scatternd": 112, "fakequantizedscatternd": 112, "dynamicconv2d": 112, "fakequantizeddynamicconv2d": 112, "scatterel": 112, "fakequantizedscatterel": 112, "fakequantizedbatchnorm": 112, "fakequantizedaimetgroupnorm": 112, "nonmaxsuppress": 112, "fakequantizednonmaxsuppress": 112, "fakequantizedsplit": 112, "concat": [112, 135], "fakequantizedconcat": 112, "fakequantizedwher": 112, "maskedfil": 112, "fakequantizedmaskedfil": 112, "allow_overwrit": [113, 114], "allow_overwit": 113, "get_encod": 113, "get_legacy_encod": 113, "register_quantization_paramet": 113, "set_legacy_encod": 113, "simpler": 114, "extend": [114, 134], "fundament": 114, "advis": [114, 127, 131, 134], "subject": [114, 134], "properti": 114, "compon": [114, 134], "seq_ms": 114, "apply_seq_ms": 114, "longer": [114, 127, 130], "libpymo": 114, "stai": 114, "quantizewrapp": 114, "quantizationsimmodelv1": 114, "all_quant_wrapp": 114, "quant_wrapp": 114, "staticgridquantwrapp": 114, "_module_to_wrap": 114, "quantizationsimmodelv2": 114, "sim2": 114, "all_q_modul": 114, "qmodul": 114, "q_modul": 114, "staticgridquant": 114, "learnedgridquant": 114, "tensor_quant": 114, "staticgridperchannelquant": 114, "fp_quantiz": 114, "affine_quant": 114, "affine_q": 114, "affine_qdq": 114, "fp_qdq": 114, "floatquantizedequant": 114, "sim1": 114, "wrap_linear": 114, "symmetri": 114, "is_unsigned_symmetr": 114, "use_strict_symmetr": 114, "simplifi": 114, "tfencod": 114, "copy_": 114, "OR": 114, "_remove_input_quant": 114, "_remove_output_quant": 114, "_remove_param_quant": 114, "temporarili": 114, "_is_encoding_frozen": 114, "freeze_encod": 114, "concept": 114, "mimick": 114, "requires_grad_": 114, "overwritten": 114, "ti": 114, "portabl": [114, 134], "learnedgridquantwrapp": 114, "encodinganalyzerforpython": 114, "affineencod": 114, "floatencod": 114, "vectorencod": 114, "meant": 115, "clearli": 115, "cifar10_train_data": 115, "fashionmnist": 115, "cifar10": 115, "cifar10_test_data": 115, "test_load": 115, "bn_1": 115, "bn_2": 115, "establish": 115, "send": 115, "batch_idx": 115, "zero_grad": 115, "fp_accuraci": 115, "91": 115, "70999908447266": 115, "coupl": [115, 116], "conform": 115, "wherea": [115, 133], "incorrectli": 115, "thankfulli": 115, "fp_accuracy_prepar": 115, "2024": 115, "07": 115, "747": 115, "806": 115, "module_relu": 115, "module_relu_1": 115, "module_softmax": 115, "12544": 115, "getattr_1": 115, "getitem": 115, "graph_modul": 115, "print_read": 115, "idea": 115, "passthrough": 115, "previous": 115, "theoret": 115, "idx": 115, "quantized_accuraci": 115, "1500015258789": 115, "discuss": [115, 120, 132, 133], "advanc": [115, 134], "post_qat_accuraci": 115, "92": 115, "05333709716797": 115, "happi": 115, "export_path": 115, "model_nam": 115, "fashion_mnist_model": 115, "sent": 115, "bnf": 116, "moder": 116, "preprat": 117, "mainli": 117, "decreas": 118, "oscil": 118, "presenc": 119, "residu": 119, "reduct": 120, "uncompress": 120, "latenc": 120, "vari": [120, 122, 128, 138], "io": [120, 135], "half": 120, "unknown": 120, "apriori": 120, "cssvd": 120, "75": 120, "2b": 120, "2a": 120, "revisit": 120, "ccp": 120, "csvd": 120, "becom": [121, 128], "familiar": [121, 134], "browsabl": 121, "metapackag": 121, "ip": 121, "browser": 121, "past": 121, "mkdir": 121, "cd": 121, "packag": [121, 135], "git": 121, "www": 121, "navig": [121, 134], "launch": 121, "ipynb": 121, "therein": 121, "assess": 122, "highest": 122, "column": 122, "unmodifi": 122, "strict": [122, 131, 133], "curv": 122, "core": 122, "met": 122, "binari": 122, "solut": [122, 130, 132], "lesser": [122, 125], "drstical": 122, "hw": 123, "redund": 123, "dilat": 124, "guidebook": [125, 127], "advic": 125, "phase": [125, 127], "nomin": 125, "fc": 125, "term": [125, 136, 137, 138, 139], "sharp": 125, "carefulli": 125, "slow": 125, "searcher": 125, "strike": 125, "xiangyu": 125, "zhang": 125, "jianhua": 125, "zou": 125, "kaim": 125, "he": 125, "jian": 125, "sun": 125, "deep": 125, "transact": 125, "pattern": 125, "intellig": 125, "vol": 125, "pp": 125, "1943": 125, "1955": 125, "oct": 125, "2016": 125, "yihui": 125, "confer": [125, 128], "vision": [125, 128], "venic": 125, "2017": 125, "1398": 125, "1406": 125, "jaderberg": 125, "andrea": 125, "vedaldi": 125, "andrew": 125, "zisserman": 125, "british": 125, "jan": 125, "2014": 125, "andrei": 125, "kuzmin": 125, "marku": [125, 128], "nagel": [125, 128], "saurabh": 125, "pitr": 125, "sandeep": 125, "pendyam": 125, "tijmen": [125, 128], "blankevoort": [125, 128], "taxonomi": 125, "primit": 126, "slice": 126, "align_corn": 126, "deconvolut": 126, "deeplabv3": 126, "address": [126, 132, 137], "advantag": 127, "fast": 127, "easi": [127, 129], "gap": 127, "robust": 127, "account": [127, 130, 132], "prep": 127, "align": 127, "retri": 127, "hand": 127, "satisfactori": [127, 132], "bring": 127, "onto": 127, "pb": 127, "trial": 127, "seem": 127, "bat": 127, "surround": 128, "big": 128, "discrep": 128, "wide": 128, "significantli": 128, "quantizaion": 128, "bottleneck": [128, 132], "hybrid": 128, "approach": [128, 133], "mart": 128, "van": 128, "baalen": 128, "seoul": 128, "octob": 128, "rune": 129, "situat": 129, "pinpoint": 129, "culprit": 129, "toss": 129, "monitor": 129, "contribut": [129, 132], "mitig": [130, 133], "accompani": 130, "throughout": [130, 131, 134, 138], "aid": 130, "converg": 130, "six": 131, "overrul": 131, "turn": 131, "empti": 131, "omit": 131, "asid": 131, "govern": 131, "unsign": [131, 133], "convent": 131, "member": 131, "whatev": 131, "earlier": 131, "diagnost": 132, "strictli": 132, "insight": [132, 137, 138], "underperform": 132, "tackl": 132, "chart": 132, "saniti": 132, "ofth": 132, "kept": 132, "toward": 132, "uneven": 132, "inner": 132, "bert": 132, "reveal": 132, "resort": 132, "revert": 132, "power": [132, 134], "ultim": 133, "ingest": 133, "000": 133, "dequantiz": 133, "hook": 133, "intercept": 133, "textrm": 133, "dfrac": 133, "strong": 133, "excess": 133, "signal": 133, "satur": 133, "erro": 133, "alongsid": 133, "ones": 133, "welcom": 134, "motiv": 134, "ground": 134, "flexibl": 134, "transpar": 134, "redesign": 134, "mainlin": 134, "compris": 134, "dispatch": 134, "uphold": 134, "migrat": 134, "blockwis": 134, "slim": 135, "backslash": 135, "user_guid": 135, "api_doc": 135, "quantizablemultiheadattent": 135, "kyuykim": 135, "mangal": 135, "geunle": 135, "correctli": 135, "klhsieh": 135, "akhobar": 135, "ashvkuma": 135, "fp16": 135, "stand": [135, 136, 139], "adaptiveround": 135, "\ud835\udc5a": [136, 139], "\ud835\udc5b": [136, 139], "\u210e": [136, 139], "\ud835\udc64": [136, 139], "\ud835\udc58": [136, 139], "degre": [136, 139], "progress": [137, 138], "computation": [137, 138], "websocket": 137, "listen": 137, "5006": 137, "lot": 138, "lose": 140, "pictori": 140, "volum": 140, "hxwx8": 140, "hxwx5": 140, "propag": 140, "That": 140, "green": 140, "color": 140, "side": 140, "pink": 140, "orang": 140}, "objects": {"aimet_common.bias_correction": [[75, 0, 1, "", "ConvBnInfoType"]], "aimet_common.defs": [[75, 0, 1, "", "ActivationType"], [61, 0, 1, "", "CompressionScheme"], [61, 0, 1, "", "CostMetric"], [76, 0, 1, "", "GreedySelectionParameters"], [87, 0, 1, "", "QuantScheme"]], "aimet_common.defs.ActivationType": [[75, 1, 1, "", "no_activation"], [75, 1, 1, "", "relu"], [75, 1, 1, "", "relu6"]], "aimet_common.defs.CompressionScheme": [[61, 1, 1, "", "channel_pruning"], [61, 1, 1, "", "spatial_svd"], [61, 1, 1, "", "weight_svd"]], "aimet_common.defs.CostMetric": [[61, 1, 1, "", "mac"], [61, 1, 1, "", "memory"]], "aimet_common.defs.QuantScheme": [[87, 1, 1, "", "post_training_percentile"], [87, 1, 1, "", "post_training_tf"], [87, 1, 1, "", "post_training_tf_enhanced"], [87, 1, 1, "", "training_range_learning_with_tf_enhanced_init"], [87, 1, 1, "", "training_range_learning_with_tf_init"]], "aimet_common.utils": [[85, 0, 1, "", "CallbackFunc"]], "aimet_tensorflow.adaround.adaround_weight.Adaround": [[57, 2, 1, "", "apply_adaround"]], "aimet_tensorflow.adaround.adaround_weight": [[57, 0, 1, "", "AdaroundParameters"]], "aimet_tensorflow.auto_quant": [[58, 0, 1, "", "AutoQuant"]], "aimet_tensorflow.auto_quant.AutoQuant": [[58, 3, 1, "", "apply"], [58, 3, 1, "", "set_adaround_params"]], "aimet_tensorflow.batch_norm_fold": [[65, 2, 1, "", "fold_all_batch_norms"], [59, 2, 1, "", "fold_all_batch_norms_to_scale"], [65, 2, 1, "", "fold_given_batch_norms"]], "aimet_tensorflow.bias_correction.BiasCorrection": [[60, 2, 1, "", "analytical_bias_correction_per_layer"], [60, 2, 1, "", "bias_correction_per_layer"], [60, 2, 1, "", "correct_bias"]], "aimet_tensorflow.bias_correction": [[60, 2, 1, "", "BiasCorrectionParams"], [60, 0, 1, "", "QuantParams"]], "aimet_tensorflow.bn_reestimation": [[59, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.compress": [[61, 0, 1, "", "ModelCompressor"]], "aimet_tensorflow.compress.ModelCompressor": [[61, 3, 1, "", "compress_model"]], "aimet_tensorflow.cross_layer_equalization": [[65, 0, 1, "", "ClsSetInfo"], [62, 2, 1, "", "equalize_model"]], "aimet_tensorflow.cross_layer_equalization.ClsSetInfo": [[65, 0, 1, "", "ClsSetLayerPairInfo"], [65, 3, 1, "", "map_cls_sets_to_new_session"]], "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling": [[65, 2, 1, "", "scale_cls_sets"], [65, 2, 1, "", "scale_model"]], "aimet_tensorflow.cross_layer_equalization.HighBiasFold": [[65, 2, 1, "id0", "bias_fold"]], "aimet_tensorflow.defs": [[61, 0, 1, "", "ChannelPruningParameters"], [61, 0, 1, "", "ModuleCompRatioPair"], [61, 0, 1, "", "SpatialSvdParameters"]], "aimet_tensorflow.defs.ChannelPruningParameters": [[61, 0, 1, "", "AutoModeParams"], [61, 0, 1, "", "ManualModeParams"], [61, 0, 1, "", "Mode"]], "aimet_tensorflow.defs.ChannelPruningParameters.Mode": [[61, 1, 1, "", "auto"], [61, 1, 1, "", "manual"]], "aimet_tensorflow.defs.SpatialSvdParameters": [[61, 0, 1, "", "AutoModeParams"], [61, 0, 1, "", "ManualModeParams"], [61, 0, 1, "", "Mode"]], "aimet_tensorflow.defs.SpatialSvdParameters.Mode": [[61, 1, 1, "", "auto"], [61, 1, 1, "", "manual"]], "aimet_tensorflow.keras.batch_norm_fold": [[43, 2, 1, "", "fold_all_batch_norms"], [37, 2, 1, "", "fold_all_batch_norms_to_scale"], [43, 2, 1, "", "fold_given_batch_norms"]], "aimet_tensorflow.keras.bn_reestimation": [[37, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.keras.compress": [[38, 0, 1, "", "ModelCompressor"]], "aimet_tensorflow.keras.compress.ModelCompressor": [[38, 3, 1, "", "compress_model"]], "aimet_tensorflow.keras.cross_layer_equalization": [[43, 0, 1, "", "ClsSetInfo"], [39, 2, 1, "", "equalize_model"]], "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo": [[43, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling": [[43, 2, 1, "", "scale_cls_sets"], [43, 2, 1, "", "scale_model"]], "aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold": [[43, 2, 1, "id0", "bias_fold"]], "aimet_tensorflow.keras.layer_output_utils": [[40, 0, 1, "", "LayerOutputUtil"]], "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil": [[40, 3, 1, "", "generate_layer_outputs"]], "aimet_tensorflow.keras.model_preparer": [[42, 2, 1, "", "prepare_model"]], "aimet_tensorflow.keras.quant_analyzer": [[44, 0, 1, "", "QuantAnalyzer"]], "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer": [[44, 3, 1, "", "analyze"]], "aimet_tensorflow.keras.quantsim": [[46, 0, 1, "", "QuantizationSimModel"]], "aimet_tensorflow.keras.quantsim.QuantizationSimModel": [[46, 3, 1, "", "compute_encodings"], [46, 3, 1, "", "export"]], "aimet_tensorflow.layer_output_utils": [[63, 0, 1, "", "LayerOutputUtil"]], "aimet_tensorflow.layer_output_utils.LayerOutputUtil": [[63, 3, 1, "", "generate_layer_outputs"]], "aimet_tensorflow.plotting_utils": [[69, 2, 1, "", "visualize_relative_weight_ranges_single_layer"], [69, 2, 1, "", "visualize_weight_ranges_single_layer"]], "aimet_tensorflow.quant_analyzer": [[66, 0, 1, "", "QuantAnalyzer"]], "aimet_tensorflow.quant_analyzer.QuantAnalyzer": [[66, 3, 1, "", "analyze"]], "aimet_tensorflow.quantsim": [[68, 0, 1, "", "QuantizationSimModel"]], "aimet_tensorflow.quantsim.QuantizationSimModel": [[68, 3, 1, "", "compute_encodings"], [68, 3, 1, "", "export"]], "aimet_tensorflow.svd": [[61, 0, 1, "", "Svd"]], "aimet_tensorflow.svd.Svd": [[61, 3, 1, "", "compress_net"]], "aimet_tensorflow.utils.convert_tf_sess_to_keras": [[33, 2, 1, "", "load_keras_model_multi_gpu"], [33, 2, 1, "", "load_tf_sess_variables_to_keras_single_gpu"], [33, 2, 1, "", "save_as_tf_module_multi_gpu"], [33, 2, 1, "", "save_tf_session_single_gpu"]], "aimet_tensorflow.utils.graph": [[64, 2, 1, "", "update_keras_bn_ops_trainable_flag"]], "aimet_torch.adaround.adaround_weight.Adaround": [[71, 2, 1, "", "apply_adaround"]], "aimet_torch.adaround.adaround_weight": [[71, 0, 1, "", "AdaroundParameters"]], "aimet_torch.arch_checker.arch_checker.ArchChecker": [[72, 2, 1, "", "check_model_arch"]], "aimet_torch.auto_quant": [[73, 0, 1, "", "AutoQuant"]], "aimet_torch.batch_norm_fold": [[84, 2, 1, "", "fold_all_batch_norms"], [74, 2, 1, "", "fold_all_batch_norms_to_scale"], [84, 2, 1, "", "fold_given_batch_norms"]], "aimet_torch.bias_correction": [[75, 2, 1, "", "correct_bias"]], "aimet_torch.bn_reestimation": [[74, 2, 1, "", "reestimate_bn_stats"]], "aimet_torch.compress": [[76, 0, 1, "", "ModelCompressor"]], "aimet_torch.compress.ModelCompressor": [[76, 3, 1, "", "compress_model"]], "aimet_torch.cross_layer_equalization": [[84, 0, 1, "", "ClsSetInfo"], [77, 2, 1, "", "equalize_model"]], "aimet_torch.cross_layer_equalization.ClsSetInfo": [[84, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_torch.cross_layer_equalization.CrossLayerScaling": [[84, 2, 1, "", "scale_cls_sets"], [84, 2, 1, "", "scale_model"]], "aimet_torch.cross_layer_equalization.HighBiasFold": [[84, 2, 1, "id0", "bias_fold"]], "aimet_torch.defs": [[76, 0, 1, "", "ChannelPruningParameters"], [76, 0, 1, "", "ModuleCompRatioPair"], [76, 0, 1, "", "SpatialSvdParameters"], [76, 0, 1, "", "TarRankSelectionParameters"], [76, 0, 1, "", "WeightSvdParameters"]], "aimet_torch.defs.ChannelPruningParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.ChannelPruningParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.defs.SpatialSvdParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.SpatialSvdParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.defs.WeightSvdParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.WeightSvdParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.layer_output_utils": [[78, 0, 1, "", "LayerOutputUtil"], [78, 0, 1, "", "NamingScheme"]], "aimet_torch.layer_output_utils.LayerOutputUtil": [[78, 3, 1, "", "generate_layer_outputs"]], "aimet_torch.layer_output_utils.NamingScheme": [[78, 1, 1, "", "ONNX"], [78, 1, 1, "", "PYTORCH"], [78, 1, 1, "", "TORCHSCRIPT"]], "aimet_torch.model_preparer": [[80, 2, 1, "", "prepare_model"]], "aimet_torch.peft": [[83, 0, 1, "", "AdapterMetaData"], [83, 0, 1, "", "PeftQuantUtils"], [83, 3, 1, "", "replace_lora_layers_with_quantizable_layers"], [83, 3, 1, "", "track_lora_meta_data"]], "aimet_torch.peft.PeftQuantUtils": [[83, 3, 1, "", "disable_lora_adapters"], [83, 3, 1, "", "enable_adapter_and_load_weights"], [83, 3, 1, "", "export_adapter_weights"], [83, 3, 1, "", "freeze_base_model"], [83, 3, 1, "", "freeze_base_model_activation_quantizers"], [83, 3, 1, "", "freeze_base_model_param_quantizers"], [83, 3, 1, "", "get_quantized_lora_layer"], [83, 3, 1, "", "set_bitwidth_for_lora_adapters"]], "aimet_torch.quant_analyzer": [[85, 0, 1, "", "QuantAnalyzer"]], "aimet_torch.quant_analyzer.QuantAnalyzer": [[85, 3, 1, "", "analyze"], [85, 3, 1, "", "check_model_sensitivity_to_quantization"], [85, 3, 1, "", "enable_per_layer_mse_loss"], [85, 3, 1, "", "export_per_layer_encoding_min_max_range"], [85, 3, 1, "", "export_per_layer_mse_loss"], [85, 3, 1, "", "export_per_layer_stats_histogram"], [85, 3, 1, "", "perform_per_layer_analysis_by_disabling_quant_wrappers"], [85, 3, 1, "", "perform_per_layer_analysis_by_enabling_quant_wrappers"]], "aimet_torch.quantsim": [[75, 0, 1, "", "QuantParams"], [87, 0, 1, "", "QuantizationSimModel"], [87, 3, 1, "", "load_checkpoint"], [87, 3, 1, "", "save_checkpoint"]], "aimet_torch.quantsim.QuantizationSimModel": [[87, 3, 1, "", "compute_encodings"], [87, 3, 1, "", "export"]], "aimet_torch.v2.nn": [[94, 0, 1, "", "FakeQuantizationMixin"], [95, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.FakeQuantizationMixin": [[94, 3, 1, "", "__quant_init__"], [94, 3, 1, "", "compute_encodings"], [94, 3, 1, "", "forward"], [94, 3, 1, "", "from_module"], [94, 3, 1, "", "implements"], [94, 1, 1, "", "input_quantizers"], [94, 1, 1, "", "output_quantizers"], [94, 1, 1, "", "param_quantizers"]], "aimet_torch.v2.nn.QuantizationMixin": [[95, 3, 1, "", "__quant_init__"], [95, 3, 1, "", "compute_encodings"], [95, 3, 1, "", "forward"], [95, 3, 1, "", "from_module"], [95, 3, 1, "", "get_default_kernel"], [95, 3, 1, "", "get_kernel"], [95, 3, 1, "", "implements"], [95, 1, 1, "", "input_quantizers"], [95, 1, 1, "", "output_quantizers"], [95, 1, 1, "", "param_quantizers"], [95, 3, 1, "", "set_default_kernel"], [95, 3, 1, "", "set_kernel"]], "aimet_torch.v2.nn.base": [[112, 0, 1, "", "BaseQuantizationMixin"]], "aimet_torch.v2.nn.base.BaseQuantizationMixin": [[112, 3, 1, "", "__quant_init__"], [112, 3, 1, "", "compute_encodings"], [112, 3, 1, "", "forward"], [112, 1, 1, "", "input_quantizers"], [112, 1, 1, "", "output_quantizers"], [112, 1, 1, "", "param_quantizers"]], "aimet_torch.v2.quantization": [[101, 4, 0, "-", "affine"], [103, 4, 0, "-", "float"]], "aimet_torch.v2.quantization.affine": [[96, 0, 1, "", "Quantize"], [97, 0, 1, "", "QuantizeDequantize"], [98, 2, 1, "", "dequantize"], [99, 2, 1, "", "quantize"], [100, 2, 1, "", "quantize_dequantize"]], "aimet_torch.v2.quantization.affine.Quantize": [[96, 3, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.QuantizeDequantize": [[97, 3, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer": [[113, 0, 1, "", "Quantize"], [113, 0, 1, "", "QuantizeDequantize"], [113, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[113, 3, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[113, 3, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[113, 3, 1, "", "allow_overwrite"], [113, 3, 1, "", "compute_encodings"], [113, 3, 1, "", "get_encoding"], [113, 3, 1, "", "get_legacy_encodings"], [113, 3, 1, "", "is_initialized"], [113, 3, 1, "", "register_quantization_parameter"], [113, 3, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization.encoding_analyzer": [[106, 0, 1, "", "EncodingAnalyzer"], [108, 0, 1, "", "MinMaxEncodingAnalyzer"], [109, 0, 1, "", "PercentileEncodingAnalyzer"], [110, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer": [[109, 3, 1, "", "set_percentile"]], "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer": [[110, 3, 1, "", "compute_encodings_from_stats"]], "aimet_torch.v2.quantization.float": [[102, 0, 1, "", "FloatQuantizeDequantize"], [102, 0, 1, "", "QuantizeDequantize"]], "aimet_torch.v2.quantization.tensor": [[104, 0, 1, "", "DequantizedTensor"], [104, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[104, 3, 1, "", "dequantize"], [104, 3, 1, "", "quantize"], [104, 3, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[104, 3, 1, "", "dequantize"], [104, 3, 1, "", "quantize"], [104, 3, 1, "", "quantized_repr"]], "aimet_torch.v2.quantsim.config_utils": [[105, 2, 1, "", "set_activation_quantizers_to_float"], [105, 2, 1, "", "set_blockwise_quantization_for_weights"], [105, 2, 1, "", "set_grouped_blockwise_quantization_for_weights"]], "aimet_torch.visualize_model": [[89, 2, 1, "", "visualize_changes_after_optimization"], [89, 2, 1, "", "visualize_relative_weight_ranges_to_identify_problematic_layers"], [89, 2, 1, "", "visualize_weight_ranges"]], "aimet_torch.visualize_serialized_data": [[88, 0, 1, "", "VisualizeCompression"]], "aimet_torch.visualize_serialized_data.VisualizeCompression": [[88, 3, 1, "", "display_comp_ratio_plot"], [88, 3, 1, "", "display_eval_scores"]]}, "objtypes": {"0": "py:class", "1": "py:attribute", "2": "py:function", "3": "py:method", "4": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "attribute", "Python attribute"], "2": ["py", "function", "Python function"], "3": ["py", "method", "Python method"], "4": ["py", "module", "Python module"]}, "titleterms": {"adapt": [0, 6, 10, 26, 48, 71], "round": [0, 6, 10, 26, 48, 71, 125], "adaround": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 57, 71, 116], "overal": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 115, 119], "flow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 83, 115, 128], "what": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "notebook": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 85, 87, 121], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "dataset": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 75, 92, 115, 135], "exampl": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 84, 85, 87, 88, 89, 111, 114, 121], "evalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "train": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 87, 107, 115, 127, 128, 130], "pipelin": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 75, 92, 115, 135], "convert": [0, 1, 2, 14], "an": [0, 1, 2], "fp32": [0, 1, 2, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31], "pytorch": [0, 1, 2, 55, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 84, 85, 86, 87, 92, 111, 115, 126, 127, 138], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 64, 79, 80, 81, 111, 115, 123, 125, 126, 127], "onnx": [0, 1, 2, 47, 48, 49, 50, 51, 52, 53, 54, 92], "": [0, 1, 2], "baselin": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31], "accuraci": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55], "creat": [0, 1, 2, 6, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31], "quantiz": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 45, 46, 53, 54, 67, 68, 69, 75, 86, 87, 89, 96, 99, 101, 103, 104, 105, 107, 112, 113, 114, 115, 127, 128, 130, 131, 132, 133, 138], "simul": [0, 1, 2, 6, 8, 9, 10, 18, 19, 20, 21, 26, 28, 29, 30, 31, 131, 133], "determin": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 133], "fold": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 115], "batch": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "normal": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "layer": [0, 1, 2, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 26, 28, 29, 30, 31, 32, 39, 40, 43, 50, 51, 60, 62, 63, 65, 77, 78, 84, 122, 125], "sim": [0, 1, 2, 6, 8, 9, 15, 16, 19, 20, 21, 28, 29, 30, 31, 46, 54, 68, 87], "comput": [0, 2, 6, 8, 9, 15, 16, 19, 20, 21, 112], "encod": [0, 2, 6, 8, 9, 15, 16, 17, 19, 20, 21, 22, 32, 55, 106, 112, 133], "4": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 25, 26, 28, 29, 30, 31, 55], "appli": [0, 6, 7, 10, 11, 17, 18, 22, 26, 32], "summari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "cross": [1, 9, 19, 29, 39, 43, 50, 62, 65, 77, 84], "equal": [1, 9, 19, 29, 39, 43, 50, 62, 65, 77, 84], "cle": [1, 9, 19, 29, 43, 65], "compress": [3, 4, 5, 23, 24, 25, 38, 61, 76, 88, 120, 122, 125, 137], "us": [3, 4, 5, 23, 24, 25, 33, 43, 65, 91, 116, 125, 127, 134, 137], "channel": [3, 4, 5, 18, 23, 25, 61, 76, 119], "prune": [3, 4, 5, 23, 25, 61, 76, 119], "load": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "find": [3, 4, 5, 23, 24, 25], "fine": [3, 4, 5, 23, 24, 25, 115, 125], "tune": [3, 4, 5, 23, 24, 25, 115, 125], "post": [3, 4, 5, 23, 24, 25, 92, 107, 127, 128], "spatial": [4, 5, 24, 25, 38, 61, 76, 136], "svd": [4, 5, 24, 25, 38, 61, 76, 136, 139], "follow": [5, 25], "after": [5, 15, 16, 25], "get": [6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31, 111, 123, 125], "score": [6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31], "autoqu": [7, 11, 27, 49, 58, 73, 117], "pretrain": [7, 11, 15, 16, 17, 27], "defin": [7, 11, 12, 27], "constant": [7, 11, 12, 27], "helper": [7, 11, 27, 43, 65], "function": [7, 11, 12, 14, 27, 33, 101], "prepar": [7, 11, 12, 14, 42, 80, 115], "unlabel": 7, "callback": [7, 11, 12], "5": [7, 8, 11, 12, 15, 16, 19, 28, 55], "option": [7, 11, 27, 125], "set": [7, 11, 27, 91], "paramet": [7, 11, 27, 36, 38, 48, 57, 60, 61, 71, 76, 133], "run": [7, 11, 27, 52, 85, 121], "awar": [8, 12, 13, 15, 16, 20, 21, 28, 30, 31, 87, 115, 130], "batchnorm": [8, 12, 28, 37, 59, 74, 115], "re": [8, 12, 28, 37, 59, 74, 118], "estim": [8, 12, 28, 37, 59, 74, 118], "rewrit": 8, "perform": [8, 12, 15, 16, 20, 21, 28, 30, 31, 43, 65], "qat": [8, 12, 15, 16, 20, 21, 28, 30, 31, 87, 130], "reestim": [8, 28, 59, 74], "statist": [8, 17, 22, 28, 32], "export": [8, 12, 15, 16, 19, 28, 105, 115], "bia": [9, 29, 60, 75], "correct": [9, 29, 60, 75], "bc": [9, 29], "instanti": 12, "kera": [12, 13, 14, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "quantizationsim": [12, 15, 16], "transform": 13, "subclass": 14, "show": 14, "similar": 14, "differ": 14, "between": 14, "origin": 14, "discuss": 14, "limit": [14, 37, 42, 80], "compil": [15, 16], "6": [15, 16, 55], "valid": [15, 16, 81], "7": [15, 16], "rang": [16, 17, 21, 22, 31, 32], "learn": [16, 21, 31], "quant": [17, 22, 32, 44, 52, 66, 85], "analyz": [17, 22, 32, 44, 52, 66, 85, 106], "quantanalyz": [17, 22, 32, 129], "per": [17, 18, 22, 32, 60, 122, 125], "analysi": [17, 22, 32, 127, 129], "enabl": [17, 22, 32], "disabl": [17, 22, 32], "wrapper": [17, 32], "min": [17, 22, 32], "max": [17, 22, 32], "pdf": [17, 22, 32], "mse": [17, 22, 32], "loss": [17, 22, 32], "quantsim": [18, 19, 114, 115, 133, 134], "pcq": 18, "op": [22, 133], "object": 27, "infer": 27, "optim": 27, "aimet": [33, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 84, 85, 86, 87, 88, 89, 90, 91, 92, 111, 116, 117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 132, 133, 135, 136, 137, 138, 139, 140], "tensorflow": [33, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 92, 127, 138], "api": [33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88, 89, 105, 111, 112, 113], "introduct": [33, 37, 38, 39, 43, 50, 59, 61, 62, 65, 74, 76, 77, 84], "code": [33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 84, 85, 87, 88, 89, 114, 121], "util": [33, 52, 81, 85], "welcom": 34, "ai": [34, 111, 123], "effici": [34, 111, 123], "toolkit": [34, 111, 123], "doc": 34, "indic": 34, "tabl": 34, "user": [36, 39, 46, 48, 49, 50, 57, 58, 60, 62, 68, 71, 73, 75, 77, 83, 85, 87, 123, 128], "guid": [36, 39, 46, 48, 49, 50, 57, 58, 60, 62, 68, 71, 73, 75, 77, 85, 87, 115, 123], "link": [36, 37, 39, 46, 48, 49, 50, 57, 58, 59, 60, 62, 68, 71, 73, 74, 75, 77, 85, 87], "top": [36, 37, 38, 40, 42, 44, 46, 48, 49, 51, 52, 54, 57, 58, 59, 61, 63, 66, 68, 69, 71, 73, 74, 76, 78, 80, 83, 85, 87, 88, 89, 105, 112, 113], "level": [36, 37, 38, 40, 42, 43, 44, 46, 48, 49, 51, 52, 54, 57, 58, 59, 61, 63, 65, 66, 68, 69, 71, 73, 74, 76, 78, 80, 83, 84, 85, 87, 88, 89, 105, 112, 113], "enum": [36, 57, 71, 78, 87], "definit": [36, 38, 57, 61, 71, 76, 78, 84, 87], "greedi": [38, 61, 76, 122], "select": [38, 61, 76, 119, 122, 125], "configur": [38, 61, 76, 112, 131, 133], "primit": [39, 43, 62, 65, 77, 84], "output": [40, 51, 63, 78], "gener": [40, 51, 63, 78], "guidelin": [41, 64, 79, 87, 126, 127], "higher": [43, 65, 84], "lower": [43, 65, 84], "custom": [43, 65], "datatyp": [43, 65], "method": [43, 65], "manual": [43, 65], "mode": [43, 65, 130], "specif": [52, 55, 85], "format": 55, "version": 55, "0": [55, 135], "up": 55, "file": [55, 131], "bn": [59, 74, 118], "input": 60, "type": 60, "data": 60, "weight": [61, 69, 76, 119, 139], "visual": [69, 88, 89, 137, 138], "tensor": [69, 104], "architectur": 72, "checker": 72, "html": 72, "report": 72, "content": 72, "convbninfotyp": 75, "activationtyp": 75, "param": 75, "empir": 75, "analyt": 75, "tar": 76, "torch": [80, 92], "fx": 80, "symbol": 80, "trace": 80, "multi": 82, "gpu": [82, 92], "support": 82, "peft": 83, "lora": 83, "clssetinfo": 84, "instal": [90, 91, 92, 121, 123], "quick": 90, "releas": [90, 91, 92, 123, 135], "packag": [90, 91, 92], "system": 90, "requir": [90, 129], "advanc": 90, "instruct": 90, "docker": 91, "variant": [91, 106], "prebuilt": 91, "imag": 91, "build": 91, "local": 91, "start": [91, 111, 123, 137], "contain": 91, "from": [91, 92, 114], "pypi": [91, 92], "environ": [91, 92], "setup": [91, 92], "prerequisit": [92, 115], "13": [92, 135], "common": [92, 116], "debian": 92, "replac": 92, "pillow": 92, "simd": 92, "onnxruntim": 92, "step": 92, "fakequantizationmixin": 94, "quantizationmixin": 95, "quantizedequant": [97, 102], "dequant": 98, "quantize_dequant": 100, "affin": [101, 114], "class": [101, 104, 112], "floatquantizedequant": 102, "float": [103, 114, 115], "blockwis": 105, "low": 105, "power": 105, "lpbq": 105, "minmaxencodinganalyz": 108, "percentileencodinganalyz": 109, "sqnrencodinganalyz": 110, "document": 111, "featur": [111, 114, 120, 123, 127, 132, 134], "descript": [111, 129], "modul": [112, 114], "migrat": 114, "v2": [114, 134], "chang": 114, "process": 114, "import": 114, "quantizationsimmodel": 114, "move": 114, "quantwrapp": 114, "staticgrid": 114, "learnedgrid": 114, "deprec": 114, "quickstart": 115, "point": 115, "case": [116, 125, 127], "terminologi": 116, "overview": [117, 118, 122, 123, 125, 128, 129, 130, 131, 133, 134, 137, 138, 140], "workflow": [117, 118, 127, 130, 133], "procedur": 119, "winnow": [119, 140], "reconstruct": 119, "guidebook": [120, 132], "brows": 121, "jupyt": 121, "download": 121, "relat": 121, "ratio": [122, 125], "how": [122, 131, 137, 140], "work": [122, 140], "explor": 122, "inform": 123, "toc": 123, "tree": 123, "known": 124, "issu": 124, "techniqu": [125, 128], "better": 125, "result": 125, "rank": 125, "faq": [125, 128], "refer": [125, 128], "debug": 127, "tool": [127, 137], "detail": 129, "recommend": 130, "structur": 131, "individu": 131, "section": 131, "nois": 133, "scheme": 133, "frequent": 133, "ask": 133, "question": 133, "new": 134, "note": 135, "22": 135, "21": 135, "20": 135, "19": 135, "py37": 135, "18": 135, "17": 135, "16": 135, "14": 135, "design": 137, "bokeh": 137, "server": 137, "session": 137}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Adaptive Rounding (AdaRound)": [[0, "Adaptive-Rounding-(AdaRound)"], [6, "Adaptive-Rounding-(AdaRound)"], [26, "Adaptive-Rounding-(AdaRound)"]], "Overall flow": [[0, "Overall-flow"], [1, "Overall-flow"], [2, "Overall-flow"], [3, "Overall-flow"], [4, "Overall-flow"], [5, "Overall-flow"], [6, "Overall-flow"], [7, "Overall-flow"], [8, "Overall-flow"], [9, "Overall-flow"], [10, "Overall-flow"], [11, "Overall-flow"], [12, "Overall-flow"], [13, "Overall-flow"], [14, "Overall-flow"], [15, "Overall-flow"], [16, "Overall-flow"], [17, "Overall-flow"], [18, "Overall-flow"], [19, "Overall-flow"], [20, "Overall-flow"], [21, "Overall-flow"], [22, "Overall-flow"], [23, "Overall-flow"], [24, "Overall-flow"], [25, "Overall-flow"], [26, "Overall-flow"], [27, "Overall-flow"], [28, "Overall-flow"], [29, "Overall-flow"], [30, "Overall-flow"], [31, "Overall-flow"], [32, "Overall-flow"], [115, "overall-flow"]], "What this notebook is not": [[0, "What-this-notebook-is-not"], [1, "What-this-notebook-is-not"], [2, "What-this-notebook-is-not"], [3, "What-this-notebook-is-not"], [4, "What-this-notebook-is-not"], [5, "What-this-notebook-is-not"], [6, "What-this-notebook-is-not"], [7, "What-this-notebook-is-not"], [8, "What-this-notebook-is-not"], [9, "What-this-notebook-is-not"], [10, "What-this-notebook-is-not"], [11, "What-this-notebook-is-not"], [15, "What-this-notebook-is-not"], [16, "What-this-notebook-is-not"], [17, "What-this-notebook-is-not"], [18, "What-this-notebook-is-not"], [19, "What-this-notebook-is-not"], [20, "What-this-notebook-is-not"], [21, "What-this-notebook-is-not"], [22, "What-this-notebook-is-not"], [23, "What-this-notebook-is-not"], [24, "What-this-notebook-is-not"], [25, "What-this-notebook-is-not"], [26, "What-this-notebook-is-not"], [27, "What-this-notebook-is-not"], [28, "What-this-notebook-is-not"], [29, "What-this-notebook-is-not"], [30, "What-this-notebook-is-not"], [31, "What-this-notebook-is-not"], [32, "What-this-notebook-is-not"]], "Dataset": [[0, "Dataset"], [1, "Dataset"], [2, "Dataset"], [3, "Dataset"], [4, "Dataset"], [5, "Dataset"], [6, "Dataset"], [7, "Dataset"], [8, "Dataset"], [9, "Dataset"], [10, "Dataset"], [11, "Dataset"], [12, "Dataset"], [15, "Dataset"], [16, "Dataset"], [17, "Dataset"], [18, "Dataset"], [19, "Dataset"], [20, "Dataset"], [21, "Dataset"], [22, "Dataset"], [23, "Dataset"], [24, "Dataset"], [25, "Dataset"], [26, "Dataset"], [27, "Dataset"], [28, "Dataset"], [29, "Dataset"], [30, "Dataset"], [31, "Dataset"], [32, "Dataset"]], "1. Example evaluation and training pipeline": [[0, "1.-Example-evaluation-and-training-pipeline"], [1, "1.-Example-evaluation-and-training-pipeline"], [4, "1.-Example-evaluation-and-training-pipeline"], [5, "1.-Example-evaluation-and-training-pipeline"], [7, "1.-Example-evaluation-and-training-pipeline"], [8, "1.-Example-evaluation-and-training-pipeline"], [9, "1.-Example-evaluation-and-training-pipeline"], [10, "1.-Example-evaluation-and-training-pipeline"], [11, "1.-Example-evaluation-and-training-pipeline"], [17, "1.-Example-evaluation-and-training-pipeline"], [18, "1.-Example-evaluation-and-training-pipeline"], [19, "1.-Example-evaluation-and-training-pipeline"], [20, "1.-Example-evaluation-and-training-pipeline"], [22, "1.-Example-evaluation-and-training-pipeline"], [23, "1.-Example-evaluation-and-training-pipeline"], [24, "1.-Example-evaluation-and-training-pipeline"], [25, "1.-Example-evaluation-and-training-pipeline"], [26, "1.-Example-evaluation-and-training-pipeline"], [28, "1.-Example-evaluation-and-training-pipeline"], [29, "1.-Example-evaluation-and-training-pipeline"], [30, "1.-Example-evaluation-and-training-pipeline"], [31, "1.-Example-evaluation-and-training-pipeline"], [32, "1.-Example-evaluation-and-training-pipeline"]], "2. Convert an FP32 PyTorch model to ONNX and evaluate the model\u2019s baseline FP32 accuracy": [[0, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [1, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [2, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"]], "3. Create a quantization simulation model and determine quantized accuracy": [[0, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [1, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [2, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [6, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [9, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [10, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [18, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [19, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [20, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [21, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [26, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [29, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [30, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [31, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"]], "Fold Batch Normalization layers": [[0, "Fold-Batch-Normalization-layers"], [1, "Fold-Batch-Normalization-layers"], [2, "Fold-Batch-Normalization-layers"], [6, "Fold-Batch-Normalization-layers"], [9, "Fold-Batch-Normalization-layers"], [10, "Fold-Batch-Normalization-layers"], [15, "Fold-Batch-Normalization-layers"], [16, "Fold-Batch-Normalization-layers"], [18, "Fold-Batch-Normalization-layers"], [19, "Fold-Batch-Normalization-layers"], [20, "Fold-Batch-Normalization-layers"], [21, "Fold-Batch-Normalization-layers"], [26, "Fold-Batch-Normalization-layers"], [29, "Fold-Batch-Normalization-layers"], [30, "Fold-Batch-Normalization-layers"], [31, "Fold-Batch-Normalization-layers"]], "Create Quantization Sim Model": [[0, "Create-Quantization-Sim-Model"], [1, "Create-Quantization-Sim-Model"], [2, "Create-Quantization-Sim-Model"], [6, "Create-Quantization-Sim-Model"], [8, "Create-Quantization-Sim-Model"], [9, "Create-Quantization-Sim-Model"], [15, "Create-Quantization-Sim-Model"], [16, "Create-Quantization-Sim-Model"], [19, "Create-Quantization-Sim-Model"], [20, "Create-Quantization-Sim-Model"], [21, "Create-Quantization-Sim-Model"], [28, "Create-Quantization-Sim-Model"], [29, "Create-Quantization-Sim-Model"], [30, "Create-Quantization-Sim-Model"], [31, "Create-Quantization-Sim-Model"]], "Compute Encodings": [[0, "Compute-Encodings"], [2, "Compute-Encodings"], [6, "Compute-Encodings"], [8, "Compute-Encodings"], [9, "Compute-Encodings"], [15, "Compute-Encodings"], [16, "Compute-Encodings"], [19, "Compute-Encodings"], [20, "Compute-Encodings"], [21, "Compute-Encodings"]], "4. Apply Adaround": [[0, "4.-Apply-Adaround"], [10, "4.-Apply-Adaround"], [18, "4.-Apply-Adaround"], [26, "4.-Apply-Adaround"]], "Summary": [[0, "Summary"], [1, "Summary"], [2, "Summary"], [3, "Summary"], [4, "Summary"], [5, "Summary"], [6, "Summary"], [7, "Summary"], [8, "Summary"], [9, "Summary"], [10, "Summary"], [11, "Summary"], [12, "Summary"], [14, "Summary"], [15, "Summary"], [16, "Summary"], [18, "Summary"], [19, "Summary"], [20, "Summary"], [21, "Summary"], [23, "Summary"], [24, "Summary"], [25, "Summary"], [26, "Summary"], [27, "Summary"], [28, "Summary"], [29, "Summary"], [30, "Summary"], [31, "Summary"]], "Cross-Layer Equalization (CLE)": [[1, "Cross-Layer-Equalization-(CLE)"]], "4. 1 Cross Layer Equalization": [[1, "4.-1-Cross-Layer-Equalization"], [9, "4.-1-Cross-Layer-Equalization"], [29, "4.-1-Cross-Layer-Equalization"]], "Quantization Simulation": [[2, "Quantization-Simulation"]], "1. Example evaluation pipeline": [[2, "1.-Example-evaluation-pipeline"]], "Model Compression Using Channel Pruning": [[3, "Model-Compression-Using-Channel-Pruning"]], "2. Load the model and evaluate it to find the baseline accuracy": [[3, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [4, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [5, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [23, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [24, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [25, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"]], "3. Compress the model and fine-tune": [[3, "3.-Compress-the-model-and-fine-tune"], [4, "3.-Compress-the-model-and-fine-tune"], [5, "3.-Compress-the-model-and-fine-tune"], [23, "3.-Compress-the-model-and-fine-tune"], [24, "3.-Compress-the-model-and-fine-tune"], [25, "3.-Compress-the-model-and-fine-tune"]], "3.1. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[3, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [4, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [5, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [23, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.2. Fine-tune the model": [[3, "3.2.-Fine-tune-the-model"], [4, "3.2.-Fine-tune-the-model"], [23, "3.2.-Fine-tune-the-model"], [24, "3.2.-Fine-tune-the-model"]], "Model compression Using Spatial SVD": [[4, "Model-compression-Using-Spatial-SVD"]], "Model Compression Using Spatial SVD Followed by Channel Pruning": [[5, "Model-Compression-Using-Spatial-SVD-Followed-by-Channel-Pruning"]], "3.2. Fine-tune the model after Spatial SVD": [[5, "3.2.-Fine-tune-the-model-after-Spatial-SVD"], [25, "3.2.-Fine-tune-the-model-after-Spatial-SVD"]], "3.3. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[5, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [25, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.4. Fine-tune the model after Channel Pruning": [[5, "3.4.-Fine-tune-the-model-after-Channel-Pruning"], [25, "3.4.-Fine-tune-the-model-after-Channel-Pruning"]], "1. Example Evaluation and Training Pipeline": [[6, "1.-Example-Evaluation-and-Training-Pipeline"], [21, "1.-Example-Evaluation-and-Training-Pipeline"]], "2. Load the model and evaluate to get a baseline FP32 accuracy score": [[6, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [9, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [10, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [18, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [19, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [20, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [21, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [26, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [29, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [30, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [31, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"]], "4. Apply AdaRound": [[6, "4.-Apply-AdaRound"]], "AutoQuant": [[7, "AutoQuant"], [11, "AutoQuant"], [27, "AutoQuant"]], "2. Load a pretrained FP32 model": [[7, "2.-Load-a-pretrained-FP32-model"], [11, "2.-Load-a-pretrained-FP32-model"], [15, "2.-Load-a-pretrained-FP32-model"], [16, "2.-Load-a-pretrained-FP32-model"], [17, "2.-Load-a-pretrained-FP32-model"], [27, "2.-Load-a-pretrained-FP32-model"]], "3. Determine the baseline FP32 accuracy": [[7, "3.-Determine-the-baseline-FP32-accuracy"], [11, "3.-Determine-the-baseline-FP32-accuracy"], [15, "3.-Determine-the-baseline-FP32-accuracy"], [16, "3.-Determine-the-baseline-FP32-accuracy"]], "4. Define Constants and Helper functions": [[7, "4.-Define-Constants-and-Helper-functions"], [11, "4.-Define-Constants-and-Helper-functions"]], "Prepare unlabeled dataset": [[7, "Prepare-unlabeled-dataset"]], "Prepare the evaluation callback function": [[7, "Prepare-the-evaluation-callback-function"], [11, "Prepare-the-evaluation-callback-function"], [12, "Prepare-the-evaluation-callback-function"]], "5. Apply AutoQuant": [[7, "5.-Apply-AutoQuant"], [11, "5.-Apply-AutoQuant"]], "Optionally set AdaRound Parameters": [[7, "Optionally-set-AdaRound-Parameters"], [11, "Optionally-set-AdaRound-Parameters"]], "Run AutoQuant": [[7, "Run-AutoQuant"], [11, "Run-AutoQuant"]], "Quantization-Aware Training with BatchNorm Re-estimation": [[8, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [12, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [28, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"]], "2. Load FP32 model": [[8, "2.-Load-FP32-model"], [28, "2.-Load-FP32-model"]], "BatchNorm Rewriter": [[8, "BatchNorm-Rewriter"]], "3. Create a quantization simulation model and Perform QAT": [[8, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"], [28, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"]], "Perform QAT": [[8, "Perform-QAT"], [28, "Perform-QAT"]], "4. Perform BatchNorm Reestimation": [[8, "4.-Perform-BatchNorm-Reestimation"], [28, "4.-Perform-BatchNorm-Reestimation"]], "Re-estimate BatchNorm Statistics": [[8, "Re-estimate-BatchNorm-Statistics"], [28, "Re-estimate-BatchNorm-Statistics"]], "Fold BatchNorm Layers": [[8, "Fold-BatchNorm-Layers"], [12, "Fold-BatchNorm-Layers"], [28, "Fold-BatchNorm-Layers"]], "5. Export Model": [[8, "5.-Export-Model"], [12, "5.-Export-Model"], [28, "5.-Export-Model"]], "Cross-Layer Equalization (CLE) and Bias Correction (BC)": [[9, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"], [29, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"]], "4. 2 Bias Correction": [[9, "4.-2-Bias-Correction"], [29, "4.-2-Bias-Correction"]], "Adaptive Rounding (Adaround)": [[10, "Adaptive-Rounding-(Adaround)"]], "1. Instantiate the example evaluation and training pipeline": [[12, "1.-Instantiate-the-example-evaluation-and-training-pipeline"]], "2. Define Constants and Datasets Prepare": [[12, "2.-Define-Constants-and-Datasets-Prepare"]], "2. Create the model in Keras": [[12, "2.-Create-the-model-in-Keras"]], "3. Train and evaluate the model": [[12, "3.-Train-and-evaluate-the-model"]], "4. Create a QuantizationSim Model": [[12, "4.-Create-a-QuantizationSim-Model"]], "5. Perform QAT": [[12, "5.-Perform-QAT"], [15, "5.-Perform-QAT"], [16, "5.-Perform-QAT"]], "Quantization-Aware Training with a Keras Transformer Model": [[13, "Quantization-Aware-Training-with-a-Keras-Transformer-Model"]], "Keras Model Preparer": [[14, "Keras-Model-Preparer"]], "1. Creating a Keras model with subclass layers": [[14, "1.-Creating-a-Keras-model-with-subclass-layers"]], "2. Converting the Keras model with subclass layers to a Keras model with functional layers": [[14, "2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers"]], "3. Showing similarities and differences between the original and converted models": [[14, "3.-Showing-similarities-and-differences-between-the-original-and-converted-models"]], "4. Discussing the limitations of the Keras Model Preparer": [[14, "4.-Discussing-the-limitations-of-the-Keras-Model-Preparer"]], "Quantization-Aware Training": [[15, "Quantization-Aware-Training"], [20, "Quantization-Aware-Training"], [30, "Quantization-Aware-Training"]], "Example evaluation and training pipeline": [[15, "Example-evaluation-and-training-pipeline"], [16, "Example-evaluation-and-training-pipeline"]], "1. Load the dataset": [[15, "1.-Load-the-dataset"], [16, "1.-Load-the-dataset"]], "4. Create a QuantizationSim Model and determine quantized accuracy": [[15, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"], [16, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"]], "Compile the model": [[15, "Compile-the-model"], [16, "Compile-the-model"]], "Evaluate the performance of the quantized model": [[15, "Evaluate-the-performance-of-the-quantized-model"], [16, "Evaluate-the-performance-of-the-quantized-model"]], "6. Evaluate validation accuracy after QAT": [[15, "6.-Evaluate-validation-accuracy-after-QAT"], [16, "6.-Evaluate-validation-accuracy-after-QAT"]], "7. Export the encodings": [[15, "7.-Export-the-encodings"], [16, "7.-Export-the-encodings"]], "Quantization-Aware Training with Range Learning": [[16, "Quantization-Aware-Training-with-Range-Learning"], [21, "Quantization-Aware-Training-with-Range-Learning"], [31, "Quantization-Aware-Training-with-Range-Learning"]], "Quant Analyzer": [[17, "Quant-Analyzer"], [22, "Quant-Analyzer"], [32, "Quant-Analyzer"]], "3. Apply QuantAnalyzer to the model": [[17, "3.-Apply-QuantAnalyzer-to-the-model"], [22, "3.-Apply-QuantAnalyzer-to-the-model"], [32, "3.-Apply-QuantAnalyzer-to-the-model"]], "Per-layer analysis by enabling/disabling quantization wrappers": [[17, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"], [32, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"]], "Encoding min/max ranges": [[17, "Encoding-min/max-ranges"], [22, "Encoding-min/max-ranges"], [32, "Encoding-min/max-ranges"]], "PDF of statistics": [[17, "PDF-of-statistics"], [22, "PDF-of-statistics"], [32, "PDF-of-statistics"]], "Per-layer MSE loss": [[17, "Per-layer-MSE-loss"], [32, "Per-layer-MSE-loss"]], "Quantsim and Adaround - Per Channel Quantization (PCQ)": [[18, "Quantsim-and-Adaround---Per-Channel-Quantization-(PCQ)"]], "Cross-Layer Equalization (CLE) with QuantSim": [[19, "Cross-Layer-Equalization-(CLE)-with-QuantSim"]], "4 Cross Layer Equalization": [[19, "4-Cross-Layer-Equalization"]], "5 Exporting": [[19, "5-Exporting"]], "4. Perform QAT": [[20, "4.-Perform-QAT"], [21, "4.-Perform-QAT"], [30, "4.-Perform-QAT"], [31, "4.-Perform-QAT"]], "2. Load the model": [[22, "2.-Load-the-model"], [32, "2.-Load-the-model"]], "Per op analysis by enabling/disabling quantization ops": [[22, "Per-op-analysis-by-enabling/disabling-quantization-ops"]], "Per op MSE loss": [[22, "Per-op-MSE-loss"]], "Model compression using Channel Pruning": [[23, "Model-compression-using-Channel-Pruning"]], "Model compression using Spatial SVD": [[24, "Model-compression-using-Spatial-SVD"]], "3.1. Compress model using Spatial SVD and evaluate it to find post-compression accuracy": [[24, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"], [25, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"]], "Model compression using Spatial SVD followed by Channel Pruning": [[25, "Model-compression-using-Spatial-SVD-followed-by-Channel-Pruning"]], "1. Define Constants and Helper functions": [[27, "1.-Define-Constants-and-Helper-functions"]], "3. Run AutoQuant": [[27, "3.-Run-AutoQuant"]], "Create AutoQuant Object": [[27, "Create-AutoQuant-Object"]], "Run AutoQuant Inference": [[27, "Run-AutoQuant-Inference"]], "Set AdaRound Parameters (optional)": [[27, "Set-AdaRound-Parameters-(optional)"]], "Run AutoQuant Optimization": [[27, "Run-AutoQuant-Optimization"]], "Using AIMET Tensorflow APIs with Keras Models": [[33, "using-aimet-tensorflow-apis-with-keras-models"]], "Introduction": [[33, "introduction"], [37, "introduction"], [38, "introduction"], [39, "introduction"], [43, "introduction"], [50, "introduction"], [59, "introduction"], [61, "introduction"], [62, "introduction"], [65, "introduction"], [74, "introduction"], [76, "introduction"], [77, "introduction"], [84, "introduction"]], "APIs": [[33, "apis"]], "Code Example": [[33, "code-example"], [37, "code-example"], [39, "code-example"], [40, "code-example"], [50, "code-example"], [51, "code-example"], [62, "code-example"], [63, "code-example"], [66, "code-example"], [77, "code-example"], [78, "code-example"]], "Utility Functions": [[33, "utility-functions"]], "Welcome to AI Model Efficiency Toolkit API Docs!": [[34, "welcome-to-ai-model-efficiency-toolkit-api-docs"]], "Indices and tables": [[34, "indices-and-tables"]], "AIMET Keras APIs": [[35, "aimet-keras-apis"]], "AIMET Keras AdaRound API": [[36, "aimet-keras-adaround-api"]], "User Guide Link": [[36, "user-guide-link"], [39, "user-guide-link"], [46, "user-guide-link"], [48, "user-guide-link"], [49, "user-guide-link"], [50, "user-guide-link"], [57, "user-guide-link"], [58, "user-guide-link"], [60, "user-guide-link"], [62, "user-guide-link"], [68, "user-guide-link"], [71, "user-guide-link"], [73, "user-guide-link"], [75, "user-guide-link"], [77, "user-guide-link"], [85, "user-guide-link"], [87, "user-guide-link"]], "Examples Notebook Link": [[36, "examples-notebook-link"], [37, "examples-notebook-link"], [39, "examples-notebook-link"], [57, "examples-notebook-link"], [58, "examples-notebook-link"], [59, "examples-notebook-link"], [62, "examples-notebook-link"], [68, "examples-notebook-link"], [71, "examples-notebook-link"], [73, "examples-notebook-link"], [74, "examples-notebook-link"], [77, "examples-notebook-link"], [85, "examples-notebook-link"], [87, "examples-notebook-link"]], "Top-level API": [[36, "top-level-api"], [40, "top-level-api"], [42, "top-level-api"], [44, "top-level-api"], [46, "top-level-api"], [48, "top-level-api"], [49, "top-level-api"], [51, "top-level-api"], [52, "top-level-api"], [54, "top-level-api"], [57, "top-level-api"], [58, "top-level-api"], [63, "top-level-api"], [66, "top-level-api"], [68, "top-level-api"], [71, "top-level-api"], [73, "top-level-api"], [78, "top-level-api"], [80, "top-level-api"], [83, "top-level-api"], [85, "top-level-api"], [87, "top-level-api"], [112, "top-level-api"], [113, "top-level-api"]], "Adaround Parameters": [[36, "adaround-parameters"], [48, "adaround-parameters"], [57, "adaround-parameters"], [71, "adaround-parameters"]], "Enum Definition": [[36, "enum-definition"], [57, "enum-definition"], [71, "enum-definition"], [78, "enum-definition"], [87, "enum-definition"]], "Code Examples": [[36, "code-examples"], [38, "code-examples"], [42, "code-examples"], [44, "code-examples"], [46, "code-examples"], [49, "code-examples"], [52, "code-examples"], [54, "code-examples"], [57, "code-examples"], [58, "code-examples"], [61, "code-examples"], [68, "code-examples"], [73, "code-examples"], [76, "code-examples"], [80, "code-examples"], [85, "code-examples"], [88, "code-examples"], [89, "code-examples"], [114, "code-examples"]], "AIMET Keras BatchNorm Re-estimation APIs": [[37, "aimet-keras-batchnorm-re-estimation-apis"]], "Top-level APIs": [[37, "top-level-apis"], [59, "top-level-apis"], [74, "top-level-apis"]], "Limitations": [[37, "limitations"], [42, "limitations"]], "AIMET Keras Compression API": [[38, "aimet-keras-compression-api"]], "Top-level API for Compression": [[38, "top-level-api-for-compression"], [61, "top-level-api-for-compression"], [76, "top-level-api-for-compression"]], "Greedy Selection Parameters": [[38, "greedy-selection-parameters"], [61, "greedy-selection-parameters"], [76, "greedy-selection-parameters"]], "Spatial SVD Configuration": [[38, "spatial-svd-configuration"], [61, "spatial-svd-configuration"], [76, "spatial-svd-configuration"]], "Configuration Definitions": [[38, "configuration-definitions"], [61, "configuration-definitions"], [76, "configuration-definitions"]], "AIMET Keras Cross Layer Equalization APIs": [[39, "aimet-keras-cross-layer-equalization-apis"]], "Cross Layer Equalization API": [[39, "cross-layer-equalization-api"], [50, "cross-layer-equalization-api"], [62, "cross-layer-equalization-api"], [77, "cross-layer-equalization-api"]], "Primitive APIs": [[39, "primitive-apis"], [62, "primitive-apis"], [77, "primitive-apis"]], "AIMET Keras Layer Output Generation API": [[40, "aimet-keras-layer-output-generation-api"]], "Keras Model Guidelines": [[41, "keras-model-guidelines"]], "Model Preparer API": [[42, "model-preparer-api"], [80, "model-preparer-api"]], "AIMET Keras Cross Layer Equalization Primitive API": [[43, "aimet-keras-cross-layer-equalization-primitive-api"]], "Higher Level APIs for Cross Layer Equalization": [[43, "higher-level-apis-for-cross-layer-equalization"], [65, "higher-level-apis-for-cross-layer-equalization"], [84, "higher-level-apis-for-cross-layer-equalization"]], "Code Examples for Higher Level APIs": [[43, "code-examples-for-higher-level-apis"], [65, "code-examples-for-higher-level-apis"], [84, "code-examples-for-higher-level-apis"]], "Lower Level APIs for Cross Layer Equalization": [[43, "lower-level-apis-for-cross-layer-equalization"], [65, "lower-level-apis-for-cross-layer-equalization"], [84, "lower-level-apis-for-cross-layer-equalization"]], "Custom Datatype used": [[43, "custom-datatype-used"], [65, "custom-datatype-used"]], "Code Example for Lower level APIs": [[43, "code-example-for-lower-level-apis"], [65, "code-example-for-lower-level-apis"]], "Example helper methods to perform CLE in manual mode": [[43, "example-helper-methods-to-perform-cle-in-manual-mode"], [65, "example-helper-methods-to-perform-cle-in-manual-mode"]], "AIMET Keras Quant Analyzer API": [[44, "aimet-keras-quant-analyzer-api"]], "AIMET Keras Quantization APIs": [[45, "aimet-keras-quantization-apis"]], "AIMET Keras Quantization SIM API": [[46, "aimet-keras-quantization-sim-api"]], "AIMET ONNX APIs": [[47, "aimet-onnx-apis"]], "AIMET ONNX AdaRound API": [[48, "aimet-onnx-adaround-api"]], "Code Example - Adaptive Rounding (AdaRound)": [[48, "code-example-adaptive-rounding-adaround"], [71, "code-example-adaptive-rounding-adaround"]], "AIMET ONNX AutoQuant API": [[49, "aimet-onnx-autoquant-api"]], "AIMET ONNX Cross Layer Equalization APIs": [[50, "aimet-onnx-cross-layer-equalization-apis"]], "AIMET ONNX Layer Output Generation API": [[51, "aimet-onnx-layer-output-generation-api"]], "AIMET ONNX Quant Analyzer API": [[52, "aimet-onnx-quant-analyzer-api"]], "Run specific utility": [[52, "run-specific-utility"], [85, "run-specific-utility"]], "AIMET ONNX Quantization APIs": [[53, "aimet-onnx-quantization-apis"]], "AIMET ONNX Quantization SIM API": [[54, "aimet-onnx-quantization-sim-api"]], "Encoding Format Specification": [[55, "encoding-format-specification"]], "1. Versioning": [[55, "versioning"]], "2. Version 0.4.0 (up to)": [[55, "version-0-4-0-up-to"]], "2.1. Encoding Specification": [[55, "encoding-specification"]], "2.2. Encoding File Example for PyTorch": [[55, "encoding-file-example-for-pytorch"]], "2.3. Encoding File Example for TensorFlow": [[55, "encoding-file-example-for-tensorflow"]], "3. Version 0.5.0": [[55, "version-0-5-0"]], "3.1. Encoding Specification": [[55, "id1"]], "3.2. Encoding File Example for PyTorch": [[55, "id2"]], "3.3. Encoding File Example for TensorFlow": [[55, "id3"]], "4. Version 0.6.1": [[55, "version-0-6-1"]], "4.1. Encoding Specification": [[55, "id4"]], "AIMET TensorFlow APIs": [[56, "aimet-tensorflow-apis"]], "AIMET TensorFlow AdaRound API": [[57, "aimet-tensorflow-adaround-api"]], "AIMET TensorFlow AutoQuant API": [[58, "aimet-tensorflow-autoquant-api"]], "AIMET TensorFlow BatchNorm Re-estimation APIs": [[59, "aimet-tensorflow-batchnorm-re-estimation-apis"]], "Code Example - BN-Reestimation": [[59, "code-example-bn-reestimation"], [74, "code-example-bn-reestimation"]], "AIMET TensorFlow Bias Correction API": [[60, "aimet-tensorflow-bias-correction-api"]], "Bias Correction API": [[60, "bias-correction-api"], [75, "bias-correction-api"]], "Input Parameter Types": [[60, "input-parameter-types"]], "Data Input Type": [[60, "data-input-type"]], "Code Examples for Bias Correction": [[60, "code-examples-for-bias-correction"]], "Bias Correction Per Layer API": [[60, "bias-correction-per-layer-api"]], "Code Example for Per-Layer Bias Correction": [[60, "code-example-for-per-layer-bias-correction"]], "AIMET TensorFlow Compression API": [[61, "aimet-tensorflow-compression-api"]], "Channel Pruning Configuration": [[61, "channel-pruning-configuration"], [76, "channel-pruning-configuration"]], "Weight SVD Top-level API": [[61, "weight-svd-top-level-api"]], "Code Examples for Weight SVD": [[61, "code-examples-for-weight-svd"]], "AIMET TensorFlow Cross Layer Equalization APIs": [[62, "aimet-tensorflow-cross-layer-equalization-apis"]], "AIMET Tensorflow Layer Output Generation API": [[63, "aimet-tensorflow-layer-output-generation-api"]], "TensorFlow Model Guidelines": [[64, "tensorflow-model-guidelines"]], "AIMET TensorFlow Cross Layer Equalization Primitive API": [[65, "aimet-tensorflow-cross-layer-equalization-primitive-api"]], "AIMET Tensorflow Quant Analyzer API": [[66, "aimet-tensorflow-quant-analyzer-api"]], "AIMET TensorFlow Quantization APIs": [[67, "aimet-tensorflow-quantization-apis"]], "AIMET TensorFlow Quantization SIM API": [[68, "aimet-tensorflow-quantization-sim-api"]], "AIMET Visualization for Quantization for TensorFlow API": [[69, "aimet-visualization-for-quantization-for-tensorflow-api"]], "Top-level API for Visualization of Weight tensors": [[69, "top-level-api-for-visualization-of-weight-tensors"]], "Code Examples for Visualization of Weight tensors": [[69, "code-examples-for-visualization-of-weight-tensors"]], "AIMET PyTorch APIs": [[70, "aimet-pytorch-apis"]], "AIMET PyTorch AdaRound API": [[71, "aimet-pytorch-adaround-api"]], "Architecture Checker API": [[72, "architecture-checker-api"]], "HTML report content": [[72, "id1"]], "AIMET PyTorch AutoQuant API": [[73, "aimet-pytorch-autoquant-api"]], "AIMET PyTorch BatchNorm Re-estimation APIs": [[74, "aimet-pytorch-batchnorm-re-estimation-apis"]], "AIMET PyTorch Bias Correction API": [[75, "aimet-pytorch-bias-correction-api"]], "ConvBnInfoType": [[75, "convbninfotype"]], "ActivationType": [[75, "activationtype"]], "Quantization Params": [[75, "quantization-params"]], "Code Example #1 Empirical Bias Correction": [[75, "code-example-1-empirical-bias-correction"]], "Code Example #2 Analytical + Empirical Bias correction": [[75, "code-example-2-analytical-empirical-bias-correction"]], "AIMET PyTorch Compression API": [[76, "aimet-pytorch-compression-api"]], "TAR Selection Parameters": [[76, "tar-selection-parameters"]], "Weight SVD Configuration": [[76, "weight-svd-configuration"]], "AIMET PyTorch Cross Layer Equalization APIs": [[77, "aimet-pytorch-cross-layer-equalization-apis"]], "AIMET PyTorch Layer Output Generation API": [[78, "aimet-pytorch-layer-output-generation-api"]], "PyTorch Model Guidelines": [[79, "pytorch-model-guidelines"]], "Limitations of torch.fx symbolic trace API": [[80, "limitations-of-torch-fx-symbolic-trace-api"]], "Model Validator Utility": [[81, "model-validator-utility"]], "PyTorch Multi-GPU support": [[82, "pytorch-multi-gpu-support"]], "PEFT LoRA": [[83, "peft-lora"]], "User flow": [[83, "user-flow"]], "AIMET PyTorch Cross Layer Equalization Primitive API": [[84, "aimet-pytorch-cross-layer-equalization-primitive-api"]], "ClsSetInfo Definition": [[84, "clssetinfo-definition"]], "Code Examples for Lower Level APIs": [[84, "code-examples-for-lower-level-apis"]], "AIMET PyTorch Quant Analyzer API": [[85, "aimet-pytorch-quant-analyzer-api"]], "AIMET PyTorch Quantization APIs": [[86, "aimet-pytorch-quantization-apis"]], "AIMET PyTorch Quantization SIM API": [[87, "aimet-pytorch-quantization-sim-api"]], "Guidelines": [[87, "guidelines"]], "Code Example - Quantization Aware Training (QAT)": [[87, "code-example-quantization-aware-training-qat"]], "AIMET Visualization Compression API": [[88, "aimet-visualization-compression-api"]], "Top-level API Compression": [[88, "top-level-api-compression"]], "AIMET Visualization for Quantization API": [[89, "aimet-visualization-for-quantization-api"]], "Top-level API Quantization": [[89, "top-level-api-quantization"]], "AIMET Installation": [[90, "aimet-installation"]], "Quick Install": [[90, "quick-install"]], "Release Packages": [[90, "release-packages"]], "System Requirements": [[90, "system-requirements"]], "Advanced Installation Instructions": [[90, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[91, "aimet-installation-in-docker"]], "Set variant": [[91, "set-variant"]], "Use prebuilt docker image": [[91, "use-prebuilt-docker-image"]], "Build docker image locally": [[91, "build-docker-image-locally"]], "Start docker container": [[91, "start-docker-container"]], "Install AIMET packages": [[91, "install-aimet-packages"], [92, "install-aimet-packages"]], "From PyPI": [[91, "from-pypi"], [92, "from-pypi"]], "From Release Package": [[91, "from-release-package"], [92, "from-release-package"]], "Environment setup": [[91, "environment-setup"], [92, "environment-setup"]], "AIMET Installation and Setup": [[92, "aimet-installation-and-setup"]], "Install prerequisite packages": [[92, "install-prerequisite-packages"]], "Install GPU packages": [[92, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or TensorFlow": [[92, "install-gpu-packages-for-pytorch-2-1-or-tensorflow"]], "Install GPU packages for PyTorch 1.13 or ONNX": [[92, "install-gpu-packages-for-pytorch-1-13-or-onnx"]], "Install common debian packages": [[92, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[92, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[92, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[92, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[92, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[92, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[92, "post-installation-steps"]], "FakeQuantizationMixin": [[94, "fakequantizationmixin"]], "QuantizationMixin": [[95, "quantizationmixin"]], "Quantize": [[96, "quantize"]], "QuantizeDequantize": [[97, "quantizedequantize"], [102, "quantizedequantize"]], "dequantize": [[98, "dequantize"]], "quantize": [[99, "quantize"]], "quantize_dequantize": [[100, "quantize-dequantize"]], "quantization.affine": [[101, "module-aimet_torch.v2.quantization.affine"]], "Classes": [[101, "classes"], [104, "classes"]], "Functions": [[101, "functions"]], "FloatQuantizeDequantize": [[102, "floatquantizedequantize"]], "quantization.float": [[103, "module-aimet_torch.v2.quantization.float"]], "quantization.tensor": [[104, "quantization-tensor"]], "Blockwise Quantization": [[105, "blockwise-quantization"]], "Low Power Blockwise Quantization (LPBQ)": [[105, "low-power-blockwise-quantization-lpbq"]], "Top Level API": [[105, "top-level-api"]], "Export": [[105, "export"]], "Encoding Analyzers": [[106, "encoding-analyzers"]], "Variants": [[106, "variants"]], "Post-Training Quantization": [[107, "post-training-quantization"], [127, "post-training-quantization"]], "MinMaxEncodingAnalyzer": [[108, "minmaxencodinganalyzer"]], "PercentileEncodingAnalyzer": [[109, "percentileencodinganalyzer"]], "SqnrEncodingAnalyzer": [[110, "sqnrencodinganalyzer"]], "AIMET: AI Model Efficiency Toolkit Documentation": [[111, "aimet-ai-model-efficiency-toolkit-documentation"]], "Getting Started": [[111, "getting-started"], [123, "getting-started"]], "Examples": [[111, null]], "Feature Descriptions": [[111, null]], "AIMET PyTorch API": [[111, null]], "Quantized Modules": [[112, "quantized-modules"]], "Configuration": [[112, "configuration"]], "Computing Encodings": [[112, "computing-encodings"]], "Quantized Module Classes": [[112, "quantized-module-classes"]], "Quantizers": [[113, "quantizers"]], "Migrate to QuantSim v2": [[114, "migrate-to-quantsim-v2"]], "Changes in QuantSim v2": [[114, "changes-in-quantsim-v2"]], "Migration Process": [[114, "migration-process"]], "Imports": [[114, "imports"]], "QuantizationSimModel": [[114, "quantizationsimmodel"]], "Moving from QuantWrapper to Quantized Modules": [[114, "moving-from-quantwrapper-to-quantized-modules"]], "Moving from StaticGrid and LearnedGrid Quantizer to Affine and Float Quantizer": [[114, "moving-from-staticgrid-and-learnedgrid-quantizer-to-affine-and-float-quantizer"]], "Deprecated Features": [[114, "deprecated-features"]], "Quickstart Guide": [[115, "quickstart-guide"]], "PyTorch prerequisites": [[115, "pytorch-prerequisites"]], "Prepare the floating point model for quantization": [[115, "prepare-the-floating-point-model-for-quantization"]], "1) Model preparation": [[115, "model-preparation"]], "2) BatchNorm fold": [[115, "batchnorm-fold"]], "Quantize the model": [[115, "quantize-the-model"]], "Fine-tune the model with quantization aware training": [[115, "fine-tune-the-model-with-quantization-aware-training"]], "Export the quantsim model": [[115, "export-the-quantsim-model"]], "AIMET AdaRound": [[116, "aimet-adaround"]], "AdaRound Use Cases": [[116, "adaround-use-cases"]], "Common terminology": [[116, "common-terminology"]], "Use Cases": [[116, "use-cases"], [127, "use-cases"]], "AIMET AutoQuant": [[117, "aimet-autoquant"]], "Overview": [[117, "overview"], [118, "overview"], [122, "overview"], [123, "overview"], [125, "overview"], [128, "overview"], [129, "overview"], [130, "overview"], [131, "overview"], [133, "overview"], [134, "overview"], [137, "overview"], [138, "overview"], [140, "overview"]], "Workflow": [[117, "workflow"], [118, "workflow"]], "AIMET BN Re-estimation": [[118, "aimet-bn-re-estimation"]], "AIMET Channel Pruning": [[119, "aimet-channel-pruning"]], "Overall Procedure": [[119, "overall-procedure"]], "Channel Selection": [[119, "channel-selection"]], "Winnowing": [[119, "winnowing"]], "Weight Reconstruction": [[119, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[120, "aimet-compression-features-guidebook"]], "AIMET Examples": [[121, "aimet-examples"]], "Browse the notebooks": [[121, "browse-the-notebooks"]], "Running the notebooks": [[121, "running-the-notebooks"]], "Install Jupyter": [[121, "install-jupyter"]], "Download the Example notebooks and related code": [[121, "download-the-example-notebooks-and-related-code"]], "Run the notebooks": [[121, "run-the-notebooks"]], "AIMET Greedy Compression Ratio Selection": [[122, "aimet-greedy-compression-ratio-selection"]], "How it works": [[122, "how-it-works"]], "Per-layer Exploration": [[122, "per-layer-exploration"]], "Compression Ratio Selection": [[122, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[123, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[123, "features"]], "Release Information": [[123, "release-information"]], "Installation Guide": [[123, "installation-guide"]], "toc tree": [[123, "toc-tree"]], "AIMET Known Issues": [[124, "aimet-known-issues"]], "AIMET Model Compression": [[125, "aimet-model-compression"]], "Use Case": [[125, "use-case"]], "Compression ratio selection": [[125, "compression-ratio-selection"]], "Model Compression": [[125, "model-compression"]], "Optional techniques to get better compression results": [[125, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[125, "rank-rounding"]], "Per-layer Fine-tuning": [[125, "per-layer-fine-tuning"]], "FAQs": [[125, "faqs"], [128, "faqs"]], "References": [[125, "references"], [128, "references"]], "Model Guidelines for PyTorch": [[126, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[127, "aimet-model-quantization"]], "AIMET Quantization Features": [[127, "aimet-quantization-features"]], "Debugging/Analysis Tools": [[127, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[127, "aimet-quantization-workflow"]], "PyTorch": [[127, "pytorch"], [138, "pytorch"]], "Tensorflow": [[127, "tensorflow"]], "Debugging Guidelines": [[127, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[128, "aimet-post-training-quantization-techniques"]], "User Flow": [[128, "user-flow"]], "AIMET QuantAnalyzer": [[129, "aimet-quantanalyzer"]], "Requirements": [[129, "requirements"]], "Detailed Analysis Descriptions": [[129, "detailed-analysis-descriptions"]], "AIMET Quantization Aware Training": [[130, "aimet-quantization-aware-training"]], "QAT workflow": [[130, "qat-workflow"]], "QAT modes": [[130, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[130, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[131, "quantization-simulation-configuration"]], "Configuration File Structure": [[131, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[131, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[132, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[133, "aimet-quantization-simulation"]], "QuantSim Workflow": [[133, "quantsim-workflow"]], "Simulating Quantization Noise": [[133, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[133, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[133, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[133, "configuring-quantization-simulation-ops"]], "Frequently Asked Questions": [[133, "frequently-asked-questions"]], "QuantSim v2": [[134, "quantsim-v2"]], "Using QuantSim v2": [[134, "using-quantsim-v2"]], "New Features": [[134, "new-features"]], "AIMET Release Notes": [[135, "aimet-release-notes"]], "1.22.2": [[135, "id1"]], "1.22.1": [[135, "id2"]], "1.22.0": [[135, "id3"]], "1.21.0": [[135, "id4"]], "1.20.0": [[135, "id5"]], "1.19.1.py37": [[135, "py37"]], "1.19.1": [[135, "id6"]], "1.18.0.py37": [[135, "id7"]], "1.18.0": [[135, "id8"]], "1.17.0.py37": [[135, "id9"]], "1.17.0": [[135, "id10"]], "1.16.2.py37": [[135, "id11"]], "1.16.2": [[135, "id12"]], "1.16.1.py37": [[135, "id13"]], "1.16.1": [[135, "id14"]], "1.16.0": [[135, "id15"]], "1.14.0": [[135, "id16"]], "1.13.0": [[135, "id17"]], "AIMET Spatial SVD": [[136, "aimet-spatial-svd"]], "AIMET Visualization": [[137, "aimet-visualization"]], "Design": [[137, "design"]], "Compression": [[137, "compression"]], "Starting a Bokeh Server Session:": [[137, "starting-a-bokeh-server-session"]], "How to use the tool": [[137, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[138, "aimet-visualization-for-quantization"]], "Quantization": [[138, "quantization"]], "TensorFlow": [[138, "tensorflow"]], "AIMET Weight SVD": [[139, "aimet-weight-svd"]], "AIMET Winnowing": [[140, "aimet-winnowing"]], "Winnowing Overview": [[140, "winnowing-overview"]], "How Winnowing Works": [[140, "how-winnowing-works"]]}, "indexentries": {"load_keras_model_multi_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.load_keras_model_multi_gpu"]], "load_tf_sess_variables_to_keras_single_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.load_tf_sess_variables_to_keras_single_gpu"]], "save_as_tf_module_multi_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.save_as_tf_module_multi_gpu"]], "save_tf_session_single_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.save_tf_session_single_gpu"]], "adaroundparameters (class in aimet_tensorflow.adaround.adaround_weight)": [[36, "aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"], [57, "aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"]], "quantscheme (class in aimet_common.defs)": [[36, "aimet_common.defs.QuantScheme"], [57, "aimet_common.defs.QuantScheme"], [71, "aimet_common.defs.QuantScheme"], [87, "aimet_common.defs.QuantScheme"]], "post_training_percentile (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_percentile"], [57, "aimet_common.defs.QuantScheme.post_training_percentile"], [71, "aimet_common.defs.QuantScheme.post_training_percentile"], [87, "aimet_common.defs.QuantScheme.post_training_percentile"]], "post_training_tf (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_tf"], [57, "aimet_common.defs.QuantScheme.post_training_tf"], [71, "aimet_common.defs.QuantScheme.post_training_tf"], [87, "aimet_common.defs.QuantScheme.post_training_tf"]], "post_training_tf_enhanced (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [57, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [71, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [87, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"]], "training_range_learning_with_tf_enhanced_init (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [57, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [71, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [87, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"]], "training_range_learning_with_tf_init (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [57, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [71, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [87, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"]], "fold_all_batch_norms_to_scale() (in module aimet_tensorflow.keras.batch_norm_fold)": [[37, "aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_tensorflow.keras.bn_reestimation)": [[37, "aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"]], "compressionscheme (class in aimet_common.defs)": [[38, "aimet_common.defs.CompressionScheme"], [61, "aimet_common.defs.CompressionScheme"]], "costmetric (class in aimet_common.defs)": [[38, "aimet_common.defs.CostMetric"], [61, "aimet_common.defs.CostMetric"]], "modelcompressor (class in aimet_tensorflow.keras.compress)": [[38, "aimet_tensorflow.keras.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.ModuleCompRatioPair"], [61, "aimet_tensorflow.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters"], [61, "aimet_tensorflow.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode"]], "auto (aimet_tensorflow.defs.spatialsvdparameters.mode attribute)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"]], "channel_pruning (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.channel_pruning"], [61, "aimet_common.defs.CompressionScheme.channel_pruning"]], "compress_model() (aimet_tensorflow.keras.compress.modelcompressor static method)": [[38, "aimet_tensorflow.keras.compress.ModelCompressor.compress_model"]], "mac (aimet_common.defs.costmetric attribute)": [[38, "aimet_common.defs.CostMetric.mac"], [61, "aimet_common.defs.CostMetric.mac"]], "manual (aimet_tensorflow.defs.spatialsvdparameters.mode attribute)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"]], "memory (aimet_common.defs.costmetric attribute)": [[38, "aimet_common.defs.CostMetric.memory"], [61, "aimet_common.defs.CostMetric.memory"]], "spatial_svd (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.spatial_svd"], [61, "aimet_common.defs.CompressionScheme.spatial_svd"]], "weight_svd (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.weight_svd"], [61, "aimet_common.defs.CompressionScheme.weight_svd"]], "equalize_model() (in module aimet_tensorflow.keras.cross_layer_equalization)": [[39, "aimet_tensorflow.keras.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_tensorflow.keras.layer_output_utils)": [[40, "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil"]], "generate_layer_outputs() (aimet_tensorflow.keras.layer_output_utils.layeroutpututil method)": [[40, "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "prepare_model() (in module aimet_tensorflow.keras.model_preparer)": [[42, "aimet_tensorflow.keras.model_preparer.prepare_model"]], "clssetinfo (class in aimet_tensorflow.keras.cross_layer_equalization)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_tensorflow.keras.cross_layer_equalization)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_tensorflow.keras.cross_layer_equalization.highbiasfold)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold.bias_fold"], [43, "id0"]], "fold_all_batch_norms() (in module aimet_tensorflow.keras.batch_norm_fold)": [[43, "aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_tensorflow.keras.batch_norm_fold)": [[43, "aimet_tensorflow.keras.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_tensorflow.keras.cross_layer_equalization.crosslayerscaling)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_tensorflow.keras.cross_layer_equalization.crosslayerscaling)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_model"]], "quantanalyzer (class in aimet_tensorflow.keras.quant_analyzer)": [[44, "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_tensorflow.keras.quant_analyzer.quantanalyzer method)": [[44, "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer.analyze"]], "quantizationsimmodel (class in aimet_tensorflow.keras.quantsim)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_tensorflow.keras.quantsim.quantizationsimmodel method)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_tensorflow.keras.quantsim.quantizationsimmodel method)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel.export"]], "apply_adaround() (in module aimet_tensorflow.adaround.adaround_weight.adaround)": [[57, "aimet_tensorflow.adaround.adaround_weight.Adaround.apply_adaround"]], "autoquant (class in aimet_tensorflow.auto_quant)": [[58, "aimet_tensorflow.auto_quant.AutoQuant"]], "apply() (aimet_tensorflow.auto_quant.autoquant method)": [[58, "aimet_tensorflow.auto_quant.AutoQuant.apply"]], "set_adaround_params() (aimet_tensorflow.auto_quant.autoquant method)": [[58, "aimet_tensorflow.auto_quant.AutoQuant.set_adaround_params"]], "fold_all_batch_norms_to_scale() (in module aimet_tensorflow.batch_norm_fold)": [[59, "aimet_tensorflow.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_tensorflow.bn_reestimation)": [[59, "aimet_tensorflow.bn_reestimation.reestimate_bn_stats"]], "biascorrectionparams() (in module aimet_tensorflow.bias_correction)": [[60, "aimet_tensorflow.bias_correction.BiasCorrectionParams"]], "quantparams (class in aimet_tensorflow.bias_correction)": [[60, "aimet_tensorflow.bias_correction.QuantParams"]], "analytical_bias_correction_per_layer() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.analytical_bias_correction_per_layer"]], "bias_correction_per_layer() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.bias_correction_per_layer"]], "correct_bias() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.correct_bias"]], "channelpruningparameters (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode"]], "modelcompressor (class in aimet_tensorflow.compress)": [[61, "aimet_tensorflow.compress.ModelCompressor"]], "svd (class in aimet_tensorflow.svd)": [[61, "aimet_tensorflow.svd.Svd"]], "auto (aimet_tensorflow.defs.channelpruningparameters.mode attribute)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode.auto"]], "compress_model() (aimet_tensorflow.compress.modelcompressor static method)": [[61, "aimet_tensorflow.compress.ModelCompressor.compress_model"]], "compress_net() (aimet_tensorflow.svd.svd method)": [[61, "aimet_tensorflow.svd.Svd.compress_net"]], "manual (aimet_tensorflow.defs.channelpruningparameters.mode attribute)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode.manual"]], "equalize_model() (in module aimet_tensorflow.cross_layer_equalization)": [[62, "aimet_tensorflow.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_tensorflow.layer_output_utils)": [[63, "aimet_tensorflow.layer_output_utils.LayerOutputUtil"]], "generate_layer_outputs() (aimet_tensorflow.layer_output_utils.layeroutpututil method)": [[63, "aimet_tensorflow.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "update_keras_bn_ops_trainable_flag() (in module aimet_tensorflow.utils.graph)": [[64, "aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"]], "clssetinfo (class in aimet_tensorflow.cross_layer_equalization)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_tensorflow.cross_layer_equalization)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_tensorflow.cross_layer_equalization.highbiasfold)": [[65, "aimet_tensorflow.cross_layer_equalization.HighBiasFold.bias_fold"], [65, "id0"]], "fold_all_batch_norms() (in module aimet_tensorflow.batch_norm_fold)": [[65, "aimet_tensorflow.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_tensorflow.batch_norm_fold)": [[65, "aimet_tensorflow.batch_norm_fold.fold_given_batch_norms"]], "map_cls_sets_to_new_session() (aimet_tensorflow.cross_layer_equalization.clssetinfo static method)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo.map_cls_sets_to_new_session"]], "scale_cls_sets() (in module aimet_tensorflow.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_tensorflow.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling.scale_model"]], "quantanalyzer (class in aimet_tensorflow.quant_analyzer)": [[66, "aimet_tensorflow.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_tensorflow.quant_analyzer.quantanalyzer method)": [[66, "aimet_tensorflow.quant_analyzer.QuantAnalyzer.analyze"]], "quantizationsimmodel (class in aimet_tensorflow.quantsim)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_tensorflow.quantsim.quantizationsimmodel method)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_tensorflow.quantsim.quantizationsimmodel method)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel.export"]], "visualize_relative_weight_ranges_single_layer() (in module aimet_tensorflow.plotting_utils)": [[69, "aimet_tensorflow.plotting_utils.visualize_relative_weight_ranges_single_layer"]], "visualize_weight_ranges_single_layer() (in module aimet_tensorflow.plotting_utils)": [[69, "aimet_tensorflow.plotting_utils.visualize_weight_ranges_single_layer"]], "adaroundparameters (class in aimet_torch.adaround.adaround_weight)": [[71, "aimet_torch.adaround.adaround_weight.AdaroundParameters"]], "apply_adaround() (in module aimet_torch.adaround.adaround_weight.adaround)": [[71, "aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"]], "check_model_arch() (in module aimet_torch.arch_checker.arch_checker.archchecker)": [[72, "aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"]], "autoquant (class in aimet_torch.auto_quant)": [[73, "aimet_torch.auto_quant.AutoQuant"]], "fold_all_batch_norms_to_scale() (in module aimet_torch.batch_norm_fold)": [[74, "aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_torch.bn_reestimation)": [[74, "aimet_torch.bn_reestimation.reestimate_bn_stats"]], "activationtype (class in aimet_common.defs)": [[75, "aimet_common.defs.ActivationType"]], "convbninfotype (class in aimet_common.bias_correction)": [[75, "aimet_common.bias_correction.ConvBnInfoType"]], "quantparams (class in aimet_torch.quantsim)": [[75, "aimet_torch.quantsim.QuantParams"]], "correct_bias() (in module aimet_torch.bias_correction)": [[75, "aimet_torch.bias_correction.correct_bias"]], "no_activation (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.no_activation"]], "relu (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.relu"]], "relu6 (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.relu6"]], "channelpruningparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode"]], "greedyselectionparameters (class in aimet_common.defs)": [[76, "aimet_common.defs.GreedySelectionParameters"]], "modelcompressor (class in aimet_torch.compress)": [[76, "aimet_torch.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode"]], "tarrankselectionparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.TarRankSelectionParameters"]], "weightsvdparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters"]], "weightsvdparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.AutoModeParams"]], "weightsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.ManualModeParams"]], "weightsvdparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode"]], "auto (aimet_torch.defs.channelpruningparameters.mode attribute)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode.auto"]], "auto (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode.auto"]], "auto (aimet_torch.defs.weightsvdparameters.mode attribute)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode.auto"]], "compress_model() (aimet_torch.compress.modelcompressor static method)": [[76, "aimet_torch.compress.ModelCompressor.compress_model"]], "manual (aimet_torch.defs.channelpruningparameters.mode attribute)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode.manual"]], "manual (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode.manual"]], "manual (aimet_torch.defs.weightsvdparameters.mode attribute)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode.manual"]], "equalize_model() (in module aimet_torch.cross_layer_equalization)": [[77, "aimet_torch.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_torch.layer_output_utils)": [[78, "aimet_torch.layer_output_utils.LayerOutputUtil"]], "namingscheme (class in aimet_torch.layer_output_utils)": [[78, "aimet_torch.layer_output_utils.NamingScheme"]], "onnx (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.ONNX"]], "pytorch (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.PYTORCH"]], "torchscript (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"]], "generate_layer_outputs() (aimet_torch.layer_output_utils.layeroutpututil method)": [[78, "aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "prepare_model() (in module aimet_torch.model_preparer)": [[80, "aimet_torch.model_preparer.prepare_model"]], "adaptermetadata (class in aimet_torch.peft)": [[83, "aimet_torch.peft.AdapterMetaData"]], "peftquantutils (class in aimet_torch.peft)": [[83, "aimet_torch.peft.PeftQuantUtils"]], "disable_lora_adapters() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"]], "enable_adapter_and_load_weights() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"]], "export_adapter_weights() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.export_adapter_weights"]], "freeze_base_model() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.freeze_base_model"]], "freeze_base_model_activation_quantizers() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"]], "freeze_base_model_param_quantizers() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"]], "get_quantized_lora_layer() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"]], "replace_lora_layers_with_quantizable_layers() (aimet_torch.peft method)": [[83, "aimet_torch.peft.replace_lora_layers_with_quantizable_layers"]], "set_bitwidth_for_lora_adapters() (aimet_torch.peft.peftquantutils method)": [[83, "aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"]], "track_lora_meta_data() (aimet_torch.peft method)": [[83, "aimet_torch.peft.track_lora_meta_data"]], "clssetinfo (class in aimet_torch.cross_layer_equalization)": [[84, "aimet_torch.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_torch.cross_layer_equalization)": [[84, "aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_torch.cross_layer_equalization.highbiasfold)": [[84, "aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"], [84, "id0"]], "fold_all_batch_norms() (in module aimet_torch.batch_norm_fold)": [[84, "aimet_torch.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_torch.batch_norm_fold)": [[84, "aimet_torch.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[84, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[84, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"]], "callbackfunc (class in aimet_common.utils)": [[85, "aimet_common.utils.CallbackFunc"]], "quantanalyzer (class in aimet_torch.quant_analyzer)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.analyze"]], "check_model_sensitivity_to_quantization() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"]], "enable_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"]], "export_per_layer_encoding_min_max_range() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"]], "export_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"]], "export_per_layer_stats_histogram() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"]], "perform_per_layer_analysis_by_disabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"]], "perform_per_layer_analysis_by_enabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[85, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"]], "quantizationsimmodel (class in aimet_torch.quantsim)": [[87, "aimet_torch.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_torch.quantsim.quantizationsimmodel method)": [[87, "aimet_torch.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_torch.quantsim.quantizationsimmodel method)": [[87, "aimet_torch.quantsim.QuantizationSimModel.export"]], "load_checkpoint() (aimet_torch.quantsim method)": [[87, "aimet_torch.quantsim.load_checkpoint"]], "save_checkpoint() (aimet_torch.quantsim method)": [[87, "aimet_torch.quantsim.save_checkpoint"]], "visualizecompression (class in aimet_torch.visualize_serialized_data)": [[88, "aimet_torch.visualize_serialized_data.VisualizeCompression"]], "display_comp_ratio_plot() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[88, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"]], "display_eval_scores() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[88, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"]], "visualize_changes_after_optimization() (in module aimet_torch.visualize_model)": [[89, "aimet_torch.visualize_model.visualize_changes_after_optimization"]], "visualize_relative_weight_ranges_to_identify_problematic_layers() (in module aimet_torch.visualize_model)": [[89, "aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"]], "visualize_weight_ranges() (in module aimet_torch.visualize_model)": [[89, "aimet_torch.visualize_model.visualize_weight_ranges"]], "fakequantizationmixin (class in aimet_torch.v2.nn)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.fakequantizationmixin method)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.fakequantizationmixin method)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.fakequantizationmixin method)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.from_module"]], "implements() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[94, "aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"]], "quantizationmixin (class in aimet_torch.v2.nn)": [[95, "aimet_torch.v2.nn.QuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.quantizationmixin method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.quantizationmixin method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.quantizationmixin class method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.from_module"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[95, "aimet_torch.v2.nn.QuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[95, "aimet_torch.v2.nn.QuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[95, "aimet_torch.v2.nn.QuantizationMixin.param_quantizers"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[95, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "quantize (class in aimet_torch.v2.quantization.affine)": [[96, "aimet_torch.v2.quantization.affine.Quantize"]], "forward() (aimet_torch.v2.quantization.affine.quantize method)": [[96, "aimet_torch.v2.quantization.affine.Quantize.forward"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine)": [[97, "aimet_torch.v2.quantization.affine.QuantizeDequantize"]], "forward() (aimet_torch.v2.quantization.affine.quantizedequantize method)": [[97, "aimet_torch.v2.quantization.affine.QuantizeDequantize.forward"]], "dequantize() (in module aimet_torch.v2.quantization.affine)": [[98, "aimet_torch.v2.quantization.affine.dequantize"]], "quantize() (in module aimet_torch.v2.quantization.affine)": [[99, "aimet_torch.v2.quantization.affine.quantize"]], "quantize_dequantize() (in module aimet_torch.v2.quantization.affine)": [[100, "aimet_torch.v2.quantization.affine.quantize_dequantize"]], "aimet_torch.v2.quantization.affine": [[101, "module-aimet_torch.v2.quantization.affine"]], "module": [[101, "module-aimet_torch.v2.quantization.affine"], [103, "module-aimet_torch.v2.quantization.float"]], "floatquantizedequantize (class in aimet_torch.v2.quantization.float)": [[102, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.float)": [[102, "aimet_torch.v2.quantization.float.QuantizeDequantize"]], "aimet_torch.v2.quantization.float": [[103, "module-aimet_torch.v2.quantization.float"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[104, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[104, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[104, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[104, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[104, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[104, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[104, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[104, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "set_activation_quantizers_to_float() (in module aimet_torch.v2.quantsim.config_utils)": [[105, "aimet_torch.v2.quantsim.config_utils.set_activation_quantizers_to_float"]], "set_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[105, "aimet_torch.v2.quantsim.config_utils.set_blockwise_quantization_for_weights"]], "set_grouped_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[105, "aimet_torch.v2.quantsim.config_utils.set_grouped_blockwise_quantization_for_weights"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[106, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[108, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[109, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "set_percentile() (aimet_torch.v2.quantization.encoding_analyzer.percentileencodinganalyzer method)": [[109, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.set_percentile"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[110, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "compute_encodings_from_stats() (aimet_torch.v2.quantization.encoding_analyzer.sqnrencodinganalyzer method)": [[110, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.compute_encodings_from_stats"]], "basequantizationmixin (class in aimet_torch.v2.nn.base)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"]], "input_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[112, "aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[113, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "allow_overwrite() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[113, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})