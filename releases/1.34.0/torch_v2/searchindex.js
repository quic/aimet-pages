Search.setIndex({"docnames": ["_templates/autosummary/class", "_templates/autosummary/function", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.fake_quantization_mixin", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/quantization/affine/index", "torch_docs/api/quantization/float/FloatQuantizeDequantize", "torch_docs/api/quantization/float/index", "torch_docs/api/quantization/tensor", "torch_docs/api/visualization_tools", "torch_docs/blockwise_quantization", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/gptvq", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/quickstart_guide", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["_templates/autosummary/class.rst", "_templates/autosummary/function.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.fake_quantization_mixin.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/quantization/affine/index.rst", "torch_docs/api/quantization/float/FloatQuantizeDequantize.rst", "torch_docs/api/quantization/float/index.rst", "torch_docs/api/quantization/tensor.rst", "torch_docs/api/visualization_tools.rst", "torch_docs/blockwise_quantization.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/gptvq.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/quickstart_guide.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["&lt;no title&gt;", "&lt;no title&gt;", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "FakeQuantizationMixin", "QuantizationMixin", "quantization.affine", "FloatQuantizeDequantize", "quantization.float", "quantization.tensor", "Visualization Tools", "Blockwise Quantization", "Encoding Analyzers", "Post-Training Quantization", "GPTVQ", "AIMET: AI Model Efficiency Toolkit Documentation", "Quantized Modules", "Quantizers", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"name": [0, 1, 3, 4, 6, 7, 12, 16, 18, 19, 32, 37, 38, 40], "escap": [0, 1], "underlin": [0, 1], "qualcomm": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "innov": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "center": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "inc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "ai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 28, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "effici": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "toolkit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "quantsim_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "default_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "json": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43], "34": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43], "The": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43], "pytorch": [2, 3, 6, 7, 16, 18, 21, 22, 23, 27, 32, 33, 35, 37, 38], "gpu": [2, 3, 31, 38], "pypi": 2, "ar": [2, 3, 4, 6, 7, 8, 9, 10, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43], "avail": [2, 7, 20, 30, 33, 35, 36], "environ": 2, "meet": [2, 22, 25, 26], "follow": [2, 3, 4, 6, 7, 13, 16, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 39, 42, 43], "64": [2, 8, 13, 14, 19, 21], "bit": [2, 9, 10, 13, 20, 21, 23, 31, 36, 37, 38], "intel": 2, "x86": 2, "compat": [2, 12, 13, 20], "processor": 2, "linux": [2, 4], "ubuntu": [2, 4], "22": [2, 4, 20], "04": [2, 4], "lt": [2, 4], "python": [2, 3, 4], "3": [2, 8, 11, 13, 14, 20, 25, 31, 34, 36, 43], "10": [2, 3, 4, 6, 7, 8, 11, 13, 18, 19, 20, 26, 29, 34], "20": [2, 6, 7, 21, 34], "8": [2, 4, 6, 7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 31, 43], "cuda": [2, 3, 4, 20], "12": [2, 3, 4, 8, 13], "torch": [2, 3, 6, 7, 8, 9, 10, 11, 13, 16, 17, 18, 19, 20, 30, 38], "2": [2, 3, 8, 9, 10, 11, 13, 16, 19, 21, 31, 36, 37], "pip": [2, 3, 4, 17], "apt": [2, 3, 4, 17], "get": [2, 3, 4, 16, 21, 24, 31, 41], "liblapack": [2, 3, 4, 17], "python3": [2, 3, 4, 17], "m": [2, 3, 4, 17], "For": [2, 3, 4, 6, 7, 13, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 31, 33, 35, 37, 40, 43], "other": [2, 13, 16, 26, 28, 29, 31, 33, 36, 37, 38], "variant": [2, 4, 21, 22, 23, 32, 33, 34, 37], "latest": [2, 3], "version": [2, 3, 4, 6, 7, 12, 13, 16, 18, 20, 27], "from": [2, 6, 7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 21, 24, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 40, 43], "whl": [2, 3, 4], "file": [2, 3, 4, 13, 16, 20, 31, 33, 34, 37, 38, 41], "host": [2, 3, 4, 38, 40], "http": [2, 3, 4, 25, 32, 38, 40], "github": [2, 3, 4, 25, 38], "com": [2, 3, 4, 38], "quic": [2, 3, 4, 25, 38], "x": [2, 9, 10, 11, 18, 20, 25, 30, 33], "download": [2, 3, 4, 20], "aimet_torch": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 30], "cu121": [2, 3, 4], "cp310": [2, 3, 4], "manylinux_2_34_x86_64": [2, 3, 4], "cpu": [2, 3, 20, 31, 38], "onli": [2, 3, 4, 8, 11, 12, 13, 18, 20, 23, 28, 31, 33, 34, 35, 38, 43], "13": [2, 3, 8], "11": [2, 3, 4, 8, 11], "cu117": 2, "tensorflow": [2, 3, 23, 27, 28, 31, 35, 37, 38], "aimet_tensorflow": [2, 4], "cu118": 2, "onnx": [2, 3, 17, 21, 22, 27, 30, 31, 32, 33, 35, 37], "16": [2, 6, 7, 8, 9, 10, 13, 16, 18, 19, 21], "aimet_onnx": [2, 4], "older": 2, "pleas": [2, 4, 17, 20, 21, 22, 23, 24, 27, 29, 32, 33, 37], "brows": [2, 3, 4], "document": [2, 4, 25, 27, 38], "correspond": [2, 3, 4, 13, 16, 18, 24, 26, 31, 33, 43], "select": [2, 3, 4, 22, 25, 33, 37, 40, 43], "appropri": [2, 4, 6, 7, 13, 16, 18, 25, 26, 29, 36], "platform": [2, 31], "setup": 2, "bash": [2, 3], "command": [2, 3, 4, 40], "shell": 2, "nvidia": [2, 3, 4], "card": 2, "comput": [2, 4, 6, 7, 9, 10, 13, 14, 16, 20, 21, 29, 30, 31, 32, 33, 37, 40, 43], "capabl": [2, 18, 40, 41], "5": [2, 8, 9, 10, 13, 18, 19, 25, 34, 36], "later": [2, 16, 20], "docker": 2, "To": [2, 16, 18, 20, 23, 26, 29, 30, 33, 35, 36, 37, 40, 41], "us": [2, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 38, 41], "acceler": [2, 17, 27, 29], "train": [2, 17, 21, 22, 23, 27, 29, 36, 37, 38], "modul": [2, 6, 7, 12, 13, 16, 17, 20, 21, 31, 38, 43], "an": [2, 6, 7, 11, 12, 13, 17, 18, 19, 20, 21, 22, 24, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 41, 43], "enabl": [2, 3, 13, 17, 23, 27, 31, 33, 35, 37, 38], "minimum": [2, 8, 18], "driver": [2, 4], "455": 2, "i": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43], "alwai": [2, 26], "recommend": [2, 13, 21, 23, 25, 31, 36], "especi": [2, 31, 34, 36], "newer": 2, "both": [2, 8, 13, 16, 17, 18, 31, 32, 34, 35, 36, 37, 39, 43], "cudnn": 2, "more": [2, 13, 16, 17, 18, 20, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41], "interfac": 2, "support": [2, 13, 16, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 42, 43], "There": [2, 21, 30, 32, 34, 40, 41], "two": [2, 13, 18, 20, 26, 27, 29, 31, 32, 33, 34, 37, 39, 40, 41, 42], "wai": [2, 13, 20, 26], "On": [2, 7], "your": [2, 3, 4, 17, 30], "machin": [2, 3, 29], "our": [2, 4, 20, 26, 36, 37], "pre": [2, 3, 4, 27, 32], "built": [2, 3], "develop": [2, 3, 4, 7, 12, 13, 16, 18], "imag": [2, 21, 33], "click": 2, "link": [2, 4, 21, 22, 23, 32, 33, 37], "contain": [2, 6, 7, 11, 12, 16, 18, 20, 31, 33, 34, 35, 37], "thi": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43], "page": [3, 4, 25, 37, 38], "provid": [3, 4, 7, 9, 10, 13, 16, 17, 18, 20, 21, 25, 26, 29, 31, 32, 33, 35, 36, 37, 40, 41, 43], "instruct": [3, 4, 17], "insid": [3, 6, 7, 18, 20], "variant_str": 3, "ONE": 3, "depend": [3, 4, 11, 25, 26, 31, 35, 38], "desir": [3, 13, 20, 25, 29, 31, 36], "pt113": 3, "tf": [3, 33, 37, 38], "export": [3, 4, 16, 17, 23, 27, 29, 30, 31, 34, 37, 38], "aimet_vari": 3, "one": [3, 13, 16, 18, 20, 24, 29, 34, 35, 38, 39, 42], "workspac": 3, "absolute_path_to_workspac": 3, "docker_image_nam": 3, "artifact": [3, 20], "codelinaro": 3, "org": [3, 4, 32], "dev": [3, 4], "docker_container_nam": 3, "any_nam": 3, "note": [3, 4, 13, 16, 20, 24, 25, 26, 27, 29, 30, 31, 33], "feel": 3, "free": [3, 31, 32, 34], "modifi": [3, 4, 31, 37, 38, 43], "need": [3, 4, 13, 16, 20, 22, 25, 29, 31, 32, 33, 34, 35, 37, 38, 40, 41], "you": [3, 4, 16, 26, 30, 39, 42], "want": 3, "If": [3, 4, 6, 7, 8, 9, 10, 13, 16, 18, 19, 20, 22, 30, 31, 32, 33, 35, 36, 40, 41, 43], "skip": [3, 24], "next": [3, 20, 36], "section": [3, 4, 13, 21, 23, 24, 29, 31, 37], "any_tag": 3, "t": [3, 21], "f": [3, 20], "jenkin": 3, "dockerfil": 3, "ensur": [3, 18, 31, 36], "alreadi": [3, 26, 36], "run": [3, 4, 8, 13, 18, 19, 23, 27, 29, 31, 32, 33, 37, 38, 40], "otherwis": [3, 4, 8, 13, 19, 36], "remov": [3, 20, 24, 27, 37, 43], "exist": [3, 6, 7, 13, 31, 37], "new": [3, 8, 13, 16, 17, 19, 20, 31, 35, 38], "p": 3, "grep": 3, "kill": 3, "rm": 3, "u": [3, 36], "id": [3, 40], "user": [3, 13, 16, 17, 18, 21, 22, 25, 29, 31, 33, 34, 35, 36, 37, 38, 40, 41], "g": [3, 20, 23, 25, 27, 36, 43], "v": [3, 13, 26], "etc": [3, 25, 31], "passwd": 3, "ro": 3, "group": [3, 13, 35, 37], "home": 3, "mnt": 3, "entrypoint": 3, "bin": [3, 4, 14], "w": [3, 43], "hostnam": 3, "abov": [3, 4, 13, 16, 17, 22, 23, 26, 27, 29, 30, 32, 36, 37, 43], "base": [3, 6, 7, 8, 9, 10, 13, 18, 19, 24, 25, 31], "filesystem": 3, "add": [3, 7, 18, 20, 35, 37, 38, 40, 41, 43], "all": [3, 6, 7, 12, 13, 16, 18, 20, 24, 26, 29, 32, 33, 35, 36], "order": [3, 4, 6, 13, 20, 23, 24, 25, 31, 34, 37, 41], "access": [3, 31], "replac": [3, 13, 18, 20, 32, 37], "port": [3, 40], "forward": [3, 6, 7, 8, 18, 19, 20, 30, 33, 36, 38], "done": [3, 8, 19, 24, 29, 35, 37, 43], "visual": [3, 29, 31, 32, 33, 36, 38, 39, 42], "api": [3, 7, 12, 20, 27, 30, 31, 35, 38, 40], "can": [3, 6, 8, 11, 13, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42], "achiev": [3, 13, 21, 25, 26, 39, 42], "port_id": 3, "ani": [3, 7, 13, 16, 20, 21, 22, 35, 38], "number": [3, 6, 7, 8, 9, 10, 13, 14, 18, 21, 26, 27, 29, 34, 37, 38, 40, 43], "default": [3, 4, 7, 8, 12, 16, 18, 19, 21, 26, 29, 35, 37, 38, 40], "mai": [3, 4, 6, 7, 11, 12, 13, 16, 18, 21, 25, 29, 31, 32, 33, 35, 36, 37], "go": [3, 4, 16, 20, 40], "project": [3, 4], "requir": [3, 4, 13, 16, 20, 21, 23, 25, 29, 31, 32, 35, 37], "each": [3, 4, 6, 7, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 37, 41, 43], "identifi": [3, 4, 13, 33, 36, 38, 43], "wish": [3, 4], "some": [3, 4, 18, 20, 21, 25, 26, 29, 30, 31, 32, 34, 36, 37], "tip": [3, 4], "32": [3, 4, 8, 16, 19, 36], "post1": [3, 4], "7": [3, 4, 8, 9, 10, 20, 43], "31": [3, 4], "prepend": [3, 4], "sudo": [3, 4], "y": [3, 4, 20, 33], "we": [3, 4, 13, 16, 18, 20, 26, 29, 31, 32, 35, 36, 37, 41], "also": [3, 4, 13, 24, 25, 26, 31, 33, 35, 36, 37, 38, 40, 41, 43], "wheel": [3, 4], "differ": [3, 4, 13, 24, 26, 29, 31, 32, 34, 35, 36, 37], "which": [3, 4, 7, 8, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42], "tag": [3, 4, 38], "below": [3, 4, 8, 13, 16, 18, 19, 20, 21, 22, 23, 31, 32, 33, 35, 36, 37, 43], "detail": [3, 4, 24, 26, 27, 29, 31, 36, 37, 40, 41], "ex": [3, 4, 13], "release_tag": [3, 4], "construct": [3, 4, 20, 30], "root": [3, 4, 20], "url": [3, 4, 40], "download_url": [3, 4], "extens": [3, 4, 18], "wheel_file_nam": [3, 4], "specifi": [3, 4, 8, 9, 10, 13, 19, 20, 22, 29, 35, 37, 41], "automat": [3, 4, 13, 25, 29, 31, 33, 38], "common": [3, 13, 36, 41], "variabl": [3, 4, 8, 19], "sourc": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 36], "usr": [3, 4], "lib": [3, 4], "dist": [3, 4], "envsetup": [3, 4], "sh": [3, 4], "unless": [4, 7, 16, 43], "pend": 4, "pip3": 4, "h": [4, 42, 43], "These": [4, 18, 20, 22, 23, 24, 25, 30, 31, 32, 33, 36, 37], "assum": [4, 13, 16], "path": [4, 12, 16], "local": [4, 40], "case": [4, 8, 13, 18, 20, 26, 32, 34, 35], "accordingli": 4, "basic": [4, 17, 20], "requisit": 4, "updat": [4, 19, 31, 32, 34, 37, 38], "upgrad": 4, "ye": [4, 29], "wget": 4, "gnupg2": 4, "have": [4, 7, 12, 13, 20, 26, 29, 31, 32, 33, 36, 37], "multipl": [4, 13, 18, 27, 29, 31, 38], "set": [4, 6, 7, 12, 13, 16, 18, 19, 21, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 43], "altern": [4, 13, 29], "do": [4, 20, 29, 33, 37], "were": [4, 16, 25, 31, 35, 43], "test": 4, "sub": [4, 24, 29, 37, 43], "visit": [4, 17, 27], "archiv": 4, "obtain": [4, 24, 25, 33, 37], "correct": [4, 20, 21, 23, 31, 32, 36], "exact": [4, 18, 23], "up": [4, 13, 29, 34, 35, 37, 43], "date": 4, "execut": [4, 20, 26, 40], "final": [4, 13, 24, 25, 26, 34, 36, 40], "aforement": 4, "repo": 4, "ubuntu2204": 4, "x86_64": 4, "keyring_1": 4, "1_all": 4, "deb": 4, "dpkg": 4, "33": [4, 8, 19], "cat": 4, "reqs_deb_common": 4, "txt": 4, "xarg": 4, "reqs_deb_torch_common": 4, "reqs_deb_onnx_common": 4, "reqs_deb_tf_gpu": 4, "reqs_deb_torch_gpu": 4, "reqs_deb_onnx_gpu": 4, "option": [4, 7, 8, 12, 13, 16, 17, 19, 20, 21, 33, 35, 37, 40], "uninstal": 4, "cach": 4, "dir": 4, "9": [4, 8, 11, 36], "onnxruntime_v": 4, "c": [4, 25], "import": [4, 7, 8, 9, 10, 11, 13, 16, 17, 18, 19, 20, 23, 24, 36], "print": [4, 6, 7, 8, 18, 20, 31, 33], "__version__": 4, "ln": 4, "": [4, 6, 7, 13, 17, 18, 19, 20, 25, 28, 29, 31, 32, 33, 34, 36, 37, 40, 41, 43], "gnu": 4, "libjpeg": 4, "so": [4, 18, 30, 33, 40], "chose": 4, "between": [4, 13, 18, 32, 33, 35, 37], "class": [6, 7, 9, 13, 14, 16, 19, 20], "v2": [6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20], "nn": [6, 7, 8, 12, 13, 17, 18, 19, 20, 30, 38], "arg": [6, 7, 8, 11, 13, 16, 18], "kwarg": [6, 7, 8, 11, 18], "mixin": [6, 7, 18], "implement": [6, 7, 18, 30, 36], "fake": [6, 7, 8, 9, 10, 18, 19, 20], "quantiz": [6, 7, 9, 12, 14, 16, 17, 21, 22, 23, 25, 27, 29, 33, 38, 40], "top": [6, 7, 24, 40], "regular": [6, 7, 18, 21, 31, 37], "specif": [6, 13, 20, 21, 22, 23, 25, 27, 29, 30, 31, 32, 35, 38], "input": [6, 7, 8, 9, 10, 12, 13, 16, 18, 19, 20, 24, 29, 33, 35, 37, 39, 40, 42, 43], "output": [6, 7, 8, 13, 18, 19, 20, 24, 29, 32, 33, 35, 37, 38, 39, 42, 43], "paramet": [6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 24, 29, 30, 31, 32, 33, 34, 35, 41], "tensor": [6, 7, 8, 9, 10, 13, 16, 18, 19, 20, 21, 24, 30, 31, 33, 35, 36, 37, 38, 39, 42], "its": [6, 7, 11, 16, 17, 18, 20, 27, 31, 33, 37, 43], "held": [6, 20], "quantizerbas": [6, 7, 18, 19], "object": [6, 7, 11, 12, 13, 16, 18, 19, 20, 23, 31, 34, 37], "dure": [6, 12, 16, 18, 20, 21, 27, 29, 31, 34, 35, 37, 40, 41], "method": [6, 7, 13, 16, 18, 20, 26, 29, 31, 36, 37], "inherit": [6, 18], "layer": [6, 7, 12, 13, 16, 18, 20, 21, 22, 23, 24, 25, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43], "oper": [6, 7, 18, 20, 30, 31, 32, 35, 36], "none": [6, 7, 8, 9, 10, 12, 13, 16, 18, 19, 20, 40], "behav": [6, 7, 18, 36], "exactli": [6, 7, 18, 37], "same": [6, 7, 11, 13, 18, 19, 23, 32, 35, 37, 41], "parent": [6, 7], "A": [6, 13, 18, 25, 31, 33, 34, 35, 36, 37], "initi": [6, 7, 8, 9, 10, 18, 19, 21, 34, 36, 37], "scratch": 6, "syntax": 6, "form": 6, "from_modul": [6, 7], "input_quant": [6, 7, 18, 20], "modulelist": [6, 7, 18, 20], "appli": [6, 7, 8, 13, 16, 18, 19, 20, 21, 22, 23, 26, 29, 31, 32, 34, 35, 36, 37, 38, 40, 41], "type": [6, 7, 11, 12, 13, 16, 18, 19, 31, 33, 35, 37, 40], "output_quant": [6, 7, 18, 20], "param_quant": [6, 7, 13, 18, 20], "moduledict": [6, 7, 18, 20], "map": [6, 7, 8, 11, 13, 18, 33, 35], "associ": [6, 7, 18, 31], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21, 25, 26, 27, 31, 33, 35, 37, 38, 43], "qlinear": [6, 7, 18], "fakequantizedlinear": [6, 18], "in_featur": [6, 7, 18, 20], "out_featur": [6, 7, 18, 20], "bia": [6, 7, 9, 10, 20, 21, 24, 31, 32, 35, 36, 38], "fals": [6, 7, 8, 11, 13, 16, 18, 19, 20, 30, 35], "weight": [6, 7, 12, 13, 14, 16, 18, 20, 21, 23, 25, 29, 31, 32, 33, 34, 35, 36, 37, 41], "linear": [6, 7, 13, 18, 20, 23, 24], "true": [6, 7, 8, 9, 10, 11, 13, 18, 19, 20, 30, 35], "abstract": [6, 7, 18, 19], "should": [6, 7, 13, 16, 18, 20, 25, 29, 35, 40, 43], "perform": [6, 7, 8, 13, 16, 18, 19, 20, 22, 23, 24, 25, 26, 29, 31, 32, 33, 34, 36], "logic": [6, 7, 38], "param": [6, 13, 19, 35], "call": [6, 7, 9, 10, 11, 13, 18, 20, 23, 29, 31, 33, 35, 37, 38, 39, 42], "pass": [6, 7, 13, 16, 17, 18, 20, 27, 30, 31, 32, 33, 34, 36, 37, 38, 40], "__quant_init__": [6, 7, 18], "invok": [6, 7, 18, 29, 31, 40, 41], "right": [6, 7, 8, 9, 10, 18, 19, 31, 43], "after": [6, 7, 16, 18, 20, 21, 22, 23, 25, 29, 31, 34, 36, 40, 41], "__init__": [6, 7, 18, 20], "structur": [6, 7, 18, 29], "size": [6, 7, 8, 13, 16, 18, 19, 21, 29, 30, 39, 42], "initializd": [6, 7, 18], "custom": [6, 7, 18, 36, 37], "overridden": [6, 7, 18], "length": [6, 7, 13, 18], "given": [6, 7, 12, 13, 18, 22, 24, 26, 27, 29, 32, 39, 40, 42], "compute_encod": [6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20], "enter": [6, 7, 18, 22], "context": [6, 7, 18, 20], "observ": [6, 7, 14, 18, 19, 20, 26, 29, 31, 32, 33, 34, 37], "encod": [6, 7, 8, 11, 12, 13, 16, 17, 19, 20, 21, 23, 31, 33, 34, 38], "upon": [6, 7, 18, 20], "exit": [6, 7, 18, 20], "quantizedlinear": [6, 7, 13, 18, 20], "symmetr": [6, 7, 8, 11, 13, 14, 18, 19, 20, 35, 37], "randn": [6, 7, 8, 11, 18, 19], "is_initi": [6, 7, 8, 9, 10, 18, 19], "classmethod": [6, 7], "creat": [6, 7, 12, 16, 17, 18, 20, 21, 23, 29, 30, 31, 34, 37], "instanc": [6, 7, 40], "result": [6, 7, 11, 13, 14, 16, 21, 22, 24, 25, 27, 32, 33, 34, 35, 37], "attribut": [6, 7, 18, 33], "origin": [6, 7, 18, 20, 24, 25, 29, 31, 32, 33, 34, 37, 40], "assign": [6, 7, 8, 18, 19], "float": [6, 7, 9, 11, 13, 17, 18, 31, 33, 36, 37, 41], "point": [6, 7, 11, 13, 17, 18, 27, 29, 31, 33, 36, 37, 41], "return": [6, 7, 11, 12, 13, 16, 17, 19, 20, 22, 26, 27, 33, 37], "quantized_linear": [6, 7], "module_cl": [6, 7], "decor": [6, 7], "regist": [6, 7, 18, 19], "defin": [6, 13, 18, 20, 30, 31, 33, 35, 37], "featur": [7, 12, 13, 16, 18, 21, 22, 23, 29, 32, 33, 37, 38, 40, 41], "under": [7, 12, 13, 16, 18, 33, 35, 40, 41], "heavi": [7, 12, 13, 16, 18, 40, 41], "chang": [7, 12, 13, 16, 18, 20, 21, 29, 33, 34, 35, 37, 41, 43], "occur": [7, 12, 13, 16, 18], "without": [7, 9, 10, 11, 12, 13, 16, 18, 22, 31, 34, 37, 43], "notic": [7, 12, 13, 16, 18, 29], "futur": [7, 12, 13, 16, 18], "verion": 7, "function": [7, 11, 12, 13, 18, 20, 21, 26, 29, 30, 31, 33, 37, 38, 40, 41], "behavior": [7, 18, 20, 27], "fakequantizationmixin": [7, 17, 18], "abil": [7, 38], "kernel": [7, 13, 18, 24, 39, 42], "place": [7, 13, 16, 34, 35], "ha": [7, 11, 13, 16, 20, 25, 26, 29, 32, 34, 37, 40, 43], "been": [7, 11, 12, 13, 16, 31, 34, 37, 43], "within": [7, 11, 18, 25, 33, 37], "fall": [7, 26, 35], "back": [7, 11, 20, 35], "equival": [7, 8, 9, 10, 13, 20], "e": [7, 12, 20, 23, 25, 27, 34, 36, 43], "get_kernel": 7, "doe": [7, 18, 20, 26, 28, 31, 36], "retriev": 7, "well": [7, 11, 13, 16, 18, 25, 29, 31, 32, 33, 37, 39], "dequant": [7, 8, 11, 18, 19, 37], "set_kernel": 7, "signatur": [7, 8], "must": [7, 13, 16, 18, 23, 27, 28, 33, 35, 43], "match": [7, 13, 24, 29, 33, 35, 36, 37, 43], "In": [7, 13, 18, 20, 21, 22, 25, 26, 29, 31, 32, 34, 35, 37, 41, 43], "gener": [7, 8, 13, 16, 19, 20, 29, 31, 33, 34, 35, 37], "quantizedtensor": [7, 8, 11, 19], "take": [7, 13, 20, 27, 29, 31, 32, 34, 35, 36, 43], "addit": [7, 13, 16, 22, 31, 34, 35, 38], "keyword": 7, "argument": [7, 9, 10, 13], "output_encod": 7, "onc": [7, 23, 24, 29, 33, 34, 37], "callabl": [7, 13], "underli": [7, 36], "q": [7, 8, 9, 10, 11, 18, 19, 37], "def": [7, 16, 20], "int_multipli": 7, "b": [7, 8, 19], "enc": 7, "affin": [7, 11, 13, 16, 17, 18, 19, 20], "rais": 7, "notimplementederror": 7, "q_output": 7, "quantized_repr": [7, 11], "offset": [7, 8, 13, 14, 16, 19, 31, 33, 34, 37], "dq_output": 7, "scale": [7, 8, 9, 10, 11, 13, 16, 19, 23, 31, 32, 33, 34, 37], "qmult": 7, "quantizedmultipli": [7, 18], "set_default_kernel": 7, "quantized_forward": 7, "cl": [7, 38], "get_default_kernel": 7, "current": [7, 12, 24, 27, 28, 29, 30, 35, 39, 42], "shape": [8, 9, 10, 11, 13, 14, 18, 19, 20, 33], "bitwidth": [8, 9, 10, 11, 13, 16, 18, 19, 20, 23, 31, 36, 37], "encoding_analyz": [8, 9, 10, 14, 19], "block_siz": [8, 13, 19], "precis": [8, 9, 10, 17, 19, 31], "out": [8, 9, 10, 19, 22, 25, 29, 33], "clamp": [8, 9, 10, 19, 37], "left": [8, 9, 10, 19, 26, 43], "lceil": [8, 9, 10, 19], "frac": [8, 9, 10, 19], "rfloor": [8, 9, 10, 19], "qmin": [8, 19, 37], "qmax": [8, 19, 37], "where": [8, 9, 10, 16, 18, 19, 20, 23, 26, 33, 34, 39, 42, 43], "deriv": [8, 18, 19], "learnabl": [8, 19], "theta_": [8, 19], "min": [8, 12, 14, 18, 19, 20, 33, 37], "max": [8, 9, 10, 12, 14, 18, 19, 20, 29, 32, 33, 37], "block": [8, 13, 16, 19], "begin": [8, 19, 34, 35], "pmatrix": [8, 19], "b_0": [8, 19], "b_1": [8, 13, 19], "cdot": [8, 19], "b_": [8, 19], "d": [8, 19], "end": [8, 19, 20, 29], "equat": [8, 13, 19, 37], "further": [8, 11, 13, 19, 20, 24, 27, 29, 31, 35], "out_": [8, 19], "j_0": [8, 19], "j_": [8, 19], "input_": [8, 19], "scale_": [8, 19], "i_0": [8, 19], "i_": [8, 19], "offset_": [8, 19], "text": [8, 19], "quad": [8, 19, 37], "forall_": [8, 19], "leq": [8, 19], "i_d": [8, 19], "lfloor": [8, 9, 10, 19], "j_d": [8, 19], "b_d": [8, 19], "tupl": [8, 13, 14, 16, 19], "int": [8, 9, 10, 13, 14, 19], "bool": [8, 13, 19], "asymmetr": [8, 14, 19, 35, 37], "encodinganalyz": [8, 9, 10, 14, 19], "analyz": [8, 12, 17, 18, 19, 22, 24, 29, 30, 33, 37, 40, 41], "calibr": [8, 12, 13, 14, 16, 17, 18, 19, 20, 31, 33, 34, 36, 37], "absolut": [8, 19], "cannot": [8, 19], "until": [8, 19, 22], "properli": [8, 19, 20], "statist": [8, 9, 10, 12, 18, 19, 20, 23, 31, 33, 41], "manual": [8, 19, 22, 29], "valu": [8, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 26, 29, 31, 32, 33, 34, 37, 39, 41, 42], "see": [8, 18, 19, 20, 24, 26, 27, 29, 31, 35, 36, 37, 39, 40, 41, 42], "_": [8, 12, 17, 18, 19, 20], "129": [8, 19, 30], "255": [8, 11, 19], "122": [8, 19], "192": [8, 19], "106": [8, 19], "94": [8, 19], "145": [8, 19], "181": [8, 19], "144": [8, 19], "194": [8, 19], "74": [8, 19], "86": [8, 19], "150": [8, 19], "103": [8, 19], "37": [8, 19], "111": [8, 19], "237": [8, 19], "218": [8, 19], "49": [8, 19], "155": [8, 19], "179": [8, 19], "66": [8, 19, 25], "89": [8, 19], "110": [8, 19], "17": [8, 14, 19], "36": [8, 19], "83": [8, 19], "grad_fn": [8, 11, 19], "aliasbackward0": [8, 11, 19], "ones_lik": [8, 19], "187": [8, 19], "186": [8, 19], "131": [8, 19], "203": [8, 19], "80": [8, 19], "143": [8, 19], "152": [8, 19], "226": [8, 19], "55": [8, 19], "172": [8, 19], "207": [8, 19], "146": [8, 19], "216": [8, 19], "238": [8, 19], "141": [8, 19], "178": [8, 19], "188": [8, 19], "63": [8, 19], "59": [8, 19], "19": [8, 19], "162": [8, 19], "30": [8, 19], "109": [8, 19], "quantizedequant": [8, 10, 11, 13, 18, 19, 20], "overlin": [8, 19], "qdq": [8, 9, 10, 19], "dequantizedtensor": [8, 11, 19], "2771": [8, 19], "3038": [8, 19], "0819": [8, 19], "9700": [8, 19], "9487": [8, 19], "1307": [8, 19], "7894": [8, 19], "1709": [8, 19], "2212": [8, 19], "7741": [8, 19], "0295": [8, 19], "2265": [8, 19], "0564": [8, 19], "6177": [8, 19], "0386": [8, 19], "0176": [8, 19], "6054": [8, 19], "8836": [8, 19], "1232": [8, 19], "8229": [8, 19], "5540": [8, 19], "3992": [8, 19], "2363": [8, 19], "2546": [8, 19], "0036": [8, 19], "2355": [8, 19], "1741": [8, 19], "6079": [8, 19], "6247": [8, 19], "0115": [8, 19], "2458": [8, 19], "9157": [8, 19], "4694": [8, 19], "0639": [8, 19], "2568": [8, 19], "0680": [8, 19], "6695": [8, 19], "7932": [8, 19], "1889": [8, 19], "0158": [8, 19], "5695": [8, 19], "5220": [8, 19], "1977": [8, 19], "4475": [8, 19], "0424": [8, 19], "1128": [8, 19], "8796": [8, 19], "1060": [8, 19], "5897": [8, 19], "6196": [8, 19], "9961": [8, 19], "0549": [8, 19], "6431": [8, 19], "0039": [8, 19], "8706": [8, 19], "4706": [8, 19], "2353": [8, 19], "8078": [8, 19], "3451": [8, 19], "1176": [8, 19], "4549": [8, 19], "0471": [8, 19], "5255": [8, 19], "4157": [8, 19], "0784": [8, 19], "5333": [8, 19], "1647": [8, 19], "2118": [8, 19], "2196": [8, 19], "9176": [8, 19], "9490": [8, 19], "7765": [8, 19], "4784": [8, 19], "6039": [8, 19], "3137": [8, 19], "3216": [8, 19], "8000": [8, 19], "4392": [8, 19], "4863": [8, 19], "overload": 8, "list": [8, 13, 16, 18, 19, 26, 28, 30, 35], "sign": [8, 37], "rceil": 8, "posit": 8, "integ": [8, 13, 21, 31, 33], "rang": [8, 12, 20, 21, 23, 26, 31, 32, 33, 34, 36, 37, 38, 41], "over": [8, 14, 18, 21, 26, 29, 41], "neg": [8, 13, 18], "num_step": 8, "num": 8, "_step": 8, "step": [8, 16, 17, 20, 21, 22, 23, 24, 25, 26, 29, 31, 32, 34, 36, 37], "maximum": [8, 9, 10, 14, 18], "arang": 8, "start": [8, 20, 21, 26, 29, 35, 37], "05": [8, 20], "0000e": 8, "01": [8, 21], "5000e": 8, "02": 8, "1921e": 8, "08": 8, "4": [8, 11, 13, 20, 23, 26, 31, 43], "6": [8, 13, 16, 34], "00": 8, "0500e": 8, "1000e": 8, "1500e": 8, "2000e": 8, "2500e": 8, "15": [8, 29, 34], "14": [8, 20], "quantize_dequant": 8, "0000": [8, 11], "0667": 8, "1333": 8, "2000": [8, 11], "2667": 8, "3333": 8, "4000": [8, 11], "4667": 8, "6000": [8, 11], "6667": 8, "7333": 8, "8667": 8, "9333": 8, "exponent_bit": [9, 10, 13], "mantissa_bit": [9, 10, 13], "dtype": [9, 10, 11, 13, 16], "simul": [9, 10, 13, 16, 17, 18, 20, 27, 31, 34, 38], "cast": [9, 10, 18], "expon": [9, 10, 13], "mantissa": [9, 10, 13], "x_c": [9, 10], "log_2": [9, 10], "ieee": [9, 10, 29, 32], "standard": [9, 10, 18], "represent": [9, 10, 11], "_max": [9, 10], "mutual": [9, 10, 13], "exclus": [9, 10, 13], "repres": [9, 10, 11, 18, 19, 20, 26, 31, 32, 33, 34, 37], "determin": [9, 10, 13, 18, 20, 22, 25, 29, 31, 32, 33], "dynam": [9, 10, 32, 37, 38, 41], "finer": [9, 10, 13], "8998": [9, 10], "0947": [9, 10], "0891": [9, 10], "1727": [9, 10], "unlik": [9, 10], "affinequant": [9, 10], "floatquant": [9, 10], "is_bfloat16": [9, 10], "8984": [9, 10], "0859": [9, 10], "1729": [9, 10], "minmaxencodinganalyz": [9, 10, 12, 14], "float16": [9, 10, 13], "is_float16": [9, 10], "8994": [9, 10], "0889": [9, 10], "alia": [9, 10], "floatquantizedequant": 10, "hold": [11, 13, 16, 18, 35], "store": [11, 13, 16], "along": [11, 13, 20, 34, 37], "encodingbas": [11, 19], "inform": [11, 16, 31, 33], "necessari": [11, 13, 20, 40], "real": 11, "self": [11, 20], "produc": [11, 12, 13, 26, 33, 40], "rtype": 11, "57": 11, "312": 11, "153": 11, "205": 11, "set_rang": 11, "128": [11, 13, 20], "127": 11, "x_q": 11, "26": 11, "23": 11, "x_dq": 11, "3000": 11, "equal": [11, 13, 18, 21, 22, 25, 26, 30, 31, 33, 41], "data": [11, 12, 13, 16, 17, 20, 21, 23, 28, 31, 32, 33, 34, 36, 37], "abl": [11, 20, 21, 40, 41], "carri": 11, "gradient": 11, "thu": 11, "autograd": 11, "allow": [11, 13, 18, 22, 27, 29, 31, 33, 34, 35, 36, 37, 38, 40], "backpropag": 11, "requires_grad": 11, "38": [11, 29], "28": 11, "40": 11, "int8": [11, 34, 37, 41], "subsequ": [11, 16, 30, 32, 34, 35], "about": [11, 20], "wa": [11, 24, 29, 35], "With": 11, "convert": [11, 20, 22, 31, 41], "loss": [11, 17, 20, 21, 27, 31, 33, 37], "39": [11, 20], "51": 11, "521": 11, "41": 11, "quant_dequ": 11, "x_qdq": 11, "52": 11, "68": 11, "97": 11, "uint8": 11, "visualization_tool": 12, "visualize_stat": 12, "sim": [12, 13, 16, 17, 20, 34, 37], "dummy_input": [12, 13, 16, 20], "save_path": 12, "interact": 12, "html": [12, 25, 33, 38, 41], "view": [12, 17, 20, 21, 22, 23, 27, 30, 32, 33, 37, 40], "stat": 12, "collect": [12, 13, 24, 33], "quantizationsimmodel": [12, 13, 16, 17, 20, 21, 23], "expect": [12, 16, 20, 29, 31, 33], "befor": [12, 18, 20, 21, 22, 23, 29, 31, 34, 40, 41], "plot": [12, 33], "activ": [12, 13, 16, 18, 20, 31, 33, 34, 35, 36, 37], "quantschem": [12, 16, 22], "post_training_tf": [12, 16], "training_range_learning_with_tf_init": 12, "quant": [12, 23], "scheme": [12, 13, 22, 23, 26, 29, 33], "quantsim": [12, 13, 16, 17, 31, 34, 35, 38], "includ": [12, 13, 23, 29, 31, 33, 35, 37, 38], "adjust": [12, 13, 23, 24, 25, 31, 32, 36], "threshold": [12, 18, 22], "flag": [12, 19], "whose": [12, 13, 32, 35, 43], "exce": 12, "tabl": [12, 18, 26, 30, 40], "exceed": 12, "save": [12, 16, 20, 22, 37, 41], "quant_schem": [12, 16], "data_load": [12, 16, 17, 20], "quant_stats_visu": 12, "sampl": [12, 17, 18, 20, 24, 31, 32, 33, 34, 37], "trace": 12, "str": [12, 16], "when": [13, 16, 17, 18, 20, 21, 27, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43], "known": [13, 26, 27], "like": [13, 16, 17, 20, 27, 29, 31, 33, 34, 35, 40], "grid": 13, "counterpart": [13, 18], "process": [13, 14, 17, 20, 22, 27, 29, 31, 32, 37], "particular": [13, 31, 35], "choos": [13, 24, 25, 29], "come": [13, 34, 37], "cover": [13, 23, 35, 37], "whole": [13, 37], "split": [13, 18], "describ": [13, 31, 32, 36, 37], "sever": [13, 18, 25], "pro": 13, "con": 13, "per": [13, 14, 16, 18, 23, 31, 32, 33, 35, 36, 37, 38], "entir": [13, 20, 26, 29], "singl": [13, 21, 32], "benefit": [13, 21], "less": [13, 14, 18, 24, 26], "storag": 13, "space": 13, "drawback": 13, "outlier": [13, 33, 37], "affect": [13, 23, 35, 43], "channel": [13, 16, 18, 23, 25, 26, 28, 29, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43], "individu": [13, 23, 24, 25, 26, 29, 31, 33, 36], "typic": [13, 20, 25, 31, 33, 34, 35, 37, 40], "dimens": [13, 16, 18, 29, 36, 39, 42], "compar": [13, 16, 20, 33, 34, 41], "would": [13, 25, 29, 35, 38, 40], "influenc": 13, "resid": [13, 38], "chunk": 13, "across": [13, 32, 33], "improv": [13, 20, 25, 31, 34, 36, 41], "granular": [13, 29, 36, 37, 41], "found": [13, 34, 37], "isol": 13, "optim": [13, 16, 20, 21, 22, 27, 29, 31, 34, 37, 38, 40], "cost": [13, 26, 29, 34], "increas": [13, 26, 32, 35], "favor": 13, "possibl": [13, 20, 33, 35, 36], "similarli": [13, 16, 36], "lead": [13, 21, 23, 32, 36, 37], "better": [13, 21, 22, 31, 32, 34], "accuraci": [13, 17, 20, 21, 22, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38, 41, 43], "runtim": [13, 16, 17, 20, 25, 27, 29, 31, 33, 35, 37, 38], "part": [13, 29, 31, 32, 33], "basi": [13, 26, 29], "instanti": [13, 16, 20, 34, 40], "relationship": 13, "actual": [13, 25, 31], "being": 13, "rule": [13, 35], "most": [13, 20, 35], "long": [13, 16], "b_2": 13, "b_n": 13, "s_1": 13, "s_2": 13, "s_n": 13, "satisfi": [13, 20, 22], "n": [13, 20, 38], "word": 13, "evenli": 13, "divid": [13, 18, 34], "valid": [13, 22, 31, 38], "sinc": [13, 23, 25, 26, 37], "divis": 13, "permit": 13, "essenti": [13, 17], "invalid": 13, "combin": [13, 22, 25, 29, 31, 32], "though": [13, 35], "3d": 13, "infer": [13, 16, 17, 20, 23, 25, 27, 32, 34, 37, 38], "while": [13, 18, 21, 26, 30, 31, 34, 36, 37, 40], "arbitrari": 13, "experiment": [13, 29, 35], "purpos": [13, 35], "restrict": [13, 30], "constraint": 13, "still": [13, 31, 36], "themselv": [13, 34], "code": [13, 20, 21], "show": [13, 16, 17, 20, 27, 32, 36], "how": [13, 16, 18, 20, 29, 32, 33, 36, 37], "configur": [13, 16, 20, 25, 28, 38], "convolut": [13, 20, 23, 25, 29, 36], "conv_1": 13, "refer": [13, 16, 21, 22, 23, 27, 31, 33, 34, 35, 37], "quantizedconv2d": [13, 18, 20], "work": [13, 23, 29, 30, 32, 35], "too": 13, "linear_1": 13, "lower": [13, 26, 31, 36], "thei": [13, 35, 40], "lie": 13, "higher": [13, 14, 23, 26, 34, 36], "leverag": 13, "than": [13, 16, 20, 28, 34, 40], "due": [13, 31, 32], "fact": 13, "expans": [13, 29], "factor": [13, 14, 25, 29, 32], "fashion": 13, "groupedblockquantizedequant": 13, "introduc": [13, 31, 35, 37], "decompressed_bw": 13, "expand": [13, 18], "greater": [13, 18], "block_group": 13, "togeth": [13, 29], "As": [13, 16, 22, 24, 25, 26, 29, 31, 32, 33, 37, 39, 42], "except": 13, "make": [13, 18, 26, 29, 30, 31, 37], "easier": 13, "config_util": 13, "set_blockwise_quantization_for_weight": 13, "consist": [13, 22, 37, 43], "either": [13, 27, 37], "union": [13, 16], "arrai": 13, "in_channel": [13, 20], "out_channel": [13, 20], "conv": [13, 28, 35, 38, 39, 42, 43], "input_channel": 13, "conv2d": [13, 18, 20, 24, 29, 38, 43], "conv2": [13, 20], "linear1": 13, "dim": [13, 20], "lambda": 13, "isinst": 13, "util": [13, 20, 23, 31], "certain": [13, 29, 30, 31, 35], "Of": 13, "signific": [13, 36], "second": [13, 18, 35], "subset": [13, 21, 23, 33, 43], "switch": 13, "docstr": 13, "instead": [13, 16, 31, 32], "4d": 13, "2d": 13, "handl": 13, "time": [13, 16, 20, 22, 29, 30, 34, 40], "mention": 13, "assist": [13, 40, 41], "transform": [13, 16, 20, 38], "set_activation_quantizers_to_float": 13, "set_grouped_blockwise_quantization_for_weight": 13, "decompress": 13, "bw": 13, "experi": [13, 29], "similar": [13, 32, 34, 37], "addition": 13, "effect": [13, 18, 20, 23, 31, 33, 35, 37], "larger": [13, 39, 42], "reduc": [13, 16, 18, 24, 29, 32, 36, 38, 43], "write": [13, 16], "snippet": [13, 16], "format": [13, 16, 19, 22, 28], "encoding_vers": [13, 16], "exported_model": [13, 16], "present": [13, 16, 20, 29, 32], "techniqu": [14, 17, 20, 21, 22, 24, 25, 27, 31, 33, 34, 36, 37, 38, 39, 42], "sqnrencodinganalyz": 14, "num_bin": 14, "2048": [14, 16], "asymmetric_delta_candid": 14, "symmetric_delta_candid": 14, "101": 14, "offset_candid": 14, "21": 14, "max_parallel": 14, "gamma": 14, "sqnr": [14, 37], "calcul": [14, 18, 26, 32, 33, 37], "histogram": [14, 31, 33, 37, 38], "delta": [14, 37], "search": [14, 26, 34, 35], "mode": [14, 19, 30, 31, 35], "paral": 14, "memori": [14, 25, 29, 39, 42, 43], "usag": [14, 17, 25, 29, 36], "faster": [14, 21, 27, 34], "clip": [14, 35, 37], "nois": [14, 20, 31, 32, 33, 34, 35], "percentileencodinganalyz": 14, "percentil": 14, "100": [14, 16, 20], "gptvq_weight": 16, "apply_gptvq": 16, "gptvq_param": 16, "param_encoding_path": 16, "module_names_to_exclud": 16, "block_level_module_nam": 16, "file_name_prefix": 16, "config_file_path": 16, "round": [16, 17, 18, 21, 31, 33, 37], "separ": [16, 23, 33, 36, 38], "qat": [16, 20, 21, 23, 27, 31, 36, 37, 38], "dummi": [16, 33], "pars": 16, "graph": [16, 30, 31, 37, 40], "devic": [16, 17, 20, 37], "gptvqparamet": 16, "dataclass": 16, "exclud": 16, "leaf": [16, 38], "prefix": 16, "filenam": 16, "forward_fn": 16, "row_axi": 16, "col_axi": 16, "rows_per_block": 16, "cols_per_block": 16, "256": [16, 20, 33], "vector_dim": 16, "vector_bw": 16, "vector_strid": 16, "index_bw": 16, "num_of_kmeans_iter": 16, "assignment_chunk_s": 16, "carrier": 16, "dataload": [16, 20, 33], "wise": [16, 36], "explicitli": [16, 43], "aimet": [16, 18, 20, 27, 30, 35], "load": [16, 29], "pretrain": [16, 33, 34, 37], "opt": 16, "125m": 16, "packag": [16, 38], "optforcausallm": 16, "from_pretrain": 16, "facebook": 16, "now": [16, 20, 31, 38, 43], "gptvq_applied_model": 16, "zero": [16, 37, 38], "lm_head": 16, "gptvq_opt": 16, "default_param_bw": [16, 20], "default_output_bw": [16, 20], "load_encod": 16, "allow_overwrit": [16, 19], "through": [16, 18, 20, 32, 33, 37, 40, 41], "here": [16, 20, 25, 34, 40], "vector": 16, "index": [16, 18, 25, 38], "blockwis": 16, "lpbq": 16, "tool": [17, 20, 29, 32, 41, 43], "compress": [17, 24, 27, 38, 39, 41, 42, 43], "deploi": [17, 37], "edg": [17, 27], "fix": [17, 27, 31, 36, 37, 38], "post": [17, 20, 21, 22, 27, 29, 34, 37, 38], "fine": [17, 25, 27, 31, 34, 37], "tune": [17, 25, 27, 31, 34, 37], "minim": [17, 27, 29, 31, 37], "incur": [17, 27, 33], "pictur": [17, 24, 27], "high": [17, 21, 23, 25, 26, 27, 32, 36, 38, 41], "level": [17, 23, 25, 26, 27, 31, 36, 40], "workflow": [17, 20, 25, 27], "low": [17, 21, 23, 29, 31, 32, 36], "recov": [17, 27, 36, 37], "lost": [17, 27], "via": [17, 25, 27, 37], "torchscript": 17, "target": [17, 23, 25, 26, 27, 29, 31, 36, 37, 38], "neural": [17, 20, 22, 25, 27, 29, 31, 34, 36, 37, 42], "sdk": [17, 20, 27], "instal": [17, 38], "sample_input": [17, 20], "sample_output": 17, "out_dir": 17, "quantized_model": 17, "quickstart": 17, "guid": [17, 25, 32, 36, 38], "depth": [17, 25, 36], "adapt": [17, 20, 21, 31, 33, 38], "adaround": [17, 22, 31, 36, 38], "quantizationmixin": [17, 18], "product": [17, 27], "technologi": [17, 27], "subsidiari": [17, 27], "network": [18, 20, 22, 25, 26, 29, 31, 34, 36, 37, 40, 42], "serv": [18, 40], "drop": [18, 22, 25, 29, 32, 33, 34, 36, 37], "nativ": 18, "state": [18, 20, 29], "superset": 18, "mean": [18, 20, 24, 35, 37], "coverag": 18, "limit": [18, 28], "full": [18, 42], "basequantizationmixin": 18, "respons": [18, 29], "control": [18, 37], "descript": [18, 30], "dict": [18, 19], "By": [18, 29, 35, 37], "respect": [18, 33], "per_channel_quant": [18, 35], "elementwis": [18, 38], "multipli": [18, 25], "qmul": 18, "sens": 18, "share": 18, "indic": [18, 25, 43], "qadd": 18, "quantizedadd": 18, "first": [18, 20, 25, 29, 31, 34, 40], "disabl": [18, 26, 29, 33, 35, 37], "them": [18, 20, 21, 43], "calibration_data_load": 18, "adaptiveavgpool1d": 18, "fakequantizedadaptiveavgpool1d": 18, "adaptiveavgpool2d": 18, "fakequantizedadaptiveavgpool2d": 18, "adaptiveavgpool3d": 18, "fakequantizedadaptiveavgpool3d": 18, "adaptivemaxpool1d": 18, "fakequantizedadaptivemaxpool1d": 18, "adaptivemaxpool2d": 18, "fakequantizedadaptivemaxpool2d": 18, "adaptivemaxpool3d": 18, "fakequantizedadaptivemaxpool3d": 18, "alphadropout": 18, "fakequantizedalphadropout": 18, "avgpool1d": 18, "fakequantizedavgpool1d": 18, "avgpool2d": 18, "fakequantizedavgpool2d": 18, "avgpool3d": 18, "fakequantizedavgpool3d": 18, "batchnorm1d": 18, "fakequantizedbatchnorm1d": 18, "batchnorm2d": [18, 20], "fakequantizedbatchnorm2d": 18, "batchnorm3d": 18, "fakequantizedbatchnorm3d": 18, "celu": 18, "fakequantizedcelu": 18, "channelshuffl": 18, "fakequantizedchannelshuffl": 18, "constantpad1d": 18, "fakequantizedconstantpad1d": 18, "constantpad2d": 18, "fakequantizedconstantpad2d": 18, "constantpad3d": 18, "fakequantizedconstantpad3d": 18, "conv1d": [18, 38], "fakequantizedconv1d": 18, "quantizedconv1d": 18, "fakequantizedconv2d": 18, "conv3d": 18, "fakequantizedconv3d": 18, "quantizedconv3d": 18, "convtranspose1d": [18, 38], "fakequantizedconvtranspose1d": 18, "convtranspose2d": 18, "fakequantizedconvtranspose2d": 18, "convtranspose3d": 18, "fakequantizedconvtranspose3d": 18, "crossmaplrn2d": 18, "fakequantizedcrossmaplrn2d": 18, "dropout": 18, "fakequantizeddropout": 18, "dropout2d": 18, "fakequantizeddropout2d": 18, "dropout3d": 18, "fakequantizeddropout3d": 18, "elu": 18, "fakequantizedelu": 18, "featurealphadropout": 18, "fakequantizedfeaturealphadropout": 18, "flatten": 18, "fakequantizedflatten": 18, "fold": [18, 21, 22, 23, 31, 32, 33, 38], "fakequantizedfold": 18, "fractionalmaxpool2d": 18, "fakequantizedfractionalmaxpool2d": 18, "fractionalmaxpool3d": 18, "fakequantizedfractionalmaxpool3d": 18, "gelu": 18, "fakequantizedgelu": 18, "quantizedgelu": 18, "glu": 18, "fakequantizedglu": 18, "groupnorm": 18, "fakequantizedgroupnorm": 18, "hardshrink": 18, "fakequantizedhardshrink": 18, "hardsigmoid": 18, "fakequantizedhardsigmoid": 18, "hardswish": 18, "fakequantizedhardswish": 18, "hardtanh": 18, "fakequantizedhardtanh": 18, "ident": [18, 20], "fakequantizedident": 18, "instancenorm1d": 18, "fakequantizedinstancenorm1d": 18, "instancenorm2d": 18, "fakequantizedinstancenorm2d": 18, "instancenorm3d": 18, "fakequantizedinstancenorm3d": 18, "lppool1d": 18, "fakequantizedlppool1d": 18, "lppool2d": 18, "fakequantizedlppool2d": 18, "layernorm": 18, "fakequantizedlayernorm": 18, "quantizedlayernorm": 18, "leakyrelu": 18, "fakequantizedleakyrelu": 18, "localresponsenorm": 18, "fakequantizedlocalresponsenorm": 18, "logsigmoid": 18, "fakequantizedlogsigmoid": 18, "logsoftmax": 18, "fakequantizedlogsoftmax": 18, "maxpool1d": 18, "fakequantizedmaxpool1d": 18, "maxpool2d": 18, "fakequantizedmaxpool2d": 18, "maxpool3d": 18, "fakequantizedmaxpool3d": 18, "maxunpool1d": 18, "fakequantizedmaxunpool1d": 18, "maxunpool2d": 18, "fakequantizedmaxunpool2d": 18, "maxunpool3d": 18, "fakequantizedmaxunpool3d": 18, "mish": 18, "fakequantizedmish": 18, "prelu": 18, "fakequantizedprelu": 18, "pixelshuffl": 18, "fakequantizedpixelshuffl": 18, "pixelunshuffl": 18, "fakequantizedpixelunshuffl": 18, "rrelu": 18, "fakequantizedrrelu": 18, "relu": [18, 20, 32, 35, 43], "fakequantizedrelu": [18, 20], "relu6": [18, 32], "fakequantizedrelu6": 18, "reflectionpad1d": 18, "fakequantizedreflectionpad1d": 18, "reflectionpad2d": 18, "fakequantizedreflectionpad2d": 18, "replicationpad1d": 18, "fakequantizedreplicationpad1d": 18, "replicationpad2d": 18, "fakequantizedreplicationpad2d": 18, "replicationpad3d": 18, "fakequantizedreplicationpad3d": 18, "selu": 18, "fakequantizedselu": 18, "silu": 18, "fakequantizedsilu": 18, "sigmoid": 18, "fakequantizedsigmoid": 18, "quantizedsigmoid": 18, "softmax": [18, 20], "fakequantizedsoftmax": 18, "quantizedsoftmax": [18, 20], "softmax2d": 18, "fakequantizedsoftmax2d": 18, "softmin": 18, "fakequantizedsoftmin": 18, "softplu": 18, "fakequantizedsoftplu": 18, "softshrink": 18, "fakequantizedsoftshrink": 18, "softsign": 18, "fakequantizedsoftsign": 18, "syncbatchnorm": 18, "fakequantizedsyncbatchnorm": 18, "tanh": 18, "fakequantizedtanh": 18, "tanhshrink": 18, "fakequantizedtanhshrink": 18, "fakequantizedthreshold": 18, "unflatten": 18, "fakequantizedunflatten": 18, "unfold": 18, "fakequantizedunfold": 18, "upsampl": [18, 30], "fakequantizedupsampl": 18, "upsamplingbilinear2d": 18, "fakequantizedupsamplingbilinear2d": 18, "upsamplingnearest2d": 18, "fakequantizedupsamplingnearest2d": 18, "zeropad2d": 18, "fakequantizedzeropad2d": 18, "bceloss": 18, "fakequantizedbceloss": 18, "bcewithlogitsloss": 18, "fakequantizedbcewithlogitsloss": 18, "bilinear": [18, 30], "fakequantizedbilinear": 18, "ctcloss": 18, "fakequantizedctcloss": 18, "cosinesimilar": 18, "fakequantizedcosinesimilar": 18, "crossentropyloss": [18, 20], "fakequantizedcrossentropyloss": 18, "hingeembeddingloss": 18, "fakequantizedhingeembeddingloss": 18, "huberloss": 18, "fakequantizedhuberloss": 18, "kldivloss": 18, "fakequantizedkldivloss": 18, "l1loss": 18, "fakequantizedl1loss": 18, "mseloss": 18, "fakequantizedmseloss": 18, "multilabelmarginloss": 18, "fakequantizedmultilabelmarginloss": 18, "multilabelsoftmarginloss": 18, "fakequantizedmultilabelsoftmarginloss": 18, "multimarginloss": 18, "fakequantizedmultimarginloss": 18, "nllloss": 18, "fakequantizednllloss": 18, "nllloss2d": 18, "fakequantizednllloss2d": 18, "pairwisedist": 18, "fakequantizedpairwisedist": 18, "poissonnllloss": 18, "fakequantizedpoissonnllloss": 18, "smoothl1loss": 18, "fakequantizedsmoothl1loss": 18, "softmarginloss": 18, "fakequantizedsoftmarginloss": 18, "cosineembeddingloss": 18, "fakequantizedcosineembeddingloss": 18, "gaussiannllloss": 18, "fakequantizedgaussiannllloss": 18, "marginrankingloss": 18, "fakequantizedmarginrankingloss": 18, "tripletmarginloss": 18, "fakequantizedtripletmarginloss": 18, "tripletmarginwithdistanceloss": 18, "fakequantizedtripletmarginwithdistanceloss": 18, "embed": [18, 29, 36], "fakequantizedembed": 18, "embeddingbag": 18, "fakequantizedembeddingbag": 18, "gru": [18, 38], "fakequantizedgru": 18, "rnn": [18, 38], "fakequantizedrnn": 18, "grucel": 18, "fakequantizedgrucel": 18, "rnncell": 18, "fakequantizedrnncel": 18, "lstm": [18, 38], "fakequantizedlstm": 18, "lstmcell": 18, "fakequantizedlstmcel": 18, "adaptivelogsoftmaxwithloss": 18, "fakequantizedadaptivelogsoftmaxwithloss": 18, "fakequantizedcast": 18, "depthtospacedcrmod": 18, "fakequantizeddepthtospacedcrmod": 18, "onehot": 18, "fakequantizedonehot": 18, "exponenti": 18, "fakequantizedexponenti": 18, "erf": 18, "fakequantizederf": 18, "sqrt": 18, "fakequantizedsqrt": 18, "log": [18, 33], "fakequantizedlog": 18, "ab": [18, 32], "fakequantizedab": 18, "fakequantizedneg": 18, "elementwiseceil": 18, "fakequantizedelementwiseceil": 18, "elementwisefloor": 18, "fakequantizedelementwisefloor": 18, "sin": 18, "fakequantizedsin": 18, "co": 18, "fakequantizedco": 18, "asin": 18, "fakequantizedasin": 18, "atan": 18, "fakequantizedatan": 18, "fakequantizedround": 18, "logicalnot": 18, "fakequantizedlogicalnot": 18, "nonzero": 18, "fakequantizednonzero": 18, "elementwiseunarysign": 18, "fakequantizedelementwiseunarysign": 18, "rsqrt": 18, "fakequantizedrsqrt": 18, "squar": [18, 37], "fakequantizedsquar": 18, "fakequantizedmean": 18, "sum": [18, 20], "fakequantizedsum": 18, "prod": 18, "fakequantizedprod": 18, "argmin": 18, "fakequantizedargmin": 18, "argmax": [18, 20], "fakequantizedargmax": 18, "gather": 18, "fakequantizedgath": 18, "reshap": 18, "fakequantizedreshap": 18, "roialign": 18, "fakequantizedroialign": 18, "permut": 18, "fakequantizedpermut": 18, "indexselect": 18, "fakequantizedindexselect": 18, "topk": 18, "fakequantizedtopk": 18, "tile": 18, "fakequantizedtil": 18, "norm": [18, 21, 23, 31, 32, 33], "fakequantizednorm": 18, "cumsum": 18, "fakequantizedcumsum": 18, "interpol": [18, 26], "fakequantizedinterpol": 18, "normal": [18, 23, 33], "pad": [18, 20], "fakequantizedpad": 18, "fakequantizedshap": 18, "fakequantizedexpand": 18, "stridedslic": 18, "fakequantizedstridedslic": 18, "matmul": [18, 38], "fakequantizedmatmul": 18, "fakequantizedadd": 18, "fakequantizedmultipli": 18, "subtract": 18, "fakequantizedsubtract": 18, "quantizedsubtract": 18, "fakequantizeddivid": 18, "floordivid": 18, "fakequantizedfloordivid": 18, "fakequantizedgreat": 18, "fakequantizedless": 18, "greaterequ": 18, "fakequantizedgreaterequ": 18, "lessequ": 18, "fakequantizedlessequ": 18, "notequ": 18, "fakequantizednotequ": 18, "fakequantizedequ": 18, "remaind": 18, "fakequantizedremaind": 18, "fmod": 18, "fakequantizedfmod": 18, "pow": 18, "fakequantizedpow": 18, "customsilu": 18, "fakequantizedcustomsilu": 18, "fakequantizedmaximum": 18, "fakequantizedmax": 18, "fakequantizedminimum": 18, "fakequantizedmin": 18, "bmm": 18, "fakequantizedbmm": 18, "logicalor": 18, "fakequantizedlogicalor": 18, "logicaland": 18, "fakequantizedlogicaland": 18, "customgath": 18, "fakequantizedcustomgath": 18, "gathernd": 18, "fakequantizedgathernd": 18, "baddbmm": 18, "fakequantizedbaddbmm": 18, "addmm": 18, "fakequantizedaddmm": 18, "scatternd": 18, "fakequantizedscatternd": 18, "dynamicconv2d": 18, "fakequantizeddynamicconv2d": 18, "scatterel": 18, "fakequantizedscatterel": 18, "batchnorm": [18, 22, 32, 43], "fakequantizedbatchnorm": 18, "fakequantizedaimetgroupnorm": 18, "nonmaxsuppress": 18, "fakequantizednonmaxsuppress": 18, "fakequantizedsplit": 18, "concat": [18, 38], "fakequantizedconcat": 18, "fakequantizedwher": 18, "maskedfil": 18, "fakequantizedmaskedfil": 18, "allow_overwit": 19, "get_encod": 19, "get_legacy_encod": 19, "register_quantization_paramet": 19, "set_legacy_encod": 19, "tutori": 20, "simpl": [20, 31, 43], "intend": [20, 25], "It": [20, 23, 26, 31, 32, 35, 40, 41, 43], "meant": 20, "demonstr": 20, "art": 20, "eval": [20, 26, 29, 40], "loop": [20, 36], "evalu": [20, 22, 26, 29, 31, 33, 34, 37, 40], "clearli": 20, "what": [20, 37, 40], "happen": 20, "let": 20, "special": 20, "look": [20, 40], "torchvis": 20, "is_avail": 20, "els": [20, 32], "loader": [20, 21], "cifar10_train_data": 20, "dataset": [20, 31, 32, 37], "fashionmnist": 20, "tmp": 20, "cifar10": 20, "totensor": 20, "cifar10_test_data": 20, "train_load": 20, "batch_siz": 20, "shuffl": 20, "test_load": 20, "super": 20, "conv1": 20, "kernel_s": 20, "stride": 20, "bn_1": 20, "bn_2": 20, "total": [20, 26, 37], "few": [20, 25, 31, 36, 37], "epoch": [20, 27, 29, 31, 34], "establish": 20, "baselin": [20, 26, 34], "send": 20, "loss_fn": 20, "adam": 20, "lr": 20, "1e": [20, 34], "batch_idx": 20, "enumer": [20, 23], "backward": 20, "zero_grad": 20, "fp_accuraci": 20, "91": 20, "70999908447266": 20, "accur": 20, "coupl": [20, 21], "care": 20, "conform": 20, "guidelin": [20, 21, 25, 34], "math": 20, "wherea": [20, 37], "incorrectli": 20, "ignor": 20, "previou": [20, 25, 26, 36], "definit": [20, 31], "complet": [20, 23, 36], "redefin": 20, "thankfulli": 20, "model_prepar": 20, "incompat": 20, "fulli": [20, 28], "prepared_model": 20, "prepare_model": 20, "fp_accuracy_prepar": 20, "assert": 20, "2024": 20, "07": 20, "747": 20, "info": [20, 38], "806": 20, "modelprepar": 20, "ad": [20, 28, 31, 35, 38], "node": [20, 34, 37], "module_relu": 20, "module_relu_1": 20, "module_softmax": 20, "graphmodul": 20, "ep": 20, "momentum": 20, "track_running_stat": 20, "12544": 20, "getattr_1": 20, "getitem": 20, "debug": [20, 36], "graph_modul": 20, "print_read": 20, "distinct": 20, "adjac": [20, 35], "whenev": 20, "unnecessari": [20, 43], "good": [20, 21], "idea": 20, "batch_norm_fold": 20, "iter": [20, 21, 32], "fold_all_batch_norm": 20, "input_shap": 20, "passthrough": 20, "previous": 20, "had": 20, "impact": [20, 26, 36], "readi": [20, 36], "involv": [20, 31, 36], "encount": 20, "therefor": [20, 25, 32], "theoret": 20, "could": [20, 24, 43], "practic": [20, 29], "usual": [20, 34], "500": [20, 21, 32, 33], "1000": [20, 21, 32, 33], "estim": [20, 31, 32], "idx": 20, "break": 20, "quantized_accuraci": 20, "1500015258789": 20, "noth": 20, "everi": [20, 26, 29, 34, 41], "discuss": [20, 25, 36, 37], "advanc": 20, "re": [20, 31], "One": [20, 25, 29, 39], "op": [20, 31, 35, 38], "repeat": [20, 24], "post_qat_accuraci": 20, "92": 20, "05333709716797": 20, "happi": 20, "export_path": 20, "model_nam": 20, "fashion_mnist_model": 20, "sent": 20, "nearest": 21, "figur": [21, 26, 36, 43], "shown": [21, 29, 32, 33, 36], "illustr": [21, 26, 31, 39, 42], "smaller": [21, 27, 36, 39, 42], "unlabel": [21, 31, 33, 37], "far": 21, "decid": [21, 40], "whether": [21, 34], "awai": 21, "closer": 21, "fp32": [21, 27, 32, 33, 34, 36, 37], "width": [21, 36, 37, 39, 42, 43], "freez": 21, "bc": 21, "bnf": 21, "batch": [21, 23, 31, 32, 33], "cle": [21, 31, 36, 38], "cross": [21, 22, 30, 31, 33, 41], "hbf": 21, "awar": [21, 23, 27, 31, 36, 37], "don": 21, "But": [21, 29], "benefici": [21, 33, 34], "consid": [21, 26, 31, 36], "help": [21, 26, 29, 31, 32, 33, 36, 40, 41], "Not": [21, 26], "hyper": [21, 34], "expos": 21, "stabl": 21, "mani": [21, 32, 37], "often": [21, 22, 29, 34], "approxim": [21, 25, 32, 33], "1024": [21, 30], "10000": 21, "moder": 21, "least": [21, 24], "beta": 21, "warm": 21, "period": 21, "kera": [21, 23, 27, 31, 32, 33, 35, 37, 38], "offer": 22, "suit": 22, "sequenc": [22, 23, 30, 35], "try": [22, 24, 26, 29, 31, 36], "variou": [22, 25, 29, 31, 36, 37, 38, 41], "error": [22, 31, 34, 36, 37], "prone": 22, "consum": [22, 29], "amount": [22, 35], "toler": [22, 25], "soon": 22, "reach": [22, 25], "stop": 22, "summari": 22, "autom": [22, 31], "prepar": [22, 31, 38], "check": [22, 31, 34, 36], "friendli": [22, 31, 32], "denot": 22, "best": [22, 25, 29, 31, 37], "preprat": 22, "mainli": 22, "three": [22, 25, 41], "stage": 22, "effort": 22, "manner": 22, "fail": [22, 30, 31], "goal": 22, "small": [23, 27, 31], "preceed": 23, "learn": [23, 29, 31, 34, 37, 38], "pcq": [23, 33], "veri": [23, 25, 29, 33, 41, 43], "NOT": [23, 43], "scenario": [23, 29, 31, 43], "decreas": 23, "main": [23, 35, 38, 41], "issu": [23, 27, 30, 36, 38, 40, 41], "depthwis": [23, 38], "oscil": 23, "flow": [23, 31, 34, 36, 37], "diagram": [23, 26, 29, 37, 39, 42], "explain": [24, 29, 32, 37, 43], "occurr": 24, "ratio": [24, 25, 40], "magnitud": 24, "matrix": 24, "upstream": [24, 43], "gain": [24, 29], "presenc": 24, "connect": [24, 28, 42], "residu": 24, "sometim": [24, 29, 32, 33], "prevent": 24, "attempt": [24, 31, 32], "close": [24, 25, 37], "prior": [24, 31, 33], "random": [24, 33], "regress": 24, "svd": [25, 26, 28, 29, 38], "spatial": [25, 26, 28, 29, 38], "ssvd": 25, "prune": [25, 26, 28, 29, 38, 43], "cp": 25, "accumul": 25, "mac": [25, 29, 39, 42], "reduct": 25, "uncompress": 25, "algorithm": [25, 26, 29, 36, 43], "overal": [25, 29, 36], "latenc": 25, "bandwidth": 25, "vari": [25, 26, 32, 41], "architectur": 25, "io": [25, 38], "At": [25, 29], "half": 25, "unknown": 25, "apriori": 25, "cssvd": 25, "tri": [25, 31], "65": 25, "75": 25, "pick": [25, 26, 29], "2b": 25, "rel": [25, 31, 36, 41], "avoid": 25, "larg": [25, 34, 39, 42], "2a": 25, "revisit": 25, "ccp": 25, "resnet": 25, "50": 25, "csvd": 25, "assess": 26, "sensit": [26, 31, 33, 36, 37, 38], "applic": [26, 30], "find": [26, 31, 33, 34, 37], "sure": [26, 30], "highest": 26, "remain": [26, 31, 32, 37], "dictionari": [26, 29, 35], "column": 26, "captur": 26, "predefin": 26, "candid": [26, 29], "unmodifi": 26, "score": [26, 29, 40], "last": [26, 28, 36], "monoton": 26, "fit": 26, "strict": [26, 35, 37], "procedur": [26, 29], "curv": 26, "core": 26, "constant": [26, 31], "met": 26, "binari": 26, "solut": [26, 34, 36], "quickli": 26, "suggest": [26, 29, 32], "lesser": [26, 29], "drstical": 26, "softwar": [27, 29], "framework": [27, 31, 35, 37], "meta": [27, 31], "h5": [27, 31], "hw": 27, "ptq": [27, 31, 33, 34], "redund": 27, "dilat": 28, "modules_to_ignor": 28, "depthwiseconv2d": 28, "librari": 29, "guidebook": [29, 31], "advic": 29, "greedi": [29, 40], "phase": [29, 31], "choic": [29, 37], "nomin": 29, "And": 29, "ml": [29, 31, 32, 40, 41], "those": 29, "prefer": 29, "fc": 29, "decompos": [29, 39, 42], "term": [29, 39, 40, 41, 42], "sharp": 29, "degrad": 29, "might": [29, 33], "rate": [29, 34], "carefulli": 29, "decai": 29, "slow": 29, "someth": [29, 40], "speed": [29, 32, 38], "itself": [29, 37, 39, 42], "searcher": 29, "Or": 29, "strike": 29, "balanc": 29, "chosen": 29, "major": 29, "sai": 29, "xiangyu": 29, "zhang": 29, "jianhua": 29, "zou": 29, "kaim": 29, "he": 29, "jian": 29, "sun": 29, "deep": 29, "classif": 29, "detect": 29, "transact": 29, "pattern": 29, "analysi": [29, 36], "intellig": 29, "vol": 29, "pp": 29, "1943": 29, "1955": 29, "oct": 29, "2016": 29, "yihui": 29, "intern": [29, 31, 32, 35], "confer": [29, 32], "vision": [29, 32], "iccv": [29, 32], "venic": 29, "2017": 29, "1398": 29, "1406": 29, "jaderberg": 29, "andrea": 29, "vedaldi": 29, "andrew": 29, "zisserman": 29, "british": 29, "jan": 29, "2014": 29, "andrei": 29, "kuzmin": 29, "marku": [29, 32], "nagel": [29, 32], "saurabh": 29, "pitr": 29, "sandeep": 29, "pendyam": 29, "tijmen": [29, 32], "blankevoort": [29, 32], "taxonomi": 29, "cross_layer_equ": 30, "equalize_model": 30, "successfulli": 30, "potenti": [30, 33, 40, 41], "workaround": 30, "primit": 30, "around": 30, "rewrit": 30, "slice": 30, "written": [30, 31], "caus": [30, 36, 37], "statement": 30, "align_corn": 30, "deconvolut": 30, "deeplabv3": 30, "address": [30, 36, 40], "releas": 30, "hardwar": [31, 32, 37], "howev": [31, 32, 34, 35, 37], "predict": 31, "oppos": [31, 35], "advantag": 31, "No": 31, "pipelin": [31, 34, 36, 37], "suffici": [31, 33, 34, 37], "even": 31, "fast": 31, "easi": [31, 33], "gap": 31, "insert": [31, 37], "robust": 31, "longer": [31, 34], "account": [31, 34, 36], "trainabl": 31, "bias": 31, "reflect": [31, 37], "autoqu": [31, 34, 38], "integr": 31, "standalon": 31, "consecut": [31, 32], "bn": [31, 38], "deprec": 31, "advis": [31, 35], "quantanalyz": [31, 38], "understand": [31, 35, 40, 41], "prep": 31, "accord": [31, 34, 35, 37], "align": 31, "retri": 31, "continu": [31, 32, 34, 36], "warn": 31, "hand": 31, "satisfactori": [31, 36], "bring": 31, "onto": 31, "thing": 31, "item": 31, "checkpoint": 31, "pb": 31, "trial": 31, "seem": 31, "off": [31, 32, 35], "bat": 31, "becom": 32, "design": 32, "paper": 32, "2019": 32, "arxiv": 32, "1906": 32, "04721": 32, "surround": 32, "highlight": [32, 40, 41], "big": 32, "discrep": 32, "accept": [32, 36], "wide": 32, "varianc": 32, "seen": [32, 33], "significantli": 32, "quantizaion": 32, "distribut": [32, 36, 37], "did": 32, "shift": 32, "empir": 32, "analyt": [32, 40, 41], "extract": 32, "bottleneck": [32, 36], "hybrid": 32, "approach": [32, 37], "mart": 32, "van": 32, "baalen": 32, "seoul": 32, "octob": 32, "hotspot": 33, "analys": 33, "callback": [33, 37], "mse": [33, 37], "label": [33, 34], "metric": [33, 37], "rune": 33, "relat": [33, 37], "doc": [33, 35, 40], "situat": 33, "pinpoint": 33, "culprit": 33, "again": [33, 34, 40], "per_layer_quant_en": 33, "per_layer_quant_dis": 33, "axi": 33, "track": 33, "directli": [33, 37], "min_max_rang": 33, "folder": 33, "enhanc": [33, 37], "toss": 33, "displai": [33, 40, 41], "activations_pdf": 33, "weights_pdf": 33, "monitor": 33, "contribut": [33, 36], "read": 33, "per_layer_mse_loss": 33, "mitig": [34, 37], "hyperparamet": 34, "accompani": 34, "throughout": [34, 35, 41], "aid": 34, "converg": 34, "schedul": 34, "placement": 35, "fuse": [35, 37], "six": 35, "overrul": 35, "turn": 35, "op_typ": 35, "empti": 35, "is_output_quant": 35, "is_symmetr": 35, "is_quant": 35, "strict_symmetr": 35, "unsigned_symmetr": 35, "omit": 35, "altogeth": 35, "asid": 35, "govern": 35, "unsign": [35, 37], "gemm": 35, "is_input_quant": 35, "recogn": [35, 37], "keep": [35, 36], "convent": 35, "preced": 35, "supergroup": [35, 38], "made": 35, "op_list": 35, "member": 35, "sequenti": [35, 36], "branch": 35, "config": [35, 38], "entri": 35, "string": 35, "model_input": 35, "whatev": 35, "earlier": 35, "model_output": 35, "diagnost": 36, "strictli": 36, "insight": [36, 40, 41], "why": 36, "underperform": 36, "tackl": 36, "chart": 36, "saniti": 36, "ofth": 36, "independ": 36, "kept": 36, "convers": 36, "toward": 36, "uneven": 36, "vanilla": 36, "global": 36, "restor": 36, "rest": 36, "inner": 36, "token": 36, "bert": 36, "reveal": 36, "problemat": [36, 41], "problem": 36, "resort": 36, "revert": 36, "power": 36, "ultim": 37, "copi": 37, "ingest": 37, "feed": 37, "000": 37, "yield": 37, "dequantiz": 37, "hook": 37, "intercept": 37, "four": 37, "vice": 37, "versa": 37, "textrm": 37, "dfrac": 37, "strong": 37, "excess": 37, "signal": 37, "satur": 37, "erro": 37, "static": 37, "alongsid": 37, "ones": 37, "just": [37, 40, 43], "non": 37, "intermedi": 37, "slim": 38, "backslash": 38, "user_guid": 38, "api_doc": 38, "quantizablemultiheadattent": 38, "kyuykim": 38, "multi": 38, "mangal": 38, "geunle": 38, "bug": 38, "correctli": 38, "klhsieh": 38, "akhobar": 38, "multiheadattent": 38, "ashvkuma": 38, "mha": 38, "pdf": 38, "fp16": 38, "minor": 38, "stand": [38, 39, 42], "adaptiveround": 38, "recurr": 38, "decomposit": [39, 42], "singular": [39, 42], "\ud835\udc5a": [39, 42], "\ud835\udc5b": [39, 42], "\u210e": [39, 42], "\ud835\udc64": [39, 42], "give": [39, 42], "height": [39, 42, 43], "\ud835\udc58": [39, 42], "k": 39, "rank": [39, 42], "degre": [39, 42], "progress": [40, 41], "computation": [40, 41], "task": [40, 41], "websocket": 40, "tell": 40, "listen": 40, "rather": 40, "5006": 40, "compress_model": 40, "visualizecompress": 40, "display_eval_scor": 40, "display_comp_ratio_plot": 40, "directori": 41, "lot": 41, "anoth": [42, 43], "lose": 43, "much": 43, "pictori": 43, "volum": 43, "hxwx8": 43, "hxwx5": 43, "simpli": 43, "propag": 43, "That": 43, "teh": 43, "green": 43, "color": 43, "side": 43, "action": 43, "taken": 43, "pink": 43, "orang": 43}, "objects": {"aimet_torch.gptvq.defs": [[16, 0, 1, "", "GPTVQParameters"]], "aimet_torch.gptvq.gptvq_weight.GPTVQ": [[16, 1, 1, "", "apply_gptvq"]], "aimet_torch.v2.nn": [[6, 0, 1, "", "FakeQuantizationMixin"], [7, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.FakeQuantizationMixin": [[6, 2, 1, "", "__quant_init__"], [6, 2, 1, "", "compute_encodings"], [6, 2, 1, "", "forward"], [6, 2, 1, "", "from_module"], [6, 2, 1, "", "implements"], [6, 3, 1, "", "input_quantizers"], [6, 3, 1, "", "output_quantizers"], [6, 3, 1, "", "param_quantizers"]], "aimet_torch.v2.nn.QuantizationMixin": [[7, 2, 1, "", "__quant_init__"], [7, 2, 1, "", "compute_encodings"], [7, 2, 1, "", "forward"], [7, 2, 1, "", "from_module"], [7, 2, 1, "", "get_default_kernel"], [7, 2, 1, "", "get_kernel"], [7, 2, 1, "", "implements"], [7, 3, 1, "", "input_quantizers"], [7, 3, 1, "", "output_quantizers"], [7, 3, 1, "", "param_quantizers"], [7, 2, 1, "", "set_default_kernel"], [7, 2, 1, "", "set_kernel"]], "aimet_torch.v2.nn.base": [[18, 0, 1, "", "BaseQuantizationMixin"]], "aimet_torch.v2.nn.base.BaseQuantizationMixin": [[18, 2, 1, "", "__quant_init__"], [18, 2, 1, "", "compute_encodings"], [18, 2, 1, "", "forward"], [18, 3, 1, "", "input_quantizers"], [18, 3, 1, "", "output_quantizers"], [18, 3, 1, "", "param_quantizers"]], "aimet_torch.v2.quantization": [[8, 4, 0, "-", "affine"], [10, 4, 0, "-", "float"]], "aimet_torch.v2.quantization.affine": [[8, 0, 1, "", "Quantize"], [8, 0, 1, "", "QuantizeDequantize"], [8, 1, 1, "", "dequantize"], [8, 1, 1, "", "quantize"], [8, 1, 1, "", "quantize_dequantize"]], "aimet_torch.v2.quantization.affine.quantizer": [[19, 0, 1, "", "Quantize"], [19, 0, 1, "", "QuantizeDequantize"], [19, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[19, 2, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[19, 2, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[19, 2, 1, "", "allow_overwrite"], [19, 2, 1, "", "compute_encodings"], [19, 2, 1, "", "get_encoding"], [19, 2, 1, "", "get_legacy_encodings"], [19, 2, 1, "", "is_initialized"], [19, 2, 1, "", "register_quantization_parameter"], [19, 2, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization.encoding_analyzer": [[14, 0, 1, "", "EncodingAnalyzer"], [14, 0, 1, "", "MinMaxEncodingAnalyzer"], [14, 0, 1, "", "PercentileEncodingAnalyzer"], [14, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.float": [[10, 0, 1, "", "FloatQuantizeDequantize"], [10, 0, 1, "", "QuantizeDequantize"]], "aimet_torch.v2.quantization.tensor": [[11, 0, 1, "", "DequantizedTensor"], [11, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[11, 2, 1, "", "dequantize"], [11, 2, 1, "", "quantize"], [11, 2, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[11, 2, 1, "", "dequantize"], [11, 2, 1, "", "quantize"], [11, 2, 1, "", "quantized_repr"]], "aimet_torch.v2.quantsim.config_utils": [[13, 1, 1, "", "set_activation_quantizers_to_float"], [13, 1, 1, "", "set_blockwise_quantization_for_weights"], [13, 1, 1, "", "set_grouped_blockwise_quantization_for_weights"]], "aimet_torch.v2.visualization_tools": [[12, 1, 1, "", "visualize_stats"]]}, "objtypes": {"0": "py:class", "1": "py:function", "2": "py:method", "3": "py:attribute", "4": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "function", "Python function"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "module", "Python module"]}, "titleterms": {"aimet": [2, 3, 4, 17, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43], "instal": [2, 3, 4, 27], "quick": 2, "releas": [2, 3, 4, 27, 38], "packag": [2, 3, 4], "system": 2, "requir": [2, 33], "advanc": 2, "instruct": 2, "docker": 3, "set": 3, "variant": [3, 14], "us": [3, 21, 29, 31, 40], "prebuilt": 3, "imag": 3, "build": 3, "local": 3, "start": [3, 17, 27, 40], "contain": 3, "from": [3, 4], "pypi": [3, 4], "environ": [3, 4], "setup": [3, 4], "prerequisit": [4, 20], "gpu": 4, "pytorch": [4, 17, 20, 30, 31, 41], "2": [4, 20, 38], "1": [4, 20, 38], "13": [4, 38], "onnx": 4, "tensorflow": [4, 41], "common": [4, 21], "debian": 4, "torch": 4, "replac": 4, "pillow": 4, "simd": 4, "onnxruntim": 4, "post": [4, 15, 31, 32], "step": 4, "fakequantizationmixin": 6, "quantizationmixin": 7, "quantiz": [8, 10, 11, 13, 15, 18, 19, 20, 31, 32, 34, 35, 36, 37, 41], "affin": 8, "class": [8, 10, 11, 18], "function": 8, "floatquantizedequant": 9, "quantizedequant": 9, "float": [10, 20], "tensor": 11, "visual": [12, 40, 41], "tool": [12, 31, 40], "blockwis": 13, "low": 13, "power": 13, "lpbq": 13, "top": [13, 16, 18, 19], "level": [13, 16, 18, 19], "api": [13, 16, 17, 18, 19, 21, 22, 23, 32, 33, 37], "export": [13, 20], "encod": [14, 18, 37], "analyz": 14, "train": [15, 20, 31, 32, 34], "gptvq": 16, "paramet": [16, 37], "code": 16, "exampl": [16, 17], "ai": [17, 27], "model": [17, 20, 27, 29, 30, 31], "effici": [17, 27], "toolkit": [17, 27], "document": 17, "get": [17, 27, 29], "featur": [17, 25, 27, 31, 36], "descript": [17, 33], "modul": 18, "configur": [18, 35, 37], "comput": 18, "quickstart": 20, "guid": [20, 27], "overal": [20, 24], "flow": [20, 32], "prepar": 20, "point": 20, "batchnorm": 20, "fold": 20, "fine": [20, 29], "tune": [20, 29], "awar": [20, 34], "quantsim": [20, 37], "adaround": 21, "case": [21, 29, 31], "terminologi": 21, "autoqu": 22, "overview": [22, 23, 26, 27, 29, 32, 33, 34, 35, 37, 40, 41, 43], "workflow": [22, 23, 31, 34, 37], "bn": 23, "re": 23, "estim": 23, "channel": 24, "prune": 24, "procedur": 24, "select": [24, 26, 29], "winnow": [24, 43], "weight": [24, 42], "reconstruct": 24, "compress": [25, 26, 29, 40], "guidebook": [25, 36], "greedi": 26, "ratio": [26, 29], "how": [26, 35, 40, 43], "work": [26, 43], "per": [26, 29], "layer": [26, 29, 32], "explor": 26, "user": [27, 32], "inform": 27, "toc": 27, "tree": 27, "known": 28, "issu": 28, "option": 29, "techniqu": [29, 32], "better": 29, "result": 29, "rank": 29, "round": 29, "faq": [29, 32], "refer": [29, 32], "guidelin": [30, 31], "debug": 31, "analysi": [31, 33], "cross": 32, "equal": 32, "quantanalyz": 33, "detail": 33, "qat": 34, "mode": 34, "recommend": 34, "simul": [35, 37], "file": 35, "structur": 35, "individu": 35, "section": 35, "nois": 37, "determin": 37, "scheme": 37, "op": 37, "frequent": 37, "ask": 37, "question": 37, "note": 38, "22": 38, "0": 38, "21": 38, "20": 38, "19": 38, "py37": 38, "18": 38, "17": 38, "16": 38, "14": 38, "spatial": 39, "svd": [39, 42], "design": 40, "bokeh": 40, "server": 40, "session": 40}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"AIMET Installation": [[2, "aimet-installation"]], "Quick Install": [[2, "quick-install"]], "Release Packages": [[2, "release-packages"]], "System Requirements": [[2, "system-requirements"]], "Advanced Installation Instructions": [[2, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[3, "aimet-installation-in-docker"]], "Set variant": [[3, "set-variant"]], "Use prebuilt docker image": [[3, "use-prebuilt-docker-image"]], "Build docker image locally": [[3, "build-docker-image-locally"]], "Start docker container": [[3, "start-docker-container"]], "Install AIMET packages": [[3, "install-aimet-packages"], [4, "install-aimet-packages"]], "From PyPI": [[3, "from-pypi"], [4, "from-pypi"]], "From Release Package": [[3, "from-release-package"], [4, "from-release-package"]], "Environment setup": [[3, "environment-setup"], [4, "environment-setup"]], "AIMET Installation and Setup": [[4, "aimet-installation-and-setup"]], "Install prerequisite packages": [[4, "install-prerequisite-packages"]], "Install GPU packages": [[4, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or PyTorch 1.13 or ONNX or TensorFlow": [[4, "install-gpu-packages-for-pytorch-2-1-or-pytorch-1-13-or-onnx-or-tensorflow"]], "Install common debian packages": [[4, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[4, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[4, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[4, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[4, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[4, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[4, "post-installation-steps"]], "FakeQuantizationMixin": [[6, "fakequantizationmixin"]], "QuantizationMixin": [[7, "quantizationmixin"]], "quantization.affine": [[8, "module-aimet_torch.v2.quantization.affine"]], "Classes": [[8, "classes"], [10, "classes"], [11, "classes"]], "Functions": [[8, "functions"]], "FloatQuantizeDequantize": [[9, "floatquantizedequantize"]], "QuantizeDequantize": [[9, "quantizedequantize"]], "quantization.float": [[10, "module-aimet_torch.v2.quantization.float"]], "quantization.tensor": [[11, "quantization-tensor"]], "Visualization Tools": [[12, "visualization-tools"]], "Blockwise Quantization": [[13, "blockwise-quantization"]], "Low Power Blockwise Quantization (LPBQ)": [[13, "low-power-blockwise-quantization-lpbq"]], "Top Level API": [[13, "top-level-api"], [16, "top-level-api"]], "Export": [[13, "export"]], "Encoding Analyzers": [[14, "encoding-analyzers"]], "Variants": [[14, "variants"]], "Post-Training Quantization": [[15, "post-training-quantization"], [31, "post-training-quantization"]], "GPTVQ": [[16, "gptvq"]], "GPTVQ Parameters": [[16, "gptvq-parameters"]], "Code Example": [[16, "code-example"]], "AIMET: AI Model Efficiency Toolkit Documentation": [[17, "aimet-ai-model-efficiency-toolkit-documentation"]], "Getting Started": [[17, "getting-started"], [27, "getting-started"]], "Examples": [[17, null]], "Feature Descriptions": [[17, null]], "AIMET PyTorch API": [[17, null]], "Quantized Modules": [[18, "quantized-modules"]], "Top-level API": [[18, "top-level-api"], [19, "top-level-api"]], "Configuration": [[18, "configuration"]], "Computing Encodings": [[18, "computing-encodings"]], "Quantized Module Classes": [[18, "quantized-module-classes"]], "Quantizers": [[19, "quantizers"]], "Quickstart Guide": [[20, "quickstart-guide"]], "Overall flow": [[20, "overall-flow"]], "PyTorch prerequisites": [[20, "pytorch-prerequisites"]], "Prepare the floating point model for quantization": [[20, "prepare-the-floating-point-model-for-quantization"]], "1) Model preparation": [[20, "model-preparation"]], "2) BatchNorm fold": [[20, "batchnorm-fold"]], "Quantize the model": [[20, "quantize-the-model"]], "Fine-tune the model with quantization aware training": [[20, "fine-tune-the-model-with-quantization-aware-training"]], "Export the quantsim model": [[20, "export-the-quantsim-model"]], "AIMET AdaRound": [[21, "aimet-adaround"]], "AdaRound Use Cases": [[21, "adaround-use-cases"]], "Common terminology": [[21, "common-terminology"]], "Use Cases": [[21, "use-cases"], [31, "use-cases"]], "AdaRound API": [[21, "adaround-api"]], "AIMET AutoQuant": [[22, "aimet-autoquant"]], "Overview": [[22, "overview"], [23, "overview"], [26, "overview"], [27, "overview"], [29, "overview"], [32, "overview"], [33, "overview"], [34, "overview"], [35, "overview"], [37, "overview"], [40, "overview"], [41, "overview"], [43, "overview"]], "Workflow": [[22, "workflow"], [23, "workflow"]], "AutoQuant API": [[22, "autoquant-api"]], "AIMET BN Re-estimation": [[23, "aimet-bn-re-estimation"]], "BN Re-estimation API": [[23, "bn-re-estimation-api"]], "AIMET Channel Pruning": [[24, "aimet-channel-pruning"]], "Overall Procedure": [[24, "overall-procedure"]], "Channel Selection": [[24, "channel-selection"]], "Winnowing": [[24, "winnowing"]], "Weight Reconstruction": [[24, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[25, "aimet-compression-features-guidebook"]], "AIMET Greedy Compression Ratio Selection": [[26, "aimet-greedy-compression-ratio-selection"]], "How it works": [[26, "how-it-works"]], "Per-layer Exploration": [[26, "per-layer-exploration"]], "Compression Ratio Selection": [[26, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[27, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[27, "features"]], "Release Information": [[27, "release-information"]], "Installation Guide": [[27, "installation-guide"]], "toc tree": [[27, "toc-tree"]], "AIMET Known Issues": [[28, "aimet-known-issues"]], "AIMET Model Compression": [[29, "aimet-model-compression"]], "Use Case": [[29, "use-case"]], "Compression ratio selection": [[29, "compression-ratio-selection"]], "Model Compression": [[29, "model-compression"]], "Optional techniques to get better compression results": [[29, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[29, "rank-rounding"]], "Per-layer Fine-tuning": [[29, "per-layer-fine-tuning"]], "FAQs": [[29, "faqs"], [32, "faqs"]], "References": [[29, "references"], [32, "references"]], "Model Guidelines for PyTorch": [[30, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[31, "aimet-model-quantization"]], "AIMET Quantization Features": [[31, "aimet-quantization-features"]], "Debugging/Analysis Tools": [[31, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[31, "aimet-quantization-workflow"]], "PyTorch": [[31, "pytorch"], [41, "pytorch"]], "Debugging Guidelines": [[31, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[32, "aimet-post-training-quantization-techniques"]], "User Flow": [[32, "user-flow"]], "Cross-Layer Equalization API": [[32, "cross-layer-equalization-api"]], "AIMET QuantAnalyzer": [[33, "aimet-quantanalyzer"]], "Requirements": [[33, "requirements"]], "Detailed Analysis Descriptions": [[33, "detailed-analysis-descriptions"]], "QuantAnalyzer API": [[33, "quantanalyzer-api"]], "AIMET Quantization Aware Training": [[34, "aimet-quantization-aware-training"]], "QAT workflow": [[34, "qat-workflow"]], "QAT modes": [[34, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[34, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[35, "quantization-simulation-configuration"]], "Configuration File Structure": [[35, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[35, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[36, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[37, "aimet-quantization-simulation"]], "QuantSim Workflow": [[37, "quantsim-workflow"]], "Simulating Quantization Noise": [[37, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[37, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[37, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[37, "configuring-quantization-simulation-ops"]], "Quantization Simulation APIs": [[37, "quantization-simulation-apis"]], "Frequently Asked Questions": [[37, "frequently-asked-questions"]], "AIMET Release Notes": [[38, "aimet-release-notes"]], "1.22.2": [[38, "id1"]], "1.22.1": [[38, "id2"]], "1.22.0": [[38, "id3"]], "1.21.0": [[38, "id4"]], "1.20.0": [[38, "id5"]], "1.19.1.py37": [[38, "py37"]], "1.19.1": [[38, "id6"]], "1.18.0.py37": [[38, "id7"]], "1.18.0": [[38, "id8"]], "1.17.0.py37": [[38, "id9"]], "1.17.0": [[38, "id10"]], "1.16.2.py37": [[38, "id11"]], "1.16.2": [[38, "id12"]], "1.16.1.py37": [[38, "id13"]], "1.16.1": [[38, "id14"]], "1.16.0": [[38, "id15"]], "1.14.0": [[38, "id16"]], "1.13.0": [[38, "id17"]], "AIMET Spatial SVD": [[39, "aimet-spatial-svd"]], "AIMET Visualization": [[40, "aimet-visualization"]], "Design": [[40, "design"]], "Compression": [[40, "compression"]], "Starting a Bokeh Server Session:": [[40, "starting-a-bokeh-server-session"]], "How to use the tool": [[40, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[41, "aimet-visualization-for-quantization"]], "Quantization": [[41, "quantization"]], "TensorFlow": [[41, "tensorflow"]], "AIMET Weight SVD": [[42, "aimet-weight-svd"]], "AIMET Winnowing": [[43, "aimet-winnowing"]], "Winnowing Overview": [[43, "winnowing-overview"]], "How Winnowing Works": [[43, "how-winnowing-works"]]}, "indexentries": {"fakequantizationmixin (class in aimet_torch.v2.nn)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.from_module"]], "implements() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"]], "quantizationmixin (class in aimet_torch.v2.nn)": [[7, "aimet_torch.v2.nn.QuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.from_module"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[7, "aimet_torch.v2.nn.QuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[7, "aimet_torch.v2.nn.QuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[7, "aimet_torch.v2.nn.QuantizationMixin.param_quantizers"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "quantize (class in aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.QuantizeDequantize"]], "aimet_torch.v2.quantization.affine": [[8, "module-aimet_torch.v2.quantization.affine"]], "dequantize() (in module aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.dequantize"]], "module": [[8, "module-aimet_torch.v2.quantization.affine"], [10, "module-aimet_torch.v2.quantization.float"]], "quantize() (in module aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.quantize"]], "quantize_dequantize() (in module aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.quantize_dequantize"]], "floatquantizedequantize (class in aimet_torch.v2.quantization.float)": [[9, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"], [10, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.float)": [[9, "aimet_torch.v2.quantization.float.QuantizeDequantize"], [10, "aimet_torch.v2.quantization.float.QuantizeDequantize"]], "aimet_torch.v2.quantization.float": [[10, "module-aimet_torch.v2.quantization.float"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[11, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[11, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[11, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[11, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[11, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[11, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[11, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[11, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "visualize_stats() (in module aimet_torch.v2.visualization_tools)": [[12, "aimet_torch.v2.visualization_tools.visualize_stats"]], "set_activation_quantizers_to_float() (in module aimet_torch.v2.quantsim.config_utils)": [[13, "aimet_torch.v2.quantsim.config_utils.set_activation_quantizers_to_float"]], "set_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[13, "aimet_torch.v2.quantsim.config_utils.set_blockwise_quantization_for_weights"]], "set_grouped_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[13, "aimet_torch.v2.quantsim.config_utils.set_grouped_blockwise_quantization_for_weights"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[14, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[14, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[14, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[14, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "gptvqparameters (class in aimet_torch.gptvq.defs)": [[16, "aimet_torch.gptvq.defs.GPTVQParameters"]], "apply_gptvq() (in module aimet_torch.gptvq.gptvq_weight.gptvq)": [[16, "aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq"]], "basequantizationmixin (class in aimet_torch.v2.nn.base)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"]], "input_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[18, "aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[19, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "allow_overwrite() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[19, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})