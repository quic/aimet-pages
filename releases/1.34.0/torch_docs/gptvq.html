<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GPTVQ &mdash; AI Model Efficiency Toolkit Documentation: ver 1.34.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../user_guide/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.34.0
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/model_quantization.html"> Quantization User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#aimet-quantization-features">AIMET Quantization Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_sim.html"> Quantization Simulation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantsim-workflow">QuantSim Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#simulating-quantization-noise">Simulating Quantization Noise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#determining-quantization-parameters-encodings">Determining Quantization Parameters (Encodings)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantization-schemes">Quantization Schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#configuring-quantization-simulation-ops">Configuring Quantization Simulation Ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantization-simulation-apis">Quantization Simulation APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#frequently-asked-questions">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_aware_training.html"> Quantization-Aware Training (QAT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#qat-workflow">QAT workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#qat-modes">QAT modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#recommendations-for-quantization-aware-training">Recommendations for Quantization-Aware Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#post-training-quantization"><span class="hideitem">Post-Training Quantization</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/auto_quant.html">AutoQuant</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#workflow">Workflow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#autoquant-api">AutoQuant API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/adaround.html">Adaptive Rounding (AdaRound)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#adaround-use-cases">AdaRound Use Cases</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#common-terminology">Common terminology</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#use-cases">Use Cases</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#adaround-api">AdaRound API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html">Cross-Layer Equalization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#cross-layer-equalization-api">Cross-Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/bn_reestimation.html">BN Re-estimation</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#workflow">Workflow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#bn-re-estimation-api">BN Re-estimation API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html">Bias Correction [Depricated]</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#cross-layer-equalization-api">Cross-Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#debugging-analysis-tools"><span class="hideitem">Debugging/Analysis Tools</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quant_analyzer.html">QuantAnalyzer</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#requirements">Requirements</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#detailed-analysis-descriptions">Detailed Analysis Descriptions</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#quantanalyzer-api">QuantAnalyzer API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_quant.html">Visualizations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/visualization_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/visualization_quant.html#quantization">Quantization</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/visualization_quant.html#pytorch">PyTorch</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/visualization_quant.html#tensorflow">TensorFlow</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#aimet-quantization-workflow">AIMET Quantization Workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#pytorch"><span class="hideitem">PyTorch</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_model_guidelines.html"> PyTorch Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_quantization.html"> AIMET PyTorch Quantization APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_quantization.html#aimet-torch">aimet_torch</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_quantization.html#api-reference">API Reference</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_model_preparer.html#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_model_preparer.html#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_peft_lora.html"> PEFT LoRA APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_fp_lora_layer()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.quantize_lora_scale_with_fixed_range()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_quantization.html#aimet-torch-v2">aimet_torch.v2</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_quantization.html#what-s-new">What’s New</a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_quantization.html#backwards-compatibility">Backwards Compatibility</a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_quantization.html#id1">API Reference</a><ul>
<li class="toctree-l7"><a class="reference internal" href="quantized_modules.html">Quantized Modules</a><ul>
<li class="toctree-l8"><a class="reference internal" href="quantized_modules.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="quantized_modules.html#configuration">Configuration</a></li>
<li class="toctree-l8"><a class="reference internal" href="quantized_modules.html#computing-encodings">Computing Encodings</a></li>
<li class="toctree-l8"><a class="reference internal" href="quantized_modules.html#quantized-module-classes">Quantized Module Classes</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="quantizer.html">Quantizers</a><ul>
<li class="toctree-l8"><a class="reference internal" href="quantizer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"><code class="docutils literal notranslate"><span class="pre">QuantizerBase</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.allow_overwrite()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.compute_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_encoding()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_legacy_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.is_initialized()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.register_quantization_parameter()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.set_legacy_encodings()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"><code class="docutils literal notranslate"><span class="pre">Quantize.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="encoding_analyzer.html">Encoding Analyzers</a><ul>
<li class="toctree-l8"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">EncodingAnalyzer</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="encoding_analyzer.html#variants">Variants</a><ul>
<li class="toctree-l9"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">MinMaxEncodingAnalyzer</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">SqnrEncodingAnalyzer</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">PercentileEncodingAnalyzer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="api/nn.fake_quantization_mixin.html">FakeQuantizationMixin</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="api/nn.quantization_mixin.html">QuantizationMixin</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_default_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_default_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="api/quantization/affine/index.html">quantization.affine</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#classes">Classes</a><ul>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#functions">Functions</a><ul>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize"><code class="docutils literal notranslate"><span class="pre">quantize()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize_dequantize"><code class="docutils literal notranslate"><span class="pre">quantize_dequantize()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.dequantize"><code class="docutils literal notranslate"><span class="pre">dequantize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="api/quantization/float/index.html">quantization.float</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/float/index.html#classes">Classes</a><ul>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/float/index.html#aimet_torch.v2.quantization.float.FloatQuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">FloatQuantizeDequantize</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="api/quantization/float/index.html#aimet_torch.v2.quantization.float.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="api/visualization_tools.html">Visualization Tools</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/visualization_tools.html#aimet_torch.v2.visualization_tools.visualize_stats"><code class="docutils literal notranslate"><span class="pre">visualize_stats()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#debugging-guidelines">Debugging Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_feature_guidebook.html">Quantization Guidebook</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/model_compression.html"> Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/compression_feature_guidebook.html">Compression Guidebook</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html">Greedy Compression Ratio Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#how-it-works">How it works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#per-layer-exploration">Per-layer Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#compression-ratio-selection">Compression Ratio Selection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#winnowing">Winnowing</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/winnowing.html">Winnowing</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#overview">Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#winnowing-overview">Winnowing Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#how-winnowing-works">How Winnowing Works</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_docs/index.html"> API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/torch.html">AIMET APIs for PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_quantization.html">PyTorch Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_quantization.html#aimet-torch">aimet_torch</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_quantization.html#api-reference">API Reference</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_model_preparer.html#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_model_preparer.html#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_peft_lora.html"> PEFT LoRA APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_fp_lora_layer()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.quantize_lora_scale_with_fixed_range()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../api_docs/torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_quantization.html#aimet-torch-v2">aimet_torch.v2</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_quantization.html#what-s-new">What’s New</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_quantization.html#backwards-compatibility">Backwards Compatibility</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_quantization.html#id1">API Reference</a><ul>
<li class="toctree-l6"><a class="reference internal" href="quantized_modules.html">Quantized Modules</a><ul>
<li class="toctree-l7"><a class="reference internal" href="quantized_modules.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="quantized_modules.html#configuration">Configuration</a></li>
<li class="toctree-l7"><a class="reference internal" href="quantized_modules.html#computing-encodings">Computing Encodings</a></li>
<li class="toctree-l7"><a class="reference internal" href="quantized_modules.html#quantized-module-classes">Quantized Module Classes</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="quantizer.html">Quantizers</a><ul>
<li class="toctree-l7"><a class="reference internal" href="quantizer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"><code class="docutils literal notranslate"><span class="pre">QuantizerBase</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.allow_overwrite()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_encoding()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_legacy_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.is_initialized()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.register_quantization_parameter()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.set_legacy_encodings()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"><code class="docutils literal notranslate"><span class="pre">Quantize.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="encoding_analyzer.html">Encoding Analyzers</a><ul>
<li class="toctree-l7"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">EncodingAnalyzer</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="encoding_analyzer.html#variants">Variants</a><ul>
<li class="toctree-l8"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">MinMaxEncodingAnalyzer</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">SqnrEncodingAnalyzer</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">PercentileEncodingAnalyzer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="api/nn.fake_quantization_mixin.html">FakeQuantizationMixin</a><ul>
<li class="toctree-l7"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="api/nn.quantization_mixin.html">QuantizationMixin</a><ul>
<li class="toctree-l7"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_default_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_default_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="api/quantization/affine/index.html">quantization.affine</a><ul>
<li class="toctree-l7"><a class="reference internal" href="api/quantization/affine/index.html#classes">Classes</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="api/quantization/affine/index.html#functions">Functions</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize"><code class="docutils literal notranslate"><span class="pre">quantize()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize_dequantize"><code class="docutils literal notranslate"><span class="pre">quantize_dequantize()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.dequantize"><code class="docutils literal notranslate"><span class="pre">dequantize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="api/quantization/float/index.html">quantization.float</a><ul>
<li class="toctree-l7"><a class="reference internal" href="api/quantization/float/index.html#classes">Classes</a><ul>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/float/index.html#aimet_torch.v2.quantization.float.FloatQuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">FloatQuantizeDequantize</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="api/quantization/float/index.html#aimet_torch.v2.quantization.float.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="api/visualization_tools.html">Visualization Tools</a><ul>
<li class="toctree-l7"><a class="reference internal" href="api/visualization_tools.html#aimet_torch.v2.visualization_tools.visualize_stats"><code class="docutils literal notranslate"><span class="pre">visualize_stats()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_common.defs.GreedySelectionParameters"><code class="docutils literal notranslate"><span class="pre">GreedySelectionParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_compress.html#aimet_torch.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_eval_scores()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_comp_ratio_plot()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"><code class="docutils literal notranslate"><span class="pre">visualize_relative_weight_ranges_to_identify_problematic_layers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_weight_ranges"><code class="docutils literal notranslate"><span class="pre">visualize_weight_ranges()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_changes_after_optimization"><code class="docutils literal notranslate"><span class="pre">visualize_changes_after_optimization()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme"><code class="docutils literal notranslate"><span class="pre">NamingScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.ONNX"><code class="docutils literal notranslate"><span class="pre">NamingScheme.ONNX</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.PYTORCH"><code class="docutils literal notranslate"><span class="pre">NamingScheme.PYTORCH</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"><code class="docutils literal notranslate"><span class="pre">NamingScheme.TORCHSCRIPT</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/keras.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/keras_quantization.html">TensorFlow Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_model_preparer.html#aimet_tensorflow.keras.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_model_preparer.html#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_quant_analyzer.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_quantsim.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_adaround.html#adaround-parameters">Adaround Parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_adaround.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#custom-datatype-used">Custom Datatype used</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#code-example-for-lower-level-apis">Code Example for Lower level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_primitive_apis_cle.html#example-helper-methods-to-perform-cle-in-manual-mode">Example helper methods to perform CLE in manual mode</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html#aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_batchnorm_re_estimation.html#limitations">Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/keras_layer_output_generation.html">TensorFlow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/keras_compression.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_compression.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_compression.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_compression.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_compression.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_compression.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CostMetric"><code class="docutils literal notranslate"><span class="pre">CostMetric</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CostMetric.mac"><code class="docutils literal notranslate"><span class="pre">CostMetric.mac</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CostMetric.memory"><code class="docutils literal notranslate"><span class="pre">CostMetric.memory</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme"><code class="docutils literal notranslate"><span class="pre">CompressionScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme.channel_pruning"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.channel_pruning</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme.spatial_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.spatial_svd</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_common.defs.CompressionScheme.weight_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.weight_svd</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/keras_compression.html#aimet_tensorflow.keras.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/keras_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/onnx_quantization.html">ONNX Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_quantsim.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_cross_layer_equalization.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_adaround.html#adaround-parameters">Adaround Parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_auto_quant.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_quant_analyzer.html"> QuantAnalyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_quant_analyzer.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_quant_analyzer.html#run-specific-utility">Run specific utility</a></li>
<li class="toctree-l5"><a class="reference internal" href="../api_docs/onnx_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/onnx_layer_output_generation.html">ONNX Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/onnx_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/examples.html"> Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html"> Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#quick-install">Quick Install</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#release-packages">Release Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#advanced-installation-instructions">Advanced Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages">Install GPU packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-pytorch-2-1-or-pytorch-1-13-or-onnx-or-tensorflow">Install GPU packages for PyTorch 2.1 or PyTorch 1.13 or ONNX or TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_docker.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_docker.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../user_guide/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../user_guide/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">GPTVQ</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/torch_docs/gptvq.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="admonition warning" id="api-torch-gptvq">
<p class="admonition-title">Warning</p>
<p>This feature is under heavy development and API changes may occur without notice in future versions.</p>
</div>
<section id="gptvq">
<h1>GPTVQ<a class="headerlink" href="#gptvq" title="Permalink to this heading"></a></h1>
<section id="top-level-api">
<h2>Top Level API<a class="headerlink" href="#top-level-api" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq">
<span class="sig-prename descclassname"><span class="pre">aimet_torch.gptvq.gptvq_weight.GPTVQ.</span></span><span class="sig-name descname"><span class="pre">apply_gptvq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gptvq_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_encoding_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_names_to_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_level_module_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gptvq'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq" title="Permalink to this definition"></a></dt>
<dd><p>Returns model with optimized weight rounding of GPTVQ supportable modules
and saves the corresponding parameter quantization encodings to a separate JSON file
that can be imported by QuantizationSimModel for inference or QAT</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – PyTorch model to GPTVQ</p></li>
<li><p><strong>dummy_input</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Dummy input to the model. Used to parse model graph. If the model has more than one input,
pass a tuple. User is expected to place the tensors on the appropriate device</p></li>
<li><p><strong>gptvq_params</strong> (<a class="reference internal" href="#aimet_torch.gptvq.defs.GPTVQParameters" title="aimet_torch.gptvq.defs.GPTVQParameters"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPTVQParameters</span></code></a>) – Dataclass holding GPTVQ parameters</p></li>
<li><p><strong>param_encoding_path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path where to store parameter encodings</p></li>
<li><p><strong>module_names_to_exclude</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]) – Module names which are excluded during GPTVQ optimization</p></li>
<li><p><strong>block_level_module_names</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]]) – List of module name lists to optimize block level GPTVQ optimization instead of leaf module level</p></li>
<li><p><strong>file_name_prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Prefix to use for filename of the encodings file</p></li>
<li><p><strong>config_file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Configuration file path for model quantizers</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>QuantizationSimModel with GPTVQ applied weights and saves corresponding parameter encodings JSON file at provided path</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="gptvq-parameters">
<h2>GPTVQ Parameters<a class="headerlink" href="#gptvq-parameters" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.gptvq.defs.GPTVQParameters">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.gptvq.defs.</span></span><span class="sig-name descname"><span class="pre">GPTVQParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rows_per_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols_per_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vector_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vector_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vector_stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_of_kmeans_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assignment_chunk_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/gptvq/defs.html#GPTVQParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.gptvq.defs.GPTVQParameters" title="Permalink to this definition"></a></dt>
<dd><p>Data carrier containing GPTVQ parameters</p>
</dd></dl>

<p>Users should set dataloader and forward_fn that are used to layer-wise optimization in GPTVQParameters.
All other parameters are optional and will be used as default values unless explicitly set</p>
</section>
<section id="code-example">
<h2>Code Example<a class="headerlink" href="#code-example" title="Permalink to this heading"></a></h2>
<p>This example shows how to use AIMET to perform GPTVQ</p>
<p><strong>Load the model</strong></p>
<p>For this example, we are going to load a pretrained OPT-125m model from transformers package. Similarly, you can load any
pretrained PyTorch model instead.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">OPTForCausalLM</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">OPTForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/opt-125m&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Apply GPTVQ</strong></p>
<p>We can now apply GPTVQ to this model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch.gptvq.defs</span> <span class="kn">import</span> <span class="n">GPTVQParameters</span>
<span class="kn">from</span> <span class="nn">aimet_torch.gptvq.gptvq_weight</span> <span class="kn">import</span> <span class="n">GPTVQ</span>

<span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">GPTVQParameters</span><span class="p">(</span>
    <span class="n">dataloader</span><span class="p">,</span>
    <span class="n">forward_fn</span><span class="o">=</span><span class="n">forward_fn</span><span class="p">,</span>
    <span class="n">num_of_kmeans_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">gptvq_applied_model</span> <span class="o">=</span> <span class="n">GPTVQ</span><span class="o">.</span><span class="n">apply_gptvq</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
    <span class="n">gptvq_params</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">param_encoding_path</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span>
    <span class="n">module_names_to_exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lm_head&quot;</span><span class="p">],</span>
    <span class="n">file_name_prefix</span><span class="o">=</span><span class="s2">&quot;gptvq_opt&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Note that we set encoding path as <strong>./data</strong> and file_name_prefix as <strong>gptvq_opt</strong> that will be used later when setting QuantizationSimModel</p>
<p><strong>Create the Quantization Simulation Model from GPTVQ applied model</strong></p>
<p>After GPTVQ optimization, we can get gptvq_applied_model object and corresponding encoding files from above step.
To instantiate QuantizationSimModel with this information, users need to instantiate and load gptvq applied model and its encodings like below</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantScheme</span>
<span class="kn">from</span> <span class="nn">aimet_torch.v2.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span>

<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span>
    <span class="n">gptvq_applied_model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">,</span>
    <span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf</span><span class="p">,</span>
    <span class="n">default_param_bw</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">vector_bw</span><span class="p">,</span>
    <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">load_encodings</span><span class="p">(</span><span class="s2">&quot;./data/gptvq_opt.encodings&quot;</span><span class="p">,</span> <span class="n">allow_overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Compute the Quantization Encodings</strong></p>
<p>To compute quantization encodings of activations and parameters which were not optimized by GPTVQ,
we can pass calibration data through the model and then subsequently compute the quantization encodings. Encodings here refer to scale/offset quantization parameters.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Export the model</strong></p>
<p>GPTVQ requires additional information such as vector dimension, index bitwidth compared to general affine quantization.
As a result, a new method of exporting encodings to json has been developed to both reduce the exported
encodings file size as well as reduce the time needed to write exported encodings to the json file.</p>
<p>The following code snippet shows how to export encodings in the new 1.0.0 format:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_common</span> <span class="kn">import</span> <span class="n">quantsim</span>

<span class="c1"># Assume &#39;sim&#39; is a QuantizationSimModel object imported from aimet_torch.v2.quantsim</span>

<span class="c1"># Set encoding_version to 1.0.0</span>
<span class="n">quantsim</span><span class="o">.</span><span class="n">encoding_version</span> <span class="o">=</span> <span class="s1">&#39;1.0.0&#39;</span>
<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="s1">&#39;exported_model&#39;</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">)</span>
</pre></div>
</div>
<p>The 1.0.0 encodings format is supported by Qualcomm runtime and can be used to export Per-Tensor, Per-Channel, Blockwise,
LPBQ and Vector quantizer encodings. If Vector quantizers are present in the model, the 1.0.0 format must be
used when exporting encodings for Qualcomm runtime.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>