<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AIMET PyTorch Mixed Precision API &mdash; AI Model Efficiency Toolkit Documentation: ver 1.34.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../user_guide/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.34.0
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/model_quantization.html"> Quantization User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#aimet-quantization-features">AIMET Quantization Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_sim.html"> Quantization Simulation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantsim-workflow">QuantSim Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#simulating-quantization-noise">Simulating Quantization Noise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#determining-quantization-parameters-encodings">Determining Quantization Parameters (Encodings)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantization-schemes">Quantization Schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#configuring-quantization-simulation-ops">Configuring Quantization Simulation Ops</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#quantization-simulation-apis">Quantization Simulation APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_sim.html#frequently-asked-questions">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_aware_training.html"> Quantization-Aware Training (QAT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#qat-workflow">QAT workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#qat-modes">QAT modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantization_aware_training.html#recommendations-for-quantization-aware-training">Recommendations for Quantization-Aware Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#post-training-quantization"><span class="hideitem">Post-Training Quantization</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/auto_quant.html">AutoQuant</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#workflow">Workflow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/auto_quant.html#autoquant-api">AutoQuant API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/adaround.html">Adaptive Rounding (AdaRound)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#adaround-use-cases">AdaRound Use Cases</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#common-terminology">Common terminology</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#use-cases">Use Cases</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/adaround.html#adaround-api">AdaRound API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html">Cross-Layer Equalization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#cross-layer-equalization-api">Cross-Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/bn_reestimation.html">BN Re-estimation</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#workflow">Workflow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/bn_reestimation.html#bn-re-estimation-api">BN Re-estimation API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html">Bias Correction [Depricated]</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#user-flow">User Flow</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#cross-layer-equalization-api">Cross-Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#faqs">FAQs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/post_training_quant_techniques.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#debugging-analysis-tools"><span class="hideitem">Debugging/Analysis Tools</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quant_analyzer.html">QuantAnalyzer</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#requirements">Requirements</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#detailed-analysis-descriptions">Detailed Analysis Descriptions</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/quant_analyzer.html#quantanalyzer-api">QuantAnalyzer API</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_quant.html">Visualizations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/visualization_quant.html#overview">Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/visualization_quant.html#quantization">Quantization</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/visualization_quant.html#pytorch">PyTorch</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/visualization_quant.html#tensorflow">TensorFlow</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#aimet-quantization-workflow">AIMET Quantization Workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_quantization.html#pytorch"><span class="hideitem">PyTorch</span></a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_model_guidelines.html"> PyTorch Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_quantization.html"> AIMET PyTorch Quantization APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_quantization.html#aimet-torch">aimet_torch</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quantization.html#api-reference">API Reference</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_model_preparer.html#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_model_preparer.html#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html"> PEFT LoRA APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_fp_lora_layer()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.quantize_lora_scale_with_fixed_range()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantization.html#aimet-torch-v2">aimet_torch.v2</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_quantization.html#what-s-new">Whatâ€™s New</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantization.html#backwards-compatibility">Backwards Compatibility</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantization.html#id1">API Reference</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantized_modules.html">Quantized Modules</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantized_modules.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantized_modules.html#configuration">Configuration</a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantized_modules.html#computing-encodings">Computing Encodings</a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantized_modules.html#quantized-module-classes">Quantized Module Classes</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantizer.html">Quantizers</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantizer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"><code class="docutils literal notranslate"><span class="pre">QuantizerBase</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.allow_overwrite()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.compute_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_encoding()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_legacy_encodings()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.is_initialized()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.register_quantization_parameter()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.set_legacy_encodings()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a><ul>
<li class="toctree-l10"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"><code class="docutils literal notranslate"><span class="pre">Quantize.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/encoding_analyzer.html">Encoding Analyzers</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">EncodingAnalyzer</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#variants">Variants</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">MinMaxEncodingAnalyzer</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">SqnrEncodingAnalyzer</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">PercentileEncodingAnalyzer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html">FakeQuantizationMixin</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html">QuantizationMixin</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_default_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_default_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_kernel()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html">quantization.affine</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#classes">Classes</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#functions">Functions</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize"><code class="docutils literal notranslate"><span class="pre">quantize()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize_dequantize"><code class="docutils literal notranslate"><span class="pre">quantize_dequantize()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.dequantize"><code class="docutils literal notranslate"><span class="pre">dequantize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html">quantization.float</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html#classes">Classes</a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html#aimet_torch.v2.quantization.float.FloatQuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">FloatQuantizeDequantize</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html#aimet_torch.v2.quantization.float.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/visualization_tools.html">Visualization Tools</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/visualization_tools.html#aimet_torch.v2.visualization_tools.visualize_stats"><code class="docutils literal notranslate"><span class="pre">visualize_stats()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_quantization.html#debugging-guidelines">Debugging Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantization_feature_guidebook.html">Quantization Guidebook</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/model_compression.html"> Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/compression_feature_guidebook.html">Compression Guidebook</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html">Greedy Compression Ratio Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#how-it-works">How it works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#per-layer-exploration">Per-layer Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/greedy_compression_ratio_selection.html#compression-ratio-selection">Compression Ratio Selection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#winnowing">Winnowing</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../user_guide/winnowing.html">Winnowing</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#overview">Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#winnowing-overview">Winnowing Overview</a></li>
<li class="toctree-l6"><a class="reference internal" href="../user_guide/winnowing.html#how-winnowing-works">How Winnowing Works</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html"> API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.html">AIMET APIs for PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch_quantization.html">PyTorch Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_quantization.html#aimet-torch">aimet_torch</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_quantization.html#api-reference">API Reference</a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_architecture_checker.html"> Architecture Checker API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_architecture_checker.html#aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"><code class="docutils literal notranslate"><span class="pre">check_model_arch()</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_model_preparer.html#aimet_torch.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_model_preparer.html#limitations-of-torch-fx-symbolic-trace-api">Limitations of torch.fx symbolic trace API</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_model_validator.html"> Model Validator API</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#run-specific-utility">Run specific utility</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quant_analyzer.html#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#guidelines">Guidelines</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel.export"><code class="docutils literal notranslate"><span class="pre">QuantizationSimModel.export()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.save_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.save_checkpoint()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.load_checkpoint"><code class="docutils literal notranslate"><span class="pre">quantsim.load_checkpoint()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_quantsim.html#code-example-quantization-aware-training-qat">Code Example - Quantization Aware Training (QAT)</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"><code class="docutils literal notranslate"><span class="pre">apply_adaround()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#adaround-parameters">Adaround Parameters</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_cross_layer_equalization.html#aimet_torch.cross_layer_equalization.equalize_model"><code class="docutils literal notranslate"><span class="pre">equalize_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#clssetinfo-definition">ClsSetInfo Definition</a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.ClsSetInfo"><code class="docutils literal notranslate"><span class="pre">ClsSetInfo</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_all_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"><code class="docutils literal notranslate"><span class="pre">scale_model()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.batch_norm_fold.fold_given_batch_norms"><code class="docutils literal notranslate"><span class="pre">fold_given_batch_norms()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"><code class="docutils literal notranslate"><span class="pre">scale_cls_sets()</span></code></a></li>
<li class="toctree-l10"><a class="reference internal" href="torch_primitive_apis_cle.html#id0"><code class="docutils literal notranslate"><span class="pre">bias_fold()</span></code></a></li>
</ul>
</li>
<li class="toctree-l9"><a class="reference internal" href="torch_primitive_apis_cle.html#code-examples-for-lower-level-apis">Code Examples for Lower Level APIs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_bias_correction.html"> Bias Correction API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#bias-correction-api">Bias Correction API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.bias_correction.correct_bias"><code class="docutils literal notranslate"><span class="pre">correct_bias()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#convbninfotype">ConvBnInfoType</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_common.bias_correction.ConvBnInfoType"><code class="docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#activationtype">ActivationType</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType"><code class="docutils literal notranslate"><span class="pre">ActivationType</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.no_activation"><code class="docutils literal notranslate"><span class="pre">ActivationType.no_activation</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_bias_correction.html#aimet_common.defs.ActivationType.relu6"><code class="docutils literal notranslate"><span class="pre">ActivationType.relu6</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#quantization-params">Quantization Params</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_bias_correction.html#aimet_torch.quantsim.QuantParams"><code class="docutils literal notranslate"><span class="pre">QuantParams</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#code-example-1-empirical-bias-correction">Code Example #1 Empirical Bias Correction</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_bias_correction.html#code-example-2-analytical-empirical-bias-correction">Code Example #2 Analytical + Empirical Bias correction</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_auto_quant.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_auto_quant.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_auto_quant.html#aimet_torch.auto_quant.AutoQuant"><code class="docutils literal notranslate"><span class="pre">AutoQuant</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_batchnorm_re_estimation.html#aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"><code class="docutils literal notranslate"><span class="pre">fold_all_batch_norms_to_scale()</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="torch_batchnorm_re_estimation.html#code-example-bn-reestimation">Code Example - BN-Reestimation</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="torch_multi_gpu.html"> Multi-GPU guidelines</a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_peft_lora.html"> PEFT LoRA APIs</a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#user-flow">User flow</a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_peft_lora.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.AdapterMetaData"><code class="docutils literal notranslate"><span class="pre">AdapterMetaData</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.replace_lora_layers_with_quantizable_layers"><code class="docutils literal notranslate"><span class="pre">peft.replace_lora_layers_with_quantizable_layers()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.track_lora_meta_data"><code class="docutils literal notranslate"><span class="pre">peft.track_lora_meta_data()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.disable_lora_adapters()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.enable_adapter_and_load_weights()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.export_adapter_weights"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.export_adapter_weights()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_activation_quantizers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.freeze_base_model_param_quantizers()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_fp_lora_layer()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.get_quantized_lora_layer()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.quantize_lora_scale_with_fixed_range()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="torch_peft_lora.html#aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"><code class="docutils literal notranslate"><span class="pre">PeftQuantUtils.set_bitwidth_for_lora_adapters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_quantization.html#aimet-torch-v2">aimet_torch.v2</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_quantization.html#what-s-new">Whatâ€™s New</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantization.html#backwards-compatibility">Backwards Compatibility</a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_quantization.html#id1">API Reference</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/quantized_modules.html">Quantized Modules</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantized_modules.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantized_modules.html#aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">BaseQuantizationMixin.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantized_modules.html#configuration">Configuration</a></li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantized_modules.html#computing-encodings">Computing Encodings</a></li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantized_modules.html#quantized-module-classes">Quantized Module Classes</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/quantizer.html">Quantizers</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/quantizer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"><code class="docutils literal notranslate"><span class="pre">QuantizerBase</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.allow_overwrite()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.compute_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_encoding()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.get_legacy_encodings()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.is_initialized()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.register_quantization_parameter()</span></code></a></li>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizerBase.set_legacy_encodings()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a><ul>
<li class="toctree-l9"><a class="reference internal" href="../torch_docs/quantizer.html#aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"><code class="docutils literal notranslate"><span class="pre">Quantize.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/encoding_analyzer.html">Encoding Analyzers</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">EncodingAnalyzer</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#variants">Variants</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">MinMaxEncodingAnalyzer</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">SqnrEncodingAnalyzer</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/encoding_analyzer.html#aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"><code class="docutils literal notranslate"><span class="pre">PercentileEncodingAnalyzer</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html">FakeQuantizationMixin</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.fake_quantization_mixin.html#aimet_torch.v2.nn.FakeQuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">FakeQuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html">QuantizationMixin</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin</span></code></a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.input_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.input_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.output_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.output_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.param_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.param_quantizers</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.forward"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.forward()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.__quant_init__"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.__quant_init__()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.set_default_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.compute_encodings"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.compute_encodings()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.from_module"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.from_module()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_default_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.get_kernel"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.get_kernel()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html#aimet_torch.v2.nn.QuantizationMixin.implements"><code class="docutils literal notranslate"><span class="pre">QuantizationMixin.implements()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html">quantization.affine</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#classes">Classes</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.Quantize"><code class="docutils literal notranslate"><span class="pre">Quantize</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#functions">Functions</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize"><code class="docutils literal notranslate"><span class="pre">quantize()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.quantize_dequantize"><code class="docutils literal notranslate"><span class="pre">quantize_dequantize()</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html#aimet_torch.v2.quantization.affine.dequantize"><code class="docutils literal notranslate"><span class="pre">dequantize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html">quantization.float</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html#classes">Classes</a><ul>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html#aimet_torch.v2.quantization.float.FloatQuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">FloatQuantizeDequantize</span></code></a></li>
<li class="toctree-l8"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html#aimet_torch.v2.quantization.float.QuantizeDequantize"><code class="docutils literal notranslate"><span class="pre">QuantizeDequantize</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="../torch_docs/api/visualization_tools.html">Visualization Tools</a><ul>
<li class="toctree-l7"><a class="reference internal" href="../torch_docs/api/visualization_tools.html#aimet_torch.v2.visualization_tools.visualize_stats"><code class="docutils literal notranslate"><span class="pre">visualize_stats()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.compress.ModelCompressor"><code class="docutils literal notranslate"><span class="pre">ModelCompressor</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.compress.ModelCompressor.compress_model"><code class="docutils literal notranslate"><span class="pre">ModelCompressor.compress_model()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_common.defs.GreedySelectionParameters"><code class="docutils literal notranslate"><span class="pre">GreedySelectionParameters</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.WeightSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">WeightSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ChannelPruningParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">ChannelPruningParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_compress.html#aimet_torch.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_eval_scores()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_visualization_compression.html#aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"><code class="docutils literal notranslate"><span class="pre">VisualizeCompression.display_comp_ratio_plot()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"><code class="docutils literal notranslate"><span class="pre">visualize_relative_weight_ranges_to_identify_problematic_layers()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_weight_ranges"><code class="docutils literal notranslate"><span class="pre">visualize_weight_ranges()</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="torch_visualization_quantization.html#aimet_torch.visualize_model.visualize_changes_after_optimization"><code class="docutils literal notranslate"><span class="pre">visualize_changes_after_optimization()</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torch_layer_output_generation.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"><code class="docutils literal notranslate"><span class="pre">LayerOutputUtil.generate_layer_outputs()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_layer_output_generation.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l5"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme"><code class="docutils literal notranslate"><span class="pre">NamingScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.ONNX"><code class="docutils literal notranslate"><span class="pre">NamingScheme.ONNX</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.PYTORCH"><code class="docutils literal notranslate"><span class="pre">NamingScheme.PYTORCH</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="torch_layer_output_generation.html#aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"><code class="docutils literal notranslate"><span class="pre">NamingScheme.TORCHSCRIPT</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="keras.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="keras_quantization.html">TensorFlow Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="keras_model_guidelines.html"> Model Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_model_preparer.html"> Model Preparer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_model_preparer.html#top-level-api">Top-level API</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_model_preparer.html#aimet_tensorflow.keras.model_preparer.prepare_model"><code class="docutils literal notranslate"><span class="pre">prepare_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_model_preparer.html#code-examples">Code Examples</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_model_preparer.html#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_quant_analyzer.html"> Quant Analyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_quant_analyzer.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_quantsim.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_quantsim.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#adaround-parameters">Adaround Parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#enum-definition">Enum Definition</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme"><code class="docutils literal notranslate"><span class="pre">QuantScheme</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.post_training_percentile"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_percentile</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.post_training_tf_enhanced"><code class="docutils literal notranslate"><span class="pre">QuantScheme.post_training_tf_enhanced</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_enhanced_init</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_adaround.html#aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"><code class="docutils literal notranslate"><span class="pre">QuantScheme.training_range_learning_with_tf_init</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_adaround.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_cross_layer_equalization.html#primitive-apis">Primitive APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_primitive_apis_cle.html">Primitive APIs for Cross Layer Equalization</a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#introduction">Introduction</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#higher-level-apis-for-cross-layer-equalization">Higher Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#code-examples-for-higher-level-apis">Code Examples for Higher Level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#lower-level-apis-for-cross-layer-equalization">Lower Level APIs for Cross Layer Equalization</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#custom-datatype-used">Custom Datatype used</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#code-example-for-lower-level-apis">Code Example for Lower level APIs</a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_primitive_apis_cle.html#example-helper-methods-to-perform-cle-in-manual-mode">Example helper methods to perform CLE in manual mode</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_batchnorm_re_estimation.html"> BN Re-estimation APIs</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#examples-notebook-link">Examples Notebook Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#top-level-apis">Top-level APIs</a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_batchnorm_re_estimation.html#aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"><code class="docutils literal notranslate"><span class="pre">reestimate_bn_stats()</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#code-example">Code Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="keras_batchnorm_re_estimation.html#limitations">Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="keras_layer_output_generation.html">TensorFlow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="keras_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="keras_compression.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#spatial-svd-configuration">Spatial SVD Configuration</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.AutoModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.AutoModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.ManualModeParams"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.ManualModeParams</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode</span></code></a><ul>
<li class="toctree-l7"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode.auto"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.auto</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode.manual"><code class="docutils literal notranslate"><span class="pre">SpatialSvdParameters.Mode.manual</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#configuration-definitions">Configuration Definitions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CostMetric"><code class="docutils literal notranslate"><span class="pre">CostMetric</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CostMetric.mac"><code class="docutils literal notranslate"><span class="pre">CostMetric.mac</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CostMetric.memory"><code class="docutils literal notranslate"><span class="pre">CostMetric.memory</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme"><code class="docutils literal notranslate"><span class="pre">CompressionScheme</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme.channel_pruning"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.channel_pruning</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme.spatial_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.spatial_svd</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="keras_compression.html#aimet_common.defs.CompressionScheme.weight_svd"><code class="docutils literal notranslate"><span class="pre">CompressionScheme.weight_svd</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="keras_compression.html#aimet_tensorflow.keras.defs.ModuleCompRatioPair"><code class="docutils literal notranslate"><span class="pre">ModuleCompRatioPair</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="keras_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="onnx_quantization.html">ONNX Model Quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx_quantsim.html"> Quantization Simulation API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_quantsim.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_quantsim.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_cross_layer_equalization.html"> Cross-Layer Equalization API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#introduction">Introduction</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#cross-layer-equalization-api">Cross Layer Equalization API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_cross_layer_equalization.html#code-example">Code Example</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_adaround.html"> Adaptive Rounding API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#adaround-parameters">Adaround Parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_adaround.html#code-example-adaptive-rounding-adaround">Code Example - Adaptive Rounding (AdaRound)</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_auto_quant.html"> AutoQuant API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_auto_quant.html#user-guide-link">User Guide Link</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_auto_quant.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_auto_quant.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="onnx_quant_analyzer.html"> QuantAnalyzer API</a><ul>
<li class="toctree-l5"><a class="reference internal" href="onnx_quant_analyzer.html#top-level-api">Top-level API</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_quant_analyzer.html#run-specific-utility">Run specific utility</a></li>
<li class="toctree-l5"><a class="reference internal" href="onnx_quant_analyzer.html#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="onnx_layer_output_generation.html">ONNX Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="onnx_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="onnx_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/examples.html"> Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html"> Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#quick-install">Quick Install</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#release-packages">Release Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#advanced-installation-instructions">Advanced Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages">Install GPU packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-pytorch-2-1-or-pytorch-1-13-or-onnx-or-tensorflow">Install GPU packages for PyTorch 2.1 or PyTorch 1.13 or ONNX or TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_host.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#install-aimet-packages">Install AIMET packages</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../install/install_docker.html#from-pypi">From PyPI</a></li>
<li class="toctree-l5"><a class="reference internal" href="../install/install_docker.html#from-release-package">From Release Package</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../user_guide/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../user_guide/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">AIMET PyTorch Mixed Precision API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api_docs/torch_mixed_precision.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="aimet-pytorch-mixed-precision-api">
<span id="api-torch-mixed-precision"></span><h1>AIMET PyTorch Mixed Precision API<a class="headerlink" href="#aimet-pytorch-mixed-precision-api" title="Permalink to this heading">ïƒ</a></h1>
<section id="top-level-api">
<h2>Top-level API<a class="headerlink" href="#top-level-api" title="Permalink to this heading">ïƒ</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_torch.mixed_precision.choose_mixed_precision">
<span class="sig-prename descclassname"><span class="pre">aimet_torch.mixed_precision.</span></span><span class="sig-name descname"><span class="pre">choose_mixed_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_accuracy_drop</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_all_amp_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase2_reverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase1_optimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_search_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AMPSearchAlgo.Binary</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/mixed_precision.html#choose_mixed_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.mixed_precision.choose_mixed_precision" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>High-level API to perform in place Mixed Precision evaluation on the given sim model. A pareto list is created and
a curve for Accuracy vs BitOps is saved under the results directory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<a class="reference internal" href="torch_quantsim.html#aimet_torch.quantsim.QuantizationSimModel" title="aimet_torch.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a>) â€“ Quantized sim model</p></li>
<li><p><strong>dummy_input</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) â€“ Dummy input to the model. If the model has more than one input, pass a tuple.
User is expected to place the tensors on the appropriate device.</p></li>
<li><p><strong>candidates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]]) â€“ <p>List of tuples for all possible bitwidth values for activations and parameters
Suppose the possible combinations are-
((Activation bitwidth - 8, Activation data type - int), (Parameter bitwidth - 16, parameter data type - int))
((Activation bitwidth - 16, Activation data type - float), (Parameter bitwidth - 16, parameter data type - float))
candidates will be [((8, QuantizationDataType.int), (16, QuantizationDataType.int)),</p>
<blockquote>
<div><p>((16, QuantizationDataType.float), (16, QuantizationDataType.float))]</p>
</div></blockquote>
</p></li>
<li><p><strong>eval_callback_for_phase1</strong> (<a class="reference internal" href="#aimet_common.defs.CallbackFunc" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a>) â€“ An object of CallbackFunc class which takes in Eval function (callable) and eval
function parameters. This evaluation callback used to measure sensitivity of each
quantizer group during phase 1. The phase 1 involves finding accuracy list/sensitivity of each
module. Therefore, a user might want to run the phase 1 with a smaller dataset</p></li>
<li><p><strong>eval_callback_for_phase2</strong> (<a class="reference internal" href="#aimet_common.defs.CallbackFunc" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a>) â€“ An object of CallbackFunc class which takes in Eval function (callable) and eval
function parameters. Evaluation callback used to get accuracy of quantized model
for phase 2 calculations. The phase 2 involves finding pareto front curve</p></li>
<li><p><strong>allowed_accuracy_drop</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]) â€“ Maximum allowed drop in accuracy from FP32 baseline. The pareto front curve is plotted only till the point where the allowable
accuracy drop is met. To get a complete plot for picking points on the curve, the user
can set the allowable accuracy drop to None.</p></li>
<li><p><strong>results_dir</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) â€“ Path to save results and cache intermediate results</p></li>
<li><p><strong>clean_start</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) â€“ If true, any cached information from previous runs will be deleted prior to starting the
mixed-precision analysis. If false, prior cached information will be used if applicable. Note
it is the userâ€™s responsibility to set this flag to true if anything in the model or
quantization parameters changes compared to the previous run.</p></li>
<li><p><strong>forward_pass_callback</strong> (<a class="reference internal" href="#aimet_common.defs.CallbackFunc" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a>) â€“ An object of CallbackFunc class which takes in Forward pass function (callable) and its
function parameters. Forward pass callback used to compute quantization encodings</p></li>
<li><p><strong>use_all_amp_candidates</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) â€“ Using the â€œsupported_kernelsâ€ field in the config file (under defaults
and op_type sections), a list of supported candidates can be specified. All the AMP candidates
which are passed through the â€œcandidatesâ€ field may not be supported based on the data passed
through â€œsupported_kernelsâ€. When the field â€œuse_all_amp_candidatesâ€ is set to True, the AMP
algorithm will ignore the â€œsupported_kernelsâ€ in the config file and continue to use all candidates.</p></li>
<li><p><strong>phase2_reverse</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) â€“ If user will set this parameter to True, then phase1 of amp algo, that is calculating accuracy list
will not be changed, whereas the phase2 algo of amp, which generate the pareto list will be changed. In phase2, algo will start,
model with all quantizer groups in least candidate, and one by one, it will put nodes in higher candidate till target accuracy does not meet.</p></li>
<li><p><strong>phase1_optimize</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) â€“ If user set this parameter to false then phase1 default logic will be executed else optimized logic will be executed.</p></li>
<li><p><strong>amp_search_algo</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">AMPSearchAlgo</span></code>) â€“ A valid value from the Enum AMPSearchAlgo. Defines the search algorithm to be used for
the phase 2 of AMP.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup" title="aimet_torch.amp.quantizer_groups.QuantizerGroup"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Pareto front list containing information including Bitops, QuantizerGroup candidates and
corresponding eval scores. The Pareto front list can be used for plotting a pareto front curve which
provides information regarding how bit ops vary w.r.t. accuracy. If the allowable accuracy drop is set to
100% then a user can use the pareto front curve to pick points and re-run,
None if we early exit the mixed precision algorithm.</p>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Note:</strong> To enable phase-3 set the attribute GreedyMixedPrecisionAlgo.ENABLE_CONVERT_OP_REDUCTION = True</p>
<p>Currently only two candidates are supported - ((8,int), (8,int)) &amp; ((16,int), (8,int))</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
<section id="quantizer-groups-definition">
<h2>Quantizer Groups definition<a class="headerlink" href="#quantizer-groups-definition" title="Permalink to this heading">ïƒ</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.amp.quantizer_groups.</span></span><span class="sig-name descname"><span class="pre">QuantizerGroup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_quantizers=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/quantizer_groups.html#QuantizerGroup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Group of modules and quantizers</p>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.get_active_quantizers">
<span class="sig-name descname"><span class="pre">get_active_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/quantizer_groups.html#QuantizerGroup.get_active_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_active_quantizers" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Find all active tensor quantizers associated with this quantizer group</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.get_candidate">
<span class="sig-name descname"><span class="pre">get_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/quantizer_groups.html#QuantizerGroup.get_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_candidate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Gets Activation &amp; parameter bitwidth
:type name_to_quantizer_dict: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
:param name_to_quantizer_dict: Gets module from module name
:rtype: <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]
:return: Tuple of Activation, parameter bitwidth and data type</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.get_input_quantizer_modules">
<span class="sig-name descname"><span class="pre">get_input_quantizer_modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/quantizer_groups.html#QuantizerGroup.get_input_quantizer_modules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_input_quantizer_modules" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>helper method to get the module names corresponding to input_quantizers</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate">
<span class="sig-name descname"><span class="pre">set_quantizers_to_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/quantizer_groups.html#QuantizerGroup.set_quantizers_to_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Sets a quantizer group to a given candidate bitwidth
:type name_to_quantizer_dict: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
:param name_to_quantizer_dict: Gets module from module name
:type candidate: <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]
:param candidate: candidate with act and param bw and data types</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.to_list">
<span class="sig-name descname"><span class="pre">to_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/quantizer_groups.html#QuantizerGroup.to_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.to_list" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Converts quantizer group to a list
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]
:return: List containing input/output quantizers &amp; weight quantizers</p>
</dd></dl>

</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
<section id="callbackfunc-definition">
<h2>CallbackFunc Definition<a class="headerlink" href="#callbackfunc-definition" title="Permalink to this heading">ïƒ</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_common.defs.CallbackFunc">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_common.defs.</span></span><span class="sig-name descname"><span class="pre">CallbackFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func_callback_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_common/defs.html#CallbackFunc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_common.defs.CallbackFunc" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Class encapsulating call back function and itâ€™s arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>) â€“ Callable Function</p></li>
<li><p><strong>func_callback_args</strong> â€“ Arguments passed to the callable function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.amp.mixed_precision_algo.</span></span><span class="sig-name descname"><span class="pre">EvalCallbackFactory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/mixed_precision_algo.html#EvalCallbackFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Factory class for various built-in eval callbacks</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>) â€“ Data loader to be used for evaluation</p></li>
<li><p><strong>forward_fn</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]) â€“ Function that runs forward pass and returns the output tensor.
This function is expected to take 1) a model and 2) a single batch
yielded from the data loader, and return a single torch.Tensor object
which represents the output of the model.
The default forward function is roughly equivalent to
<code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">model,</span> <span class="pre">batch:</span> <span class="pre">model(batch)</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory.sqnr">
<span class="sig-name descname"><span class="pre">sqnr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/amp/mixed_precision_algo.html#EvalCallbackFactory.sqnr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory.sqnr" title="Permalink to this definition">ïƒ</a></dt>
<dd><p>Returns SQNR eval callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) â€“ Number of samples used for evaluation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#aimet_common.defs.CallbackFunc" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A callback function that evaluates the input modelâ€™s SQNR
between fp32 outputs and fake-quantized outputs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
<section id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this heading">ïƒ</a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantizationDataType</span><span class="p">,</span> <span class="n">CallbackFunc</span>
<span class="kn">from</span> <span class="nn">aimet_torch.mixed_precision</span> <span class="kn">import</span> <span class="n">choose_mixed_precision</span>
<span class="kn">from</span> <span class="nn">aimet_torch.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span>
<span class="kn">from</span> <span class="nn">aimet_torch.amp.mixed_precision_algo</span> <span class="kn">import</span> <span class="n">GreedyMixedPrecisionAlgo</span>
</pre></div>
</div>
<p><strong>Quantization with mixed precision</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quantize_with_mixed_precision</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Code example showing the call flow for Auto Mixed Precision</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Define parameters to pass to mixed precision algo</span>
    <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">default_bitwidth</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="c1"># ((activation bitwidth, activation data type), (param bitwidth, param data type))</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
                 <span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
                 <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">))]</span>
    <span class="c1"># Allowed accuracy drop in absolute value</span>
    <span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># Implies 50% drop</span>

    <span class="n">eval_callback_for_phase_1</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_callback_func</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
    <span class="n">eval_callback_for_phase_2</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_callback_func</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">forward_pass_call_back</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">)</span>

    <span class="c1"># Create quant sim</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span> <span class="n">default_output_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span>
                               <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Enable phase-3 (optional)</span>
    <span class="c1"># GreedyMixedPrecisionAlgo.ENABLE_CONVERT_OP_REDUCTION = True</span>
    <span class="c1"># Note: supported candidates ((8,int), (8,int)) &amp; ((16,int), (8,int))</span>

    <span class="c1"># Call the mixed precision algo with clean start = True i.e. new accuracy list and pareto list will be generated</span>
    <span class="c1"># If set to False then pareto front list and accuracy list will be loaded from the provided directory path</span>
    <span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                               <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                               <span class="n">clean_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_call_back</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="p">),</span> <span class="n">dummy_input</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Quantization with mixed precision start from existing cache</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quantize_with_mixed_precision_start_from_existing_cache</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Code example shows how to start from an existing cache when using the API of Auto Mixed Precision</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Define parameters to pass to mixed precision algo</span>
    <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">default_bitwidth</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="c1"># ((activation bitwidth, activation data type), (param bitwidth, param data type))</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
                 <span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
                 <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">))]</span>
    <span class="c1"># Allowed accuracy drop in absolute value</span>
    <span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># Implies 50% drop</span>

    <span class="n">eval_callback_for_phase_1</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_callback_func</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
    <span class="n">eval_callback_for_phase_2</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_callback_func</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">forward_pass_call_back</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">)</span>

    <span class="c1"># Create quant sim</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span> <span class="n">default_output_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span>
                               <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Enable phase-3 (optional)</span>
    <span class="n">GreedyMixedPrecisionAlgo</span><span class="o">.</span><span class="n">ENABLE_CONVERT_OP_REDUCTION</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Call the mixed precision algo with clean start = True i.e. new accuracy list and pareto list will be generated</span>
    <span class="c1"># If set to False then pareto front list and accuracy list will be loaded from the provided directory path</span>
    <span class="c1"># A allowed_accuracy_drop can be specified to export the final model with reference to the pareto list</span>
    <span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                               <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                               <span class="n">clean_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_call_back</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="p">),</span> <span class="n">dummy_input</span><span class="p">)</span>

    <span class="c1"># Set clean_start to False to start from an existing cache</span>
    <span class="c1"># Set allowed_accuracy_drop to 0.9 to export the 90% drop point in pareto list</span>
    <span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                               <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                               <span class="n">clean_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_call_back</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="p">),</span> <span class="n">dummy_input</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Eval function</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eval_callback_func</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Call eval function for model &quot;&quot;&quot;</span>
    <span class="c1"># Note: A user can populate this function as per their model. This is a toy example to show how the API</span>
    <span class="c1"># for the function can look like</span>
    <span class="n">model</span><span class="o">.</span><span class="n">perform_eval</span><span class="p">(</span><span class="n">number_of_samples</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Forward Pass</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward_pass_callback</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Call forward pass of model &quot;&quot;&quot;</span>
    <span class="c1"># Note: A user can populate this function as per their model. This is a toy example to show how the API</span>
    <span class="c1"># for the function can look like</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>