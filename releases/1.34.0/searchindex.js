Search.setIndex({"docnames": ["Examples/onnx/quantization/AMP", "Examples/onnx/quantization/adaround", "Examples/onnx/quantization/cle", "Examples/onnx/quantization/quantsim", "Examples/tensorflow/quantization/keras/KerasAMP", "Examples/tensorflow/quantization/keras/adaround", "Examples/tensorflow/quantization/keras/autoquant", "Examples/tensorflow/quantization/keras/bn_reestimation", "Examples/tensorflow/quantization/keras/keras_transformer_qat", "Examples/tensorflow/quantization/keras/model_preparer", "Examples/tensorflow/quantization/keras/qat", "Examples/tensorflow/quantization/keras/qat_range_learning", "Examples/tensorflow/quantization/keras/quant_analyzer", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq", "Examples/tensorflow/quantization/keras/quantsim_cle", "Examples/torch/compression/channel_pruning", "Examples/torch/compression/spatial_svd", "Examples/torch/compression/spatial_svd_channel_pruning", "Examples/torch/quantization/AMP", "Examples/torch/quantization/adaround", "Examples/torch/quantization/autoquant", "Examples/torch/quantization/bn_reestimation", "Examples/torch/quantization/cle_bc", "Examples/torch/quantization/qat", "Examples/torch/quantization/qat_range_learning", "Examples/torch/quantization/quant_analyzer", "api_docs/index", "api_docs/keras", "api_docs/keras_adaround", "api_docs/keras_batchnorm_re_estimation", "api_docs/keras_compression", "api_docs/keras_cross_layer_equalization", "api_docs/keras_layer_output_generation", "api_docs/keras_mixed_precision", "api_docs/keras_model_guidelines", "api_docs/keras_model_preparer", "api_docs/keras_primitive_apis_cle", "api_docs/keras_quant_analyzer", "api_docs/keras_quantization", "api_docs/keras_quantsim", "api_docs/onnx", "api_docs/onnx_adaround", "api_docs/onnx_auto_quant", "api_docs/onnx_cross_layer_equalization", "api_docs/onnx_layer_output_generation", "api_docs/onnx_mixed_precision", "api_docs/onnx_quant_analyzer", "api_docs/onnx_quantization", "api_docs/onnx_quantsim", "api_docs/quantization_encoding_specification", "api_docs/torch", "api_docs/torch_adaround", "api_docs/torch_architecture_checker", "api_docs/torch_auto_quant", "api_docs/torch_batchnorm_re_estimation", "api_docs/torch_bias_correction", "api_docs/torch_compress", "api_docs/torch_cross_layer_equalization", "api_docs/torch_layer_output_generation", "api_docs/torch_mixed_precision", "api_docs/torch_model_guidelines", "api_docs/torch_model_preparer", "api_docs/torch_model_validator", "api_docs/torch_multi_gpu", "api_docs/torch_peft_lora", "api_docs/torch_primitive_apis_cle", "api_docs/torch_quant_analyzer", "api_docs/torch_quantization", "api_docs/torch_quantsim", "api_docs/torch_spconv_custom_onnx_export", "api_docs/torch_visualization_compression", "api_docs/torch_visualization_quantization", "api_docs/v2_migrgation_guide", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.fake_quantization_mixin", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/quantization/affine/index", "torch_docs/api/quantization/float/FloatQuantizeDequantize", "torch_docs/api/quantization/float/index", "torch_docs/api/quantization/tensor", "torch_docs/api/visualization_tools", "torch_docs/blockwise_quantization", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/gptvq", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/quickstart_guide", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/examples", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["Examples/onnx/quantization/AMP.ipynb", "Examples/onnx/quantization/adaround.ipynb", "Examples/onnx/quantization/cle.ipynb", "Examples/onnx/quantization/quantsim.ipynb", "Examples/tensorflow/quantization/keras/KerasAMP.ipynb", "Examples/tensorflow/quantization/keras/adaround.ipynb", "Examples/tensorflow/quantization/keras/autoquant.ipynb", "Examples/tensorflow/quantization/keras/bn_reestimation.ipynb", "Examples/tensorflow/quantization/keras/keras_transformer_qat.ipynb", "Examples/tensorflow/quantization/keras/model_preparer.ipynb", "Examples/tensorflow/quantization/keras/qat.ipynb", "Examples/tensorflow/quantization/keras/qat_range_learning.ipynb", "Examples/tensorflow/quantization/keras/quant_analyzer.ipynb", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq.ipynb", "Examples/tensorflow/quantization/keras/quantsim_cle.ipynb", "Examples/torch/compression/channel_pruning.ipynb", "Examples/torch/compression/spatial_svd.ipynb", "Examples/torch/compression/spatial_svd_channel_pruning.ipynb", "Examples/torch/quantization/AMP.ipynb", "Examples/torch/quantization/adaround.ipynb", "Examples/torch/quantization/autoquant.ipynb", "Examples/torch/quantization/bn_reestimation.ipynb", "Examples/torch/quantization/cle_bc.ipynb", "Examples/torch/quantization/qat.ipynb", "Examples/torch/quantization/qat_range_learning.ipynb", "Examples/torch/quantization/quant_analyzer.ipynb", "api_docs/index.rst", "api_docs/keras.rst", "api_docs/keras_adaround.rst", "api_docs/keras_batchnorm_re_estimation.rst", "api_docs/keras_compression.rst", "api_docs/keras_cross_layer_equalization.rst", "api_docs/keras_layer_output_generation.rst", "api_docs/keras_mixed_precision.rst", "api_docs/keras_model_guidelines.rst", "api_docs/keras_model_preparer.rst", "api_docs/keras_primitive_apis_cle.rst", "api_docs/keras_quant_analyzer.rst", "api_docs/keras_quantization.rst", "api_docs/keras_quantsim.rst", "api_docs/onnx.rst", "api_docs/onnx_adaround.rst", "api_docs/onnx_auto_quant.rst", "api_docs/onnx_cross_layer_equalization.rst", "api_docs/onnx_layer_output_generation.rst", "api_docs/onnx_mixed_precision.rst", "api_docs/onnx_quant_analyzer.rst", "api_docs/onnx_quantization.rst", "api_docs/onnx_quantsim.rst", "api_docs/quantization_encoding_specification.rst", "api_docs/torch.rst", "api_docs/torch_adaround.rst", "api_docs/torch_architecture_checker.rst", "api_docs/torch_auto_quant.rst", "api_docs/torch_batchnorm_re_estimation.rst", "api_docs/torch_bias_correction.rst", "api_docs/torch_compress.rst", "api_docs/torch_cross_layer_equalization.rst", "api_docs/torch_layer_output_generation.rst", "api_docs/torch_mixed_precision.rst", "api_docs/torch_model_guidelines.rst", "api_docs/torch_model_preparer.rst", "api_docs/torch_model_validator.rst", "api_docs/torch_multi_gpu.rst", "api_docs/torch_peft_lora.rst", "api_docs/torch_primitive_apis_cle.rst", "api_docs/torch_quant_analyzer.rst", "api_docs/torch_quantization.rst", "api_docs/torch_quantsim.rst", "api_docs/torch_spconv_custom_onnx_export.rst", "api_docs/torch_visualization_compression.rst", "api_docs/torch_visualization_quantization.rst", "api_docs/v2_migrgation_guide.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.fake_quantization_mixin.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/quantization/affine/index.rst", "torch_docs/api/quantization/float/FloatQuantizeDequantize.rst", "torch_docs/api/quantization/float/index.rst", "torch_docs/api/quantization/tensor.rst", "torch_docs/api/visualization_tools.rst", "torch_docs/blockwise_quantization.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/gptvq.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/quickstart_guide.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/examples.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["Automatic Mixed-Precision (AMP)", "Adaptive Rounding (AdaRound)", "Cross-Layer Equalization (CLE)", "Quantization Simulation", "Automatic Mixed-Precision (AMP)", "Adaptive Rounding (Adaround)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Quantization-Aware Training with a Keras Transformer Model", "Keras Model Preparer", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Quantsim and Adaround - Per Channel Quantization (PCQ)", "Cross-Layer Equalization (CLE) with QuantSim", "Model compression using Channel Pruning", "Model compression using Spatial SVD", "Model compression using Spatial SVD followed by Channel Pruning", "Automatic Mixed-Precision (AMP)", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Welcome to AI Model Efficiency Toolkit API Docs!", "AIMET TensorFlow APIs", "AIMET TensorFlow AdaRound API", "AIMET TensorFlow BatchNorm Re-estimation APIs", "AIMET TensorFlow Compression API", "AIMET TensorFlow Cross Layer Equalization APIs", "AIMET TensorFlow Layer Output Generation API", "AIMET TensorFlow Mixed Precision API", "TensorFlow Model Guidelines", "TensorFlow Model Preparer API", "AIMET TensorFlow Cross Layer Equalization Primitive API", "AIMET TensorFlow Quant Analyzer API", "AIMET TensorFlow Quantization APIs", "AIMET TensorFlow Quantization SIM API", "AIMET ONNX APIs", "AIMET ONNX AdaRound API", "AIMET ONNX AutoQuant API", "AIMET ONNX Cross Layer Equalization APIs", "AIMET ONNX Layer Output Generation API", "AIMET ONNX Mixed Precision API", "AIMET ONNX Quant Analyzer API", "AIMET ONNX Quantization APIs", "AIMET ONNX Quantization SIM API", "Encoding Format Specification", "AIMET PyTorch APIs", "AIMET PyTorch AdaRound API", "Architecture Checker API", "AIMET PyTorch AutoQuant API", "AIMET PyTorch BatchNorm Re-estimation APIs", "AIMET PyTorch Bias Correction API", "AIMET PyTorch Compression API", "AIMET PyTorch Cross Layer Equalization APIs", "AIMET PyTorch Layer Output Generation API", "AIMET PyTorch Mixed Precision API", "PyTorch Model Guidelines", "Model Preparer API", "Model Validator Utility", "PyTorch Multi-GPU support", "PEFT LoRA", "AIMET PyTorch Cross Layer Equalization Primitive API", "AIMET PyTorch Quant Analyzer API", "AIMET PyTorch Quantization APIs", "AIMET PyTorch Quantization SIM API", "AIMET Torch SparseConvolution custom onnx export", "AIMET Visualization Compression API", "AIMET Visualization for Quantization API", "Migrate to aimet_torch.v2", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "FakeQuantizationMixin", "QuantizationMixin", "quantization.affine", "FloatQuantizeDequantize", "quantization.float", "quantization.tensor", "Visualization Tools", "Blockwise Quantization", "Encoding Analyzers", "Post-Training Quantization", "GPTVQ", "AIMET: AI Model Efficiency Toolkit Documentation", "Quantized Modules", "Quantizers", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Examples", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"show": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 41, 45, 51, 52, 53, 54, 57, 59, 62, 64, 66, 68, 71, 84, 87, 88, 91, 99, 104, 108], "work": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 41, 48, 51, 62, 63, 68, 84, 94, 97, 101, 102, 104, 107], "code": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 84, 91, 92], "how": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 41, 45, 48, 49, 51, 52, 53, 54, 55, 57, 59, 62, 64, 66, 67, 68, 69, 72, 84, 87, 89, 91, 97, 101, 104, 105, 108, 109], "us": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 75, 77, 78, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 102, 104, 105, 106, 107, 108, 109, 110, 113], "aimet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 49, 52, 60, 61, 62, 63, 64, 72, 87, 89, 91, 99, 102, 107], "perform": [0, 1, 2, 3, 4, 5, 6, 8, 12, 13, 14, 15, 16, 17, 18, 19, 22, 25, 28, 29, 31, 33, 37, 41, 43, 46, 49, 51, 52, 54, 55, 56, 57, 59, 63, 64, 65, 66, 67, 68, 71, 77, 78, 79, 84, 87, 89, 90, 91, 93, 94, 95, 96, 98, 101, 103, 104, 105, 106, 108], "auto": [0, 4, 15, 16, 17, 18, 26, 30, 31, 36, 43, 45, 49, 56, 57, 59, 65, 70], "techniqu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 30, 31, 38, 41, 42, 43, 47, 51, 53, 55, 56, 57, 66, 67, 85, 88, 91, 92, 93, 95, 96, 99, 103, 105, 106, 108, 109, 110, 111, 114], "where": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 49, 51, 56, 59, 60, 61, 64, 68, 79, 80, 81, 87, 89, 90, 91, 94, 98, 105, 106, 111, 114, 115], "given": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 31, 33, 36, 49, 51, 53, 54, 56, 57, 59, 65, 68, 69, 77, 78, 83, 84, 89, 93, 95, 98, 99, 101, 104, 111, 112, 114], "target": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 32, 35, 39, 42, 44, 48, 49, 51, 54, 56, 58, 59, 64, 68, 88, 94, 96, 98, 99, 101, 103, 108, 109, 110], "find": [0, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 18, 19, 20, 22, 23, 24, 36, 51, 55, 59, 62, 65, 68, 71, 98, 103, 105, 106, 109], "bit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 49, 51, 59, 66, 73, 80, 81, 84, 91, 92, 94, 103, 108, 109, 110], "per": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 37, 45, 46, 49, 54, 56, 58, 59, 64, 66, 68, 84, 85, 87, 89, 94, 103, 104, 105, 107, 108, 109, 110], "meet": [0, 4, 18, 53, 59, 73, 93, 96, 98], "while": [0, 1, 2, 4, 5, 8, 11, 13, 14, 15, 16, 17, 18, 19, 22, 51, 56, 64, 84, 89, 92, 98, 102, 103, 106, 108, 109, 112], "try": [0, 1, 4, 5, 6, 13, 15, 16, 17, 18, 19, 22, 23, 24, 30, 52, 56, 70, 93, 95, 98, 101, 103, 108], "optim": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 30, 37, 38, 39, 42, 47, 48, 51, 52, 53, 56, 59, 67, 68, 70, 71, 84, 87, 91, 92, 93, 99, 101, 103, 106, 109, 110, 112], "infer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 33, 38, 42, 46, 47, 48, 49, 51, 67, 68, 69, 84, 87, 88, 91, 94, 96, 99, 104, 106, 109, 110], "speed": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 51, 56, 64, 101, 104, 110], "As": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 60, 68, 84, 87, 93, 95, 96, 98, 101, 103, 104, 105, 109, 111, 114], "sai": [0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 61, 101], "particular": [0, 4, 18, 84, 103, 107], "desir": [0, 4, 15, 16, 17, 18, 30, 46, 56, 66, 68, 74, 84, 91, 96, 101, 103, 108], "when": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 34, 35, 38, 43, 45, 49, 56, 57, 59, 60, 61, 66, 67, 68, 84, 87, 88, 89, 91, 92, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 115], "int8": [0, 1, 2, 3, 4, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 51, 82, 106, 109, 113], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36, 39, 41, 43, 44, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 91, 92, 93, 94, 95, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115], "featur": [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 34, 35, 36, 38, 43, 49, 51, 57, 60, 61, 62, 63, 65, 67, 68, 69, 72, 78, 83, 84, 87, 89, 92, 93, 94, 97, 101, 104, 105, 109, 110, 112, 113], "minim": [0, 4, 10, 11, 15, 16, 17, 18, 23, 24, 28, 51, 68, 88, 99, 101, 103, 109], "set": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 30, 33, 35, 36, 39, 41, 42, 45, 48, 49, 51, 53, 56, 59, 61, 62, 64, 65, 66, 68, 72, 75, 77, 78, 83, 84, 87, 89, 90, 92, 96, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 115], "need": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 33, 34, 35, 36, 39, 46, 49, 51, 55, 56, 58, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 84, 87, 91, 93, 96, 101, 103, 104, 105, 106, 107, 109, 110, 112, 113], "int16": [0, 4, 18], "get": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 15, 16, 17, 30, 32, 33, 36, 44, 52, 56, 58, 59, 61, 64, 68, 71, 73, 74, 75, 87, 92, 95, 103, 113], "It": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 30, 31, 33, 35, 36, 37, 42, 46, 49, 51, 56, 61, 65, 66, 68, 91, 94, 97, 98, 103, 104, 107, 112, 113, 115], "should": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 34, 35, 37, 38, 41, 42, 46, 48, 49, 51, 53, 56, 58, 60, 61, 64, 66, 67, 68, 72, 77, 78, 84, 87, 89, 91, 96, 101, 107, 112, 115], "note": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 33, 35, 36, 37, 39, 42, 43, 44, 45, 46, 48, 53, 56, 57, 59, 63, 64, 65, 66, 68, 69, 72, 74, 75, 84, 87, 91, 95, 96, 98, 99, 101, 102, 103, 105], "choos": [0, 4, 15, 16, 17, 18, 68, 71, 84, 95, 96, 101], "higher": [0, 4, 15, 16, 17, 18, 51, 56, 59, 84, 85, 94, 98, 106, 108], "some": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 30, 35, 36, 38, 39, 51, 56, 61, 65, 67, 68, 71, 74, 75, 89, 91, 92, 96, 98, 101, 102, 103, 104, 106, 108, 109], "necessarili": [0, 4, 18], "involv": [0, 4, 18, 59, 72, 91, 103, 108], "trade": [0, 4, 15, 17, 18, 33, 51], "off": [0, 4, 15, 17, 18, 51, 68, 103, 104, 107], "lower": [0, 1, 2, 3, 4, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 33, 51, 72, 84, 98, 103, 108], "sec": [0, 1, 2, 3, 4, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "vice": [0, 4, 18, 64, 109], "versa": [0, 4, 18, 64, 109], "altern": [0, 4, 15, 16, 17, 18, 75, 84, 101], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 36, 38, 39, 44, 45, 46, 48, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 84, 87, 88, 89, 90, 91, 93, 94, 96, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114], "gener": [0, 4, 8, 10, 11, 15, 16, 17, 18, 22, 26, 33, 39, 45, 49, 52, 59, 64, 69, 78, 79, 84, 87, 90, 91, 97, 101, 103, 105, 106, 107, 109], "pareto": [0, 4, 18, 45, 59], "curv": [0, 4, 18, 59, 98], "v": [0, 4, 12, 18, 25, 51, 59, 74, 84, 98], "op": [0, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 30, 36, 51, 52, 59, 62, 68, 91, 103, 107, 110], "guid": [0, 4, 6, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 30, 56, 67, 72, 88, 96, 97, 104, 108, 110], "user": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 34, 35, 36, 37, 38, 45, 46, 48, 49, 54, 56, 59, 60, 61, 63, 65, 67, 70, 71, 72, 74, 84, 87, 88, 89, 92, 93, 96, 97, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113], "decid": [0, 1, 2, 3, 4, 5, 13, 15, 16, 17, 18, 19, 22, 23, 24, 25, 92, 112], "right": [0, 4, 8, 18, 20, 77, 78, 79, 80, 81, 89, 90, 103, 115], "oper": [0, 3, 4, 9, 18, 30, 35, 60, 61, 62, 72, 77, 78, 89, 91, 102, 103, 104, 107, 108], "point": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 35, 37, 38, 45, 46, 47, 49, 55, 59, 64, 65, 66, 67, 68, 72, 77, 78, 82, 84, 88, 89, 99, 101, 103, 105, 108, 109, 113], "tradeoff": [0, 4, 18], "specif": [0, 1, 4, 5, 6, 7, 9, 13, 18, 19, 21, 23, 24, 33, 35, 39, 56, 68, 77, 84, 91, 92, 93, 94, 96, 99, 101, 102, 103, 104, 107, 110], "abov": [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 28, 37, 46, 51, 56, 61, 63, 66, 68, 74, 75, 84, 87, 88, 93, 94, 97, 98, 99, 101, 102, 104, 108, 109, 115], "cover": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 68, 84, 94, 107, 109], "follow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 35, 36, 38, 39, 43, 44, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 84, 87, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 109, 111, 114, 115], "instanti": [0, 1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 60, 63, 64, 84, 87, 91, 106, 112], "fake": [0, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 51, 59, 68, 77, 78, 79, 80, 81, 89, 90, 91], "insert": [0, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 51, 61, 68, 103, 109], "design": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 62, 67, 104], "state": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 33, 69, 89, 91, 101], "art": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 91], "result": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 35, 51, 53, 56, 59, 66, 68, 77, 78, 82, 84, 85, 87, 92, 93, 95, 96, 99, 104, 105, 106, 107, 109], "For": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 39, 44, 46, 48, 51, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 71, 72, 73, 74, 75, 77, 78, 84, 87, 88, 89, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 105, 107, 109, 112, 115], "rel": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 18, 19, 20, 22, 23, 24, 25, 30, 56, 71, 96, 103, 108, 113], "friendli": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 18, 19, 20, 22, 23, 24, 25, 67, 93, 103, 104], "like": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 31, 35, 45, 51, 57, 59, 65, 68, 72, 84, 87, 88, 91, 99, 101, 103, 105, 106, 107, 112], "resnet18": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 53, 54, 57, 65, 66, 68, 70, 71], "also": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 37, 46, 49, 51, 53, 60, 61, 66, 68, 74, 75, 84, 95, 96, 97, 98, 103, 105, 107, 108, 109, 110, 112, 113, 115], "number": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 33, 35, 37, 46, 51, 54, 55, 56, 59, 61, 66, 68, 74, 77, 78, 79, 80, 81, 84, 85, 89, 92, 98, 99, 101, 106, 109, 110, 112, 115], "sampl": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 33, 36, 37, 46, 48, 49, 51, 53, 55, 59, 66, 68, 83, 88, 89, 91, 95, 103, 104, 105, 106, 109], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 44, 46, 48, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 72, 73, 74, 75, 77, 78, 79, 80, 81, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109, 112, 113, 115], "deliber": [0, 1, 2, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25], "chosen": [0, 1, 2, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 97, 101], "have": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 35, 43, 46, 49, 51, 52, 57, 58, 61, 62, 66, 68, 71, 72, 75, 78, 83, 84, 91, 98, 101, 103, 104, 105, 108, 109], "execut": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 53, 59, 61, 70, 75, 91, 97, 98, 112], "more": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 36, 37, 39, 41, 42, 43, 46, 49, 51, 52, 53, 55, 56, 57, 59, 62, 65, 66, 67, 68, 72, 73, 84, 87, 88, 89, 91, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113], "quickli": [0, 1, 2, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 98], "reli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 72], "imagenet": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 48, 51, 54, 55, 68, 97], "task": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 49, 112, 113], "imag": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 33, 37, 46, 53, 55, 66, 73, 92, 97, 105], "classif": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 35, 101], "If": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 33, 34, 35, 36, 45, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 81, 84, 87, 89, 90, 91, 93, 102, 103, 104, 105, 107, 108, 112, 113, 115], "you": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 51, 56, 61, 63, 67, 68, 74, 75, 87, 97, 98, 102, 111, 114], "alreadi": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 57, 65, 68, 74, 98, 108], "version": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 44, 51, 61, 67, 68, 72, 73, 74, 75, 77, 78, 83, 84, 87, 89, 91, 97, 99], "readili": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "avail": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 31, 51, 53, 61, 66, 68, 73, 78, 91, 102, 105, 107, 108], "pleas": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 37, 39, 41, 42, 43, 46, 51, 53, 54, 55, 56, 57, 62, 64, 66, 67, 68, 69, 72, 73, 75, 88, 91, 92, 93, 94, 95, 97, 99, 101, 104, 105, 109], "els": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 42, 54, 59, 61, 62, 91, 104], "download": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 73, 74, 75, 91], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 95, 96, 97, 98, 102, 103, 104, 105, 106, 107, 108, 109, 112, 115], "appropri": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 51, 56, 59, 68, 73, 75, 77, 78, 84, 87, 89, 96, 97, 98, 101, 108], "locat": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 97], "e": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 33, 37, 38, 45, 46, 48, 49, 51, 55, 59, 66, 68, 78, 83, 91, 94, 96, 99, 106, 108, 115], "g": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 33, 37, 46, 49, 51, 66, 68, 74, 91, 94, 96, 99, 108, 115], "http": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 61, 73, 74, 75, 96, 97, 104, 110, 112], "net": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 97], "org": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 61, 74, 75, 97, 104], "challeng": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "lsvrc": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "2012": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "index": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 53, 66, 69, 87, 89, 96, 110], "php": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 97], "note1": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "typic": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 35, 51, 68, 84, 91, 96, 103, 105, 106, 107, 109, 112], "ha": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 35, 36, 37, 43, 46, 51, 52, 56, 57, 59, 61, 62, 64, 65, 66, 68, 71, 72, 78, 82, 84, 87, 91, 96, 97, 98, 101, 104, 106, 109, 112, 115], "characterist": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "dataload": [0, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 33, 41, 42, 46, 48, 51, 53, 54, 59, 66, 87, 91, 97, 105], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 35, 36, 38, 41, 45, 47, 48, 49, 51, 52, 53, 59, 62, 64, 66, 67, 68, 70, 72, 74, 75, 78, 80, 81, 84, 87, 88, 89, 91, 92, 96, 97, 98, 101, 103, 104, 105, 107, 108, 109, 112, 113, 115], "subfold": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "train": [0, 3, 4, 9, 18, 20, 26, 28, 29, 35, 37, 38, 46, 47, 48, 51, 53, 54, 56, 63, 66, 67, 73, 88, 92, 93, 94, 97, 99, 101, 108, 109, 110], "val": [0, 1, 2, 3, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "valid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 37, 46, 48, 51, 55, 56, 59, 66, 67, 68, 84, 93, 103, 110], "see": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 35, 39, 41, 42, 43, 51, 53, 54, 55, 56, 57, 66, 67, 68, 79, 89, 90, 91, 95, 98, 99, 101, 103, 107, 108, 109, 111, 112, 113, 114], "descript": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 89, 102], "detail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 61, 67, 68, 74, 75, 95, 97, 98, 99, 101, 103, 108, 109, 112, 113], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 37, 45, 46, 51, 52, 53, 54, 55, 56, 57, 59, 63, 64, 65, 66, 68, 70, 71, 77, 84, 89, 96, 103, 105, 106, 107, 108, 109], "subdirectori": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 33, 34, 35, 36, 39, 45, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 77, 78, 80, 84, 85, 87, 90, 91], "file": [0, 1, 2, 3, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 51, 52, 53, 55, 56, 59, 64, 66, 68, 70, 73, 74, 75, 84, 87, 91, 103, 105, 106, 109, 110, 113], "each": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 35, 36, 49, 51, 52, 55, 56, 59, 62, 65, 66, 68, 70, 71, 74, 75, 77, 78, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 106, 107, 108, 109, 113, 115], "note2": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "To": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 33, 35, 39, 41, 42, 43, 51, 53, 55, 56, 57, 59, 64, 66, 68, 72, 73, 87, 89, 91, 94, 97, 98, 101, 102, 105, 107, 108, 109, 112, 113], "up": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 35, 37, 46, 51, 56, 64, 66, 68, 75, 84, 101, 106, 107, 109, 115], "mai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 35, 49, 51, 53, 59, 61, 64, 68, 74, 75, 77, 78, 82, 83, 84, 87, 89, 92, 96, 101, 103, 104, 105, 107, 108, 109], "reduc": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 64, 84, 87, 89, 95, 101, 104, 108, 110, 115], "subset": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 37, 46, 66, 84, 92, 94, 105, 115], "entir": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 37, 46, 56, 64, 66, 84, 91, 98, 101], "ilsvrc2012": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "1000": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 33, 37, 46, 48, 51, 53, 55, 56, 66, 68, 91, 92, 104, 105], "50": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 45, 56, 59, 96], "But": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 61, 68, 92, 101], "purpos": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 68, 84, 107], "could": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 37, 46, 49, 51, 60, 66, 68, 72, 91, 95, 115], "perhap": [0, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25], "exercis": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "left": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 79, 80, 81, 90, 98, 115], "upto": [0, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 33], "reader": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "necessari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 37, 46, 51, 53, 56, 66, 68, 82, 84, 91, 112], "edit": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 48, 49, 51, 68], "cell": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "below": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 31, 32, 33, 34, 35, 36, 39, 43, 44, 49, 51, 57, 58, 60, 64, 67, 72, 74, 75, 79, 84, 87, 89, 90, 91, 92, 93, 94, 103, 104, 105, 107, 108, 109, 115], "specifi": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 45, 49, 51, 56, 59, 66, 68, 71, 74, 75, 79, 80, 81, 84, 90, 91, 93, 101, 107, 109, 113], "directori": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 45, 53, 56, 58, 59, 64, 66, 71, 97, 113], "save": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 32, 36, 44, 51, 53, 56, 58, 59, 64, 65, 66, 68, 71, 83, 87, 91, 93, 109, 113], "dataset_dir": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33], "path": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 32, 33, 44, 45, 51, 53, 55, 56, 58, 59, 61, 64, 66, 68, 69, 70, 75, 83, 87, 97], "replac": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 48, 51, 54, 55, 61, 64, 65, 67, 68, 72, 74, 84, 89, 91, 104, 109], "real": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 53, 82], "loop": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 61, 91, 108], "doe": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 28, 35, 37, 43, 46, 56, 57, 59, 60, 61, 66, 72, 78, 89, 91, 98, 100, 103, 108], "ani": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36, 37, 38, 46, 51, 54, 56, 59, 60, 61, 62, 65, 66, 67, 68, 69, 72, 74, 78, 84, 87, 91, 92, 93, 97, 107, 110], "limit": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 72, 89, 100], "written": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 102, 103], "Not": [0, 1, 2, 3, 5, 6, 7, 10, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 63, 64, 66, 92, 98], "realli": [0, 1, 2, 3, 5, 6, 7, 10, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 30, 32, 33, 35, 44, 46, 51, 52, 54, 55, 58, 59, 61, 62, 64, 66, 68, 71, 72, 74, 75, 84, 87, 89, 91, 98, 101, 103, 104, 107, 108, 109, 113], "later": [0, 1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 68, 73, 87, 91], "modifi": [0, 1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 36, 44, 61, 64, 65, 68, 74, 75, 103, 109, 110, 115], "quantizationsim": [0, 1, 2, 3, 5, 6, 8, 12, 13, 14, 19, 21, 22, 23, 24, 25, 51, 63], "session": [0, 1, 2, 3, 28, 42, 44, 45, 46, 48, 70], "act": [0, 3, 10, 11, 14, 59, 66], "regular": [0, 3, 8, 15, 16, 17, 51, 68, 77, 78, 89, 92, 103, 109], "onnxruntim": [0, 1, 2, 3, 42, 44, 46], "howev": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 22, 23, 24, 25, 34, 35, 51, 56, 68, 72, 103, 104, 106, 107, 109], "recommend": [0, 1, 3, 4, 5, 9, 13, 19, 20, 30, 35, 37, 46, 51, 52, 56, 66, 73, 84, 92, 94, 96, 103, 108], "onli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 32, 33, 34, 39, 41, 44, 46, 48, 51, 52, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 73, 74, 75, 79, 82, 83, 84, 89, 91, 94, 100, 103, 105, 106, 107, 110, 115], "quantizationsimmodel": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 32, 39, 41, 44, 45, 48, 51, 54, 58, 59, 64, 66, 67, 68, 69, 83, 84, 87, 88, 91, 92, 94], "regist": [0, 3, 77, 78, 89, 90], "requir": [0, 1, 3, 4, 9, 12, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 29, 30, 31, 33, 35, 36, 37, 39, 41, 43, 45, 46, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 68, 70, 71, 74, 75, 84, 87, 91, 92, 94, 96, 101, 103, 104, 107, 109], "custom": [0, 1, 3, 8, 11, 20, 35, 49, 61, 67, 77, 78, 89, 97, 108, 109], "import": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 75, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 94, 95, 108], "torch": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 52, 53, 54, 56, 58, 59, 60, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 97, 102, 110], "ort": [0, 1, 2, 3, 42], "common": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 64, 68, 72, 74, 84, 108, 113], "image_net_config": [0, 1, 2, 3, 5, 6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25], "util": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 35, 36, 37, 39, 52, 53, 64, 65, 68, 70, 72, 84, 91, 94, 97, 103], "image_net_evalu": [0, 1, 2, 3, 5, 6, 7, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25], "imagenetevalu": [0, 1, 2, 3, 5, 6, 7, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25], "image_net_data_load": [0, 1, 2, 3, 15, 17, 19, 21, 22, 23, 24, 25], "imagenetdataload": [0, 1, 2, 3, 12, 15, 17, 19, 21, 22, 23, 24, 25], "imagenetdatapipelin": [0, 1, 2, 3, 5, 6, 7, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 51, 54, 55, 68], "staticmethod": [0, 1, 2, 3, 5, 6, 7, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 61], "def": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 33, 34, 35, 36, 37, 39, 41, 42, 43, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 65, 66, 68, 69, 70, 71, 72, 78, 87, 91], "get_val_dataload": [0, 1, 2, 3, 15, 17, 18, 19, 21, 22, 23, 24, 25, 51, 55, 68], "data": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 33, 36, 37, 39, 41, 42, 45, 46, 48, 51, 53, 54, 55, 56, 59, 61, 63, 64, 66, 68, 70, 72, 82, 83, 84, 87, 88, 91, 92, 94, 100, 103, 104, 105, 106, 108, 109], "return": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 34, 35, 36, 37, 42, 46, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 77, 78, 82, 83, 84, 87, 88, 90, 91, 93, 98, 99, 105, 109], "data_load": [0, 1, 2, 3, 5, 6, 7, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 41, 42, 48, 51, 53, 55, 56, 59, 68, 83, 87, 88, 91], "image_s": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 33, 53], "batch_siz": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 33, 37, 42, 46, 48, 51, 53, 56, 66, 68, 91], "is_train": [0, 1, 2, 3, 4, 15, 17, 19, 21, 22, 23, 24, 25, 33], "fals": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 33, 35, 44, 45, 48, 49, 52, 53, 55, 56, 59, 61, 62, 64, 68, 69, 72, 77, 78, 79, 82, 84, 87, 89, 90, 91, 102, 107], "num_work": [0, 1, 2, 3, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25], "sess": [0, 1, 2, 3, 30], "inferencesess": [0, 1, 2, 3, 42, 44, 46], "float": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 37, 42, 46, 49, 51, 53, 55, 56, 59, 66, 67, 68, 77, 78, 80, 82, 84, 88, 89, 103, 105, 108, 109, 113], "its": [0, 1, 2, 3, 5, 6, 7, 9, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 30, 35, 59, 77, 78, 82, 87, 88, 89, 91, 97, 99, 103, 105, 109, 115], "top": [0, 1, 2, 3, 4, 5, 6, 7, 8, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 77, 78, 95, 112], "param": [0, 1, 2, 3, 5, 6, 7, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 28, 30, 33, 36, 37, 41, 42, 45, 46, 48, 51, 53, 56, 59, 64, 66, 68, 69, 70, 77, 84, 90, 107], "iter": [0, 1, 2, 3, 4, 5, 6, 7, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 30, 33, 37, 42, 46, 51, 53, 56, 66, 91, 92, 104], "none": [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 33, 35, 36, 37, 39, 41, 42, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 70, 71, 72, 77, 78, 79, 80, 81, 83, 84, 87, 89, 90, 91, 112], "go": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 35, 51, 54, 68, 74, 75, 87, 91, 97, 112], "load": [0, 1, 2, 3, 8, 32, 33, 36, 44, 45, 51, 54, 55, 56, 58, 59, 61, 62, 64, 68, 69, 87, 101], "pretrain": [0, 1, 2, 3, 4, 5, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 33, 51, 53, 54, 57, 65, 66, 68, 70, 71, 87, 105, 106, 109], "torchvis": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 53, 54, 57, 65, 66, 68, 70, 71, 91], "similarli": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 68, 84, 87, 108], "instead": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 34, 51, 60, 61, 62, 68, 84, 87, 103, 104], "input_shap": [0, 1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 31, 33, 34, 37, 42, 46, 48, 51, 53, 55, 56, 57, 61, 65, 66, 68, 70, 91], "224": [0, 1, 2, 3, 4, 7, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 37, 39, 42, 45, 46, 48, 51, 53, 55, 57, 58, 65, 66, 68, 70, 71], "shape": [0, 1, 2, 3, 7, 8, 9, 13, 18, 19, 21, 22, 23, 24, 25, 34, 35, 52, 56, 57, 61, 62, 64, 65, 69, 72, 79, 80, 81, 82, 84, 85, 89, 90, 91, 105], "channel": [0, 1, 2, 3, 14, 16, 18, 19, 21, 22, 23, 24, 25, 30, 49, 52, 54, 64, 66, 71, 84, 87, 89, 94, 96, 98, 100, 101, 104, 105, 107, 108, 109, 110, 111, 113, 114, 115], "x": [0, 1, 2, 3, 4, 5, 8, 9, 12, 13, 18, 19, 21, 22, 23, 24, 25, 30, 33, 34, 35, 39, 52, 60, 61, 62, 73, 80, 81, 82, 89, 91, 96, 102, 105], "height": [0, 1, 2, 3, 8, 18, 19, 21, 22, 23, 24, 25, 111, 114, 115], "width": [0, 1, 2, 3, 5, 13, 18, 19, 21, 22, 23, 24, 25, 49, 66, 92, 108, 109, 111, 114, 115], "dummy_input": [0, 1, 2, 3, 18, 19, 20, 21, 22, 23, 24, 25, 29, 32, 42, 44, 45, 46, 48, 51, 52, 53, 57, 58, 59, 60, 64, 65, 66, 68, 69, 83, 84, 87, 91], "randn": [0, 1, 2, 3, 20, 39, 42, 46, 48, 51, 53, 59, 61, 62, 66, 68, 69, 77, 78, 79, 82, 89, 90], "filenam": [0, 1, 2, 3, 51, 64, 68, 87], "resnet": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 30, 33, 96], "18": [0, 1, 2, 3], "pt_model": [0, 1, 2, 3], "true": [0, 1, 2, 3, 4, 5, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 36, 39, 41, 45, 49, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 77, 78, 79, 80, 81, 82, 84, 89, 90, 91, 102, 107], "export": [0, 1, 2, 3, 4, 5, 8, 13, 18, 19, 22, 23, 24, 32, 33, 37, 39, 44, 45, 46, 48, 49, 51, 54, 58, 59, 60, 64, 66, 68, 72, 74, 75, 87, 88, 94, 97, 99, 101, 102, 103, 106, 109, 110], "eval": [0, 1, 2, 3, 4, 7, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 33, 37, 42, 45, 46, 51, 53, 55, 56, 57, 59, 61, 63, 65, 66, 68, 70, 71, 91, 98, 101, 112], "trainingmod": [0, 3], "preserv": [0, 3, 15, 16, 17, 61], "export_param": [0, 1, 2, 3], "do_constant_fold": [0, 1, 2, 3], "input_nam": [0, 1, 2, 3, 68], "input": [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 25, 30, 32, 34, 35, 42, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 72, 77, 78, 79, 80, 81, 83, 84, 87, 89, 90, 91, 95, 101, 105, 107, 109, 111, 112, 114, 115], "output_nam": [0, 1, 2, 3, 68], "output": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 30, 34, 35, 49, 51, 52, 53, 55, 59, 60, 61, 62, 64, 66, 67, 68, 69, 71, 72, 77, 78, 79, 84, 89, 90, 91, 95, 101, 104, 105, 107, 109, 110, 111, 114, 115], "dynamic_ax": [0, 1, 2, 3], "0": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115], "load_model": [0, 1, 2, 3, 32], "whether": [0, 1, 2, 3, 5, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 32, 38, 44, 58, 61, 62, 67, 92, 106], "cpu": [0, 1, 2, 3, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 51, 53, 54, 57, 58, 61, 65, 68, 69, 71, 73, 74, 91, 103, 110], "cuda": [0, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 53, 54, 55, 56, 59, 66, 68, 70, 73, 74, 75, 91], "devic": [0, 1, 2, 3, 7, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 32, 44, 51, 53, 54, 55, 58, 59, 61, 64, 65, 68, 70, 71, 87, 88, 91, 109], "your": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 42, 48, 51, 54, 55, 61, 62, 68, 72, 73, 74, 75, 88, 97, 102], "environ": [0, 1, 2, 3, 4, 6, 7, 10, 11, 15, 16, 17, 18, 19, 22, 23, 24, 25, 33, 73, 97], "chang": [0, 1, 2, 3, 4, 7, 8, 10, 11, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 38, 49, 51, 53, 59, 60, 61, 64, 67, 68, 71, 78, 83, 84, 87, 89, 91, 92, 101, 105, 106, 107, 109, 113, 115], "logic": [0, 1, 2, 3, 15, 16, 17, 18, 19, 22, 23, 24, 25, 59, 77, 78, 110], "forc": [0, 1, 2, 3, 15, 16, 17, 18, 19, 22, 23, 24, 25], "placement": [0, 1, 2, 3, 15, 16, 17, 18, 19, 22, 23, 24, 25, 107], "cudnn_conv_algo_search": [0, 1, 2, 3], "fix": [0, 1, 2, 3, 49, 62, 88, 99, 103, 108, 109, 110], "default": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 33, 35, 51, 53, 55, 56, 59, 61, 66, 68, 74, 75, 78, 79, 83, 87, 89, 90, 92, 98, 101, 107, 109, 110, 112], "avoid": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 34, 46, 51, 60, 66, 68, 96], "everi": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 37, 46, 51, 58, 66, 68, 91, 98, 101, 106, 113], "cudaexecutionprovid": [0, 1, 2, 3], "get_available_provid": [0, 1, 2, 3], "cpuexecutionprovid": [0, 1, 2, 3], "use_cuda": [0, 1, 2, 3, 4, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 41, 44, 48, 51, 54, 56, 68], "let": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 51, 61, 68, 91], "determin": [0, 8, 15, 16, 17, 18, 20, 28, 30, 37, 46, 49, 51, 56, 66, 68, 80, 81, 84, 89, 91, 93, 96, 101, 103, 104, 105], "32": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 28, 33, 34, 35, 37, 42, 49, 51, 52, 61, 62, 68, 74, 75, 79, 87, 90, 108], "routin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 51, 68], "print": [0, 1, 2, 3, 7, 8, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 33, 42, 45, 51, 52, 53, 56, 59, 61, 62, 68, 72, 75, 77, 78, 79, 89, 91, 103, 105], "befor": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 32, 34, 35, 36, 38, 42, 44, 51, 53, 58, 65, 67, 68, 71, 72, 83, 89, 91, 92, 93, 94, 101, 103, 106, 112, 113], "batchnorm": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 31, 35, 36, 38, 39, 43, 52, 53, 55, 57, 65, 71, 89, 93, 104, 115], "bn": [0, 1, 2, 3, 5, 7, 10, 11, 13, 14, 18, 19, 22, 23, 24, 29, 36, 55, 65, 67, 103, 110], "These": [0, 1, 2, 3, 5, 8, 10, 11, 13, 14, 18, 19, 20, 22, 23, 24, 28, 53, 67, 68, 72, 75, 89, 91, 93, 94, 95, 96, 102, 103, 104, 105, 108, 109], "adjac": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 91, 107], "convolut": [0, 1, 2, 3, 5, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 30, 35, 36, 52, 84, 91, 94, 96, 101, 108], "cannot": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 52, 61, 62, 79, 90], "thei": [0, 1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 34, 36, 61, 65, 67, 84, 107, 112], "why": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 108], "do": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 29, 35, 39, 51, 61, 63, 64, 71, 75, 91, 101, 105, 109], "On": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 49, 73, 78], "runtim": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 48, 49, 51, 56, 68, 69, 84, 87, 88, 91, 96, 99, 101, 103, 105, 107, 109, 110], "tflite": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "snapdragon": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "neural": [0, 1, 2, 3, 5, 6, 10, 11, 13, 14, 18, 19, 20, 22, 23, 24, 88, 91, 93, 96, 99, 101, 103, 106, 108, 109, 114], "process": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 18, 19, 20, 22, 23, 24, 30, 32, 44, 51, 58, 68, 70, 84, 85, 88, 91, 93, 99, 101, 103, 104, 109], "sdk": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 88, 91, 99], "etc": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 49, 51, 68, 74, 96, 103], "practic": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 51, 68, 91, 101], "so": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 29, 37, 39, 46, 51, 56, 61, 62, 63, 66, 68, 72, 75, 89, 102, 105, 112], "speedup": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "sinc": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 48, 51, 64, 68, 84, 94, 96, 98, 109], "unnecessari": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 91, 115], "now": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 35, 51, 61, 62, 68, 69, 87, 91, 103, 110, 115], "perspect": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "mathemat": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 60], "equival": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 25, 51, 59, 60, 67, 68, 78, 79, 80, 81, 84, 91], "produc": [0, 1, 2, 3, 5, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 49, 53, 61, 82, 83, 84, 98, 105, 112], "same": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 32, 35, 44, 51, 53, 58, 61, 62, 64, 66, 68, 69, 72, 77, 78, 82, 84, 89, 90, 94, 104, 107, 109, 113], "increas": [0, 1, 2, 3, 5, 10, 11, 13, 14, 15, 17, 18, 19, 22, 23, 24, 30, 56, 71, 84, 98, 104, 107], "rang": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 18, 19, 20, 21, 22, 23, 35, 37, 46, 51, 53, 54, 61, 66, 68, 71, 79, 83, 91, 92, 94, 97, 98, 103, 104, 105, 106, 108, 109, 110, 113], "tensor": [0, 1, 2, 3, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 28, 35, 38, 47, 48, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 77, 78, 79, 80, 81, 84, 87, 89, 90, 91, 92, 95, 102, 103, 105, 107, 108, 109, 110, 111, 114], "valu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 37, 45, 46, 49, 51, 55, 56, 58, 59, 61, 64, 65, 66, 68, 79, 80, 81, 82, 83, 84, 85, 87, 90, 91, 92, 98, 101, 103, 104, 105, 106, 109, 111, 113, 114], "weight": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 28, 30, 33, 35, 36, 37, 38, 39, 46, 47, 49, 51, 55, 59, 62, 64, 65, 66, 67, 68, 71, 72, 77, 78, 83, 84, 85, 87, 89, 91, 92, 94, 96, 101, 103, 104, 105, 106, 107, 108, 109, 113], "And": [0, 2, 3, 5, 10, 11, 13, 14, 18, 22, 23, 24, 36, 65, 101], "neg": [0, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 79, 84, 89], "impact": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 91, 98, 108], "especi": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 20, 22, 23, 24, 73, 103, 106, 108], "want": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 32, 36, 44, 51, 58, 59, 61, 65, 67, 68, 74], "behavior": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 61, 72, 78, 89, 91, 99], "here": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 29, 30, 31, 51, 53, 54, 57, 61, 64, 66, 68, 69, 72, 87, 91, 96, 97, 106, 112], "place": [0, 1, 2, 3, 5, 6, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 51, 55, 57, 59, 65, 68, 78, 84, 87, 106, 107], "aimet_onnx": [0, 1, 2, 3, 41, 42, 43, 44, 45, 46, 48, 73, 75], "batch_norm_fold": [0, 1, 2, 3, 4, 5, 7, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 29, 36, 54, 65, 71, 91], "fold_all_batch_norms_to_weight": [0, 1, 2, 3], "_": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 22, 23, 24, 25, 28, 32, 33, 35, 36, 37, 44, 46, 48, 53, 58, 66, 79, 83, 88, 89, 90, 91], "basic": [0, 1, 2, 3, 4, 7, 8, 10, 11, 14, 18, 21, 22, 23, 24, 51, 68, 75, 88, 91], "mean": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 38, 51, 54, 68, 71, 89, 91, 95, 107, 109], "graph": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 35, 49, 51, 52, 61, 68, 70, 87, 102, 103, 109, 112], "configur": [0, 1, 2, 3, 4, 7, 8, 10, 11, 18, 19, 21, 22, 23, 24, 49, 51, 53, 55, 64, 66, 68, 84, 87, 91, 96, 100, 110], "them": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 35, 46, 51, 61, 62, 64, 66, 68, 72, 89, 91, 92, 115], "few": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 68, 91, 96, 103, 108, 109], "explain": [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 51, 68, 95, 101, 104, 109, 115], "quant_schem": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 37, 46, 48, 49, 51, 53, 55, 66, 68, 69, 83, 87], "quantschem": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 37, 46, 48, 51, 53, 54, 55, 66, 68, 69, 72, 83, 87, 93], "post_training_tf_enhanc": [0, 1, 2, 3, 4, 7, 8, 10, 12, 14, 18, 19, 21, 22, 23, 25, 28, 37, 46, 49, 51, 53, 55, 66, 68], "support": [0, 1, 2, 3, 4, 7, 8, 9, 10, 14, 18, 21, 22, 23, 24, 26, 30, 31, 33, 34, 35, 39, 48, 51, 55, 56, 59, 60, 61, 66, 67, 68, 69, 73, 84, 87, 95, 96, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 114, 115], "option": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 33, 39, 42, 51, 52, 53, 54, 55, 56, 59, 61, 64, 65, 66, 68, 71, 75, 78, 79, 83, 84, 87, 88, 90, 91, 92, 97, 105, 107, 109, 112], "tf_enhanc": [0, 1, 2, 3, 4, 7, 8, 10, 14, 18, 21, 22, 23, 55], "tf": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 48, 55, 66, 74, 105, 109, 110], "quant": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 21, 22, 23, 24, 28, 38, 45, 48, 51, 55, 59, 67, 68, 83, 94], "scheme": [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 28, 30, 48, 51, 53, 55, 56, 58, 66, 68, 83, 84, 93, 94, 98, 101, 105], "enum": [0, 1, 2, 3, 4, 7, 8, 10, 14, 18, 21, 22, 23, 55, 56, 59], "post_training_tf": [0, 1, 2, 3, 4, 5, 7, 8, 10, 13, 14, 18, 21, 22, 23, 28, 48, 49, 51, 55, 66, 68, 69, 83, 87], "default_output_bw": [0, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 37, 45, 51, 59, 66, 68, 87, 91], "8": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 33, 36, 37, 41, 45, 46, 48, 49, 51, 53, 55, 56, 59, 61, 62, 64, 66, 68, 70, 72, 73, 75, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 103, 115], "essenti": [0, 1, 2, 3, 4, 7, 8, 10, 11, 14, 18, 21, 22, 23, 24, 84, 88], "ask": [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 14, 18, 21, 22, 23, 24, 25], "all": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 31, 34, 35, 36, 46, 49, 51, 54, 55, 56, 59, 61, 62, 64, 65, 66, 67, 68, 71, 72, 74, 77, 78, 83, 84, 87, 89, 91, 95, 98, 101, 104, 105, 107, 108], "activ": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 33, 34, 35, 36, 37, 45, 46, 48, 49, 51, 52, 55, 59, 60, 61, 64, 65, 66, 68, 69, 83, 84, 87, 89, 91, 103, 105, 106, 107, 108, 109], "integ": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 37, 46, 49, 66, 68, 79, 84, 92, 103, 105], "default_param_bw": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 37, 41, 45, 46, 48, 51, 59, 66, 68, 87, 91], "There": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 58, 62, 68, 72, 73, 92, 102, 104, 106, 112, 113], "other": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 60, 61, 65, 67, 68, 69, 72, 73, 84, 87, 98, 100, 101, 103, 105, 108, 109, 110], "check": [0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 32, 35, 37, 38, 44, 46, 52, 58, 60, 61, 62, 66, 67, 68, 93, 103, 106, 108], "document": [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 18, 20, 21, 22, 23, 24, 25, 26, 33, 64, 70, 73, 75, 96, 97, 99, 110], "refer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 45, 49, 51, 55, 58, 59, 64, 68, 72, 84, 87, 92, 93, 94, 97, 99, 103, 105, 106, 107, 109], "aimet_common": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "quantsim": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 18, 19, 21, 22, 23, 24, 28, 32, 39, 41, 44, 45, 46, 48, 51, 53, 54, 55, 58, 59, 64, 66, 67, 68, 69, 72, 83, 84, 87, 88, 97, 103, 106, 107, 110], "default_activation_bw": [0, 1, 2, 3, 41, 46, 48], "even": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 51, 68, 103], "though": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 51, 68, 84, 107], "ad": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 22, 23, 24, 49, 51, 62, 64, 68, 69, 91, 100, 103, 107, 110], "node": [0, 1, 2, 3, 4, 5, 7, 8, 13, 18, 19, 22, 23, 24, 51, 52, 59, 60, 61, 68, 91, 106, 109], "readi": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 51, 68, 91, 108], "yet": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 51, 68], "scale": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 29, 31, 36, 43, 49, 51, 54, 57, 64, 65, 68, 78, 79, 80, 81, 82, 84, 87, 90, 94, 103, 104, 105, 106, 109], "offset": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 37, 46, 49, 51, 66, 68, 78, 79, 84, 85, 87, 90, 103, 105, 106, 109], "pass": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 30, 32, 33, 35, 36, 37, 41, 44, 45, 46, 48, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 72, 77, 78, 84, 87, 88, 89, 91, 99, 102, 103, 104, 105, 106, 108, 109, 110, 112], "unlabel": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 24, 25, 42, 46, 48, 51, 53, 66, 68, 92, 103, 105, 109], "through": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 35, 51, 55, 59, 61, 66, 68, 71, 72, 87, 89, 91, 104, 105, 109, 112, 113], "collect": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 51, 53, 66, 68, 83, 84, 95, 105], "statist": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 29, 30, 37, 38, 46, 51, 54, 56, 66, 67, 68, 71, 79, 80, 81, 83, 89, 90, 91, 94, 103, 105, 113], "which": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 32, 33, 35, 38, 44, 46, 49, 51, 52, 55, 56, 58, 59, 61, 62, 64, 65, 67, 68, 71, 74, 75, 78, 79, 82, 84, 87, 88, 89, 90, 91, 92, 93, 94, 96, 98, 101, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114], "calcul": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 28, 33, 51, 53, 59, 65, 68, 85, 89, 98, 104, 105, 109], "sometim": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 22, 23, 24, 51, 68, 95, 101, 104, 105], "calibr": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 37, 41, 46, 48, 51, 66, 68, 79, 83, 84, 85, 87, 88, 89, 90, 91, 103, 105, 106, 108, 109], "simpli": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 37, 46, 51, 61, 66, 68, 115], "benefici": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 51, 68, 92, 105, 106], "forward": [0, 4, 7, 8, 9, 10, 11, 12, 18, 19, 21, 22, 23, 24, 25, 33, 35, 37, 45, 46, 51, 52, 54, 59, 60, 61, 62, 63, 65, 66, 68, 69, 74, 77, 78, 79, 89, 90, 91, 102, 105, 108, 110], "well": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 33, 46, 51, 52, 62, 64, 66, 68, 78, 82, 84, 87, 89, 96, 101, 103, 104, 105, 109, 111], "distribut": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 30, 51, 56, 68, 104, 108, 109], "doesn": [0, 18, 63], "t": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 51, 59, 61, 63, 64, 67, 68, 74, 92], "look": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 35, 45, 51, 59, 68, 91, 112], "definit": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 34, 38, 60, 61, 64, 67, 72, 91, 103], "extrem": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 51, 68], "bias": [0, 2, 14, 18, 22, 103], "origin": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 32, 33, 35, 44, 56, 58, 61, 68, 72, 77, 78, 89, 91, 95, 96, 101, 103, 104, 105, 106, 109, 112], "consist": [0, 18, 58, 72, 84, 93, 109, 115], "dark": [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 51, 68], "light": [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 51, 68], "mani": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 61, 92, 104, 109], "differ": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 30, 51, 53, 56, 61, 64, 66, 68, 69, 72, 74, 75, 84, 95, 97, 98, 101, 103, 104, 106, 107, 108, 109], "wai": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 30, 56, 58, 68, 72, 73, 84, 91, 97, 98], "just": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 51, 68, 109, 112, 115], "pass_calibration_data": [0, 1, 2, 3, 5, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 41, 48, 51, 68], "get_input": [0, 1, 2, 3], "name": [0, 1, 2, 3, 7, 9, 11, 12, 25, 30, 32, 35, 44, 49, 55, 58, 59, 64, 66, 68, 74, 75, 77, 78, 83, 87, 89, 90, 104, 109, 110, 112], "batch_cntr": [0, 1, 2, 3, 5, 10, 11, 13, 14, 19, 21, 22, 23, 24, 25, 42], "input_data": [0, 1, 2, 3, 18, 19, 21, 22, 23, 24, 25, 28, 42, 48, 51, 68], "target_data": [0, 1, 2, 3, 18, 19, 21, 22, 23, 24, 25, 51, 68], "inputs_batch": [0, 1, 2, 3, 18, 19, 21, 22, 23, 24, 25, 51, 68], "numpi": [0, 1, 2, 3, 9, 28, 30, 33, 37, 39, 42, 45, 46, 48], "break": [0, 1, 2, 3, 4, 5, 10, 11, 13, 14, 19, 21, 22, 23, 24, 25, 30, 33, 42, 48, 51, 68, 91], "subsequ": [0, 1, 2, 3, 5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 51, 68, 82, 87, 102, 104, 106, 107], "compute_encod": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 28, 39, 45, 48, 51, 59, 68, 69, 72, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91], "forward_pass_callback": [0, 1, 2, 3, 5, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 28, 37, 45, 46, 59, 66, 68], "forward_pass_callback_arg": [0, 1, 2, 3, 4, 5, 7, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 39, 41, 45, 51, 59, 68], "10000": [0, 1, 5, 6, 13, 18, 19, 51, 92], "initi": [0, 1, 5, 11, 12, 13, 18, 19, 23, 24, 25, 28, 51, 68, 69, 77, 78, 79, 80, 81, 89, 90, 92, 106, 108, 109], "phase": [0, 4, 18, 33, 59, 101, 103], "compris": [0, 4, 18], "sensit": [0, 2, 4, 14, 18, 22, 37, 38, 46, 47, 59, 66, 67, 98, 103, 105, 108, 109, 110], "greedili": [0, 4, 18], "select": [0, 4, 18, 28, 51, 68, 71, 73, 74, 75, 93, 96, 105, 109, 112, 115], "bitwidth": [0, 1, 4, 5, 13, 18, 19, 33, 45, 49, 51, 53, 55, 59, 64, 66, 68, 72, 79, 80, 81, 82, 84, 87, 89, 90, 91, 94, 103, 108, 109], "base": [0, 1, 4, 5, 6, 7, 13, 18, 19, 20, 21, 28, 29, 41, 48, 51, 59, 64, 66, 68, 69, 72, 74, 77, 78, 79, 80, 81, 84, 89, 90, 95, 96, 103], "three": [0, 18, 31, 61, 93, 96, 113], "eval_callback_for_phase1": [0, 18, 59], "eval_callback_for_phase2": [0, 18, 59], "callbackfunc": [0, 4, 12, 18, 25, 37, 46, 66], "object": [0, 6, 7, 12, 18, 19, 22, 23, 24, 25, 28, 32, 33, 37, 42, 44, 46, 53, 56, 58, 59, 64, 66, 68, 77, 78, 82, 83, 84, 87, 89, 90, 91, 94, 103, 106, 109], "In": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 34, 35, 37, 38, 42, 46, 49, 51, 52, 53, 56, 59, 60, 61, 62, 66, 67, 68, 72, 78, 84, 89, 91, 92, 93, 96, 98, 101, 103, 104, 106, 107, 109, 113, 115], "reus": [0, 18, 34, 60, 61, 62], "previou": [0, 4, 18, 22, 30, 56, 59, 65, 67, 91, 96, 98, 108], "snippet": [0, 18, 39, 49, 61, 84, 87], "func_callback_arg": [0, 18, 33, 45, 46, 59, 66], "measur": [0, 15, 16, 17, 18, 20, 30, 56, 59, 66], "score": [0, 1, 2, 3, 4, 7, 10, 11, 20, 21, 30, 51, 53, 56, 59, 66, 70, 98, 101, 112], "respecit": [0, 18], "both": [0, 4, 11, 14, 15, 16, 17, 18, 23, 24, 35, 49, 51, 61, 66, 68, 69, 72, 73, 79, 84, 87, 88, 89, 103, 104, 106, 107, 108, 109, 111, 115], "qualiti": [0, 18], "slightli": [0, 18], "goal": [0, 18, 37, 42, 46, 53, 66, 93], "rough": [0, 18], "wherea": [0, 18, 59, 91, 109], "callbak": [0, 18], "impli": [0, 18, 45, 59], "flexibl": [0, 18], "than": [0, 7, 8, 18, 21, 29, 30, 49, 51, 52, 56, 59, 61, 62, 65, 68, 72, 84, 87, 91, 100, 106, 112], "smaller": [0, 5, 13, 18, 51, 52, 59, 92, 99, 108, 111, 114], "indirect": [0, 18], "sqnr": [0, 4, 18, 59, 85, 109], "between": [0, 13, 18, 30, 36, 51, 53, 56, 58, 59, 65, 66, 68, 72, 75, 84, 89, 104, 105, 107, 109], "faster": [0, 1, 5, 6, 7, 13, 15, 16, 17, 18, 19, 20, 33, 85, 92, 99, 106], "correl": [0, 18], "metric": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 30, 37, 39, 51, 56, 68, 105, 109], "aimet_torch": [0, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 102], "mixed_precision_algo": [0, 4, 18, 59], "evalcallbackfactori": [0, 18, 59], "forward_one_batch": [0, 18], "label": [0, 4, 5, 6, 7, 10, 11, 13, 18, 20, 30, 33, 37, 46, 51, 53, 66, 68, 105, 106], "eval_callback_factori": [0, 18], "forward_fn": [0, 1, 7, 18, 21, 41, 51, 54, 59, 87], "small": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 20, 22, 23, 24, 25, 51, 68, 94, 99, 103], "hand": [0, 18, 103], "miou": [0, 18], "full": [0, 4, 7, 18, 21, 30, 33, 34, 38, 60, 67, 89, 114], "appli": [0, 2, 7, 8, 14, 15, 16, 17, 18, 20, 21, 22, 28, 30, 31, 36, 38, 41, 51, 53, 55, 56, 62, 65, 67, 69, 71, 77, 78, 79, 84, 87, 89, 90, 91, 92, 93, 94, 97, 98, 101, 103, 104, 106, 107, 108, 109, 110, 112, 113], "dummi": [0, 12, 18, 25, 28, 39, 41, 51, 52, 53, 57, 58, 59, 65, 66, 68, 87, 105], "one": [0, 1, 4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 23, 24, 25, 36, 49, 51, 52, 59, 61, 62, 64, 65, 68, 74, 84, 87, 89, 91, 95, 97, 101, 106, 107, 110, 111, 114], "tupl": [0, 4, 12, 18, 25, 28, 30, 37, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 68, 79, 84, 85, 87, 90], "expect": [0, 1, 7, 15, 16, 17, 18, 21, 34, 36, 37, 41, 46, 48, 51, 52, 56, 59, 61, 62, 66, 68, 83, 87, 91, 101, 103, 105], "group": [0, 18, 36, 74, 84, 107, 109], "list": [0, 4, 7, 9, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 31, 35, 36, 45, 51, 54, 55, 56, 57, 58, 59, 61, 65, 66, 68, 71, 79, 84, 87, 89, 90, 98, 100, 102, 107], "modul": [0, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 34, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 71, 73, 77, 78, 83, 84, 87, 88, 91, 92, 103, 110, 115], "therefor": [0, 4, 7, 8, 9, 18, 59, 64, 91, 96, 104], "might": [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 18, 19, 22, 23, 24, 25, 49, 51, 59, 68, 101, 105], "front": [0, 4, 18, 45, 59], "candid": [0, 4, 15, 16, 17, 18, 30, 31, 33, 45, 56, 59, 98, 101], "possibl": [0, 2, 4, 6, 9, 14, 18, 20, 22, 33, 34, 35, 53, 59, 60, 62, 68, 84, 91, 105, 107, 108], "suppos": [0, 4, 18, 59], "combin": [0, 4, 6, 15, 16, 17, 18, 20, 55, 59, 61, 84, 93, 96, 101, 103, 104], "type": [0, 4, 6, 7, 9, 12, 15, 16, 17, 18, 20, 23, 24, 28, 29, 30, 33, 37, 45, 46, 51, 52, 53, 54, 55, 56, 59, 61, 64, 65, 66, 68, 71, 72, 77, 78, 82, 83, 84, 87, 89, 90, 103, 105, 107, 109, 112], "int": [0, 4, 6, 7, 12, 15, 16, 17, 18, 20, 29, 30, 33, 42, 45, 49, 51, 53, 54, 55, 56, 59, 64, 66, 68, 69, 72, 79, 80, 81, 84, 85, 90], "16": [0, 4, 7, 18, 22, 28, 30, 33, 45, 48, 49, 51, 59, 61, 64, 68, 69, 73, 77, 78, 79, 80, 81, 84, 87, 89, 90, 92], "quantizationdatatyp": [0, 4, 18, 33, 45, 59, 68, 72], "allowed_accuracy_drop": [0, 4, 6, 18, 20, 33, 42, 45, 53, 59], "maximum": [0, 4, 5, 6, 7, 12, 13, 14, 18, 25, 28, 51, 59, 68, 79, 80, 81, 85, 89], "allow": [0, 4, 6, 8, 18, 20, 30, 32, 33, 35, 38, 44, 45, 47, 49, 56, 58, 59, 60, 61, 67, 68, 82, 84, 89, 93, 99, 101, 103, 105, 106, 107, 108, 109, 110, 112], "drop": [0, 4, 6, 7, 8, 10, 11, 15, 16, 17, 18, 20, 21, 23, 24, 33, 45, 59, 67, 68, 89, 93, 96, 101, 104, 105, 106, 108, 109], "plot": [0, 4, 12, 18, 25, 59, 71, 83, 105], "till": [0, 4, 18, 59], "met": [0, 4, 18, 59, 98], "complet": [0, 4, 6, 15, 16, 17, 18, 20, 30, 59, 91, 94, 108], "pick": [0, 4, 18, 30, 35, 36, 56, 59, 96, 98, 101], "results_dir": [0, 4, 12, 18, 25, 37, 45, 46, 53, 59, 66, 71], "cach": [0, 4, 18, 45, 53, 59, 75], "intermedi": [0, 4, 18, 32, 44, 52, 58, 59, 68, 109], "clean_start": [0, 4, 18, 45, 59], "inform": [0, 4, 18, 21, 49, 55, 59, 62, 65, 67, 72, 82, 87, 103, 105], "delet": [0, 4, 18, 59], "prior": [0, 4, 18, 19, 22, 23, 24, 59, 95, 103, 105], "start": [0, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 21, 23, 24, 25, 30, 33, 35, 45, 51, 56, 59, 61, 62, 68, 79, 91, 92, 97, 98, 101, 107, 109], "analysi": [0, 4, 8, 15, 16, 17, 18, 20, 30, 37, 46, 56, 59, 66, 101, 108], "applic": [0, 4, 5, 6, 10, 11, 12, 13, 14, 18, 30, 31, 33, 36, 37, 39, 49, 59, 65, 98, 102], "respons": [0, 4, 18, 59, 89, 101], "flag": [0, 4, 15, 17, 18, 33, 36, 53, 59, 61, 68, 72, 83, 90], "anyth": [0, 4, 12, 18, 25, 59], "compar": [0, 4, 7, 8, 9, 10, 11, 12, 18, 21, 25, 52, 59, 61, 71, 84, 87, 91, 105, 106, 113], "use_all_amp_candid": [0, 18, 59], "supported_kernel": [0, 18, 59], "field": [0, 18, 49, 59], "config": [0, 13, 18, 59, 66, 107, 110], "under": [0, 18, 22, 31, 59, 72, 78, 83, 84, 87, 89, 97, 105, 107, 112, 113], "op_typ": [0, 7, 18, 59, 107], "section": [0, 6, 7, 18, 20, 22, 52, 59, 62, 74, 75, 84, 92, 94, 95, 97, 101, 103, 109], "ignor": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 30, 51, 55, 56, 59, 61, 68, 91], "continu": [0, 11, 18, 24, 35, 59, 62, 68, 103, 104, 106, 108], "amp_search_algo": [0, 18, 59], "ampsearchalgo": [0, 18, 59], "search": [0, 7, 8, 10, 11, 15, 16, 17, 18, 21, 23, 24, 26, 28, 51, 59, 68, 85, 98, 106, 107], "binari": [0, 18, 59, 98], "interpol": [0, 18, 89, 98], "bruteforc": [0, 18], "phase1_optim": [0, 18, 59], "implement": [0, 18, 37, 42, 46, 53, 58, 66, 68, 69, 77, 78, 89, 102, 108], "either": [0, 5, 13, 14, 15, 16, 17, 18, 19, 26, 30, 51, 56, 60, 64, 84, 99, 109], "optmiz": [0, 18], "phase1": [0, 18, 59], "001": [0, 18, 39], "p": [0, 18, 74], "store": [0, 4, 18, 51, 64, 68, 82, 84, 87], "final": [0, 4, 7, 8, 10, 11, 12, 18, 21, 25, 35, 45, 56, 59, 62, 70, 75, 84, 95, 96, 98, 106, 108, 112], "after": [0, 1, 2, 4, 5, 7, 8, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 28, 29, 36, 42, 51, 53, 54, 61, 62, 65, 66, 68, 71, 77, 78, 87, 89, 91, 92, 93, 94, 96, 101, 103, 106, 108, 112, 113], "multipli": [0, 18, 89, 96], "mac": [0, 15, 16, 17, 18, 30, 56, 70, 96, 101, 111, 114], "therebi": [0, 18], "lesser": [0, 18, 98, 101], "re": [0, 9, 18, 38, 59, 67, 91, 97, 103], "mixed_precis": [0, 4, 18, 33, 45, 59], "choose_mixed_precis": [0, 4, 18, 33, 45, 59], "pareto_front_list": [0, 18, 45, 59], "next": [0, 1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 51, 64, 65, 68, 74, 91, 108], "step": [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 36, 42, 51, 53, 54, 61, 64, 66, 68, 79, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 108, 109], "would": [0, 1, 4, 5, 7, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 30, 31, 35, 51, 57, 68, 72, 84, 96, 101, 107, 110, 112], "actual": [0, 4, 7, 9, 18, 21, 23, 24, 32, 37, 42, 44, 46, 51, 53, 58, 63, 66, 68, 84, 96, 103], "take": [0, 1, 4, 5, 6, 7, 9, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 51, 56, 59, 65, 68, 78, 84, 91, 99, 101, 103, 104, 106, 107, 108, 115], "o": [0, 1, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 33, 56], "makedir": [0, 1, 4, 5, 7, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24], "exist_ok": [0, 1, 4, 5, 7, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24], "filename_prefix": [0, 1, 4, 5, 7, 13, 14, 18, 19, 21, 22, 23, 24, 28, 33, 51, 64, 68], "resnet18_mixed_precis": [0, 18], "hope": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "wa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 30, 32, 44, 49, 51, 56, 58, 64, 82, 95, 101, 107], "understand": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 72, 103, 107, 112, 113], "qat": [0, 1, 2, 5, 8, 13, 14, 18, 19, 22, 29, 48, 51, 54, 63, 67, 87, 91, 92, 94, 97, 99, 103, 108, 109, 110], "learn": [0, 1, 2, 5, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 28, 29, 30, 31, 39, 41, 42, 43, 51, 53, 54, 55, 56, 57, 66, 68, 72, 94, 97, 101, 103, 106, 109, 110], "addit": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 49, 68, 78, 84, 87, 93, 103, 106, 107, 110], "resourc": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "doc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 61, 64, 105, 107, 112], "know": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "nearest": [1, 2, 4, 5, 8, 10, 11, 13, 14, 19, 22, 48, 53, 55, 68, 92], "achiev": [1, 5, 11, 13, 15, 16, 17, 19, 20, 30, 56, 74, 84, 92, 96, 98, 111, 114], "loss": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 19, 22, 23, 24, 37, 39, 46, 51, 66, 68, 82, 88, 91, 92, 99, 103, 105, 109], "function": [1, 2, 4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 78, 82, 83, 84, 89, 91, 92, 98, 101, 102, 103, 105, 109, 110, 112, 113], "closer": [1, 5, 13, 19, 92], "farther": [1, 19], "abl": [1, 2, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 35, 61, 62, 66, 82, 91, 92, 112, 113], "low": [1, 5, 13, 15, 17, 19, 22, 67, 88, 92, 94, 101, 103, 104, 108], "simuat": [1, 2, 5, 13, 14, 19, 22, 23, 24], "post": [1, 2, 5, 6, 7, 8, 10, 11, 13, 14, 19, 20, 21, 22, 23, 24, 38, 47, 48, 49, 53, 67, 88, 91, 92, 93, 99, 101, 106, 109, 110], "finetun": [1, 2, 5, 6, 7, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 48, 68], "paramet": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 29, 33, 35, 37, 38, 45, 46, 47, 49, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 89, 90, 91, 92, 94, 95, 101, 102, 103, 104, 105, 106, 107, 113], "otherwis": [1, 19, 62, 64, 68, 74, 75, 79, 84, 90, 108], "run": [1, 2, 3, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 30, 32, 35, 37, 38, 41, 42, 44, 45, 48, 49, 52, 53, 54, 56, 58, 59, 61, 62, 68, 72, 74, 75, 79, 84, 89, 90, 94, 99, 101, 103, 104, 105, 109, 110, 112], "still": [1, 2, 5, 6, 7, 10, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 34, 67, 84, 103, 108], "put": [1, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 59], "interfac": [1, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 67, 73], "method": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 33, 55, 58, 59, 61, 68, 72, 77, 78, 84, 87, 89, 91, 98, 101, 103, 108, 109], "exist": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 45, 51, 59, 68, 74, 77, 78, 84, 103, 109], "framework": [1, 2, 3, 26, 48, 99, 103, 107, 109], "altogeth": [1, 2, 3, 107], "precis": [1, 2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 19, 21, 22, 23, 24, 25, 49, 51, 79, 80, 81, 88, 90, 103], "call": [1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 29, 30, 31, 33, 34, 35, 36, 45, 46, 49, 51, 56, 57, 59, 61, 65, 66, 68, 77, 78, 80, 81, 82, 84, 89, 91, 94, 101, 103, 105, 107, 109, 110, 111, 114], "case": [1, 3, 8, 9, 12, 25, 37, 42, 46, 49, 53, 60, 61, 62, 64, 66, 72, 75, 79, 84, 89, 91, 98, 104, 106, 107], "compil": [1, 3, 6, 7, 8, 12, 37, 39], "via": [1, 3, 35, 67, 88, 96, 99, 109], "user_onnx_lib": [1, 3], "custom_op1": [1, 3], "custom_op2": [1, 3], "api": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 34, 60, 63, 72, 74, 78, 83, 91, 97, 99, 102, 103, 107, 110, 112], "copi": [1, 18, 19, 22, 23, 24, 35, 68, 71, 97, 109], "deepcopi": [1, 71], "fairli": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68], "simpl": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 28, 37, 46, 51, 56, 61, 66, 68, 91, 103, 115], "loader": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 21, 22, 23, 24, 25, 33, 37, 46, 48, 51, 54, 55, 59, 66, 68, 91, 92], "extract": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68, 104], "don": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 61, 64, 68, 92], "pointer": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68], "regard": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 59, 68], "veri": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 20, 22, 23, 24, 25, 51, 68, 69, 94, 96, 101, 105, 113, 115], "percentag": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68], "1m": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68], "500": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 19, 20, 22, 23, 24, 25, 33, 42, 51, 56, 68, 91, 92, 104, 105], "scenario": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68, 94, 101, 103, 115], "pictur": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68, 88, 95, 99], "captur": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 32, 44, 51, 58, 61, 68, 98], "night": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 51, 68], "give": [1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 33, 51, 68, 69, 111, 114], "ideal": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 51, 68], "first": [1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 15, 16, 17, 19, 21, 22, 23, 24, 25, 30, 35, 38, 51, 61, 67, 69, 89, 91, 96, 101, 103, 106, 112], "u": [1, 2, 3, 5, 8, 13, 19, 22, 23, 24, 51, 74, 108], "saw": [1, 2, 3, 5, 13, 19, 22, 23, 24], "describ": [1, 5, 13, 19, 39, 49, 51, 61, 68, 72, 84, 103, 104, 108, 109], "over": [1, 35, 42, 53, 56, 66, 79, 85, 89, 92, 98, 101, 113], "vector": [1, 5, 13, 19, 51, 87], "compli": [1, 18, 19, 22, 23, 24, 25, 51, 68], "signatur": [1, 15, 16, 17, 28, 37, 42, 46, 56, 66, 78, 79], "num_batch": [1, 2, 5, 6, 7, 12, 13, 14, 19, 20, 21, 22, 25, 28, 37, 41, 42, 46, 51, 53, 54, 66], "around": [1, 5, 8, 13, 19, 37, 46, 48, 51, 66, 68, 102], "2000": [1, 5, 6, 13, 19, 20, 22, 42, 51, 53, 79, 82], "size": [1, 5, 6, 7, 8, 9, 13, 19, 33, 35, 39, 48, 51, 52, 53, 62, 66, 68, 77, 78, 79, 84, 87, 89, 90, 92, 101, 102, 111, 114], "translat": [1, 5, 13, 15, 16, 17, 19, 51], "64": [1, 5, 13, 19, 34, 35, 37, 46, 48, 51, 66, 68, 73, 79, 84, 85, 90, 92], "default_num_iter": [1, 5, 13, 19, 20, 28, 41, 51], "strongli": [1, 5, 13, 19, 35, 51, 61], "adaround_weight": [1, 5, 6, 13, 19, 20, 28, 41, 42, 51, 53, 67, 72], "adaroundparamet": [1, 5, 6, 13, 19, 20, 28, 41, 42, 51, 53, 67], "satisfi": [1, 20, 61, 84, 91, 93], "deriv": [1, 4, 18, 49, 79, 89, 90], "form": [1, 12, 25, 35, 69, 77, 97], "arrai": [1, 84], "__init__": [1, 9, 20, 34, 35, 52, 53, 56, 60, 61, 62, 69, 77, 78, 89, 91], "self": [1, 9, 20, 34, 35, 52, 53, 56, 60, 61, 62, 69, 82, 91], "_torch_data_load": 1, "_iter": 1, "__iter__": 1, "__next__": 1, "__len__": [1, 20, 53, 66], "len": [1, 4, 8, 18, 20, 30, 33, 42, 51, 53, 61], "ada_model": [1, 5, 13, 19], "apply_adaround": [1, 5, 13, 19, 28, 41, 51], "default_quant_schem": [1, 5, 13, 19, 28, 51], "again": [1, 2, 5, 13, 14, 15, 16, 17, 19, 22, 105, 106, 112], "two": [1, 2, 4, 5, 8, 9, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 30, 33, 35, 36, 56, 59, 61, 62, 65, 72, 73, 84, 89, 91, 98, 99, 101, 103, 104, 105, 106, 109, 111, 112, 113, 114], "thing": [1, 5, 13, 19, 103], "biwidth": [1, 5, 13, 19], "must": [1, 5, 7, 8, 10, 11, 12, 13, 19, 25, 35, 51, 78, 84, 87, 89, 94, 99, 100, 105, 107, 115], "freez": [1, 5, 13, 19, 28, 51, 64, 72, 92], "set_and_freeze_param_encod": [1, 5, 13, 19, 28, 41, 51], "been": [1, 5, 6, 7, 8, 13, 14, 15, 16, 17, 19, 20, 35, 51, 62, 71, 78, 82, 83, 84, 87, 103, 106, 109, 115], "down": [1, 2, 5, 13, 14, 19, 22, 49, 51], "intern": [1, 5, 6, 8, 9, 13, 19, 35, 51, 53, 68, 69, 72, 101, 103, 104, 107], "NOT": [1, 5, 13, 19, 51, 94, 115], "frozen": [1, 5, 13, 19, 51], "alter": [1, 5, 13, 19, 51], "reflect": [1, 19, 103, 109], "encoding_path": [1, 5, 6, 13, 19, 20, 28, 42, 51, 53], "join": [1, 5, 10, 11, 13, 18, 19, 20, 56, 70], "newli": [1, 19], "updat": [1, 5, 9, 10, 11, 13, 14, 19, 22, 23, 24, 49, 51, 52, 68, 70, 72, 75, 90, 97, 103, 104, 106, 109, 110], "depend": [1, 5, 13, 15, 16, 17, 19, 22, 23, 24, 61, 72, 74, 75, 82, 96, 97, 98, 103, 107, 110], "observ": [1, 5, 13, 15, 16, 17, 19, 21, 22, 23, 24, 71, 77, 78, 85, 89, 90, 91, 98, 101, 103, 104, 105, 106, 109], "slight": [1, 5, 13, 15, 16, 17, 19, 22, 23, 24], "gain": [1, 5, 13, 15, 16, 17, 19, 22, 23, 24, 95, 101], "serv": [1, 19, 37, 42, 46, 53, 66, 89, 112], "workflow": [1, 19, 88, 91, 96, 99], "against": [1, 5, 13, 15, 16, 17, 19, 21, 22, 23, 24, 37, 46, 66, 71], "choic": [1, 2, 5, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 37, 49, 101, 109], "plai": [1, 5, 13, 15, 16, 17, 19, 22, 23, 24], "best": [1, 5, 6, 13, 15, 16, 17, 19, 20, 22, 23, 24, 53, 93, 96, 101, 103, 109], "without": [1, 5, 6, 8, 11, 13, 14, 19, 20, 22, 23, 24, 51, 64, 68, 78, 80, 81, 82, 83, 84, 87, 89, 93, 103, 106, 109, 115], "resnet18_after_adaround": [1, 19], "illustr": [1, 5, 13, 19, 68, 92, 98, 103, 111, 114], "invok": [1, 5, 13, 19, 28, 30, 36, 38, 51, 56, 66, 67, 68, 77, 78, 89, 101, 103, 112, 113], "indic": [1, 5, 13, 15, 16, 17, 18, 19, 20, 30, 36, 49, 53, 56, 69, 89, 96, 115], "make": [1, 5, 7, 8, 9, 13, 19, 21, 29, 34, 36, 38, 60, 63, 67, 84, 89, 98, 101, 102, 103, 109], "showcas": [2, 12, 14, 22, 25], "aim": [2, 7, 14, 15, 16, 17, 21, 22, 29], "improv": [2, 3, 7, 8, 10, 11, 14, 15, 16, 17, 21, 22, 23, 24, 26, 51, 68, 84, 91, 96, 103, 106, 108, 113], "help": [2, 12, 14, 22, 25, 52, 62, 64, 68, 71, 92, 98, 101, 103, 104, 105, 108, 112, 113], "recov": [2, 14, 15, 16, 17, 22, 88, 99, 108, 109], "oppos": [2, 14, 22, 103, 107], "about": [2, 4, 9, 14, 21, 22, 28, 30, 31, 39, 41, 42, 43, 48, 49, 51, 53, 55, 56, 57, 65, 66, 67, 68, 82, 91], "free": [2, 7, 8, 10, 11, 14, 15, 16, 17, 21, 22, 23, 24, 68, 74, 103, 104, 106], "bia": [2, 7, 14, 31, 36, 43, 52, 57, 61, 62, 64, 65, 67, 69, 72, 77, 78, 80, 81, 91, 92, 95, 103, 104, 107, 108, 110], "correct": [2, 5, 13, 14, 20, 25, 36, 51, 53, 65, 67, 75, 91, 92, 94, 103, 104, 108], "paper": [2, 14, 22, 104], "iccv": [2, 14, 22, 101, 104], "2019": [2, 14, 22, 104], "arxiv": [2, 14, 22, 104], "ab": [2, 14, 22, 89, 104], "1906": [2, 14, 22, 104], "04721": [2, 14, 22, 104], "norm": [2, 4, 14, 22, 33, 36, 52, 54, 65, 89, 92, 94, 103, 104, 105], "conv": [2, 7, 14, 22, 36, 51, 54, 55, 61, 65, 71, 84, 100, 107, 110, 111, 114, 115], "immedi": [2, 14, 20, 22], "consecut": [2, 14, 22, 36, 64, 65, 103, 104], "correspond": [2, 13, 14, 15, 16, 17, 20, 22, 28, 36, 51, 54, 58, 59, 64, 65, 66, 68, 73, 74, 75, 84, 87, 89, 95, 98, 103, 105, 115], "high": [2, 14, 15, 16, 17, 22, 31, 36, 43, 57, 59, 65, 72, 88, 92, 94, 96, 98, 99, 104, 108, 110, 113], "current": [2, 7, 8, 9, 15, 16, 17, 18, 19, 22, 23, 24, 25, 30, 33, 35, 52, 56, 59, 62, 63, 78, 83, 95, 99, 100, 101, 102, 107, 111, 114], "comput": [2, 5, 7, 8, 12, 13, 15, 16, 17, 19, 22, 23, 24, 25, 28, 30, 32, 37, 39, 44, 46, 48, 49, 51, 53, 56, 58, 59, 63, 64, 66, 68, 69, 73, 75, 77, 78, 80, 81, 84, 85, 87, 91, 92, 101, 102, 103, 104, 105, 109, 112, 115], "encod": [2, 5, 6, 7, 8, 13, 19, 20, 22, 23, 24, 28, 32, 37, 39, 41, 44, 46, 48, 51, 53, 54, 58, 59, 63, 64, 66, 67, 68, 69, 72, 77, 78, 79, 82, 83, 84, 87, 88, 90, 91, 92, 94, 103, 105, 106, 110], "5": [2, 4, 8, 13, 15, 16, 17, 22, 23, 24, 30, 41, 42, 45, 53, 54, 56, 59, 61, 64, 68, 69, 70, 72, 73, 79, 80, 81, 84, 89, 90, 96, 106, 108], "suffici": [2, 14, 22, 103, 105, 106, 109], "rounding_mod": [2, 4, 5, 8, 10, 11, 13, 14, 22, 48, 53, 68], "round": [2, 13, 14, 22, 30, 38, 47, 53, 55, 56, 67, 68, 87, 88, 89, 92, 97, 103, 105, 109], "mode": [2, 14, 15, 16, 17, 22, 30, 31, 43, 53, 55, 56, 57, 61, 63, 65, 68, 70, 85, 90, 102, 103, 107], "stochast": [2, 14, 22, 55, 68], "interestingli": [2, 14, 22], "procedur": [2, 14, 15, 16, 17, 22, 98, 101], "cl": [2, 14, 22, 36, 65, 78, 110], "skip": [2, 14, 22, 31, 33, 51, 53, 55, 74, 95], "hba": [2, 14, 22], "absorpt": [2, 14, 22], "cross_layer_equ": [2, 14, 22, 31, 36, 43, 57, 65, 71, 72, 102], "equalize_model": [2, 14, 22, 31, 43, 57, 71, 72, 102], "add": [3, 7, 24, 34, 35, 49, 60, 61, 62, 64, 68, 74, 78, 89, 91, 107, 109, 110, 112, 113, 115], "ml": [3, 8, 10, 11, 23, 24, 26, 68, 101, 103, 104, 112, 113], "order": [3, 7, 8, 9, 10, 11, 12, 15, 16, 17, 21, 23, 24, 25, 34, 36, 38, 60, 62, 65, 67, 68, 74, 75, 77, 84, 91, 94, 95, 96, 103, 106, 109, 113], "estim": [3, 38, 67, 91, 103, 104], "deploi": [3, 88, 109], "acceler": [3, 8, 10, 11, 23, 24, 56, 68, 73, 88, 99, 101], "awar": [3, 29, 38, 54, 63, 92, 94, 97, 99, 103, 108, 109], "adaround": [3, 42, 47, 53, 67, 72, 88, 93, 97, 103, 108, 110], "cross": [3, 38, 47, 53, 55, 63, 67, 71, 92, 93, 97, 102, 103, 105, 113], "equal": [3, 9, 38, 47, 53, 55, 63, 67, 71, 82, 84, 89, 92, 93, 96, 97, 98, 102, 103, 105, 113], "emploi": [3, 23, 24, 51, 68], "automat": [3, 20, 30, 36, 56, 65, 74, 75, 84, 96, 101, 103, 105, 110], "quantizationsimul": 3, "layer": [4, 8, 15, 16, 17, 30, 34, 35, 37, 38, 39, 46, 47, 51, 52, 53, 54, 55, 56, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 77, 78, 83, 84, 87, 89, 91, 92, 93, 94, 95, 96, 97, 100, 102, 103, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115], "an": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 33, 34, 35, 37, 45, 46, 48, 49, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 66, 68, 69, 72, 73, 77, 78, 82, 83, 84, 88, 89, 90, 91, 92, 93, 95, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 113, 115], "resnet50": [4, 5, 6, 10, 11, 12, 13, 14, 30, 31, 33, 36, 37, 39], "disabl": [4, 15, 17, 64, 66, 68, 72, 89, 98, 101, 105, 107, 109], "log": [4, 7, 8, 10, 11, 28, 33, 62, 89, 105], "info": [4, 36, 52, 55, 62, 65, 91, 110], "level": [4, 8, 57, 72, 88, 94, 96, 98, 99, 103, 108, 112], "verbos": 4, "displai": [4, 8, 97, 105, 112, 113], "erorr": 4, "tensorflow": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 25, 26, 73, 74, 94, 97, 99, 100, 103, 107, 109, 110], "messag": 4, "error": [4, 6, 33, 35, 53, 61, 93, 103, 106, 108, 109], "critic": 4, "tf_cpp_min_log_level": [4, 6, 7, 10, 11, 33], "compat": [4, 7, 8, 33, 49, 60, 73, 83, 84, 91], "v1": [4, 33, 72], "set_verbos": [4, 33], "evlauat": 4, "kera": [4, 5, 6, 10, 11, 12, 13, 14, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 92, 94, 97, 99, 103, 104, 105, 107, 109, 110], "preprocess_input": [4, 5, 10, 11, 13, 14, 30, 33], "decode_predict": [4, 30, 33], "center_crop": [4, 33], "img_height": 4, "256": [4, 18, 33, 37, 46, 66, 87, 91, 105], "img_width": 4, "crop_length": 4, "start_x": 4, "start_i": 4, "cropped_imag": 4, "get_eval_func": [4, 30, 33], "num_iter": [4, 6, 30, 33], "50000": [4, 30, 33], "debug": [4, 26, 27, 28, 32, 40, 44, 49, 50, 58, 72, 91, 108], "get_top5_acc": 4, "func_wrapp": [4, 30, 33], "validation_d": [4, 30, 33], "preprocess": [4, 5, 8, 10, 11, 13, 30, 33], "image_dataset_from_directori": [4, 5, 10, 11, 13, 30, 33], "label_mod": [4, 5, 10, 11, 13, 30, 33], "categor": [4, 5, 10, 11, 13, 30, 33], "shuffl": [4, 5, 10, 11, 13, 30, 33, 56, 91], "top1": [4, 20, 30, 33], "top5": 4, "total": [4, 9, 30, 33, 91, 98, 109], "img": [4, 30, 33], "pred": [4, 18, 30, 33, 42], "predict": [4, 12, 30, 32, 33, 37, 53, 103], "np": [4, 9, 28, 30, 33, 35, 37, 39, 42, 45, 46, 48], "class_nam": [4, 9, 30, 33], "cnt": [4, 30, 33], "sum": [4, 18, 20, 30, 33, 53, 89, 91], "b": [4, 30, 33, 54, 64, 78, 79, 90], "zip": [4, 30, 33, 37], "str": [4, 9, 30, 33, 45, 51, 53, 55, 58, 59, 60, 61, 64, 66, 68, 71, 83, 87], "eval_func": [4, 12, 30, 33, 70], "aimet_tensorflow": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 28, 29, 30, 31, 32, 35, 36, 37, 39, 73, 75], "fold_all_batch_norm": [4, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24, 33, 36, 65, 71, 91], "get_model": [4, 33, 34], "include_top": [4, 5, 13, 14, 33], "input_tensor": [4, 5, 13, 14, 33, 35, 48, 59, 61], "pool": [4, 5, 7, 13, 14, 33], "batch": [4, 6, 7, 15, 16, 17, 21, 28, 29, 30, 33, 36, 37, 46, 48, 51, 52, 54, 58, 59, 65, 66, 68, 92, 94, 103, 104, 105], "fold": [4, 29, 31, 33, 36, 43, 52, 53, 54, 57, 65, 67, 71, 89, 92, 93, 94, 103, 104, 105, 110], "acccuraci": 4, "fp32_acccuraci": 4, "sim": [4, 5, 7, 8, 13, 19, 20, 28, 33, 41, 42, 45, 51, 53, 54, 55, 59, 63, 64, 66, 72, 83, 84, 87, 88, 91, 106, 109], "solut": [4, 18, 98, 106, 108], "less": [4, 18, 52, 84, 85, 89, 95, 98], "convert": [4, 14, 18, 34, 35, 36, 59, 61, 69, 82, 91, 93, 103, 113], "overhead": [4, 15, 17, 18], "done": [4, 9, 13, 14, 15, 16, 17, 21, 23, 24, 34, 74, 79, 90, 95, 101, 107, 109, 115], "defin": [4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 28, 34, 35, 37, 38, 42, 45, 46, 49, 51, 53, 56, 59, 60, 61, 62, 66, 67, 68, 77, 84, 89, 91, 102, 103, 105, 107, 109], "separ": [4, 15, 16, 17, 23, 24, 35, 51, 61, 62, 65, 68, 72, 87, 94, 105, 108, 110], "larg": [4, 64, 96, 106, 111, 114], "enough": [4, 15, 16, 17, 52], "meaning": 4, "": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 30, 31, 33, 34, 35, 37, 42, 45, 46, 48, 49, 51, 54, 55, 56, 59, 61, 65, 66, 68, 69, 71, 75, 77, 78, 84, 88, 89, 90, 91, 96, 100, 101, 103, 104, 105, 106, 108, 109, 112, 113, 115], "One": [4, 12, 18, 19, 22, 23, 24, 25, 91, 96, 101, 111], "opt": [4, 87], "01": [4, 6, 20, 42, 51, 53, 79, 92], "discuss": [4, 91, 96, 108, 109], "eval_callback_phase1": 4, "eval_callback_phase2": 4, "forward_pass_call_back": [4, 33, 45, 59], "greedymixedprecisionalgo": [4, 18, 33, 59], "enabl": [4, 11, 13, 15, 17, 18, 24, 26, 33, 54, 56, 59, 64, 66, 72, 73, 74, 84, 88, 94, 99, 103, 105, 107, 109, 110], "enable_convert_op_reduct": [4, 18, 33, 59], "acuraci": [4, 33], "time": [4, 6, 12, 15, 16, 17, 20, 25, 30, 36, 49, 56, 61, 62, 84, 87, 91, 93, 101, 102, 106, 112], "wrapper": [4, 8, 14, 18, 19, 22, 23, 24, 28, 33, 37, 46, 56, 66], "callback": [4, 8, 10, 11, 12, 15, 16, 17, 25, 30, 33, 37, 42, 46, 53, 56, 59, 66, 68, 105, 109], "get_data_loader_wrapp": [4, 33], "dataloader_wrapp": [4, 33], "map": [4, 5, 6, 7, 9, 13, 33, 37, 49, 62, 64, 77, 78, 79, 82, 84, 89, 105, 107], "lambda": [4, 5, 6, 7, 8, 9, 13, 33, 37, 59, 84], "y": [4, 5, 12, 13, 25, 33, 39, 61, 74, 75, 91, 105], "data_loader_wrapp": [4, 33], "choose_fast_mixed_precis": [4, 33], "resnet50_after_amp": 4, "awai": [5, 13, 92], "dir": [5, 6, 7, 11, 12, 13, 14, 69, 75], "image_net_dataset": [5, 6, 7, 12, 13, 14], "imagenetdataset": [5, 6, 7, 12, 13, 14], "get_val_dataset": [5, 6, 7, 12, 13, 14], "10": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 21, 23, 24, 28, 30, 34, 35, 36, 39, 54, 56, 61, 62, 64, 68, 69, 70, 73, 74, 75, 77, 78, 79, 82, 84, 89, 90, 91, 98, 101, 106], "dure": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 21, 23, 24, 25, 28, 29, 30, 35, 51, 56, 59, 68, 70, 77, 83, 87, 89, 91, 92, 99, 101, 103, 106, 107, 109, 112, 113], "new": [5, 9, 10, 11, 13, 14, 18, 19, 22, 23, 24, 25, 34, 35, 45, 49, 51, 59, 60, 61, 64, 68, 72, 74, 79, 84, 87, 88, 90, 91, 103, 107, 110], "rest": [5, 10, 11, 13, 14, 108], "progbar": [5, 10, 11, 13, 14], "sim_model": [5, 10, 11, 12, 13, 14, 19, 21, 22, 23, 24, 25, 51, 68], "tf_dataset": [5, 13, 14], "progbar_stat_upd": [5, 10, 11, 13, 14], "data_set": [5, 13, 28], "ada_round_data": [5, 13], "image_width": [5, 13], "image_height": [5, 13], "fo": [5, 13, 51], "r": [5, 13, 51, 59, 64, 66], "Of": [5, 13, 84], "cours": [5, 13], "resnet50_after_adaround": 5, "quick": [5, 9, 13, 97], "offer": [6, 20, 46, 66, 93], "suit": [6, 20, 93], "network": [6, 8, 9, 13, 20, 35, 89, 91, 93, 96, 98, 101, 103, 106, 108, 109, 112, 114], "quantiz": [6, 9, 15, 16, 17, 20, 26, 27, 28, 29, 32, 35, 37, 40, 42, 44, 46, 49, 50, 51, 53, 54, 58, 60, 61, 63, 64, 66, 77, 78, 80, 83, 85, 87, 88, 92, 93, 94, 96, 97, 99, 101, 105, 110, 112], "often": [6, 92, 93, 101, 106], "sequenc": [6, 8, 20, 52, 93, 94, 102, 107], "better": [6, 13, 21, 52, 71, 84, 92, 93, 103, 104, 106], "manual": [6, 15, 16, 17, 30, 49, 56, 65, 72, 79, 90, 93, 101], "out": [6, 9, 17, 35, 37, 38, 46, 47, 61, 64, 66, 67, 68, 79, 80, 81, 90, 93, 96, 101, 105], "variou": [6, 12, 15, 16, 17, 20, 25, 30, 56, 59, 93, 96, 101, 103, 108, 109, 110, 113], "prone": [6, 93], "consum": [6, 14, 20, 49, 93, 101], "analyz": [6, 20, 30, 38, 47, 56, 67, 79, 83, 88, 89, 90, 93, 95, 101, 102, 105, 109, 112, 113], "amount": [6, 12, 20, 25, 33, 93, 107], "toler": [6, 20, 93, 96], "soon": [6, 93], "threshold": [6, 83, 89, 93], "reach": [6, 20, 93, 96], "stop": [6, 51, 93], "autom": [6, 18, 19, 22, 23, 24, 25, 38, 51, 60, 61, 67, 68, 93, 103], "auto_qu": [6, 20, 42, 53], "creat": [6, 8, 12, 25, 28, 30, 35, 36, 37, 42, 44, 45, 46, 51, 53, 54, 56, 59, 61, 63, 64, 65, 66, 68, 69, 71, 77, 78, 83, 87, 88, 89, 91, 92, 94, 101, 102, 103, 106, 109], "eval_dataset_s": [6, 7, 20, 42, 53], "5000": [6, 20, 42, 45, 53, 59], "calibration_dataset_s": [6, 20, 42, 53], "20": [6, 7, 8, 9, 10, 11, 15, 16, 17, 21, 23, 24, 30, 35, 49, 51, 68, 73, 77, 78, 92, 106], "_create_sampled_data_load": [6, 20, 53], "eval_dataset": [6, 7, 37, 53], "unlabeled_dataset": [6, 7, 12, 37, 53], "eval_callback": [6, 7, 12, 15, 16, 17, 20, 25, 30, 33, 37, 42, 46, 53, 56, 66, 70], "dictionari": [6, 7, 9, 30, 56, 66, 68, 70, 98, 101, 107], "argument": [6, 7, 12, 25, 28, 32, 33, 37, 44, 45, 46, 51, 58, 59, 61, 66, 68, 78, 80, 81, 84], "num_sampl": [6, 7, 18, 20, 37, 53, 59], "whole": [6, 7, 84, 109], "sampled_dataset": [6, 7, 12], "adam": [6, 7, 8, 10, 11, 12, 37, 39, 91], "categoricalcrossentropi": [6, 7, 12, 37], "categoricalaccuraci": [6, 7, 12, 37], "acc": [6, 7, 8, 12, 37], "convei": 6, "much": [6, 11, 15, 16, 17, 24, 115], "seri": [6, 20, 68], "shown": [6, 12, 25, 36, 60, 63, 64, 72, 92, 101, 104, 105, 108], "adaround_dataset_s": [6, 20, 42, 53], "adaround_dataset": 6, "adaround_param": [6, 20, 42, 53], "set_adaround_param": [6, 20, 42, 53], "associ": [6, 12, 25, 28, 53, 59, 62, 77, 78, 89, 103], "eval_scor": [6, 30, 56, 66], "cle": [6, 20, 57, 63, 67, 92, 97, 103, 108, 110], "standalon": [6, 20, 52, 103], "fashion": [6, 13, 20, 84], "thi": [7, 8, 9, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115], "notebook": [7, 8, 9], "i": [7, 8, 9, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115], "counter": [7, 21, 38, 68], "potenti": [7, 21, 36, 38, 52, 102, 105, 112, 113], "instabl": [7, 21, 38], "varianc": [7, 21, 38, 104], "recalcul": [7, 21, 29], "By": [7, 18, 19, 21, 22, 23, 24, 29, 30, 35, 56, 64, 89, 101, 107, 109], "our": [7, 8, 10, 11, 14, 15, 16, 17, 21, 29, 46, 64, 66, 73, 75, 91, 98, 108, 109], "stabl": [7, 21, 29, 61, 69, 92], "rather": [7, 21, 29, 61, 112], "noisi": [7, 21, 29], "6": [7, 8, 9, 28, 35, 42, 51, 53, 61, 64, 68, 79, 84, 87, 106], "simul": [7, 8, 10, 11, 25, 32, 38, 39, 44, 47, 49, 51, 55, 58, 60, 63, 64, 67, 68, 80, 81, 84, 87, 88, 89, 91, 99, 103, 106, 110], "7": [7, 16, 17, 21, 23, 24, 36, 53, 54, 64, 68, 74, 75, 79, 80, 81, 91, 115], "accuraci": [7, 8, 12, 20, 21, 25, 26, 28, 30, 32, 33, 39, 42, 44, 45, 51, 53, 56, 58, 59, 64, 68, 84, 88, 91, 92, 93, 96, 98, 99, 101, 103, 104, 105, 106, 108, 109, 110, 113, 115], "helper": [7, 21, 33, 53, 59], "train_dataset_s": 7, "re_estimation_dataset_s": 7, "train_dataset": 7, "re_estimation_dataset": 7, "built": [7, 8, 59, 73, 74], "sequenti": [7, 8, 9, 34, 35, 72, 107, 108], "subclass": [7, 8, 34, 35], "incompat": [7, 8, 91], "backend": [7, 28], "clear_sess": [7, 28], "conv2d": [7, 8, 13, 15, 16, 17, 35, 49, 52, 61, 62, 65, 72, 84, 89, 91, 95, 101, 110, 115], "conv1": [7, 15, 16, 17, 35, 52, 56, 60, 61, 62, 65, 70, 91], "fuse": [7, 107, 109], "relu": [7, 8, 9, 34, 35, 36, 49, 52, 55, 60, 61, 62, 65, 69, 72, 89, 91, 104, 107, 115], "maxpooling2d": 7, "conv2": [7, 35, 49, 56, 60, 61, 65, 84, 91], "flatten": [7, 61, 89], "dens": [7, 8, 9, 34, 35, 69], "functional_model": [7, 8, 9], "fp32": [7, 8, 15, 16, 17, 25, 32, 44, 58, 59, 64, 66, 92, 99, 104, 105, 106, 108, 109], "baselin": [7, 8, 20, 33, 59, 91, 98, 106], "loss_fn": [7, 91], "fit": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 30, 39, 56, 68, 98], "epoch": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 39, 54, 56, 68, 91, 99, 101, 103, 106], "test": [7, 8, 9, 37, 46, 52, 54, 66, 69, 75], "training_range_learning_with_tf_init": [7, 11, 21, 24, 28, 51, 68, 83], "json": [7, 12, 14, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "default_config_per_channel": 7, "is_output_quant": [7, 107], "is_quant": [7, 107], "is_symmetr": [7, 49, 107], "strict_symmetr": [7, 107], "unsigned_symmetr": [7, 107], "per_channel_quant": [7, 13, 49, 89, 107], "squeez": [7, 18], "pad": [7, 35, 52, 61, 62, 89, 91], "supergroup": [7, 107, 110], "op_list": [7, 107], "clip": [7, 85, 107, 109], "gemm": [7, 107], "model_input": [7, 62, 107], "is_input_quant": [7, 107], "model_output": [7, 107], "open": 7, "tmp": [7, 12, 25, 53, 66, 91], "w": [7, 59, 66, 74, 115], "f": [7, 20, 42, 53, 61, 62, 74, 91], "dump": 7, "qsim": [7, 29, 69], "config_fil": [7, 12, 13, 25, 37, 46, 53, 55, 66, 68], "posit": [7, 8, 9, 35, 79], "15": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 68, 79, 101, 106], "job": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 68], "hyper": [7, 8, 15, 16, 17, 21, 23, 24, 68, 92, 106], "good": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 35, 64, 67, 68, 91, 92], "rate": [7, 8, 9, 10, 11, 15, 16, 17, 21, 23, 24, 35, 68, 101, 106], "end": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 28, 29, 31, 33, 51, 53, 54, 57, 61, 62, 66, 68, 79, 90, 91, 101], "factor": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 36, 65, 68, 84, 85, 96, 101, 104], "feel": [7, 8, 10, 11, 15, 16, 17, 21, 23, 24, 68, 74], "quantized_callback": [7, 8, 10, 11], "tensorboard": [7, 8, 10, 11], "log_dir": [7, 8, 10, 11], "histori": [7, 8, 10, 11], "validation_data": [7, 8, 10, 11], "reestimate_bn_stat": [7, 21, 29, 54], "reestim": [7, 29], "100": [7, 21, 29, 53, 54, 59, 72, 85, 87, 91], "adapt": [7, 13, 21, 38, 54, 64, 67, 88, 91, 92, 97, 103, 105, 110], "yield": [7, 21, 46, 51, 54, 59, 66, 109], "directli": [7, 11, 21, 29, 42, 63, 66, 72, 105, 109], "bn_reestim": [7, 21, 29, 54], "far": [7, 21, 92], "effici": [7, 21, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "fold_all_batch_norms_to_scal": [7, 21, 29, 54], "mnist_after_bn_re_estimation_qat_range_learn": 7, "exampl": [8, 9, 20, 34, 52, 60, 62, 63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 96, 98, 99, 103, 105, 107, 109, 110, 115], "standard": [8, 10, 11, 23, 24, 61, 68, 71, 80, 81, 89], "pipelin": [8, 32, 44, 53, 54, 58, 68, 103, 106, 108, 109], "fine": [8, 10, 11, 23, 24, 26, 39, 56, 64, 68, 88, 96, 99, 103, 106, 109], "tune": [8, 10, 11, 23, 24, 26, 39, 56, 64, 68, 88, 96, 99, 103, 106, 109], "1": [8, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115], "dataset": [8, 28, 29, 30, 33, 37, 42, 46, 48, 51, 53, 54, 55, 59, 66, 68, 91, 97, 103, 104, 109], "2": [8, 28, 30, 35, 36, 42, 48, 51, 52, 53, 54, 56, 58, 59, 61, 62, 64, 65, 66, 68, 69, 72, 73, 74, 79, 80, 81, 82, 84, 87, 90, 92, 103, 108, 109], "3": [8, 28, 30, 31, 33, 36, 37, 39, 42, 43, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 79, 82, 84, 85, 91, 96, 103, 106, 108, 115], "evalu": [8, 20, 28, 30, 33, 37, 39, 46, 48, 51, 53, 56, 59, 66, 68, 70, 91, 93, 97, 98, 101, 103, 105, 106, 109, 112], "4": [8, 12, 15, 25, 28, 29, 36, 37, 42, 46, 51, 53, 54, 55, 56, 61, 64, 65, 66, 68, 69, 72, 79, 82, 84, 91, 94, 98, 103, 115], "imdb": 8, "sentiment": 8, "vocab_s": [8, 9, 35], "20000": [8, 9, 35], "consid": [8, 15, 17, 52, 92, 98, 103, 108], "20k": 8, "word": [8, 84], "maxlen": [8, 9, 35], "200": [8, 9, 20, 35, 72], "movi": 8, "review": 8, "x_train": [8, 29], "y_train": 8, "x_val": 8, "y_val": 8, "load_data": 8, "num_word": 8, "pad_sequ": 8, "embed_dim": [8, 9, 35], "embed": [8, 9, 35, 61, 68, 89, 101, 108], "token": [8, 9, 35, 108], "num_head": [8, 9, 35], "attent": [8, 9, 35], "head": [8, 9, 35], "ff_dim": [8, 9, 35], "hidden": [8, 9, 35], "feed": [8, 9, 15, 16, 17, 35, 109], "insid": [8, 9, 30, 35, 61, 74, 77, 78, 89, 91], "delta": [8, 9, 35, 37, 46, 66, 85, 109], "input_dim": [8, 9, 35], "output_dim": [8, 9, 35], "block": [8, 53, 72, 79, 84, 87, 90], "multiheadattent": [8, 9, 35, 110], "key_dim": [8, 9, 35], "dropout": [8, 9, 35, 89], "layernorm": [8, 9, 35, 89], "epsilon": [8, 9, 35], "1e": [8, 9, 35, 52, 64, 91, 106], "globalaveragepooling1d": [8, 9, 35], "softmax": [8, 9, 18, 35, 89, 91], "functional_callback": 8, "histogram_freq": 8, "sparse_categorical_crossentropi": 8, "128": [8, 10, 11, 59, 61, 82, 84, 91], "wrap": [8, 10, 11, 12, 14, 25, 61, 72], "effect": [8, 10, 11, 23, 24, 29, 51, 54, 64, 68, 84, 89, 91, 94, 103, 105, 107, 109], "visual": [8, 12, 25, 26, 50, 56, 67, 74, 101, 103, 104, 105, 108, 110, 111, 114], "multi": [8, 67, 110], "encount": [8, 91], "access": [8, 18, 19, 22, 23, 24, 67, 72, 74, 103], "within": [8, 78, 82, 89, 96, 105, 109], "granular": [8, 15, 16, 17, 30, 56, 84, 101, 108, 109, 113], "mha": [8, 110], "accur": [8, 91], "clone_lay": 8, "clone": [8, 97], "diagram": [8, 94, 98, 101, 109, 111, 114], "m": [8, 73, 74, 75, 88, 97], "convert_to_pb": 8, "onc": [8, 10, 11, 15, 16, 17, 22, 23, 24, 34, 60, 62, 64, 68, 78, 94, 95, 101, 105, 106, 109], "inspect": 8, "1024": [8, 48, 51, 68, 92, 102], "artifact": [8, 10, 11, 32, 44, 58, 74, 91], "3000": [8, 82], "model_after_qat": [8, 10, 11], "anoth": [8, 11, 24, 64, 68, 114, 115], "most": [8, 84, 91, 107], "complex": [8, 28, 37, 46, 66, 68], "elementari": 8, "logdir": 8, "summari": [8, 71, 93], "vanilla": [8, 11, 20, 24, 108], "becaus": [9, 21, 35, 61, 69], "tool": [9, 66, 67, 88, 91, 101, 104, 113, 115], "sequanti": 9, "build": [9, 35, 72], "dicuss": 9, "text": [9, 35, 79, 90], "transform": [9, 18, 19, 20, 22, 23, 24, 25, 35, 51, 53, 61, 68, 84, 87, 91, 110], "found": [9, 36, 65, 69, 72, 84, 106, 109], "tokenandpositionembed": [9, 35], "transformerblock": [9, 35], "super": [9, 35, 52, 61, 62, 69, 91], "att": [9, 35], "ffn": [9, 35], "layernorm1": [9, 35], "layernorm2": [9, 35], "dropout1": [9, 35], "dropout2": [9, 35], "kwarg": [9, 35, 77, 78, 79, 82, 89], "attn_output": [9, 35], "out1": [9, 35], "ffn_output": [9, 35], "token_emb": [9, 35], "pos_emb": [9, 35], "With": [9, 11, 12, 24, 25, 82], "those": [9, 11, 15, 16, 17, 24, 46, 66, 101], "random": [9, 20, 28, 33, 35, 37, 39, 42, 45, 46, 48, 53, 69, 95, 105], "random_input": [9, 35], "embedding_lay": [9, 35], "transformer_block": [9, 35], "token_and_position_embed": 9, "symmetr": [9, 49, 64, 72, 77, 78, 79, 82, 84, 85, 89, 90, 91, 107, 109], "model_prepar": [9, 18, 19, 21, 22, 23, 24, 25, 35, 37, 51, 54, 61, 66, 68, 69, 72, 91], "prepare_model": [9, 18, 19, 21, 22, 23, 24, 25, 35, 37, 51, 54, 61, 66, 68, 69, 72, 91], "input_lay": [9, 35], "begin": [9, 35, 52, 61, 62, 79, 90, 106, 107], "unwrap": 9, "ident": [9, 34, 60, 89, 91], "present": [9, 21, 26, 52, 58, 62, 64, 72, 84, 87, 91, 101, 104], "get_weight": 9, "represent": [9, 49, 80, 81, 82], "reorder": 9, "get_original_models_weights_in_functional_model_ord": 9, "original_model": [9, 35], "ndarrai": [9, 65], "arg": [9, 68, 77, 78, 79, 82, 84, 87, 89], "lookup": 9, "remov": [9, 29, 54, 61, 72, 74, 91, 95, 99, 109, 115], "match": [9, 28, 32, 37, 44, 46, 56, 58, 66, 68, 78, 84, 95, 101, 105, 107, 108, 109, 115], "original_model_weight": 9, "pop": 9, "weight_nam": 9, "kei": [9, 11, 24, 49, 65], "functional_model_weight_ord": 9, "enumer": [9, 28, 30, 51, 56, 58, 68, 91, 94], "sort": 9, "weights_in_correct_ord": 9, "item": [9, 12, 25, 42, 103], "weight_info": 9, "assert": [9, 18, 61, 72, 91], "count_param": 9, "output_shap": 9, "textclassif": 9, "what": [9, 91, 109, 112], "architectur": [9, 67, 96], "model_weights_in_correct_ord": 9, "assert_array_equ": 9, "modelprepar": [9, 18, 19, 22, 23, 24, 25, 29, 35, 51, 61, 68, 91], "arthmet": [9, 35], "experss": [9, 35], "tfoplambda": [9, 35], "ressembl": 9, "conv_1": [9, 35, 84], "conv_2": [9, 35], "becuas": [9, 35, 44], "rais": [9, 35, 78], "except": [9, 12, 25, 35, 84], "hopefulli": [9, 14], "pre": [10, 11, 32, 44, 58, 73, 74, 75, 97, 99, 104], "min": [10, 11, 13, 37, 46, 49, 64, 66, 71, 72, 79, 83, 85, 89, 90, 91, 105, 109], "max": [10, 11, 13, 37, 46, 49, 64, 66, 71, 72, 79, 80, 81, 83, 85, 89, 90, 91, 101, 104, 105, 109], "keep": [10, 23, 24, 61, 68, 107, 108], "constant": [10, 23, 24, 42, 53, 61, 68, 98, 103], "imagenet_dir": 10, "assign": [10, 11, 49, 64, 77, 78, 79, 89, 90], "dataset_train": [10, 11], "dataset_valid": [10, 11], "respect": [10, 11, 34, 71, 89, 105], "categorical_crossentropi": [10, 11, 39], "being": [10, 11, 14, 30, 34, 49, 56, 60, 61, 62, 65, 66, 72, 84], "hyperparamet": [10, 11, 106], "henc": 11, "jointli": [11, 23, 24], "ye": [11, 75, 101], "due": [11, 26, 35, 62, 67, 84, 103, 104], "restrict": [11, 84, 102], "prevent": [11, 52, 61, 72, 95], "mention": [11, 84], "trainabl": [11, 24, 39, 103], "training_range_learning_with_tf_enhanced_init": [11, 24, 28, 51, 68], "similar": [11, 17, 24, 64, 84, 104, 106, 109], "enhanc": [11, 12, 24, 25, 48, 64, 66, 105, 109], "benefit": [11, 24, 49, 84, 92], "analys": [12, 25, 105], "respond": [12, 25], "repres": [12, 15, 16, 17, 25, 28, 33, 35, 37, 46, 49, 56, 59, 60, 64, 66, 68, 80, 81, 82, 89, 90, 91, 98, 103, 104, 105, 106, 109], "second": [12, 25, 35, 51, 69, 84, 89, 107], "singl": [12, 13, 15, 16, 17, 25, 28, 37, 46, 56, 59, 61, 63, 66, 84, 92, 104], "val_dataset": 12, "itself": [12, 21, 25, 44, 101, 109, 111, 114], "exactli": [12, 25, 77, 78, 89, 109], "multipl": [12, 25, 30, 52, 56, 57, 58, 61, 62, 65, 68, 70, 75, 84, 89, 99, 101, 103, 110], "demonstr": [12, 25, 33, 91], "quant_analyz": [12, 25, 37, 46, 66, 67, 72], "enable_per_layer_mse_loss": [12, 25, 37, 46, 66], "track": [12, 25, 64, 105], "minimum": [12, 25, 28, 51, 61, 68, 71, 73, 79, 89], "histogram": [12, 25, 37, 46, 66, 71, 85, 103, 105, 109, 110], "seen": [12, 25, 104, 105], "html": [12, 25, 61, 66, 83, 96, 105, 110, 113], "folder": [12, 15, 16, 17, 23, 24, 25, 71, 105], "structur": [12, 15, 16, 17, 25, 49, 61, 77, 78, 89, 101], "per_layer_quant_en": [12, 25, 105], "per_layer_quant_dis": [12, 25, 105], "min_max_rang": [12, 25, 105], "activations_pdf": [12, 25, 105], "name_": [12, 25, 66], "index_0": [12, 25], "index_1": [12, 25], "index_n": [12, 25], "weights_pdf": [12, 25, 105], "layer1": [12, 25, 65], "param_name_": [12, 25, 66], "channel_index_0": [12, 25], "channel_index_1": [12, 25], "channel_index_n": [12, 25], "layer2": [12, 25, 65], "layern": [12, 25], "per_layer_mse_loss": [12, 25, 105], "axi": [12, 25, 49, 105], "contain": [12, 15, 16, 17, 25, 36, 49, 52, 56, 59, 61, 62, 66, 73, 77, 78, 82, 83, 87, 89, 91, 103, 105, 106, 107, 109], "sub": [12, 25, 52, 75, 95, 101, 109, 115], "basi": [13, 49, 84, 98, 101], "2d": [13, 15, 16, 17, 84], "imagin": 13, "filter": [13, 35], "kernel": [13, 67, 78, 84, 89, 95, 111, 114], "28": [13, 56, 59, 82], "were": [13, 20, 23, 24, 32, 36, 44, 49, 51, 58, 64, 65, 68, 75, 87, 96, 103, 107, 115], "entireti": [13, 35], "matrix": [13, 15, 16, 17, 95], "contrast": [13, 35, 72], "repeat": [13, 64, 91, 95], "uniqu": 13, "attribut": [13, 33, 35, 59, 61, 64, 72, 77, 78, 89, 105], "conv2d_lay": 13, "kernel_s": [13, 35, 52, 61, 62, 69, 91], "snpe": [13, 14], "qnn": [13, 14], "style": 13, "ensur": [13, 58, 74, 89, 103, 108], "mismatch": 13, "togeth": [13, 84, 101], "pcq_quantsim_config": 13, "tell": [13, 112], "did": [13, 104], "resnet50_pcq_adaround": 13, "mimic": 14, "aimet_cl": 14, "cle_applied_model": [14, 31], "yaml": 14, "h5": [14, 32, 99, 103], "savedmodel": 14, "protobuff": 14, "safe": 14, "resnet50_after_cl": 14, "brief": [15, 16, 17], "introduct": [15, 16, 17], "spatial": [15, 96, 98, 100, 101, 110], "svd": [15, 96, 98, 100, 101, 110], "decomposit": [15, 16, 17, 111, 114], "decompos": [15, 16, 17, 101, 111, 114], "split": [15, 16, 17, 84, 89], "flattend": [15, 16, 17], "singular": [15, 16, 17, 111, 114], "discard": [15, 16, 17, 46, 66], "least": [15, 16, 17, 59, 92, 95], "signific": [15, 16, 17, 84, 108], "diagon": [15, 16, 17], "matric": [15, 16, 17], "back": [15, 16, 17, 33, 45, 51, 59, 63, 68, 78, 82, 91, 107], "magnitud": [15, 16, 17, 95], "dimens": [15, 16, 17, 84, 87, 89, 101, 108, 111, 114], "reconstruct": [15, 16, 17, 51], "distanc": [15, 16, 17], "memori": [15, 16, 17, 30, 56, 64, 85, 96, 101, 111, 114, 115], "close": [15, 16, 17, 95, 96, 109], "num_comp_ratio_candid": [15, 16, 17, 30, 56, 70], "num_eval_iter": [15, 16, 17], "pytorch": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 52, 61, 62, 69, 71, 73, 74, 77, 78, 87, 89, 92, 93, 94, 97, 99, 104, 105, 107, 109, 110], "image_net_train": [15, 16, 17, 21, 22, 23, 24], "imagenettrain": [15, 16, 17, 21, 22, 23, 24], "nn": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 51, 52, 53, 56, 60, 61, 62, 63, 65, 66, 68, 69, 72, 77, 78, 79, 83, 84, 88, 89, 90, 91, 102, 110], "bool": [15, 16, 17, 19, 21, 22, 23, 24, 25, 53, 55, 56, 59, 61, 64, 65, 68, 79, 84, 90], "gpu": [15, 16, 17, 19, 21, 22, 23, 24, 25, 39, 56, 58, 67, 69, 73, 74, 103, 110], "learning_r": [15, 16, 17, 21, 23, 24, 54, 68], "learning_rate_schedul": [15, 16, 17, 21, 23, 24, 54, 68], "schedul": [15, 16, 17, 21, 23, 24, 106], "trainer": [15, 16, 17, 21, 23, 24, 56, 97], "max_epoch": [15, 16, 17, 21, 23, 24], "is_avail": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 54, 91], "target_comp_ratio": [15, 16, 17, 30, 56, 70], "ratio": [15, 16, 17, 30, 56, 70, 95, 96, 112], "9": [15, 17, 18, 19, 22, 23, 24, 25, 30, 33, 45, 51, 59, 61, 64, 68, 69, 75, 79, 82, 108], "part": [15, 16, 17, 35, 37, 42, 46, 53, 63, 66, 84, 101, 103, 104, 105], "denot": [15, 16, 17, 30, 93], "tri": [15, 16, 17, 96, 103], "33": [15, 16, 17, 75, 79, 90], "66": [15, 16, 17, 79, 90, 96], "00": [15, 16, 17, 79], "taken": [15, 16, 17, 35, 115], "modules_to_ignor": [15, 16, 17, 30, 56, 66, 70, 100], "interact": [15, 16, 17, 72, 83], "too": [15, 16, 17, 84], "choss": [15, 16, 17], "retriev": [15, 17, 78], "num_reconstruction_sampl": [15, 17, 56], "ridicul": [15, 17], "allow_custom_downsample_op": [15, 17, 56], "downsampl": [15, 17], "bandwidth": [15, 17, 96], "suggest": [15, 17, 68, 98, 101, 104], "function_nam": [15, 16, 17], "eval_iter": [15, 16, 17, 30, 56, 70], "trust": [15, 16, 17], "invoc": [15, 16, 17], "compress_schem": [15, 16, 17, 30, 56, 70], "cost_metr": [15, 16, 17, 30, 56, 70], "decim": [15, 16, 17, 30, 56, 70], "greedyselectionparamet": [15, 16, 17, 30, 56, 70], "channelpruningparamet": [15, 17, 56], "compressionschem": [15, 16, 17, 30, 56, 70], "costmetr": [15, 16, 17, 30, 56, 70], "greedy_param": [15, 16, 17, 30, 56, 70], "auto_param": [15, 16, 17, 30, 56, 70], "automodeparam": [15, 16, 17, 30, 56, 70], "greedy_select_param": [15, 16, 17, 30, 56], "channel_prun": [15, 17, 30, 56], "modelcompressor": [15, 16, 17, 30, 56, 70], "compress_model": [15, 16, 17, 30, 56, 70, 112], "relev": [15, 16, 17], "compressed_model": [15, 16, 30, 56], "comp_stat": [15, 16], "fell": [15, 16, 17], "sharpli": [15, 16, 17], "15e": [15, 17], "finetu": [15, 16, 17], "ofcours": [15, 16, 17, 22, 23, 24], "finetuned_model": [15, 16], "prune": [16, 30, 96, 98, 100, 101, 110, 115], "spatialsvdparamet": [16, 17, 30, 56, 70], "spatial_svd": [16, 17, 30, 56, 70], "5e": [16, 17, 21, 23, 24, 54, 68], "ssvd_compressed_model": 17, "ssvd_comp_stat": 17, "ssvd_finetuned_model": 17, "further": [17, 26, 61, 72, 79, 82, 84, 90, 91, 95, 99, 101, 103, 107], "mostli": 17, "ssvd_cp_compressed_model": 17, "cp_comp_stat": 17, "ok": 17, "ssvd_cp_finetuned_model": 17, "imagefold": [18, 20], "tqdm": [18, 20], "root": [18, 20, 74, 75, 91], "compos": [18, 20, 53], "resiz": 18, "centercrop": [18, 20], "totensor": [18, 20, 53, 91], "images_mean": 18, "std": [18, 20], "images_std": 18, "manual_se": 18, "randperm": 18, "tolist": 18, "pin_memori": [18, 61], "evaluate_accuraci": 18, "top1_accuraci": 18, "dim": [18, 53, 69, 84, 91], "no_grad": [18, 19, 20, 22, 23, 24, 25, 51, 62, 68], "logit": [18, 20], "topk": [18, 20, 42, 89], "certain": [18, 19, 22, 23, 24, 25, 51, 60, 61, 66, 68, 84, 101, 102, 103, 107], "guidelin": [18, 19, 22, 23, 24, 25, 38, 41, 48, 51, 61, 67, 91, 92, 96, 106], "rand": [18, 19, 21, 22, 23, 24, 25, 28, 37, 45, 52, 58, 62], "modif": [18, 19, 22, 23, 24], "made": [18, 19, 22, 23, 24, 61, 107], "overrid": [18, 19, 22, 23, 24, 61, 68], "300": 18, "tfrecord": 19, "ptq": [20, 53, 99, 103, 105, 106], "success": 20, "care": [20, 91], "non": [20, 39, 52, 61, 109], "expert": 20, "effort": [20, 53, 93], "known": [20, 62, 84, 98, 99], "heurist": 20, "cumul": 20, "until": [20, 53, 79, 90, 93], "val_transform": 20, "normal": [20, 52, 69, 89, 94, 105], "485": 20, "456": 20, "406": 20, "229": 20, "225": 20, "imagenet_dataset": 20, "eaxmpl": 20, "subsetrandomsampl": [20, 53], "in_eval_mod": 20, "get_devic": 20, "_dataset": [20, 53], "k": [20, 111], "view_a": 20, "unlabeleddatasetwrapp": [20, 53], "__getitem__": [20, 53], "unlabeled_imagenet_dataset": 20, "unlabeled_imagenet_data_load": 20, "initial_accuraci": [20, 42, 53], "run_infer": [20, 42, 53], "predefin": [20, 98], "empir": [20, 104], "adaround_data_load": [20, 42, 53], "furhter": 20, "optimized_accuraci": [20, 42, 53], "batchnrom": 21, "focu": 21, "unlik": [21, 80, 81], "script": 21, "didn": [21, 67], "statatist": 21, "finetuned_accuraci": [21, 23, 24], "train_load": [21, 54, 56, 91], "images_dir": 21, "finetuned_accuracy_bn_reestim": 21, "resnet18_after_qat": [21, 23, 24], "lead": [22, 37, 46, 66, 84, 92, 94, 104, 108, 109], "shift": [22, 67, 104], "adjust": [22, 28, 51, 52, 68, 83, 84, 94, 95, 96, 103, 104, 108], "hood": [22, 72], "correct_bia": [22, 55], "num_quant_sampl": [22, 55], "num_bias_correct_sampl": [22, 55], "quantparam": [22, 55], "bias_correct": [22, 55], "bc_param": 22, "weight_bw": [22, 55], "act_bw": [22, 55], "round_mod": [22, 55], "resnet18_after_cle_bc": 22, "Then": [23, 24, 28, 46, 51, 66, 68], "matter": 25, "softwar": [26, 99, 101], "compress": [26, 27, 50, 88, 95, 97, 99, 110, 111, 113, 114, 115], "dramat": 26, "lost": [26, 88, 99], "At": [26, 96, 101], "onnx": [26, 49, 58, 60, 68, 73, 74, 88, 92, 93, 97, 99, 102, 103, 104, 105, 107, 109], "link": [26, 73, 75, 92, 93, 94, 97, 104, 105, 109], "codebas": 26, "sphinx": 26, "page": [26, 69, 74, 75, 96, 109, 110], "qualcomm": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "innov": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "center": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "inc": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "quantsim_config": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "default_config": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "34": [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "model": [27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "ai": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "toolkit": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "sourc": [28, 29, 30, 33, 35, 45, 51, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 68, 69, 70, 71, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 108], "post_training_percentil": [28, 51, 68], "percentil": [28, 51, 68, 85], "absolut": [28, 45, 51, 56, 59, 68, 79, 90], "nois": [28, 51, 67, 68, 85, 91, 103, 104, 105, 106, 107], "aimetlogg": 28, "test_model": 28, "keras_model": 28, "dummy_forward_pass": [28, 69], "intend": [28, 37, 46, 49, 56, 66, 91, 96], "Or": [28, 37, 46, 58, 61, 66, 68, 101], "someth": [28, 37, 46, 66, 68, 101, 112], "apply_adaround_exampl": [28, 41], "set_level_for_all_area": 28, "dataset_s": 28, "possible_batch": 28, "from_tensor_slic": [28, 29, 37], "w4a8": 28, "param_bw": [28, 51, 53, 64], "output_bw": [28, 51, 53, 64], "adarounded_model": [28, 51], "adarounded_sess": 28, "grid": [28, 51, 84], "bn_re_estimation_dataset": 29, "bn_num_batch": 29, "datasetv2": 29, "handl": [29, 53, 54, 84], "undo": [29, 54], "upon": [29, 54, 77, 78, 89, 91], "prepar": [29, 34, 37, 38, 42, 46, 51, 53, 60, 64, 66, 67, 68, 69, 93, 103, 110], "overal": [30, 51, 56, 68, 96, 101, 108], "algorithm": [30, 33, 49, 56, 59, 96, 98, 101, 108, 115], "tweak": [30, 36, 56, 64, 65], "use_monotonic_fit": [30, 56], "saved_eval_scores_dict": [30, 56, 70], "variabl": [30, 35, 56, 61, 74, 75, 79, 90, 97], "express": [30, 56], "cost": [30, 56, 84, 98, 101, 106], "comp": [30, 56], "greater": [30, 56, 65, 84, 89], "monoton": [30, 56, 98], "dict": [30, 55, 56, 58, 59, 60, 61, 64, 65, 66, 68, 69, 89, 90], "pickl": [30, 56], "experi": [30, 56, 84, 101], "input_op_nam": 30, "output_op_nam": 30, "union": [30, 35, 51, 52, 53, 55, 56, 57, 58, 59, 65, 66, 68, 84, 87], "manualmodeparam": [30, 56], "rank": [30, 56, 64, 111, 114], "noth": [30, 56, 91], "list_of_module_comp_ratio_pair": [30, 56], "modulecompratiopair": [30, 56], "pair": [30, 36, 54, 55, 56, 65], "space": [30, 56, 84], "weight_svd": [30, 56], "comp_ratio": [30, 56], "ivar": 30, "aimet_common_def": 30, "aimet_tensorflow_def": 30, "inp_data": 30, "aimet_spatial_svd": 30, "evalfunct": 30, "compressionstat": [30, 56], "80": [30, 79, 90], "driver": [30, 73, 75], "stat": [30, 54, 56, 83], "comprehens": 31, "detect": [31, 101], "shall": [31, 49], "cross_layer_equalization_auto": [31, 57], "individu": [31, 36, 57, 66, 84, 94, 95, 96, 98, 101, 103, 105, 108], "accord": [32, 44, 58, 103, 106, 107, 109], "comparison": [32, 44, 58], "amongst": [32, 44, 58], "miss": [32, 35, 44, 49, 58, 62], "issu": [32, 35, 44, 52, 58, 62, 94, 99, 102, 108, 110, 112, 113], "layer_output_util": [32, 44, 58], "layeroutpututil": [32, 44, 58], "obtain": [32, 36, 44, 46, 49, 58, 65, 69, 75, 95, 96, 105, 109], "aimet_export_artifact": [32, 44, 58], "sake": [32, 44, 58], "simplic": [32, 44, 58], "mandatori": [32, 44, 58], "load_encodings_to_sim": [32, 44, 58], "construct": [32, 44, 52, 58, 74, 75, 91, 102], "properli": [32, 44, 58, 79, 90, 91], "input_batch": [32, 44, 58], "get_pre_processed_input": [32, 44, 58], "fp32_layer_output_util": [32, 44, 58], "save_dir": 32, "fp32_layer_output": [32, 44, 58], "quantsim_layer_output_util": [32, 44, 58], "quantsim_layer_output": [32, 44, 58], "generate_layer_output": [32, 44, 58], "func": [33, 45, 59, 66], "encapsul": [33, 45, 59, 66], "callabl": [33, 45, 51, 53, 54, 56, 59, 61, 66, 78, 84], "OF": 33, "SUCH": 33, "damag": 33, "spdx": 33, "licens": 33, "identifi": [33, 55, 62, 74, 75, 84, 97, 105, 108, 110, 115], "bsd": 33, "claus": 33, "copyright": 33, "pylint": 33, "statement": [33, 61, 67, 72, 102], "alpha": [33, 64], "directrori": 33, "preset": 33, "parent": [33, 77, 78], "retuern": 33, "seed": [33, 56], "set_se": 33, "evalutaion": 33, "org_top1": 33, "get_quantizated_model": 33, "format": [33, 34, 36, 39, 51, 64, 66, 68, 84, 87, 90, 93, 100], "accept": [33, 104, 108], "09": 33, "cmp_re": 33, "mixed_preision_quant_model": 33, "fast_mixed_precis": 33, "sever": [34, 38, 60, 62, 67, 84, 89, 96], "encourag": [34, 35, 38, 60, 61, 67], "mix": 34, "had": [34, 60, 91], "x2": [34, 60, 61], "relu2": [34, 35, 60, 62], "manditori": 35, "submodul": [35, 60], "inherit": [35, 77, 89], "pure": [35, 60], "inputlay": 35, "portion": 35, "rtype": [35, 59, 82], "get_text_classificaiton_model": 35, "model_preparer_two_subclassed_lay": 35, "get_subclass_model_with_functional_lay": 35, "sigmoid": [35, 61, 89], "binary_classifi": 35, "myfunctionalmodel": 35, "my_functional_model": 35, "classifi": 35, "model_preparer_subclassed_model_with_functional_lay": 35, "resembl": 35, "piec": [35, 61], "python": [35, 68, 73, 74, 75], "static": [35, 56, 61, 109], "caus": [35, 102, 108, 109], "trace": [35, 60, 83], "symbol": 35, "touch": 35, "static_patch_count": 35, "guarante": 35, "verifi": [35, 61], "furthermor": 35, "resu": 35, "resblock": 35, "twice": 35, "bad": 35, "bn1": [35, 52, 62, 65], "bn2": 35, "relu1": [35, 60, 62, 69], "appear": [36, 52, 56, 61, 62, 65], "plug": [36, 65], "highbiasfold": [36, 65], "crosslayersc": [36, 65], "model_transform_util": 36, "replace_relu6_with_relu": 36, "cross_layer_equalization_auto_stepwis": 36, "relu6": [36, 55, 65, 89, 104], "model_for_cl": 36, "folded_pair": [36, 65], "bn_dict": [36, 65], "conv_or_linear": 36, "cls_set_info_list": [36, 65], "scale_model": [36, 65], "bias_fold": [36, 65], "fold_given_batch_norm": [36, 65], "cross_layer_equalization_manu": [36, 65], "layer_pair": [36, 65], "get_example_layer_pairs_resnet50_for_fold": 36, "consecutive_layer_list": [36, 65], "get_consecutive_layer_list_from_resnet50_for_sc": 36, "scaling_factor_list": [36, 65], "scale_cls_set": [36, 65], "format_info_for_high_bias_fold": 36, "conv_op_1": 36, "bn_op_1": 36, "conv_op_2": 36, "bn_op_2": 36, "conv_op_3": 36, "bn_op_3": 36, "11": [36, 49, 64, 73, 74, 75, 79, 82], "bn_op": 36, "along": [36, 64, 65, 82, 84, 91, 106, 109], "upstream": [36, 95, 115], "downstream": [36, 49], "usag": [36, 49, 62, 64, 68, 85, 88, 96, 97, 101, 108], "conv_op": 36, "bn_op_with_meta": 36, "_fold_upstream_flag": 36, "append": [36, 56], "hold": [36, 55, 65, 82, 84, 87, 89, 107], "boolean": 36, "is_relu_activation_in_cls_set": 36, "fill": [36, 68], "element": [36, 49, 65], "create_cls_set_info_list": 36, "mse": [37, 46, 66, 72, 105, 109], "quantanalyz": [37, 46, 47, 66, 67, 72, 103, 110], "toi": [37, 45, 59], "num_class": [37, 39, 53], "ey": 37, "image_dataset": 37, "label_dataset": 37, "own": [37, 42, 46, 48, 51, 53, 54, 55, 66, 68], "action": [37, 46, 48, 51, 54, 55, 66, 68, 115], "scalar": [37, 46, 66], "prepared_model": [37, 51, 61, 66, 68, 69, 91], "forward_pass_callback_fn": [37, 46, 66], "eval_callback_fn": [37, 46, 66], "approxim": [37, 46, 66, 92, 96, 104, 105], "quant_analyzer_result": [37, 46, 66], "abil": [38, 47, 67, 78, 110], "hardwar": [38, 47, 67, 71, 103, 104, 109], "quant_sim": [39, 54, 68], "qc_quantize_wrapp": 39, "qcquantizewrapp": [39, 54], "quantize_model": [39, 48], "dummy_x": 39, "dummy_i": 39, "randint": 39, "to_categor": 39, "lr": [39, 91], "workload": 39, "explicitli": [39, 87, 115], "isinst": [39, 84], "_layer_to_wrap": 39, "write": [41, 48, 51, 68, 84, 87], "ada_rounded_model": 41, "math": [42, 91], "auto_quant_v2": [42, 53], "onnx_model": [42, 43, 46, 48], "dummy_data": [42, 46, 48], "astyp": [42, 45, 46, 48], "float32": [42, 45, 46, 48, 69], "Its": 42, "fed": 42, "unlabelled_data_load": 42, "ceil": [42, 51], "maintain": 42, "num_of_sampl": 42, "evaldataload": 42, "acc_top1": 42, "acc_top5": 42, "batch_avg_top_1_5": 42, "4f": [42, 53], "happen": [43, 57, 91], "dummy_input_dict": 44, "serializetostr": 44, "dir_path": [44, 58], "quantize_with_mixed_precis": [45, 59], "flow": [45, 59, 61, 63, 67, 94, 103, 106, 108, 109], "algo": [45, 59], "default_bitwidth": [45, 59], "eval_callback_for_phase_1": [45, 59], "eval_callback_func": [45, 59], "eval_callback_for_phase_2": [45, 59], "clean": [45, 59], "quantize_with_mixed_precision_start_from_existing_cach": [45, 59], "90": [45, 59], "number_of_sampl": [45, 59], "popul": [45, 49, 59], "perform_ev": [45, 59], "in_tensor": 45, "interest": [46, 66], "create_quantsim_and_encod": 46, "unlabeled_data_load": [46, 53, 66], "_get_unlabled_data_load": [46, 66], "unlabeled_dataset_iter": [46, 53, 66], "autoqu": [47, 67, 97, 103, 106, 110], "unifi": [47, 67], "integr": [47, 53, 63, 64, 67, 103], "line": [48, 51, 54, 55, 68, 71, 97], "max_batch_count": [48, 51, 68], "current_batch_count": [48, 51, 68], "use_symmetric_encod": [48, 72], "forward_pass_funct": 48, "syntax": [49, 77], "usabl": 49, "xx": 49, "yy": 49, "zz": 49, "major": [49, 101], "revis": 49, "minor": [49, 110], "patch": 49, "substanti": 49, "fulli": [49, 67, 91, 100], "bug": [49, 110], "backward": [49, 65, 91], "assum": [49, 53, 75, 84, 87], "string": [49, 107], "activation_encod": 49, "tensor_nam": 49, "param_encod": [49, 72], "constraint": [49, 84], "depict": 49, "6086959838867188": 49, "109158515930176": 49, "114": 49, "018501389771699905": 49, "21": [49, 85], "558866932988167": 49, "12636379897594452": 49, "12": [49, 73, 74, 75, 79, 84], "010530316270887852": 49, "06318144500255585": 49, "06268782913684845": 49, "127": [49, 82], "0004936049808748066": 49, "fc1": [49, 61], "05589814856648445": 49, "05546144023537636": 49, "0004367042565718293": 49, "184721499681473": 49, "10788747668266296": 49, "0089906234367221": 49, "conv2d_1": 49, "1020304188132286": 49, "10380396991968155": 49, "008650330936207491": 49, "readvariableop": 49, "1462666392326355": 49, "1451239287853241": 49, "126": 49, "0011427081098743512": 49, "08333279937505722": 49, "08268175274133682": 49, "0006510374592799766": 49, "includ": [49, 53, 59, 68, 72, 83, 84, 94, 101, 103, 105, 107, 109, 110], "dtype": [49, 61, 64, 72, 80, 81, 82, 84, 87], "datatyp": [49, 69], "highlight": [49, 104, 112, 113], "quantizer_arg": 49, "activation_bitwidth": 49, "param_bitwidth": 49, "broken": 49, "occur": [49, 78, 83, 84, 87, 89], "who": 49, "knowledg": 49, "experiment": [51, 52, 53, 66, 68, 72, 84, 101, 107], "v2": [51, 53, 66, 68, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91], "namespac": [51, 53, 66, 67, 68, 72], "visit": [51, 53, 66, 68, 75, 88, 99], "overview": [51, 53, 66, 68, 72], "param_bw_override_list": 51, "ignore_quant_ops_list": 51, "default_config_fil": 51, "linear": [51, 54, 61, 62, 64, 65, 71, 72, 77, 78, 84, 89, 91, 94, 95], "pars": [51, 68, 87], "prefix": [51, 64, 68, 87], "31": [51, 52, 55, 66, 68, 74, 75], "affect": [51, 84, 94, 107, 115], "default_reg_param": 51, "default_beta_rang": 51, "default_warm_start": 51, "commonli": 51, "among": 51, "10k": 51, "15k": 51, "beta": [51, 92], "anneal": 51, "start_beta": 51, "end_beta": 51, "warm": [51, 92], "period": [51, 92], "zero": [51, 64, 87, 109, 110], "get_train_dataload": [51, 54], "quantized_resnet18": [51, 68], "arch_check": 52, "archcheck": 52, "check_model_arch": 52, "result_dir": 52, "_node_check_dict": 52, "record": [52, 66], "fail": [52, 61, 62, 93, 102, 103], "arch_checker_report": 52, "dotted_name_op": 52, "nodeerrorreportobject": 52, "archcheckerreport": 52, "condit": [52, 61, 62], "modelwithnotenoughchannel": 52, "prelu": [52, 89], "stride": [52, 61, 62, 91], "batchnorm2d": [52, 62, 65, 89, 91], "example_check_for_number_of_conv_channel": 52, "fewer": 52, "logger": [52, 62], "_check_conv_channel_32_bas": 52, "_check_conv_channel_larger_than_32": 52, "layer_nam": [52, 66], "modelwithprelu": 52, "prelu1": 52, "example_check_for_non_performant_activ": 52, "num_paramet": 52, "_activation_check": 52, "modelwithnonfoldablebn": 52, "foldabl": 52, "avg_pool1": 52, "avgpool2d": [52, 89], "example_check_for_standalone_bn": 52, "averagepool": 52, "ep": [52, 91], "05": [52, 64, 79, 91], "momentum": [52, 91], "affin": [52, 64, 67, 78, 82, 84, 87, 88, 89, 90, 91], "track_running_stat": [52, 91], "_check_batch_norm_fold": 52, "cache_id": 53, "strict_valid": 53, "model_prepare_requir": 53, "manner": [53, 93], "id": [53, 70, 74, 112], "hen": 53, "proce": 53, "unid": 53, "unintuit": 53, "_subset_sampl": 53, "sampler": 53, "fp32_model": 53, "fakedata": 53, "eval_data_load": 53, "num_correct_predict": 53, "argmax": [53, 89, 91], "deprec": [53, 72, 103], "dummy_input_on_cpu": 53, "dummy_input_on_gpu": 53, "preced": [54, 107], "var": 54, "batch_norm": [54, 65], "got": [54, 61, 65], "load_fp32_model": 54, "imagenetpipelin": 54, "quant_param": 55, "conv_bn_dict": 55, "perform_only_empirical_bias_corr": 55, "layers_to_ignor": 55, "unless": [55, 75, 78, 87, 115], "remain": [55, 72, 98, 103, 104, 109], "relat": [55, 56, 65, 72, 105, 109], "calc": 55, "corr": 55, "irrespect": 55, "fact": [55, 84], "elig": 55, "input_bn": 55, "output_bn": 55, "in_activation_typ": 55, "no_activ": 55, "out_activation_typ": 55, "hode": 55, "No": [55, 62, 103], "constructor": [55, 58, 60, 61, 65, 68], "mobilenetv2": [55, 65], "512": 55, "module_prop_dict": 55, "find_all_conv_bn_with_activ": 55, "compressor": 56, "visualization_url": [56, 70], "train_model": 56, "train_flag": 56, "weightsvdparamet": 56, "url": [56, 70, 74, 75, 97, 112], "rank_select_schem": 56, "select_param": 56, "rankselectschem": 56, "tar": 56, "evaluate_model": 56, "honor": 56, "obvious": 56, "spatial_svd_auto_mod": 56, "mnist": 56, "mnist_trained_on_gpu": 56, "pth": [56, 58, 64, 68], "pretti": 56, "easili": 56, "spatial_svd_manual_mod": 56, "manual_param": 56, "weight_svd_auto_mod": 56, "rank_select": 56, "weight_svd_manual_mod": 56, "channel_pruning_auto_mod": 56, "mnist_torch_model": 56, "dataloadermnist": 56, "channel_pruning_manual_mod": 56, "_layer_db": 56, "ture": 56, "batch_callback": 56, "wise": [56, 65, 66, 87, 108], "spatial_svd_auto_mode_with_layerwise_finetun": 56, "torchscript": [58, 68, 88], "naming_schem": 58, "namingschem": 58, "onnx_export_arg": [58, 68, 69], "whose": [58, 61, 65, 72, 83, 84, 104, 107, 115], "wherein": 58, "onnxexportapiarg": [58, 68], "disk": 58, "numer": 58, "onnx_util": 58, "pythonpath": [58, 97], "successfulli": [58, 102], "map_loc": 58, "model_torch": 58, "phase2_revers": 59, "bitop": 59, "amp": 59, "phase2": 59, "quantizergroup": 59, "vari": [59, 96, 98, 104, 113], "earli": 59, "exit": [59, 77, 78, 89, 91], "quantizer_group": 59, "input_quant": [59, 72, 77, 78, 89, 91], "factori": 59, "output_quant": [59, 72, 77, 78, 89, 91], "parameter_quant": 59, "get_active_quant": 59, "name_to_quantizer_dict": 59, "get_candid": 59, "get_input_quantizer_modul": 59, "set_quantizers_to_candid": 59, "bw": [59, 60, 64, 68, 84], "to_list": 59, "roughli": 59, "convers": [60, 108], "onnx_file_nam": 60, "jit": 60, "traceabl": [60, 61], "stateless": 60, "former": 60, "retrain": 60, "whenev": [60, 91], "image_rgb": 60, "rgb_output": 60, "image_bw": 60, "bw_output": 60, "rgb": 60, "elementwis": [61, 89, 110], "unrol": 61, "independ": [61, 108], "modules_to_exclud": 61, "module_classes_to_exclud": 61, "concrete_arg": 61, "instanc": [61, 62, 68, 77, 78, 112], "duplic": 61, "exclud": [61, 62, 66, 87], "partial": 61, "special": [61, 91], "control": [61, 89, 109], "won": 61, "symbolic_trac": 61, "graphmodul": [61, 91], "modelwithfunctionalrelu": 61, "9216": 61, "fc2": 61, "model_preparer_functional_exampl": 61, "allclos": 61, "modelwithreusedrelu": 61, "model_preparer_reused_exampl": 61, "modelwithelementwiseaddop": 61, "x1": 61, "model_preparer_elementwise_add_exampl": 61, "dynam": [61, 80, 81, 104, 109, 110, 113], "branch": [61, 97, 107], "weren": 61, "traceerror": 61, "workaround": [61, 102], "problem": [61, 108], "across": [61, 64, 84, 104, 105], "Such": 61, "concret": 61, "truli": 61, "scope": 61, "custom_function_not_to_be_trac": 61, "call_funct": 61, "__torch_function__": 61, "mechan": [61, 68], "sqrt": [61, 89], "modelwithnontorchfunct": 61, "model_transform": 61, "tracer": 61, "is_leaf_modul": 61, "leaf": [61, 87, 110], "expos": [61, 92], "module_to_exclud": 61, "examin": 61, "custommodul": 61, "softplu": [61, 89], "custommodel": 61, "arang": [61, 69, 79], "traceback": 61, "typeerror": 61, "receiv": 61, "invalid": [61, 84], "proxi": 61, "layout": 61, "requires_grad": [61, 82], "problemat": [61, 108, 113], "determinist": 61, "hard": 61, "do_not_trace_m": 61, "share": [62, 69, 89], "modelwithreusednod": 62, "inplac": 62, "2592": 62, "view": [62, 69, 83, 88, 91, 92, 93, 94, 99, 102, 104, 105, 109, 112], "model_valid": 62, "modelvalid": 62, "validate_example_model": 62, "validate_model": 62, "validate_for_reused_modul": 62, "0x7f127685a598": 62, "resolv": 62, "warn": [62, 103], "redefin": [62, 91], "distinct": [62, 91], "rewrit": [62, 102], "modelwithoutreusednod": 62, "rerun": 62, "0x7ff577373598": 62, "validate_for_missing_modul": 62, "0x7ff5703eff28": 62, "modelwithfunctionallinear": 62, "0x7f9dd9bd90d0": 62, "matmul_8": 62, "reason": 62, "connectedgraph": 62, "op_type_map": 62, "recogn": [62, 107, 109], "functional_op": 62, "modelwithoutfunctionallinear": 62, "parallel": 63, "dataparallel": [63, 67], "move": 63, "forth": 63, "librari": [64, 69, 101], "huggingfac": 64, "alon": 64, "loraconfig": 64, "get_peft_model": 64, "lora_config": 64, "lora_alpha": 64, "lora_dropout": 64, "target_modul": 64, "replace_lora_layers_with_quantizable_lay": 64, "meta": [64, 99, 103], "track_lora_meta_data": 64, "meta_data": 64, "tmp_dir": 64, "convinplacelinear": 64, "peftquantutil": 64, "peft_util": 64, "name_to_module_dict": 64, "disable_lora_adapt": 64, "recomput": 64, "freeze_base_model_param_quant": 64, "tmpdir": 64, "export_model": [64, 68], "filename_prefix_encod": [64, 68], "base_encod": 64, "enable_adapter_and_load_weight": 64, "lora_weights_after_adaptation_for_adapter1": 64, "safetensor": 64, "use_safetensor": 64, "lora_modul": 64, "get_quantized_lora_lay": 64, "param_quant": [64, 72, 77, 78, 84, 89, 91], "quantizedequant": [64, 72, 79, 81, 82, 84, 89, 90, 91], "base_model": 64, "adapter1": 64, "export_adapter_weight": 64, "adapter1_weight": 64, "configr": 64, "adaptermetadata": 64, "lora_a": 64, "lora_b": 64, "replaced_module_typ": 64, "adapater_name_to_meta_data": 64, "init": 64, "track_meta_data": 64, "pt": 64, "adapter_weights_path": 64, "bin": [64, 74, 75, 85], "freeze_base_model": 64, "freeze_base_model_activation_quant": 64, "get_fp_lora_lay": 64, "quantize_lora_scale_with_fixed_rang": 64, "scale_min": 64, "scale_max": 64, "mul": 64, "set_bitwidth_for_lora_adapt": 64, "cls_pair_1": 65, "cls_pair_2": 65, "depth": [65, 88, 96, 108], "clssetlayerpairinfo": 65, "scale_factor": 65, "relu_activation_between_lay": 65, "conv1d": [65, 89, 110], "convtranspose2d": [65, 89], "batchnorm1d": [65, 89], "bn_layer": 65, "sigma": 65, "cross_layer_equalization_auto_step_by_step": 65, "conv_bn": 65, "replace_modules_of_type1_with_type2": 65, "cls_set": 65, "layer_list": 65, "clspairinfo": 65, "depthwis": [65, 94, 110], "cross_layer_equalization_depthwise_lay": 65, "pdf": [66, 110], "hotspot": [66, 105], "check_model_sensitivity_to_quant": 66, "perform_per_layer_analysis_by_enabling_quant_wrapp": 66, "occurr": [66, 95], "perform_per_layer_analysis_by_disabling_quant_wrapp": 66, "export_per_layer_encoding_min_max_rang": 66, "esults_dir": 66, "pcq": [66, 94, 105], "wrapped_module_nam": 66, "param_nam": 66, "export_per_layer_stats_histogram": 66, "ctivations_pdf": 66, "eights_pdf": 66, "n": [66, 84, 91, 110], "am": 66, "channel_index": 66, "export_per_layer_mse_loss": 66, "tap": 66, "packag": [67, 87, 97, 110], "plan": 67, "upgrad": [67, 75], "flexibil": 67, "extens": [67, 74, 75, 89, 97], "futur": [67, 78, 83, 84, 87, 89], "releas": [67, 97, 102], "core": [67, 98], "checker": 67, "concern": 67, "peft": 67, "lora": 67, "introduc": [67, 84, 103, 107, 109], "power": [67, 108], "blockwis": [67, 87], "lpbq": [67, 87], "dispatch": 67, "carefulli": [67, 101], "compatibil": 67, "public": 67, "seq_ms": [67, 72], "apply_seq_ms": [67, 72], "orthogon": 67, "migrat": 67, "fakequantizationmixin": [67, 78, 88, 89], "quantizationmixin": [67, 88, 89], "in_plac": 68, "default_data_typ": 68, "restor": [68, 108], "save_checkpoint": 68, "file_path": 68, "checkpoint": [68, 103], "load_checkpoint": 68, "quant_sim_model": 68, "propagate_encod": 68, "export_to_torchscript": 68, "use_embedded_encod": 68, "opset_vers": [68, 69], "enable_onnx_check": 68, "entri": [68, 107], "data_typ": [68, 72], "fakequ": 68, "trainingextens": 68, "src": 68, "forward_pass_arg": 68, "quatiz": 68, "unction": 68, "idea": [69, 91], "travel": 69, "sparseconvolution3d": 69, "spars": 69, "sparsetensorwrapp": 69, "sparseconvtensor": 69, "scriptmodul": 69, "scatterdens": 69, "pro": [69, 84], "spconv3d": 69, "spconvmodel": 69, "spconv_tensor": 69, "sparseconv3d": 69, "spconv1": 69, "in_channel": [69, 84, 91], "out_channel": [69, 84, 91], "spconv2": 69, "conv3d": [69, 89], "normal_conv3d": 69, "spconv_scatter_dens": 69, "coord": 69, "voxel": 69, "sp_tensor": 69, "sp_outputs1": 69, "sp_outputs2": 69, "sp_outputs2_dens": 69, "sp_output": 69, "sp_outputs_relu": 69, "dense_tensor_sp_input": 69, "ncdhw": 69, "permut": [69, 89], "ndhwc": 69, "stack": 69, "meshgrid": 69, "ij": 69, "reshap": [69, 89], "operator_export_typ": 69, "operatorexporttyp": 69, "onnx_aten_fallback": 69, "converter_arg": 69, "input_dtyp": 69, "int32": 69, "expand_sparse_op_structur": 69, "preserve_io": 69, "exported_sp_conv_model": 69, "visualize_serialized_data": 70, "visualizecompress": [70, 112], "bokeh": [70, 71], "server": [70, 97], "publish": [70, 71], "tabl": [70, 83, 89, 97, 98, 102, 112], "display_eval_scor": [70, 112], "saved_eval_scores_dict_path": 70, "display_comp_ratio_plot": [70, 112], "comp_ratio_list_path": 70, "pkl": 70, "start_bokeh_server_sess": 70, "model_compression_with_visu": 70, "65": [70, 96], "resnet18_eval_scor": 70, "comp_ratios_file_path": 70, "greedy_selection_comp_ratios_list": 70, "eval_scores_path": 70, "compression_visu": 70, "termin": [70, 97], "visualize_model": 71, "visualize_relative_weight_ranges_to_identify_problematic_lay": 71, "selected_lay": 71, "figur": [71, 92, 98, 108, 115], "visualize_weight_rang": 71, "scatter": 71, "deviat": 71, "visualize_changes_after_optim": 71, "old_model": 71, "new_model": 71, "visualize_changes_in_model_after_and_before_cl": 71, "visualiz": 71, "model_copi": 71, "visualize_weight_ranges_model": 71, "usual": [71, 91, 106], "visualize_relative_weight_ranges_model": 71, "easier": [72, 84], "simpler": 72, "extend": 72, "fundament": 72, "advis": [72, 103, 107], "subject": 72, "properti": 72, "compon": 72, "stai": 72, "quantizewrapp": 72, "quantizationsimmodelv1": 72, "all_quant_wrapp": 72, "quant_wrapp": 72, "staticgridquantwrapp": 72, "_module_to_wrap": 72, "in_featur": [72, 77, 78, 89, 91], "out_featur": [72, 77, 78, 89, 91], "longer": [72, 103, 106], "quantizedlinear": [72, 77, 78, 84, 89, 91], "quantizedconv2d": [72, 84, 89, 91], "quantizationsimmodelv2": 72, "sim2": 72, "all_q_modul": 72, "qmodul": 72, "q_modul": 72, "moduledict": [72, 77, 78, 89, 91], "modulelist": [72, 77, 78, 89, 91], "fakequantizedrelu": [72, 89, 91], "staticgridquant": 72, "learnedgridquant": 72, "tensor_quant": 72, "staticgridperchannelquant": 72, "fp_quantiz": 72, "affine_quant": 72, "affinequant": [72, 80, 81], "floatquant": [72, 80, 81], "q": [72, 78, 79, 80, 81, 82, 89, 90, 109], "affine_q": 72, "affine_qdq": 72, "fp_qdq": 72, "floatquantizedequant": [72, 81], "float16": [72, 80, 81, 84], "setup": [72, 73], "sim1": 72, "wrap_linear": 72, "qlinear": [72, 77, 78, 89], "symmetri": 72, "is_unsigned_symmetr": 72, "use_strict_symmetr": 72, "simplifi": 72, "sign": [72, 79, 109], "libpymo": 72, "tfencod": 72, "copy_": 72, "OR": 72, "_remove_input_quant": 72, "_remove_output_quant": 72, "_remove_param_quant": 72, "temporarili": 72, "_is_encoding_frozen": 72, "freeze_encod": 72, "concept": 72, "mimick": 72, "allow_overwrit": [72, 87, 90], "requires_grad_": 72, "overwritten": 72, "pypi": 73, "intel": 73, "x86": 73, "processor": 73, "linux": [73, 75], "ubuntu": [73, 75], "22": [73, 75, 91], "04": [73, 75], "lt": [73, 75], "pip": [73, 74, 75, 88, 97], "apt": [73, 74, 75, 88], "liblapack": [73, 74, 75, 88], "python3": [73, 74, 75, 88, 97], "variant": [73, 75, 92, 93, 94, 104, 105, 106, 109], "latest": [73, 74], "whl": [73, 74, 75], "host": [73, 74, 75, 110, 112], "github": [73, 74, 75, 96, 97, 110], "com": [73, 74, 75, 97, 110], "quic": [73, 74, 75, 96, 97, 110], "cu121": [73, 74, 75], "cp310": [73, 74, 75], "manylinux_2_34_x86_64": [73, 74, 75], "13": [73, 74, 79], "cu117": 73, "cu118": 73, "older": 73, "brows": [73, 74, 75], "platform": [73, 103], "bash": [73, 74], "command": [73, 74, 75, 97, 112], "shell": 73, "nvidia": [73, 74, 75], "card": 73, "capabl": [73, 89, 112, 113], "docker": 73, "455": 73, "alwai": [73, 98], "newer": 73, "cudnn": 73, "machin": [73, 74, 101], "develop": [73, 74, 75, 78, 83, 84, 87, 89], "click": 73, "instruct": [74, 75, 88, 97], "variant_str": 74, "ONE": 74, "pt113": 74, "aimet_vari": 74, "workspac": [74, 97], "absolute_path_to_workspac": [74, 97], "docker_image_nam": 74, "codelinaro": 74, "dev": [74, 75], "docker_container_nam": 74, "any_nam": 74, "any_tag": 74, "jenkin": 74, "dockerfil": 74, "grep": 74, "kill": 74, "rm": 74, "passwd": 74, "ro": 74, "home": 74, "mnt": 74, "entrypoint": 74, "hostnam": 74, "filesystem": 74, "port": [74, 112], "port_id": 74, "project": [74, 75], "wish": [74, 75], "tip": [74, 75], "post1": [74, 75], "prepend": [74, 75], "sudo": [74, 75, 97], "wheel": [74, 75], "tag": [74, 75, 97, 110], "ex": [74, 75, 84], "release_tag": [74, 75, 97], "download_url": [74, 75], "wheel_file_nam": [74, 75], "usr": [74, 75], "lib": [74, 75], "dist": [74, 75], "envsetup": [74, 75], "sh": [74, 75], "pend": [75, 97], "pip3": 75, "h": [75, 97, 114, 115], "local": [75, 112], "accordingli": 75, "requisit": 75, "wget": 75, "gnupg2": 75, "archiv": 75, "exact": [75, 89, 94], "date": 75, "aforement": 75, "repo": [75, 97], "ubuntu2204": 75, "x86_64": 75, "keyring_1": 75, "1_all": 75, "deb": 75, "dpkg": 75, "cat": 75, "reqs_deb_common": 75, "txt": 75, "xarg": 75, "reqs_deb_torch_common": 75, "reqs_deb_onnx_common": 75, "reqs_deb_tf_gpu": 75, "reqs_deb_torch_gpu": 75, "reqs_deb_onnx_gpu": 75, "uninstal": 75, "onnxruntime_v": 75, "c": [75, 96], "__version__": 75, "ln": 75, "gnu": 75, "libjpeg": 75, "chose": 75, "mixin": [77, 78, 89], "held": [77, 91], "quantizerbas": [77, 78, 89, 90], "behav": [77, 78, 89, 108], "scratch": 77, "from_modul": [77, 78], "fakequantizedlinear": [77, 89], "abstract": [77, 78, 89, 90], "__quant_init__": [77, 78, 89], "initializd": [77, 78, 89], "overridden": [77, 78, 89], "length": [77, 78, 84, 89], "enter": [77, 78, 89, 93], "context": [77, 78, 89, 91], "is_initi": [77, 78, 79, 80, 81, 89, 90], "classmethod": [77, 78], "quantized_linear": [77, 78], "module_cl": [77, 78], "decor": [77, 78], "heavi": [78, 83, 84, 87, 89, 112, 113], "notic": [78, 83, 84, 87, 89, 101], "verion": 78, "fall": [78, 98, 107], "get_kernel": 78, "dequant": [78, 79, 82, 89, 90, 109], "set_kernel": 78, "quantizedtensor": [78, 79, 82, 90], "keyword": 78, "output_encod": 78, "underli": [78, 108], "int_multipli": 78, "enc": 78, "notimplementederror": 78, "q_output": 78, "quantized_repr": [78, 82], "dq_output": 78, "qmult": 78, "quantizedmultipli": [78, 89], "set_default_kernel": 78, "quantized_forward": 78, "get_default_kernel": 78, "encoding_analyz": [79, 80, 81, 85, 90], "block_siz": [79, 84, 90], "clamp": [79, 80, 81, 90, 109], "lceil": [79, 80, 81, 90], "frac": [79, 80, 81, 90], "rfloor": [79, 80, 81, 90], "qmin": [79, 90, 109], "qmax": [79, 90, 109], "learnabl": [79, 90], "theta_": [79, 90], "pmatrix": [79, 90], "b_0": [79, 90], "b_1": [79, 84, 90], "cdot": [79, 90], "b_": [79, 90], "d": [79, 90], "equat": [79, 84, 90, 109], "out_": [79, 90], "j_0": [79, 90], "j_": [79, 90], "input_": [79, 90], "scale_": [79, 90], "i_0": [79, 90], "i_": [79, 90], "offset_": [79, 90], "quad": [79, 90, 109], "forall_": [79, 90], "leq": [79, 90], "i_d": [79, 90], "lfloor": [79, 80, 81, 90], "j_d": [79, 90], "b_d": [79, 90], "asymmetr": [79, 85, 90, 107, 109], "encodinganalyz": [79, 80, 81, 85, 90], "129": [79, 90, 102], "255": [79, 82, 90], "122": [79, 90], "192": [79, 90], "106": [79, 90], "94": [79, 90], "145": [79, 90], "181": [79, 90], "144": [79, 90], "194": [79, 90], "74": [79, 90], "86": [79, 90], "150": [79, 90], "103": [79, 90], "37": [79, 90], "111": [79, 90], "237": [79, 90], "218": [79, 90], "49": [79, 90], "155": [79, 90], "179": [79, 90], "89": [79, 90], "110": [79, 90], "17": [79, 85, 90], "36": [79, 90], "83": [79, 90], "grad_fn": [79, 82, 90], "aliasbackward0": [79, 82, 90], "ones_lik": [79, 90], "187": [79, 90], "186": [79, 90], "131": [79, 90], "203": [79, 90], "143": [79, 90], "152": [79, 90], "226": [79, 90], "55": [79, 90], "172": [79, 90], "207": [79, 90], "146": [79, 90], "216": [79, 90], "238": [79, 90], "141": [79, 90], "178": [79, 90], "188": [79, 90], "63": [79, 90], "59": [79, 90], "19": [79, 90], "162": [79, 90], "30": [79, 90], "109": [79, 90], "overlin": [79, 90], "qdq": [79, 80, 81, 90], "dequantizedtensor": [79, 82, 90], "2771": [79, 90], "3038": [79, 90], "0819": [79, 90], "9700": [79, 90], "9487": [79, 90], "1307": [79, 90], "7894": [79, 90], "1709": [79, 90], "2212": [79, 90], "7741": [79, 90], "0295": [79, 90], "2265": [79, 90], "0564": [79, 90], "6177": [79, 90], "0386": [79, 90], "0176": [79, 90], "6054": [79, 90], "8836": [79, 90], "1232": [79, 90], "8229": [79, 90], "5540": [79, 90], "3992": [79, 90], "2363": [79, 90], "2546": [79, 90], "0036": [79, 90], "2355": [79, 90], "1741": [79, 90], "6079": [79, 90], "6247": [79, 90], "0115": [79, 90], "2458": [79, 90], "9157": [79, 90], "4694": [79, 90], "0639": [79, 90], "2568": [79, 90], "0680": [79, 90], "6695": [79, 90], "7932": [79, 90], "1889": [79, 90], "0158": [79, 90], "5695": [79, 90], "5220": [79, 90], "1977": [79, 90], "4475": [79, 90], "0424": [79, 90], "1128": [79, 90], "8796": [79, 90], "1060": [79, 90], "5897": [79, 90], "6196": [79, 90], "9961": [79, 90], "0549": [79, 90], "6431": [79, 90], "0039": [79, 90], "8706": [79, 90], "4706": [79, 90], "2353": [79, 90], "8078": [79, 90], "3451": [79, 90], "1176": [79, 90], "4549": [79, 90], "0471": [79, 90], "5255": [79, 90], "4157": [79, 90], "0784": [79, 90], "5333": [79, 90], "1647": [79, 90], "2118": [79, 90], "2196": [79, 90], "9176": [79, 90], "9490": [79, 90], "7765": [79, 90], "4784": [79, 90], "6039": [79, 90], "3137": [79, 90], "3216": [79, 90], "8000": [79, 90], "4392": [79, 90], "4863": [79, 90], "overload": 79, "rceil": 79, "num_step": 79, "num": 79, "_step": 79, "0000e": 79, "5000e": 79, "02": 79, "1921e": 79, "08": 79, "0500e": 79, "1000e": 79, "1500e": 79, "2000e": 79, "2500e": 79, "14": [79, 91], "quantize_dequant": 79, "0000": [79, 82], "0667": 79, "1333": 79, "2667": 79, "3333": 79, "4000": [79, 82], "4667": 79, "6000": [79, 82], "6667": 79, "7333": 79, "8667": 79, "9333": 79, "exponent_bit": [80, 81, 84], "mantissa_bit": [80, 81, 84], "cast": [80, 81, 89], "expon": [80, 81, 84], "mantissa": [80, 81, 84], "x_c": [80, 81], "log_2": [80, 81], "ieee": [80, 81, 101, 104], "_max": [80, 81], "mutual": [80, 81, 84], "exclus": [80, 81, 84], "finer": [80, 81, 84], "8998": [80, 81], "0947": [80, 81], "0891": [80, 81], "1727": [80, 81], "is_bfloat16": [80, 81], "8984": [80, 81], "0859": [80, 81], "1729": [80, 81], "minmaxencodinganalyz": [80, 81, 83, 85], "is_float16": [80, 81], "8994": [80, 81], "0889": [80, 81], "alia": [80, 81], "encodingbas": [82, 90], "57": 82, "312": 82, "153": 82, "205": 82, "set_rang": 82, "x_q": 82, "26": 82, "23": 82, "x_dq": 82, "carri": 82, "gradient": 82, "thu": 82, "autograd": 82, "backpropag": 82, "38": [82, 101], "40": 82, "39": [82, 91], "51": 82, "521": 82, "41": 82, "quant_dequ": 82, "x_qdq": 82, "52": 82, "68": 82, "97": 82, "uint8": 82, "visualization_tool": 83, "visualize_stat": 83, "save_path": 83, "exce": 83, "exceed": 83, "quant_stats_visu": 83, "counterpart": [84, 89], "come": [84, 106, 109], "con": 84, "storag": 84, "drawback": 84, "outlier": [84, 105, 109], "influenc": 84, "resid": [84, 110], "chunk": 84, "isol": 84, "favor": 84, "relationship": 84, "rule": [84, 107], "long": [84, 87], "b_2": 84, "b_n": 84, "s_1": 84, "s_2": 84, "s_n": 84, "evenli": 84, "divid": [84, 89, 106], "divis": 84, "permit": 84, "3d": 84, "arbitrari": 84, "themselv": [84, 106], "linear_1": 84, "lie": 84, "leverag": 84, "expans": [84, 101], "groupedblockquantizedequant": 84, "decompressed_bw": 84, "expand": [84, 89], "block_group": 84, "config_util": 84, "set_blockwise_quantization_for_weight": 84, "input_channel": 84, "linear1": 84, "switch": 84, "docstr": 84, "4d": 84, "assist": [84, 112, 113], "set_activation_quantizers_to_float": 84, "set_grouped_blockwise_quantization_for_weight": 84, "decompress": 84, "addition": 84, "larger": [84, 111, 114], "encoding_vers": [84, 87], "exported_model": [84, 87], "sqnrencodinganalyz": 85, "num_bin": 85, "2048": [85, 87], "asymmetric_delta_candid": 85, "symmetric_delta_candid": 85, "101": 85, "offset_candid": 85, "max_parallel": 85, "gamma": 85, "paral": 85, "percentileencodinganalyz": 85, "gptvq_weight": 87, "apply_gptvq": 87, "gptvq_param": 87, "param_encoding_path": 87, "module_names_to_exclud": 87, "block_level_module_nam": 87, "file_name_prefix": 87, "config_file_path": 87, "gptvqparamet": 87, "dataclass": 87, "row_axi": 87, "col_axi": 87, "rows_per_block": 87, "cols_per_block": 87, "vector_dim": 87, "vector_bw": 87, "vector_strid": 87, "index_bw": 87, "num_of_kmeans_iter": 87, "assignment_chunk_s": 87, "carrier": 87, "125m": 87, "optforcausallm": 87, "from_pretrain": 87, "facebook": 87, "gptvq_applied_model": 87, "lm_head": 87, "gptvq_opt": 87, "load_encod": 87, "edg": [88, 99], "incur": [88, 99, 105], "instal": [88, 110], "sample_input": [88, 91], "sample_output": 88, "out_dir": 88, "quantized_model": 88, "quickstart": 88, "product": [88, 99], "technologi": [88, 99], "subsidiari": [88, 99], "nativ": 89, "superset": 89, "coverag": 89, "basequantizationmixin": 89, "qmul": 89, "sens": 89, "qadd": 89, "quantizedadd": 89, "calibration_data_load": 89, "adaptiveavgpool1d": 89, "fakequantizedadaptiveavgpool1d": 89, "adaptiveavgpool2d": 89, "fakequantizedadaptiveavgpool2d": 89, "adaptiveavgpool3d": 89, "fakequantizedadaptiveavgpool3d": 89, "adaptivemaxpool1d": 89, "fakequantizedadaptivemaxpool1d": 89, "adaptivemaxpool2d": 89, "fakequantizedadaptivemaxpool2d": 89, "adaptivemaxpool3d": 89, "fakequantizedadaptivemaxpool3d": 89, "alphadropout": 89, "fakequantizedalphadropout": 89, "avgpool1d": 89, "fakequantizedavgpool1d": 89, "fakequantizedavgpool2d": 89, "avgpool3d": 89, "fakequantizedavgpool3d": 89, "fakequantizedbatchnorm1d": 89, "fakequantizedbatchnorm2d": 89, "batchnorm3d": 89, "fakequantizedbatchnorm3d": 89, "celu": 89, "fakequantizedcelu": 89, "channelshuffl": 89, "fakequantizedchannelshuffl": 89, "constantpad1d": 89, "fakequantizedconstantpad1d": 89, "constantpad2d": 89, "fakequantizedconstantpad2d": 89, "constantpad3d": 89, "fakequantizedconstantpad3d": 89, "fakequantizedconv1d": 89, "quantizedconv1d": 89, "fakequantizedconv2d": 89, "fakequantizedconv3d": 89, "quantizedconv3d": 89, "convtranspose1d": [89, 110], "fakequantizedconvtranspose1d": 89, "fakequantizedconvtranspose2d": 89, "convtranspose3d": 89, "fakequantizedconvtranspose3d": 89, "crossmaplrn2d": 89, "fakequantizedcrossmaplrn2d": 89, "fakequantizeddropout": 89, "dropout2d": 89, "fakequantizeddropout2d": 89, "dropout3d": 89, "fakequantizeddropout3d": 89, "elu": 89, "fakequantizedelu": 89, "featurealphadropout": 89, "fakequantizedfeaturealphadropout": 89, "fakequantizedflatten": 89, "fakequantizedfold": 89, "fractionalmaxpool2d": 89, "fakequantizedfractionalmaxpool2d": 89, "fractionalmaxpool3d": 89, "fakequantizedfractionalmaxpool3d": 89, "gelu": 89, "fakequantizedgelu": 89, "quantizedgelu": 89, "glu": 89, "fakequantizedglu": 89, "groupnorm": 89, "fakequantizedgroupnorm": 89, "hardshrink": 89, "fakequantizedhardshrink": 89, "hardsigmoid": 89, "fakequantizedhardsigmoid": 89, "hardswish": 89, "fakequantizedhardswish": 89, "hardtanh": 89, "fakequantizedhardtanh": 89, "fakequantizedident": 89, "instancenorm1d": 89, "fakequantizedinstancenorm1d": 89, "instancenorm2d": 89, "fakequantizedinstancenorm2d": 89, "instancenorm3d": 89, "fakequantizedinstancenorm3d": 89, "lppool1d": 89, "fakequantizedlppool1d": 89, "lppool2d": 89, "fakequantizedlppool2d": 89, "fakequantizedlayernorm": 89, "quantizedlayernorm": 89, "leakyrelu": 89, "fakequantizedleakyrelu": 89, "localresponsenorm": 89, "fakequantizedlocalresponsenorm": 89, "logsigmoid": 89, "fakequantizedlogsigmoid": 89, "logsoftmax": 89, "fakequantizedlogsoftmax": 89, "maxpool1d": 89, "fakequantizedmaxpool1d": 89, "maxpool2d": 89, "fakequantizedmaxpool2d": 89, "maxpool3d": 89, "fakequantizedmaxpool3d": 89, "maxunpool1d": 89, "fakequantizedmaxunpool1d": 89, "maxunpool2d": 89, "fakequantizedmaxunpool2d": 89, "maxunpool3d": 89, "fakequantizedmaxunpool3d": 89, "mish": 89, "fakequantizedmish": 89, "fakequantizedprelu": 89, "pixelshuffl": 89, "fakequantizedpixelshuffl": 89, "pixelunshuffl": 89, "fakequantizedpixelunshuffl": 89, "rrelu": 89, "fakequantizedrrelu": 89, "fakequantizedrelu6": 89, "reflectionpad1d": 89, "fakequantizedreflectionpad1d": 89, "reflectionpad2d": 89, "fakequantizedreflectionpad2d": 89, "replicationpad1d": 89, "fakequantizedreplicationpad1d": 89, "replicationpad2d": 89, "fakequantizedreplicationpad2d": 89, "replicationpad3d": 89, "fakequantizedreplicationpad3d": 89, "selu": 89, "fakequantizedselu": 89, "silu": 89, "fakequantizedsilu": 89, "fakequantizedsigmoid": 89, "quantizedsigmoid": 89, "fakequantizedsoftmax": 89, "quantizedsoftmax": [89, 91], "softmax2d": 89, "fakequantizedsoftmax2d": 89, "softmin": 89, "fakequantizedsoftmin": 89, "fakequantizedsoftplu": 89, "softshrink": 89, "fakequantizedsoftshrink": 89, "softsign": 89, "fakequantizedsoftsign": 89, "syncbatchnorm": 89, "fakequantizedsyncbatchnorm": 89, "tanh": 89, "fakequantizedtanh": 89, "tanhshrink": 89, "fakequantizedtanhshrink": 89, "fakequantizedthreshold": 89, "unflatten": 89, "fakequantizedunflatten": 89, "unfold": 89, "fakequantizedunfold": 89, "upsampl": [89, 102], "fakequantizedupsampl": 89, "upsamplingbilinear2d": 89, "fakequantizedupsamplingbilinear2d": 89, "upsamplingnearest2d": 89, "fakequantizedupsamplingnearest2d": 89, "zeropad2d": 89, "fakequantizedzeropad2d": 89, "bceloss": 89, "fakequantizedbceloss": 89, "bcewithlogitsloss": 89, "fakequantizedbcewithlogitsloss": 89, "bilinear": [89, 102], "fakequantizedbilinear": 89, "ctcloss": 89, "fakequantizedctcloss": 89, "cosinesimilar": 89, "fakequantizedcosinesimilar": 89, "crossentropyloss": [89, 91], "fakequantizedcrossentropyloss": 89, "hingeembeddingloss": 89, "fakequantizedhingeembeddingloss": 89, "huberloss": 89, "fakequantizedhuberloss": 89, "kldivloss": 89, "fakequantizedkldivloss": 89, "l1loss": 89, "fakequantizedl1loss": 89, "mseloss": 89, "fakequantizedmseloss": 89, "multilabelmarginloss": 89, "fakequantizedmultilabelmarginloss": 89, "multilabelsoftmarginloss": 89, "fakequantizedmultilabelsoftmarginloss": 89, "multimarginloss": 89, "fakequantizedmultimarginloss": 89, "nllloss": 89, "fakequantizednllloss": 89, "nllloss2d": 89, "fakequantizednllloss2d": 89, "pairwisedist": 89, "fakequantizedpairwisedist": 89, "poissonnllloss": 89, "fakequantizedpoissonnllloss": 89, "smoothl1loss": 89, "fakequantizedsmoothl1loss": 89, "softmarginloss": 89, "fakequantizedsoftmarginloss": 89, "cosineembeddingloss": 89, "fakequantizedcosineembeddingloss": 89, "gaussiannllloss": 89, "fakequantizedgaussiannllloss": 89, "marginrankingloss": 89, "fakequantizedmarginrankingloss": 89, "tripletmarginloss": 89, "fakequantizedtripletmarginloss": 89, "tripletmarginwithdistanceloss": 89, "fakequantizedtripletmarginwithdistanceloss": 89, "fakequantizedembed": 89, "embeddingbag": 89, "fakequantizedembeddingbag": 89, "gru": [89, 110], "fakequantizedgru": 89, "rnn": [89, 110], "fakequantizedrnn": 89, "grucel": 89, "fakequantizedgrucel": 89, "rnncell": 89, "fakequantizedrnncel": 89, "lstm": [89, 110], "fakequantizedlstm": 89, "lstmcell": 89, "fakequantizedlstmcel": 89, "adaptivelogsoftmaxwithloss": 89, "fakequantizedadaptivelogsoftmaxwithloss": 89, "fakequantizedcast": 89, "depthtospacedcrmod": 89, "fakequantizeddepthtospacedcrmod": 89, "onehot": 89, "fakequantizedonehot": 89, "exponenti": 89, "fakequantizedexponenti": 89, "erf": 89, "fakequantizederf": 89, "fakequantizedsqrt": 89, "fakequantizedlog": 89, "fakequantizedab": 89, "fakequantizedneg": 89, "elementwiseceil": 89, "fakequantizedelementwiseceil": 89, "elementwisefloor": 89, "fakequantizedelementwisefloor": 89, "sin": 89, "fakequantizedsin": 89, "co": 89, "fakequantizedco": 89, "asin": 89, "fakequantizedasin": 89, "atan": 89, "fakequantizedatan": 89, "fakequantizedround": 89, "logicalnot": 89, "fakequantizedlogicalnot": 89, "nonzero": 89, "fakequantizednonzero": 89, "elementwiseunarysign": 89, "fakequantizedelementwiseunarysign": 89, "rsqrt": 89, "fakequantizedrsqrt": 89, "squar": [89, 109], "fakequantizedsquar": 89, "fakequantizedmean": 89, "fakequantizedsum": 89, "prod": 89, "fakequantizedprod": 89, "argmin": 89, "fakequantizedargmin": 89, "fakequantizedargmax": 89, "gather": 89, "fakequantizedgath": 89, "fakequantizedreshap": 89, "roialign": 89, "fakequantizedroialign": 89, "fakequantizedpermut": 89, "indexselect": 89, "fakequantizedindexselect": 89, "fakequantizedtopk": 89, "tile": 89, "fakequantizedtil": 89, "fakequantizednorm": 89, "cumsum": 89, "fakequantizedcumsum": 89, "fakequantizedinterpol": 89, "fakequantizedpad": 89, "fakequantizedshap": 89, "fakequantizedexpand": 89, "stridedslic": 89, "fakequantizedstridedslic": 89, "matmul": [89, 110], "fakequantizedmatmul": 89, "fakequantizedadd": 89, "fakequantizedmultipli": 89, "subtract": 89, "fakequantizedsubtract": 89, "quantizedsubtract": 89, "fakequantizeddivid": 89, "floordivid": 89, "fakequantizedfloordivid": 89, "fakequantizedgreat": 89, "fakequantizedless": 89, "greaterequ": 89, "fakequantizedgreaterequ": 89, "lessequ": 89, "fakequantizedlessequ": 89, "notequ": 89, "fakequantizednotequ": 89, "fakequantizedequ": 89, "remaind": 89, "fakequantizedremaind": 89, "fmod": 89, "fakequantizedfmod": 89, "pow": 89, "fakequantizedpow": 89, "customsilu": 89, "fakequantizedcustomsilu": 89, "fakequantizedmaximum": 89, "fakequantizedmax": 89, "fakequantizedminimum": 89, "fakequantizedmin": 89, "bmm": 89, "fakequantizedbmm": 89, "logicalor": 89, "fakequantizedlogicalor": 89, "logicaland": 89, "fakequantizedlogicaland": 89, "customgath": 89, "fakequantizedcustomgath": 89, "gathernd": 89, "fakequantizedgathernd": 89, "baddbmm": 89, "fakequantizedbaddbmm": 89, "addmm": 89, "fakequantizedaddmm": 89, "scatternd": 89, "fakequantizedscatternd": 89, "dynamicconv2d": 89, "fakequantizeddynamicconv2d": 89, "scatterel": 89, "fakequantizedscatterel": 89, "fakequantizedbatchnorm": 89, "fakequantizedaimetgroupnorm": 89, "nonmaxsuppress": 89, "fakequantizednonmaxsuppress": 89, "fakequantizedsplit": 89, "concat": [89, 110], "fakequantizedconcat": 89, "fakequantizedwher": 89, "maskedfil": 89, "fakequantizedmaskedfil": 89, "allow_overwit": 90, "get_encod": 90, "get_legacy_encod": 90, "register_quantization_paramet": 90, "set_legacy_encod": 90, "tutori": 91, "meant": 91, "clearli": 91, "cifar10_train_data": 91, "fashionmnist": 91, "cifar10": 91, "cifar10_test_data": 91, "test_load": 91, "bn_1": 91, "bn_2": 91, "establish": 91, "send": 91, "batch_idx": 91, "zero_grad": 91, "fp_accuraci": 91, "91": 91, "70999908447266": 91, "coupl": [91, 92], "conform": 91, "incorrectli": 91, "thankfulli": 91, "fp_accuracy_prepar": 91, "2024": 91, "07": 91, "747": 91, "806": 91, "module_relu": 91, "module_relu_1": 91, "module_softmax": 91, "12544": 91, "getattr_1": 91, "getitem": 91, "graph_modul": 91, "print_read": 91, "passthrough": 91, "previous": 91, "theoret": 91, "idx": 91, "quantized_accuraci": 91, "1500015258789": 91, "advanc": 91, "post_qat_accuraci": 91, "92": 91, "05333709716797": 91, "happi": 91, "export_path": 91, "model_nam": 91, "fashion_mnist_model": 91, "sent": 91, "bc": 92, "bnf": 92, "hbf": 92, "moder": 92, "preprat": 93, "mainli": 93, "stage": 93, "preceed": 94, "decreas": 94, "main": [94, 107, 110, 113], "oscil": 94, "presenc": 95, "connect": [95, 100, 114], "residu": 95, "attempt": [95, 103, 104], "regress": 95, "ssvd": 96, "cp": 96, "accumul": 96, "reduct": 96, "uncompress": 96, "latenc": 96, "io": [96, 110], "half": 96, "unknown": 96, "apriori": 96, "cssvd": 96, "75": 96, "2b": 96, "2a": 96, "revisit": 96, "ccp": 96, "csvd": 96, "becom": [97, 104], "familiar": 97, "browsabl": 97, "metapackag": 97, "ip": 97, "browser": 97, "past": 97, "mkdir": 97, "cd": 97, "git": 97, "www": 97, "navig": 97, "launch": 97, "ipynb": 97, "therein": 97, "assess": 98, "sure": [98, 102], "highest": 98, "column": 98, "unmodifi": 98, "last": [98, 100, 108], "strict": [98, 107, 109], "drstical": 98, "hw": 99, "redund": 99, "dilat": 100, "depthwiseconv2d": 100, "guidebook": [101, 103], "advic": 101, "greedi": [101, 112], "nomin": 101, "prefer": 101, "fc": 101, "term": [101, 111, 112, 113, 114], "sharp": 101, "degrad": 101, "decai": 101, "slow": 101, "searcher": 101, "strike": 101, "balanc": 101, "xiangyu": 101, "zhang": 101, "jianhua": 101, "zou": 101, "kaim": 101, "he": 101, "jian": 101, "sun": 101, "deep": 101, "transact": 101, "pattern": 101, "intellig": 101, "vol": 101, "pp": 101, "1943": 101, "1955": 101, "oct": 101, "2016": 101, "yihui": 101, "confer": [101, 104], "vision": [101, 104], "venic": 101, "2017": 101, "1398": 101, "1406": 101, "jaderberg": 101, "andrea": 101, "vedaldi": 101, "andrew": 101, "zisserman": 101, "british": 101, "jan": 101, "2014": 101, "andrei": 101, "kuzmin": 101, "marku": [101, 104], "nagel": [101, 104], "saurabh": 101, "pitr": 101, "sandeep": 101, "pendyam": 101, "tijmen": [101, 104], "blankevoort": [101, 104], "taxonomi": 101, "primit": 102, "slice": 102, "align_corn": 102, "deconvolut": 102, "deeplabv3": 102, "address": [102, 108, 112], "advantag": 103, "fast": 103, "easi": [103, 105], "gap": 103, "robust": 103, "account": [103, 106, 108], "prep": 103, "align": 103, "retri": 103, "satisfactori": [103, 108], "bring": 103, "onto": 103, "pb": 103, "trial": 103, "seem": 103, "bat": 103, "surround": 104, "big": 104, "discrep": 104, "wide": 104, "significantli": 104, "quantizaion": 104, "analyt": [104, 112, 113], "bottleneck": [104, 108], "hybrid": 104, "approach": [104, 109], "mart": 104, "van": 104, "baalen": 104, "seoul": 104, "octob": 104, "rune": 105, "situat": 105, "pinpoint": 105, "culprit": 105, "toss": 105, "monitor": 105, "contribut": [105, 108], "read": 105, "mitig": [106, 109], "accompani": 106, "throughout": [106, 107, 113], "aid": 106, "converg": 106, "six": 107, "overrul": 107, "turn": 107, "empti": 107, "omit": 107, "asid": 107, "govern": 107, "unsign": [107, 109], "convent": 107, "member": 107, "whatev": 107, "earlier": 107, "diagnost": 108, "strictli": 108, "insight": [108, 112, 113], "underperform": 108, "tackl": 108, "chart": 108, "saniti": 108, "ofth": 108, "kept": 108, "toward": 108, "uneven": 108, "global": 108, "inner": 108, "bert": 108, "reveal": 108, "resort": 108, "revert": 108, "ultim": 109, "ingest": 109, "000": 109, "dequantiz": 109, "hook": 109, "intercept": 109, "four": 109, "textrm": 109, "dfrac": 109, "strong": 109, "excess": 109, "signal": 109, "satur": 109, "erro": 109, "alongsid": 109, "ones": 109, "slim": 110, "backslash": 110, "user_guid": 110, "api_doc": 110, "quantizablemultiheadattent": 110, "kyuykim": 110, "mangal": 110, "geunle": 110, "correctli": 110, "klhsieh": 110, "akhobar": 110, "ashvkuma": 110, "fp16": 110, "stand": [110, 111, 114], "adaptiveround": 110, "recurr": 110, "\ud835\udc5a": [111, 114], "\ud835\udc5b": [111, 114], "\u210e": [111, 114], "\ud835\udc64": [111, 114], "\ud835\udc58": [111, 114], "degre": [111, 114], "progress": [112, 113], "computation": [112, 113], "websocket": 112, "listen": 112, "5006": 112, "lot": 113, "lose": 115, "pictori": 115, "volum": 115, "hxwx8": 115, "hxwx5": 115, "propag": 115, "That": 115, "teh": 115, "green": 115, "color": 115, "side": 115, "pink": 115, "orang": 115}, "objects": {"aimet_common.bias_correction": [[55, 0, 1, "", "ConvBnInfoType"]], "aimet_common.defs": [[55, 0, 1, "", "ActivationType"], [59, 0, 1, "", "CallbackFunc"], [30, 0, 1, "", "CompressionScheme"], [30, 0, 1, "", "CostMetric"], [56, 0, 1, "", "GreedySelectionParameters"], [68, 0, 1, "", "QuantScheme"]], "aimet_common.defs.ActivationType": [[55, 1, 1, "", "no_activation"], [55, 1, 1, "", "relu"], [55, 1, 1, "", "relu6"]], "aimet_common.defs.CompressionScheme": [[30, 1, 1, "", "channel_pruning"], [30, 1, 1, "", "spatial_svd"], [30, 1, 1, "", "weight_svd"]], "aimet_common.defs.CostMetric": [[30, 1, 1, "", "mac"], [30, 1, 1, "", "memory"]], "aimet_common.defs.QuantScheme": [[68, 1, 1, "", "post_training_percentile"], [68, 1, 1, "", "post_training_tf"], [68, 1, 1, "", "post_training_tf_enhanced"], [68, 1, 1, "", "training_range_learning_with_tf_enhanced_init"], [68, 1, 1, "", "training_range_learning_with_tf_init"]], "aimet_common.utils": [[66, 0, 1, "", "CallbackFunc"]], "aimet_tensorflow.keras.bn_reestimation": [[29, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.keras.defs": [[30, 0, 1, "", "ModuleCompRatioPair"], [30, 0, 1, "", "SpatialSvdParameters"]], "aimet_tensorflow.keras.defs.SpatialSvdParameters": [[30, 0, 1, "", "AutoModeParams"], [30, 0, 1, "", "ManualModeParams"], [30, 0, 1, "", "Mode"]], "aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode": [[30, 1, 1, "", "auto"], [30, 1, 1, "", "manual"]], "aimet_tensorflow.keras.model_preparer": [[35, 2, 1, "", "prepare_model"]], "aimet_torch.adaround.adaround_weight.Adaround": [[51, 2, 1, "", "apply_adaround"]], "aimet_torch.adaround.adaround_weight": [[51, 0, 1, "", "AdaroundParameters"]], "aimet_torch.amp.mixed_precision_algo": [[59, 0, 1, "", "EvalCallbackFactory"]], "aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory": [[59, 3, 1, "", "sqnr"]], "aimet_torch.amp.quantizer_groups": [[59, 0, 1, "", "QuantizerGroup"]], "aimet_torch.amp.quantizer_groups.QuantizerGroup": [[59, 3, 1, "", "get_active_quantizers"], [59, 3, 1, "", "get_candidate"], [59, 3, 1, "", "get_input_quantizer_modules"], [59, 3, 1, "", "set_quantizers_to_candidate"], [59, 3, 1, "", "to_list"]], "aimet_torch.arch_checker.arch_checker.ArchChecker": [[52, 2, 1, "", "check_model_arch"]], "aimet_torch.auto_quant": [[53, 0, 1, "", "AutoQuant"]], "aimet_torch.batch_norm_fold": [[65, 2, 1, "", "fold_all_batch_norms"], [54, 2, 1, "", "fold_all_batch_norms_to_scale"], [65, 2, 1, "", "fold_given_batch_norms"]], "aimet_torch.bias_correction": [[55, 2, 1, "", "correct_bias"]], "aimet_torch.bn_reestimation": [[54, 2, 1, "", "reestimate_bn_stats"]], "aimet_torch.compress": [[56, 0, 1, "", "ModelCompressor"]], "aimet_torch.compress.ModelCompressor": [[56, 3, 1, "", "compress_model"]], "aimet_torch.cross_layer_equalization": [[65, 0, 1, "", "ClsSetInfo"], [57, 2, 1, "", "equalize_model"]], "aimet_torch.cross_layer_equalization.ClsSetInfo": [[65, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_torch.cross_layer_equalization.CrossLayerScaling": [[65, 2, 1, "", "scale_cls_sets"], [65, 2, 1, "", "scale_model"]], "aimet_torch.cross_layer_equalization.HighBiasFold": [[65, 2, 1, "id0", "bias_fold"]], "aimet_torch.defs": [[56, 0, 1, "", "ChannelPruningParameters"], [56, 0, 1, "", "ModuleCompRatioPair"], [56, 0, 1, "", "SpatialSvdParameters"], [56, 0, 1, "", "WeightSvdParameters"]], "aimet_torch.defs.ChannelPruningParameters": [[56, 0, 1, "", "AutoModeParams"], [56, 0, 1, "", "ManualModeParams"], [56, 0, 1, "", "Mode"]], "aimet_torch.defs.ChannelPruningParameters.Mode": [[56, 1, 1, "", "auto"], [56, 1, 1, "", "manual"]], "aimet_torch.defs.SpatialSvdParameters": [[56, 0, 1, "", "AutoModeParams"], [56, 0, 1, "", "ManualModeParams"], [56, 0, 1, "", "Mode"]], "aimet_torch.defs.SpatialSvdParameters.Mode": [[56, 1, 1, "", "auto"], [56, 1, 1, "", "manual"]], "aimet_torch.defs.WeightSvdParameters": [[56, 0, 1, "", "AutoModeParams"], [56, 0, 1, "", "ManualModeParams"], [56, 0, 1, "", "Mode"]], "aimet_torch.defs.WeightSvdParameters.Mode": [[56, 1, 1, "", "auto"], [56, 1, 1, "", "manual"]], "aimet_torch.gptvq.defs": [[87, 0, 1, "", "GPTVQParameters"]], "aimet_torch.gptvq.gptvq_weight.GPTVQ": [[87, 2, 1, "", "apply_gptvq"]], "aimet_torch.layer_output_utils": [[58, 0, 1, "", "LayerOutputUtil"], [58, 0, 1, "", "NamingScheme"]], "aimet_torch.layer_output_utils.LayerOutputUtil": [[58, 3, 1, "", "generate_layer_outputs"]], "aimet_torch.layer_output_utils.NamingScheme": [[58, 1, 1, "", "ONNX"], [58, 1, 1, "", "PYTORCH"], [58, 1, 1, "", "TORCHSCRIPT"]], "aimet_torch.mixed_precision": [[59, 2, 1, "", "choose_mixed_precision"]], "aimet_torch.model_preparer": [[61, 2, 1, "", "prepare_model"]], "aimet_torch.nn.modules.custom": [[69, 0, 1, "", "ScatterDense"], [69, 0, 1, "", "SparseTensorWrapper"]], "aimet_torch.peft": [[64, 0, 1, "", "AdapterMetaData"], [64, 0, 1, "", "PeftQuantUtils"], [64, 3, 1, "", "replace_lora_layers_with_quantizable_layers"], [64, 3, 1, "", "track_lora_meta_data"]], "aimet_torch.peft.PeftQuantUtils": [[64, 3, 1, "", "disable_lora_adapters"], [64, 3, 1, "", "enable_adapter_and_load_weights"], [64, 3, 1, "", "export_adapter_weights"], [64, 3, 1, "", "freeze_base_model"], [64, 3, 1, "", "freeze_base_model_activation_quantizers"], [64, 3, 1, "", "freeze_base_model_param_quantizers"], [64, 3, 1, "", "get_fp_lora_layer"], [64, 3, 1, "", "get_quantized_lora_layer"], [64, 3, 1, "", "quantize_lora_scale_with_fixed_range"], [64, 3, 1, "", "set_bitwidth_for_lora_adapters"]], "aimet_torch.quant_analyzer": [[66, 0, 1, "", "QuantAnalyzer"]], "aimet_torch.quant_analyzer.QuantAnalyzer": [[66, 3, 1, "", "analyze"], [66, 3, 1, "", "check_model_sensitivity_to_quantization"], [66, 3, 1, "", "enable_per_layer_mse_loss"], [66, 3, 1, "", "export_per_layer_encoding_min_max_range"], [66, 3, 1, "", "export_per_layer_mse_loss"], [66, 3, 1, "", "export_per_layer_stats_histogram"], [66, 3, 1, "", "perform_per_layer_analysis_by_disabling_quant_wrappers"], [66, 3, 1, "", "perform_per_layer_analysis_by_enabling_quant_wrappers"]], "aimet_torch.quantsim": [[55, 0, 1, "", "QuantParams"], [68, 0, 1, "", "QuantizationSimModel"], [68, 3, 1, "", "load_checkpoint"], [68, 3, 1, "", "save_checkpoint"]], "aimet_torch.quantsim.QuantizationSimModel": [[68, 3, 1, "", "compute_encodings"], [68, 3, 1, "", "export"]], "aimet_torch.v2.nn": [[77, 0, 1, "", "FakeQuantizationMixin"], [78, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.FakeQuantizationMixin": [[77, 3, 1, "", "__quant_init__"], [77, 3, 1, "", "compute_encodings"], [77, 3, 1, "", "forward"], [77, 3, 1, "", "from_module"], [77, 3, 1, "", "implements"], [77, 1, 1, "", "input_quantizers"], [77, 1, 1, "", "output_quantizers"], [77, 1, 1, "", "param_quantizers"]], "aimet_torch.v2.nn.QuantizationMixin": [[78, 3, 1, "", "__quant_init__"], [78, 3, 1, "", "compute_encodings"], [78, 3, 1, "", "forward"], [78, 3, 1, "", "from_module"], [78, 3, 1, "", "get_default_kernel"], [78, 3, 1, "", "get_kernel"], [78, 3, 1, "", "implements"], [78, 1, 1, "", "input_quantizers"], [78, 1, 1, "", "output_quantizers"], [78, 1, 1, "", "param_quantizers"], [78, 3, 1, "", "set_default_kernel"], [78, 3, 1, "", "set_kernel"]], "aimet_torch.v2.nn.base": [[89, 0, 1, "", "BaseQuantizationMixin"]], "aimet_torch.v2.nn.base.BaseQuantizationMixin": [[89, 3, 1, "", "__quant_init__"], [89, 3, 1, "", "compute_encodings"], [89, 3, 1, "", "forward"], [89, 1, 1, "", "input_quantizers"], [89, 1, 1, "", "output_quantizers"], [89, 1, 1, "", "param_quantizers"]], "aimet_torch.v2.quantization": [[79, 4, 0, "-", "affine"], [81, 4, 0, "-", "float"]], "aimet_torch.v2.quantization.affine": [[79, 0, 1, "", "Quantize"], [79, 0, 1, "", "QuantizeDequantize"], [79, 2, 1, "", "dequantize"], [79, 2, 1, "", "quantize"], [79, 2, 1, "", "quantize_dequantize"]], "aimet_torch.v2.quantization.affine.quantizer": [[90, 0, 1, "", "Quantize"], [90, 0, 1, "", "QuantizeDequantize"], [90, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[90, 3, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[90, 3, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[90, 3, 1, "", "allow_overwrite"], [90, 3, 1, "", "compute_encodings"], [90, 3, 1, "", "get_encoding"], [90, 3, 1, "", "get_legacy_encodings"], [90, 3, 1, "", "is_initialized"], [90, 3, 1, "", "register_quantization_parameter"], [90, 3, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization.encoding_analyzer": [[85, 0, 1, "", "EncodingAnalyzer"], [85, 0, 1, "", "MinMaxEncodingAnalyzer"], [85, 0, 1, "", "PercentileEncodingAnalyzer"], [85, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.float": [[81, 0, 1, "", "FloatQuantizeDequantize"], [81, 0, 1, "", "QuantizeDequantize"]], "aimet_torch.v2.quantization.tensor": [[82, 0, 1, "", "DequantizedTensor"], [82, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[82, 3, 1, "", "dequantize"], [82, 3, 1, "", "quantize"], [82, 3, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[82, 3, 1, "", "dequantize"], [82, 3, 1, "", "quantize"], [82, 3, 1, "", "quantized_repr"]], "aimet_torch.v2.quantsim.config_utils": [[84, 2, 1, "", "set_activation_quantizers_to_float"], [84, 2, 1, "", "set_blockwise_quantization_for_weights"], [84, 2, 1, "", "set_grouped_blockwise_quantization_for_weights"]], "aimet_torch.v2.visualization_tools": [[83, 2, 1, "", "visualize_stats"]], "aimet_torch.visualize_model": [[71, 2, 1, "", "visualize_changes_after_optimization"], [71, 2, 1, "", "visualize_relative_weight_ranges_to_identify_problematic_layers"], [71, 2, 1, "", "visualize_weight_ranges"]], "aimet_torch.visualize_serialized_data": [[70, 0, 1, "", "VisualizeCompression"]], "aimet_torch.visualize_serialized_data.VisualizeCompression": [[70, 3, 1, "", "display_comp_ratio_plot"], [70, 3, 1, "", "display_eval_scores"]]}, "objtypes": {"0": "py:class", "1": "py:attribute", "2": "py:function", "3": "py:method", "4": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "attribute", "Python attribute"], "2": ["py", "function", "Python function"], "3": ["py", "method", "Python method"], "4": ["py", "module", "Python module"]}, "titleterms": {"automat": [0, 4, 18], "mix": [0, 4, 18, 33, 45, 59], "precis": [0, 4, 18, 33, 45, 59], "amp": [0, 4, 18, 33], "overal": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 91, 95], "flow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 64, 91, 104], "what": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 67], "thi": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "notebook": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 31, 51, 53, 54, 57, 66, 68, 97], "i": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "dataset": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "1": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 49, 55, 75, 91, 110], "exampl": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 68, 69, 70, 71, 72, 87, 88, 97], "evalu": [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25], "pipelin": [0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25], "2": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 33, 49, 55, 75, 91, 110], "convert": [0, 1, 2, 3, 9], "an": [0, 1, 2, 3], "fp32": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24], "pytorch": [0, 1, 2, 3, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 63, 65, 66, 67, 68, 75, 88, 91, 102, 103, 113], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 35, 60, 61, 62, 88, 91, 99, 101, 102, 103], "onnx": [0, 1, 2, 3, 40, 41, 42, 43, 44, 45, 46, 47, 48, 69, 75], "": [0, 1, 2, 3, 67], "baselin": [0, 1, 2, 3, 4, 5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24], "accuraci": [0, 1, 2, 3, 4, 5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24], "3": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 49], "creat": [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 23, 24], "quantiz": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 33, 38, 39, 45, 47, 48, 55, 59, 67, 68, 71, 72, 79, 81, 82, 84, 86, 89, 90, 91, 103, 104, 106, 107, 108, 109, 113], "simul": [0, 1, 2, 3, 4, 5, 13, 14, 18, 19, 21, 22, 23, 24, 107, 109], "fold": [0, 1, 2, 3, 5, 7, 10, 11, 13, 14, 18, 19, 21, 22, 23, 24, 91], "batch": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "normal": [0, 1, 2, 3, 5, 10, 11, 13, 14, 18, 19, 22, 23, 24], "layer": [0, 1, 2, 3, 5, 7, 9, 10, 11, 12, 13, 14, 18, 19, 21, 22, 23, 24, 25, 31, 32, 36, 43, 44, 57, 58, 65, 98, 101, 104], "sim": [0, 1, 2, 3, 10, 11, 14, 18, 21, 22, 23, 24, 39, 48, 68], "comput": [0, 1, 3, 4, 10, 11, 14, 18, 89], "encod": [0, 1, 3, 4, 10, 11, 12, 14, 18, 25, 49, 85, 89, 109], "4": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17, 18, 19, 21, 22, 23, 24, 49], "run": [0, 4, 6, 18, 20, 46, 66, 97], "algorithm": [0, 4, 18], "defin": [0, 6, 7, 18, 20], "callback": [0, 6, 7, 18], "function": [0, 6, 7, 9, 18, 20, 79], "paramet": [0, 4, 6, 18, 20, 28, 30, 41, 51, 56, 87, 109], "call": [0, 4, 18], "api": [0, 4, 18, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 84, 87, 88, 89, 90, 92, 93, 94, 104, 105, 109], "adapt": [1, 5, 19, 41, 51], "round": [1, 5, 19, 41, 51, 101], "adaround": [1, 5, 6, 13, 19, 20, 28, 41, 51, 92], "train": [1, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 68, 86, 91, 103, 104, 106], "determin": [1, 2, 3, 5, 6, 10, 11, 13, 14, 19, 22, 23, 24, 109], "appli": [1, 5, 6, 12, 13, 19, 25], "summari": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24], "cross": [2, 14, 22, 31, 36, 43, 57, 65, 104], "equal": [2, 14, 22, 31, 36, 43, 57, 65, 104], "cle": [2, 14, 22, 36], "instanti": [4, 7], "method": [4, 36], "load": [4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "find": [4, 15, 16, 17], "fake": 4, "op": [4, 109], "insert": 4, "regular": [4, 33], "fast": [4, 33], "0": [4, 33, 49, 110], "get": [5, 13, 14, 18, 19, 22, 23, 24, 88, 99, 101], "score": [5, 13, 14, 18, 19, 22, 23, 24], "autoqu": [6, 20, 42, 53, 93], "pretrain": [6, 10, 11, 12, 20], "constant": [6, 7, 20], "helper": [6, 20, 36], "prepar": [6, 7, 9, 35, 61, 91], "5": [6, 7, 10, 11, 14, 21, 49], "option": [6, 20, 101], "set": [6, 20, 74], "awar": [7, 8, 10, 11, 21, 23, 24, 68, 91, 106], "batchnorm": [7, 21, 29, 54, 91], "re": [7, 21, 29, 54, 94], "estim": [7, 21, 29, 54, 94], "kera": [7, 8, 9], "quantizationsim": [7, 10, 11], "perform": [7, 10, 11, 21, 23, 24, 36], "qat": [7, 10, 11, 21, 23, 24, 68, 106], "export": [7, 10, 11, 14, 21, 69, 84, 91], "transform": 8, "subclass": 9, "show": 9, "similar": 9, "differ": 9, "between": 9, "origin": 9, "discuss": 9, "limit": [9, 29, 35, 61], "compil": [10, 11], "6": [10, 11, 49], "valid": [10, 11, 62], "after": [10, 11, 17], "7": [10, 11], "rang": [11, 12, 24, 25], "learn": [11, 24], "quant": [12, 25, 37, 46, 66], "analyz": [12, 25, 37, 46, 66, 85], "quantanalyz": [12, 25, 105], "per": [12, 13, 25, 98, 101], "analysi": [12, 25, 103, 105], "enabl": [12, 25], "disabl": [12, 25], "wrapper": [12, 25], "min": [12, 25], "max": [12, 25], "pdf": [12, 25], "statist": [12, 21, 25], "mse": [12, 25], "loss": [12, 25], "quantsim": [13, 14, 91, 109], "channel": [13, 15, 17, 56, 95], "pcq": 13, "compress": [15, 16, 17, 30, 56, 70, 96, 98, 101, 112], "us": [15, 16, 17, 36, 74, 92, 101, 103, 112], "prune": [15, 17, 56, 95], "fine": [15, 16, 17, 91, 101], "tune": [15, 16, 17, 91, 101], "post": [15, 16, 17, 75, 86, 103, 104], "spatial": [16, 17, 30, 56, 111], "svd": [16, 17, 30, 56, 111, 114], "follow": 17, "object": 20, "infer": 20, "optim": 20, "reestim": [21, 54], "bia": [22, 55], "correct": [22, 55], "bc": 22, "welcom": 26, "ai": [26, 88, 99], "effici": [26, 88, 99], "toolkit": [26, 88, 99], "doc": 26, "indic": 26, "tabl": 26, "aimet": [27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 88, 92, 93, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115], "tensorflow": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 49, 75, 113], "user": [28, 31, 39, 41, 42, 43, 51, 53, 55, 57, 64, 66, 68, 99, 104], "guid": [28, 31, 39, 41, 42, 43, 51, 53, 55, 57, 66, 68, 91, 99], "link": [28, 29, 31, 39, 41, 42, 43, 51, 53, 54, 55, 57, 66, 68], "top": [28, 29, 30, 32, 33, 35, 37, 39, 41, 42, 44, 45, 46, 48, 51, 53, 54, 56, 58, 59, 61, 64, 66, 68, 70, 71, 84, 87, 89, 90], "level": [28, 29, 30, 32, 33, 35, 36, 37, 39, 41, 42, 44, 45, 46, 48, 51, 53, 54, 56, 58, 59, 61, 64, 65, 66, 68, 70, 71, 84, 87, 89, 90], "enum": [28, 51, 58, 68], "definit": [28, 30, 33, 45, 51, 56, 58, 59, 65, 68], "code": [28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 68, 69, 70, 71, 72, 87, 97], "introduct": [29, 30, 31, 36, 43, 54, 56, 57, 65], "greedi": [30, 56, 98], "select": [30, 56, 95, 98, 101], "configur": [30, 56, 89, 107, 109], "primit": [31, 36, 57, 65], "output": [32, 44, 58], "gener": [32, 44, 58], "group": [33, 45, 59], "callbackfunc": [33, 45, 59], "guidelin": [34, 60, 68, 102, 103], "higher": [36, 65], "lower": [36, 65], "custom": [36, 69], "datatyp": 36, "manual": 36, "mode": [36, 106], "specif": [46, 49, 66], "util": [46, 62, 66], "format": 49, "version": 49, "up": 49, "file": [49, 107], "architectur": 52, "checker": 52, "html": 52, "report": 52, "content": 52, "bn": [54, 94], "convbninfotyp": 55, "activationtyp": 55, "param": 55, "empir": 55, "analyt": 55, "weight": [56, 95, 114], "torch": [61, 69, 75], "fx": 61, "symbol": 61, "trace": 61, "multi": 63, "gpu": [63, 75], "support": 63, "peft": 64, "lora": 64, "clssetinfo": 65, "aimet_torch": [67, 72], "refer": [67, 101, 104], "v2": [67, 72], "new": 67, "backward": 67, "compat": 67, "sparseconvolut": 69, "spconv": 69, "modul": [69, 72, 89], "visual": [70, 71, 83, 112, 113], "migrat": 72, "chang": 72, "process": 72, "import": 72, "quantizationsimmodel": 72, "move": 72, "from": [72, 74, 75], "quantwrapp": 72, "staticgrid": 72, "learnedgrid": 72, "affin": [72, 79], "float": [72, 81, 91], "instal": [73, 74, 75, 97, 99], "quick": 73, "releas": [73, 74, 75, 99, 110], "packag": [73, 74, 75], "system": 73, "requir": [73, 105], "advanc": 73, "instruct": 73, "docker": 74, "variant": [74, 85], "prebuilt": 74, "imag": 74, "build": 74, "local": 74, "start": [74, 88, 99, 112], "contain": 74, "pypi": [74, 75], "environ": [74, 75], "setup": [74, 75], "prerequisit": [75, 91], "13": [75, 110], "common": [75, 92], "debian": 75, "replac": 75, "pillow": 75, "simd": 75, "onnxruntim": 75, "step": 75, "fakequantizationmixin": 77, "quantizationmixin": 78, "class": [79, 81, 82, 89], "floatquantizedequant": 80, "quantizedequant": 80, "tensor": 82, "tool": [83, 103, 112], "blockwis": 84, "low": 84, "power": 84, "lpbq": 84, "gptvq": 87, "document": 88, "featur": [88, 96, 99, 103, 108], "descript": [88, 105], "quickstart": 91, "point": 91, "case": [92, 101, 103], "terminologi": 92, "overview": [93, 94, 98, 99, 101, 104, 105, 106, 107, 109, 112, 113, 115], "workflow": [93, 94, 103, 106, 109], "procedur": 95, "winnow": [95, 115], "reconstruct": 95, "guidebook": [96, 108], "brows": 97, "jupyt": 97, "download": 97, "relat": 97, "ratio": [98, 101], "how": [98, 107, 112, 115], "work": [98, 115], "explor": 98, "inform": 99, "toc": 99, "tree": 99, "known": 100, "issu": 100, "techniqu": [101, 104], "better": 101, "result": 101, "rank": 101, "faq": [101, 104], "debug": 103, "detail": 105, "recommend": 106, "structur": 107, "individu": 107, "section": 107, "nois": 109, "scheme": 109, "frequent": 109, "ask": 109, "question": 109, "note": 110, "22": 110, "21": 110, "20": 110, "19": 110, "py37": 110, "18": 110, "17": 110, "16": 110, "14": 110, "design": 112, "bokeh": 112, "server": 112, "session": 112}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Automatic Mixed-Precision (AMP)": [[0, "Automatic-Mixed-Precision-(AMP)"], [4, "Automatic-Mixed-Precision-(AMP)"], [18, "Automatic-Mixed-Precision-(AMP)"]], "Overall flow": [[0, "Overall-flow"], [1, "Overall-flow"], [2, "Overall-flow"], [3, "Overall-flow"], [4, "Overall-flow"], [5, "Overall-flow"], [6, "Overall-flow"], [7, "Overall-flow"], [8, "Overall-flow"], [9, "Overall-flow"], [10, "Overall-flow"], [11, "Overall-flow"], [12, "Overall-flow"], [13, "Overall-flow"], [14, "Overall-flow"], [15, "Overall-flow"], [16, "Overall-flow"], [17, "Overall-flow"], [18, "Overall-flow"], [19, "Overall-flow"], [20, "Overall-flow"], [21, "Overall-flow"], [22, "Overall-flow"], [23, "Overall-flow"], [24, "Overall-flow"], [25, "Overall-flow"], [91, "overall-flow"]], "What this notebook is not": [[0, "What-this-notebook-is-not"], [1, "What-this-notebook-is-not"], [2, "What-this-notebook-is-not"], [3, "What-this-notebook-is-not"], [4, "What-this-notebook-is-not"], [5, "What-this-notebook-is-not"], [6, "What-this-notebook-is-not"], [10, "What-this-notebook-is-not"], [11, "What-this-notebook-is-not"], [12, "What-this-notebook-is-not"], [13, "What-this-notebook-is-not"], [14, "What-this-notebook-is-not"], [15, "What-this-notebook-is-not"], [16, "What-this-notebook-is-not"], [17, "What-this-notebook-is-not"], [18, "What-this-notebook-is-not"], [19, "What-this-notebook-is-not"], [20, "What-this-notebook-is-not"], [21, "What-this-notebook-is-not"], [22, "What-this-notebook-is-not"], [23, "What-this-notebook-is-not"], [24, "What-this-notebook-is-not"], [25, "What-this-notebook-is-not"]], "Dataset": [[0, "Dataset"], [1, "Dataset"], [2, "Dataset"], [3, "Dataset"], [4, "Dataset"], [5, "Dataset"], [6, "Dataset"], [7, "Dataset"], [10, "Dataset"], [11, "Dataset"], [12, "Dataset"], [13, "Dataset"], [14, "Dataset"], [15, "Dataset"], [16, "Dataset"], [17, "Dataset"], [18, "Dataset"], [19, "Dataset"], [20, "Dataset"], [21, "Dataset"], [22, "Dataset"], [23, "Dataset"], [24, "Dataset"], [25, "Dataset"]], "1. Example evaluation pipeline": [[0, "1.-Example-evaluation-pipeline"], [3, "1.-Example-evaluation-pipeline"], [18, "1.-Example-evaluation-pipeline"]], "2. Convert an FP32 PyTorch model to ONNX and evaluate the model\u2019s baseline FP32 accuracy": [[0, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [1, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [2, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [3, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"]], "3. Create a quantization simulation model": [[0, "3.-Create-a-quantization-simulation-model"], [18, "3.-Create-a-quantization-simulation-model"]], "Fold Batch Normalization layers": [[0, "Fold-Batch-Normalization-layers"], [1, "Fold-Batch-Normalization-layers"], [2, "Fold-Batch-Normalization-layers"], [3, "Fold-Batch-Normalization-layers"], [5, "Fold-Batch-Normalization-layers"], [10, "Fold-Batch-Normalization-layers"], [11, "Fold-Batch-Normalization-layers"], [13, "Fold-Batch-Normalization-layers"], [14, "Fold-Batch-Normalization-layers"], [18, "Fold-Batch-Normalization-layers"], [19, "Fold-Batch-Normalization-layers"], [22, "Fold-Batch-Normalization-layers"], [23, "Fold-Batch-Normalization-layers"], [24, "Fold-Batch-Normalization-layers"]], "Create Quantization Sim Model": [[0, "Create-Quantization-Sim-Model"], [1, "Create-Quantization-Sim-Model"], [2, "Create-Quantization-Sim-Model"], [3, "Create-Quantization-Sim-Model"], [10, "Create-Quantization-Sim-Model"], [11, "Create-Quantization-Sim-Model"], [14, "Create-Quantization-Sim-Model"], [18, "Create-Quantization-Sim-Model"], [21, "Create-Quantization-Sim-Model"], [22, "Create-Quantization-Sim-Model"], [23, "Create-Quantization-Sim-Model"], [24, "Create-Quantization-Sim-Model"]], "Compute Encodings": [[0, "Compute-Encodings"], [1, "Compute-Encodings"], [3, "Compute-Encodings"], [4, "Compute-Encodings"], [10, "Compute-Encodings"], [11, "Compute-Encodings"], [14, "Compute-Encodings"], [18, "Compute-Encodings"]], "4. Run AMP algorithm on the quantized model": [[0, "4.-Run-AMP-algorithm-on-the-quantized-model"], [4, "4.-Run-AMP-algorithm-on-the-quantized-model"], [18, "4.-Run-AMP-algorithm-on-the-quantized-model"]], "Define callback functions for AMP": [[0, "Define-callback-functions-for-AMP"], [18, "Define-callback-functions-for-AMP"]], "Parameters for AMP algorithm": [[0, "Parameters-for-AMP-algorithm"], [4, "Parameters-for-AMP-algorithm"], [18, "Parameters-for-AMP-algorithm"]], "Call AMP API": [[0, "Call-AMP-API"], [18, "Call-AMP-API"]], "Adaptive Rounding (AdaRound)": [[1, "Adaptive-Rounding-(AdaRound)"], [19, "Adaptive-Rounding-(AdaRound)"]], "1. Example evaluation and training pipeline": [[1, "1.-Example-evaluation-and-training-pipeline"], [2, "1.-Example-evaluation-and-training-pipeline"], [5, "1.-Example-evaluation-and-training-pipeline"], [6, "1.-Example-evaluation-and-training-pipeline"], [12, "1.-Example-evaluation-and-training-pipeline"], [13, "1.-Example-evaluation-and-training-pipeline"], [14, "1.-Example-evaluation-and-training-pipeline"], [15, "1.-Example-evaluation-and-training-pipeline"], [16, "1.-Example-evaluation-and-training-pipeline"], [17, "1.-Example-evaluation-and-training-pipeline"], [19, "1.-Example-evaluation-and-training-pipeline"], [21, "1.-Example-evaluation-and-training-pipeline"], [22, "1.-Example-evaluation-and-training-pipeline"], [23, "1.-Example-evaluation-and-training-pipeline"], [24, "1.-Example-evaluation-and-training-pipeline"], [25, "1.-Example-evaluation-and-training-pipeline"]], "3. Create a quantization simulation model and determine quantized accuracy": [[1, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [2, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [3, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [5, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [13, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [14, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [19, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [22, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [23, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [24, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"]], "4. Apply Adaround": [[1, "4.-Apply-Adaround"], [5, "4.-Apply-Adaround"], [13, "4.-Apply-Adaround"], [19, "4.-Apply-Adaround"]], "Summary": [[1, "Summary"], [2, "Summary"], [3, "Summary"], [4, "Summary"], [5, "Summary"], [6, "Summary"], [7, "Summary"], [9, "Summary"], [10, "Summary"], [11, "Summary"], [13, "Summary"], [14, "Summary"], [15, "Summary"], [16, "Summary"], [17, "Summary"], [19, "Summary"], [20, "Summary"], [21, "Summary"], [22, "Summary"], [23, "Summary"], [24, "Summary"]], "Cross-Layer Equalization (CLE)": [[2, "Cross-Layer-Equalization-(CLE)"]], "4. 1 Cross Layer Equalization": [[2, "4.-1-Cross-Layer-Equalization"], [22, "4.-1-Cross-Layer-Equalization"]], "Quantization Simulation": [[3, "Quantization-Simulation"]], "1. Instantiate the example evaluation method": [[4, "1.-Instantiate-the-example-evaluation-method"]], "2. Load the FP32 model and evaluate the model to find the baseline FP32 accuracy": [[4, "2.-Load-the-FP32-model-and-evaluate-the-model-to-find-the-baseline-FP32-accuracy"]], "3.Create a quantization simulation model (with fake quantization ops inserted)": [[4, "3.Create-a-quantization-simulation-model-(with-fake-quantization-ops-inserted)"]], "Regular AMP": [[4, "Regular-AMP"]], "API Call for Regular AMP": [[4, "API-Call-for-Regular-AMP"]], "Fast AMP (AMP 2.0)": [[4, "Fast-AMP-(AMP-2.0)"]], "Adaptive Rounding (Adaround)": [[5, "Adaptive-Rounding-(Adaround)"]], "2. Load the model and evaluate to get a baseline FP32 accuracy score": [[5, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [13, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [14, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [18, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [19, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [22, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [23, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [24, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"]], "AutoQuant": [[6, "AutoQuant"], [20, "AutoQuant"]], "2. Load a pretrained FP32 model": [[6, "2.-Load-a-pretrained-FP32-model"], [10, "2.-Load-a-pretrained-FP32-model"], [11, "2.-Load-a-pretrained-FP32-model"], [12, "2.-Load-a-pretrained-FP32-model"], [20, "2.-Load-a-pretrained-FP32-model"]], "3. Determine the baseline FP32 accuracy": [[6, "3.-Determine-the-baseline-FP32-accuracy"], [10, "3.-Determine-the-baseline-FP32-accuracy"], [11, "3.-Determine-the-baseline-FP32-accuracy"]], "4. Define Constants and Helper functions": [[6, "4.-Define-Constants-and-Helper-functions"]], "Prepare the evaluation callback function": [[6, "Prepare-the-evaluation-callback-function"], [7, "Prepare-the-evaluation-callback-function"]], "5. Apply AutoQuant": [[6, "5.-Apply-AutoQuant"]], "Optionally set AdaRound Parameters": [[6, "Optionally-set-AdaRound-Parameters"]], "Run AutoQuant": [[6, "Run-AutoQuant"]], "Quantization-Aware Training with BatchNorm Re-estimation": [[7, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [21, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"]], "1. Instantiate the example evaluation and training pipeline": [[7, "1.-Instantiate-the-example-evaluation-and-training-pipeline"]], "2. Define Constants and Datasets Prepare": [[7, "2.-Define-Constants-and-Datasets-Prepare"]], "2. Create the model in Keras": [[7, "2.-Create-the-model-in-Keras"]], "3. Train and evaluate the model": [[7, "3.-Train-and-evaluate-the-model"]], "4. Create a QuantizationSim Model": [[7, "4.-Create-a-QuantizationSim-Model"]], "5. Perform QAT": [[7, "5.-Perform-QAT"], [10, "5.-Perform-QAT"], [11, "5.-Perform-QAT"]], "Fold BatchNorm Layers": [[7, "Fold-BatchNorm-Layers"], [21, "Fold-BatchNorm-Layers"]], "5. Export Model": [[7, "5.-Export-Model"], [21, "5.-Export-Model"]], "Quantization-Aware Training with a Keras Transformer Model": [[8, "Quantization-Aware-Training-with-a-Keras-Transformer-Model"]], "Keras Model Preparer": [[9, "Keras-Model-Preparer"]], "1. Creating a Keras model with subclass layers": [[9, "1.-Creating-a-Keras-model-with-subclass-layers"]], "2. Converting the Keras model with subclass layers to a Keras model with functional layers": [[9, "2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers"]], "3. Showing similarities and differences between the original and converted models": [[9, "3.-Showing-similarities-and-differences-between-the-original-and-converted-models"]], "4. Discussing the limitations of the Keras Model Preparer": [[9, "4.-Discussing-the-limitations-of-the-Keras-Model-Preparer"]], "Quantization-Aware Training": [[10, "Quantization-Aware-Training"], [23, "Quantization-Aware-Training"]], "Example evaluation and training pipeline": [[10, "Example-evaluation-and-training-pipeline"], [11, "Example-evaluation-and-training-pipeline"]], "1. Load the dataset": [[10, "1.-Load-the-dataset"], [11, "1.-Load-the-dataset"]], "4. Create a QuantizationSim Model and determine quantized accuracy": [[10, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"], [11, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"]], "Compile the model": [[10, "Compile-the-model"], [11, "Compile-the-model"]], "Evaluate the performance of the quantized model": [[10, "Evaluate-the-performance-of-the-quantized-model"], [11, "Evaluate-the-performance-of-the-quantized-model"]], "6. Evaluate validation accuracy after QAT": [[10, "6.-Evaluate-validation-accuracy-after-QAT"], [11, "6.-Evaluate-validation-accuracy-after-QAT"]], "7. Export the encodings": [[10, "7.-Export-the-encodings"], [11, "7.-Export-the-encodings"]], "Quantization-Aware Training with Range Learning": [[11, "Quantization-Aware-Training-with-Range-Learning"], [24, "Quantization-Aware-Training-with-Range-Learning"]], "Quant Analyzer": [[12, "Quant-Analyzer"], [25, "Quant-Analyzer"]], "3. Apply QuantAnalyzer to the model": [[12, "3.-Apply-QuantAnalyzer-to-the-model"], [25, "3.-Apply-QuantAnalyzer-to-the-model"]], "Per-layer analysis by enabling/disabling quantization wrappers": [[12, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"], [25, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"]], "Encoding min/max ranges": [[12, "Encoding-min/max-ranges"], [25, "Encoding-min/max-ranges"]], "PDF of statistics": [[12, "PDF-of-statistics"], [25, "PDF-of-statistics"]], "Per-layer MSE loss": [[12, "Per-layer-MSE-loss"], [25, "Per-layer-MSE-loss"]], "Quantsim and Adaround - Per Channel Quantization (PCQ)": [[13, "Quantsim-and-Adaround---Per-Channel-Quantization-(PCQ)"]], "Cross-Layer Equalization (CLE) with QuantSim": [[14, "Cross-Layer-Equalization-(CLE)-with-QuantSim"]], "4 Cross Layer Equalization": [[14, "4-Cross-Layer-Equalization"]], "5 Exporting": [[14, "5-Exporting"]], "Model compression using Channel Pruning": [[15, "Model-compression-using-Channel-Pruning"]], "2. Load the model and evaluate it to find the baseline accuracy": [[15, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [16, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [17, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"]], "3. Compress the model and fine-tune": [[15, "3.-Compress-the-model-and-fine-tune"], [16, "3.-Compress-the-model-and-fine-tune"], [17, "3.-Compress-the-model-and-fine-tune"]], "3.1. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[15, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.2. Fine-tune the model": [[15, "3.2.-Fine-tune-the-model"], [16, "3.2.-Fine-tune-the-model"]], "Model compression using Spatial SVD": [[16, "Model-compression-using-Spatial-SVD"]], "3.1. Compress model using Spatial SVD and evaluate it to find post-compression accuracy": [[16, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"], [17, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"]], "Model compression using Spatial SVD followed by Channel Pruning": [[17, "Model-compression-using-Spatial-SVD-followed-by-Channel-Pruning"]], "3.2. Fine-tune the model after Spatial SVD": [[17, "3.2.-Fine-tune-the-model-after-Spatial-SVD"]], "3.3. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[17, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.4. Fine-tune the model after Channel Pruning": [[17, "3.4.-Fine-tune-the-model-after-Channel-Pruning"]], "1. Define Constants and Helper functions": [[20, "1.-Define-Constants-and-Helper-functions"]], "3. Run AutoQuant": [[20, "3.-Run-AutoQuant"]], "Create AutoQuant Object": [[20, "Create-AutoQuant-Object"]], "Run AutoQuant Inference": [[20, "Run-AutoQuant-Inference"]], "Set AdaRound Parameters (optional)": [[20, "Set-AdaRound-Parameters-(optional)"]], "Run AutoQuant Optimization": [[20, "Run-AutoQuant-Optimization"]], "2. Load FP32 model": [[21, "2.-Load-FP32-model"]], "3. Create a quantization simulation model and Perform QAT": [[21, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"]], "Perform QAT": [[21, "Perform-QAT"]], "4. Perform BatchNorm Reestimation": [[21, "4.-Perform-BatchNorm-Reestimation"]], "Re-estimate BatchNorm Statistics": [[21, "Re-estimate-BatchNorm-Statistics"]], "Cross-Layer Equalization (CLE) and Bias Correction (BC)": [[22, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"]], "4. 2 Bias Correction": [[22, "4.-2-Bias-Correction"]], "4. Perform QAT": [[23, "4.-Perform-QAT"], [24, "4.-Perform-QAT"]], "2. Load the model": [[25, "2.-Load-the-model"]], "Welcome to AI Model Efficiency Toolkit API Docs!": [[26, "welcome-to-ai-model-efficiency-toolkit-api-docs"]], "Indices and tables": [[26, "indices-and-tables"]], "AIMET TensorFlow APIs": [[27, "aimet-tensorflow-apis"]], "AIMET TensorFlow AdaRound API": [[28, "aimet-tensorflow-adaround-api"]], "User Guide Link": [[28, "user-guide-link"], [31, "user-guide-link"], [39, "user-guide-link"], [41, "user-guide-link"], [42, "user-guide-link"], [43, "user-guide-link"], [51, "user-guide-link"], [53, "user-guide-link"], [55, "user-guide-link"], [57, "user-guide-link"], [66, "user-guide-link"], [68, "user-guide-link"]], "Examples Notebook Link": [[28, "examples-notebook-link"], [29, "examples-notebook-link"], [31, "examples-notebook-link"], [51, "examples-notebook-link"], [53, "examples-notebook-link"], [54, "examples-notebook-link"], [57, "examples-notebook-link"], [66, "examples-notebook-link"], [68, "examples-notebook-link"]], "Top-level API": [[28, "top-level-api"], [32, "top-level-api"], [35, "top-level-api"], [37, "top-level-api"], [39, "top-level-api"], [41, "top-level-api"], [42, "top-level-api"], [44, "top-level-api"], [45, "top-level-api"], [46, "top-level-api"], [48, "top-level-api"], [51, "top-level-api"], [53, "top-level-api"], [58, "top-level-api"], [59, "top-level-api"], [61, "top-level-api"], [64, "top-level-api"], [66, "top-level-api"], [68, "top-level-api"], [89, "top-level-api"], [90, "top-level-api"]], "Adaround Parameters": [[28, "adaround-parameters"], [41, "adaround-parameters"], [51, "adaround-parameters"]], "Enum Definition": [[28, "enum-definition"], [51, "enum-definition"], [58, "enum-definition"], [68, "enum-definition"]], "Code Examples": [[28, "code-examples"], [30, "code-examples"], [33, "code-examples"], [35, "code-examples"], [37, "code-examples"], [39, "code-examples"], [42, "code-examples"], [45, "code-examples"], [46, "code-examples"], [48, "code-examples"], [53, "code-examples"], [56, "code-examples"], [59, "code-examples"], [61, "code-examples"], [66, "code-examples"], [70, "code-examples"], [71, "code-examples"], [72, "code-examples"]], "AIMET TensorFlow BatchNorm Re-estimation APIs": [[29, "aimet-tensorflow-batchnorm-re-estimation-apis"]], "Introduction": [[29, "introduction"], [30, "introduction"], [31, "introduction"], [36, "introduction"], [43, "introduction"], [54, "introduction"], [56, "introduction"], [57, "introduction"], [65, "introduction"]], "Top-level APIs": [[29, "top-level-apis"], [54, "top-level-apis"]], "Code Example": [[29, "code-example"], [31, "code-example"], [32, "code-example"], [43, "code-example"], [44, "code-example"], [57, "code-example"], [58, "code-example"], [69, "code-example"], [87, "code-example"]], "Limitations": [[29, "limitations"], [35, "limitations"]], "AIMET TensorFlow Compression API": [[30, "aimet-tensorflow-compression-api"]], "Top-level API for Compression": [[30, "top-level-api-for-compression"], [56, "top-level-api-for-compression"]], "Greedy Selection Parameters": [[30, "greedy-selection-parameters"], [56, "greedy-selection-parameters"]], "Spatial SVD Configuration": [[30, "spatial-svd-configuration"], [56, "spatial-svd-configuration"]], "Configuration Definitions": [[30, "configuration-definitions"], [56, "configuration-definitions"]], "AIMET TensorFlow Cross Layer Equalization APIs": [[31, "aimet-tensorflow-cross-layer-equalization-apis"]], "Cross Layer Equalization API": [[31, "cross-layer-equalization-api"], [43, "cross-layer-equalization-api"], [57, "cross-layer-equalization-api"]], "Primitive APIs": [[31, "primitive-apis"], [57, "primitive-apis"]], "AIMET TensorFlow Layer Output Generation API": [[32, "aimet-tensorflow-layer-output-generation-api"]], "AIMET TensorFlow Mixed Precision API": [[33, "aimet-tensorflow-mixed-precision-api"]], "Top-level API for Regular AMP": [[33, "top-level-api-for-regular-amp"]], "Top-level API for Fast AMP (AMP 2.0)": [[33, "top-level-api-for-fast-amp-amp-2-0"]], "Quantizer Groups definition": [[33, "quantizer-groups-definition"], [45, "quantizer-groups-definition"], [59, "quantizer-groups-definition"]], "CallbackFunc Definition": [[33, "callbackfunc-definition"], [45, "callbackfunc-definition"], [59, "callbackfunc-definition"]], "TensorFlow Model Guidelines": [[34, "tensorflow-model-guidelines"]], "TensorFlow Model Preparer API": [[35, "tensorflow-model-preparer-api"]], "AIMET TensorFlow Cross Layer Equalization Primitive API": [[36, "aimet-tensorflow-cross-layer-equalization-primitive-api"]], "Higher Level APIs for Cross Layer Equalization": [[36, "higher-level-apis-for-cross-layer-equalization"], [65, "higher-level-apis-for-cross-layer-equalization"]], "Code Examples for Higher Level APIs": [[36, "code-examples-for-higher-level-apis"], [65, "code-examples-for-higher-level-apis"]], "Lower Level APIs for Cross Layer Equalization": [[36, "lower-level-apis-for-cross-layer-equalization"], [65, "lower-level-apis-for-cross-layer-equalization"]], "Custom Datatype used": [[36, "custom-datatype-used"]], "Code Example for Lower level APIs": [[36, "code-example-for-lower-level-apis"]], "Example helper methods to perform CLE in manual mode": [[36, "example-helper-methods-to-perform-cle-in-manual-mode"]], "AIMET TensorFlow Quant Analyzer API": [[37, "aimet-tensorflow-quant-analyzer-api"]], "AIMET TensorFlow Quantization APIs": [[38, "aimet-tensorflow-quantization-apis"]], "AIMET TensorFlow Quantization SIM API": [[39, "aimet-tensorflow-quantization-sim-api"]], "AIMET ONNX APIs": [[40, "aimet-onnx-apis"]], "AIMET ONNX AdaRound API": [[41, "aimet-onnx-adaround-api"]], "Code Example - Adaptive Rounding (AdaRound)": [[41, "code-example-adaptive-rounding-adaround"], [51, "code-example-adaptive-rounding-adaround"]], "AIMET ONNX AutoQuant API": [[42, "aimet-onnx-autoquant-api"]], "AIMET ONNX Cross Layer Equalization APIs": [[43, "aimet-onnx-cross-layer-equalization-apis"]], "AIMET ONNX Layer Output Generation API": [[44, "aimet-onnx-layer-output-generation-api"]], "AIMET ONNX Mixed Precision API": [[45, "aimet-onnx-mixed-precision-api"]], "AIMET ONNX Quant Analyzer API": [[46, "aimet-onnx-quant-analyzer-api"]], "Run specific utility": [[46, "run-specific-utility"], [66, "run-specific-utility"]], "AIMET ONNX Quantization APIs": [[47, "aimet-onnx-quantization-apis"]], "AIMET ONNX Quantization SIM API": [[48, "aimet-onnx-quantization-sim-api"]], "Encoding Format Specification": [[49, "encoding-format-specification"]], "1. Versioning": [[49, "versioning"]], "2. Version 0.4.0 (up to)": [[49, "version-0-4-0-up-to"]], "2.1. Encoding Specification": [[49, "encoding-specification"]], "2.2. Encoding File Example for PyTorch": [[49, "encoding-file-example-for-pytorch"]], "2.3. Encoding File Example for TensorFlow": [[49, "encoding-file-example-for-tensorflow"]], "3. Version 0.5.0": [[49, "version-0-5-0"]], "3.1. Encoding Specification": [[49, "id1"]], "3.2. Encoding File Example for PyTorch": [[49, "id2"]], "3.3. Encoding File Example for TensorFlow": [[49, "id3"]], "4. Version 0.6.1": [[49, "version-0-6-1"]], "4.1. Encoding Specification": [[49, "id4"]], "AIMET PyTorch APIs": [[50, "aimet-pytorch-apis"]], "AIMET PyTorch AdaRound API": [[51, "aimet-pytorch-adaround-api"]], "Architecture Checker API": [[52, "architecture-checker-api"]], "HTML report content": [[52, "id1"]], "AIMET PyTorch AutoQuant API": [[53, "aimet-pytorch-autoquant-api"]], "AIMET PyTorch BatchNorm Re-estimation APIs": [[54, "aimet-pytorch-batchnorm-re-estimation-apis"]], "Code Example - BN-Reestimation": [[54, "code-example-bn-reestimation"]], "AIMET PyTorch Bias Correction API": [[55, "aimet-pytorch-bias-correction-api"]], "Bias Correction API": [[55, "bias-correction-api"]], "ConvBnInfoType": [[55, "convbninfotype"]], "ActivationType": [[55, "activationtype"]], "Quantization Params": [[55, "quantization-params"]], "Code Example #1 Empirical Bias Correction": [[55, "code-example-1-empirical-bias-correction"]], "Code Example #2 Analytical + Empirical Bias correction": [[55, "code-example-2-analytical-empirical-bias-correction"]], "AIMET PyTorch Compression API": [[56, "aimet-pytorch-compression-api"]], "Weight SVD Configuration": [[56, "weight-svd-configuration"]], "Channel Pruning Configuration": [[56, "channel-pruning-configuration"]], "AIMET PyTorch Cross Layer Equalization APIs": [[57, "aimet-pytorch-cross-layer-equalization-apis"]], "AIMET PyTorch Layer Output Generation API": [[58, "aimet-pytorch-layer-output-generation-api"]], "AIMET PyTorch Mixed Precision API": [[59, "aimet-pytorch-mixed-precision-api"]], "PyTorch Model Guidelines": [[60, "pytorch-model-guidelines"]], "Model Preparer API": [[61, "model-preparer-api"]], "Limitations of torch.fx symbolic trace API": [[61, "limitations-of-torch-fx-symbolic-trace-api"]], "Model Validator Utility": [[62, "model-validator-utility"]], "PyTorch Multi-GPU support": [[63, "pytorch-multi-gpu-support"]], "PEFT LoRA": [[64, "peft-lora"]], "User flow": [[64, "user-flow"]], "AIMET PyTorch Cross Layer Equalization Primitive API": [[65, "aimet-pytorch-cross-layer-equalization-primitive-api"]], "ClsSetInfo Definition": [[65, "clssetinfo-definition"]], "Code Examples for Lower Level APIs": [[65, "code-examples-for-lower-level-apis"]], "AIMET PyTorch Quant Analyzer API": [[66, "aimet-pytorch-quant-analyzer-api"]], "AIMET PyTorch Quantization APIs": [[67, "aimet-pytorch-quantization-apis"]], "aimet_torch": [[67, "aimet-torch"]], "API Reference": [[67, "api-reference"], [67, "id1"]], "aimet_torch.v2": [[67, "aimet-torch-v2"]], "What\u2019s New": [[67, "what-s-new"]], "Backwards Compatibility": [[67, "backwards-compatibility"]], "AIMET PyTorch Quantization SIM API": [[68, "aimet-pytorch-quantization-sim-api"]], "Guidelines": [[68, "guidelines"]], "Code Example - Quantization Aware Training (QAT)": [[68, "code-example-quantization-aware-training-qat"]], "AIMET Torch SparseConvolution custom onnx export": [[69, "aimet-torch-sparseconvolution-custom-onnx-export"]], "Custom API for the spconv modules": [[69, "custom-api-for-the-spconv-modules"]], "AIMET Visualization Compression API": [[70, "aimet-visualization-compression-api"]], "Top-level API Compression": [[70, "top-level-api-compression"]], "AIMET Visualization for Quantization API": [[71, "aimet-visualization-for-quantization-api"]], "Top-level API Quantization": [[71, "top-level-api-quantization"]], "Migrate to aimet_torch.v2": [[72, "migrate-to-aimet-torch-v2"]], "Changes in aimet_torch v2": [[72, "changes-in-aimet-torch-v2"]], "Migration Process": [[72, "migration-process"]], "Imports": [[72, "imports"]], "QuantizationSimModel": [[72, "quantizationsimmodel"]], "Moving from QuantWrapper to Quantized Modules": [[72, "moving-from-quantwrapper-to-quantized-modules"]], "Moving from StaticGrid and LearnedGrid Quantizer to Affine and Float Quantizer": [[72, "moving-from-staticgrid-and-learnedgrid-quantizer-to-affine-and-float-quantizer"]], "AIMET Installation": [[73, "aimet-installation"]], "Quick Install": [[73, "quick-install"]], "Release Packages": [[73, "release-packages"]], "System Requirements": [[73, "system-requirements"]], "Advanced Installation Instructions": [[73, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[74, "aimet-installation-in-docker"]], "Set variant": [[74, "set-variant"]], "Use prebuilt docker image": [[74, "use-prebuilt-docker-image"]], "Build docker image locally": [[74, "build-docker-image-locally"]], "Start docker container": [[74, "start-docker-container"]], "Install AIMET packages": [[74, "install-aimet-packages"], [75, "install-aimet-packages"]], "From PyPI": [[74, "from-pypi"], [75, "from-pypi"]], "From Release Package": [[74, "from-release-package"], [75, "from-release-package"]], "Environment setup": [[74, "environment-setup"], [75, "environment-setup"]], "AIMET Installation and Setup": [[75, "aimet-installation-and-setup"]], "Install prerequisite packages": [[75, "install-prerequisite-packages"]], "Install GPU packages": [[75, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or PyTorch 1.13 or ONNX or TensorFlow": [[75, "install-gpu-packages-for-pytorch-2-1-or-pytorch-1-13-or-onnx-or-tensorflow"]], "Install common debian packages": [[75, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[75, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[75, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[75, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[75, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[75, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[75, "post-installation-steps"]], "FakeQuantizationMixin": [[77, "fakequantizationmixin"]], "QuantizationMixin": [[78, "quantizationmixin"]], "quantization.affine": [[79, "module-aimet_torch.v2.quantization.affine"]], "Classes": [[79, "classes"], [81, "classes"], [82, "classes"]], "Functions": [[79, "functions"]], "FloatQuantizeDequantize": [[80, "floatquantizedequantize"]], "QuantizeDequantize": [[80, "quantizedequantize"]], "quantization.float": [[81, "module-aimet_torch.v2.quantization.float"]], "quantization.tensor": [[82, "quantization-tensor"]], "Visualization Tools": [[83, "visualization-tools"]], "Blockwise Quantization": [[84, "blockwise-quantization"]], "Low Power Blockwise Quantization (LPBQ)": [[84, "low-power-blockwise-quantization-lpbq"]], "Top Level API": [[84, "top-level-api"], [87, "top-level-api"]], "Export": [[84, "export"]], "Encoding Analyzers": [[85, "encoding-analyzers"]], "Variants": [[85, "variants"]], "Post-Training Quantization": [[86, "post-training-quantization"], [103, "post-training-quantization"]], "GPTVQ": [[87, "gptvq"]], "GPTVQ Parameters": [[87, "gptvq-parameters"]], "AIMET: AI Model Efficiency Toolkit Documentation": [[88, "aimet-ai-model-efficiency-toolkit-documentation"]], "Getting Started": [[88, "getting-started"], [99, "getting-started"]], "Examples": [[88, null]], "Feature Descriptions": [[88, null]], "AIMET PyTorch API": [[88, null]], "Quantized Modules": [[89, "quantized-modules"]], "Configuration": [[89, "configuration"]], "Computing Encodings": [[89, "computing-encodings"]], "Quantized Module Classes": [[89, "quantized-module-classes"]], "Quantizers": [[90, "quantizers"]], "Quickstart Guide": [[91, "quickstart-guide"]], "PyTorch prerequisites": [[91, "pytorch-prerequisites"]], "Prepare the floating point model for quantization": [[91, "prepare-the-floating-point-model-for-quantization"]], "1) Model preparation": [[91, "model-preparation"]], "2) BatchNorm fold": [[91, "batchnorm-fold"]], "Quantize the model": [[91, "quantize-the-model"]], "Fine-tune the model with quantization aware training": [[91, "fine-tune-the-model-with-quantization-aware-training"]], "Export the quantsim model": [[91, "export-the-quantsim-model"]], "AIMET AdaRound": [[92, "aimet-adaround"]], "AdaRound Use Cases": [[92, "adaround-use-cases"]], "Common terminology": [[92, "common-terminology"]], "Use Cases": [[92, "use-cases"], [103, "use-cases"]], "AdaRound API": [[92, "adaround-api"]], "AIMET AutoQuant": [[93, "aimet-autoquant"]], "Overview": [[93, "overview"], [94, "overview"], [98, "overview"], [99, "overview"], [101, "overview"], [104, "overview"], [105, "overview"], [106, "overview"], [107, "overview"], [109, "overview"], [112, "overview"], [113, "overview"], [115, "overview"]], "Workflow": [[93, "workflow"], [94, "workflow"]], "AutoQuant API": [[93, "autoquant-api"]], "AIMET BN Re-estimation": [[94, "aimet-bn-re-estimation"]], "BN Re-estimation API": [[94, "bn-re-estimation-api"]], "AIMET Channel Pruning": [[95, "aimet-channel-pruning"]], "Overall Procedure": [[95, "overall-procedure"]], "Channel Selection": [[95, "channel-selection"]], "Winnowing": [[95, "winnowing"]], "Weight Reconstruction": [[95, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[96, "aimet-compression-features-guidebook"]], "AIMET Examples": [[97, "aimet-examples"]], "Browse the notebooks": [[97, "browse-the-notebooks"]], "Running the notebooks": [[97, "running-the-notebooks"]], "Install Jupyter": [[97, "install-jupyter"]], "Download the Example notebooks and related code": [[97, "download-the-example-notebooks-and-related-code"]], "Run the notebooks": [[97, "run-the-notebooks"]], "AIMET Greedy Compression Ratio Selection": [[98, "aimet-greedy-compression-ratio-selection"]], "How it works": [[98, "how-it-works"]], "Per-layer Exploration": [[98, "per-layer-exploration"]], "Compression Ratio Selection": [[98, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[99, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[99, "features"]], "Release Information": [[99, "release-information"]], "Installation Guide": [[99, "installation-guide"]], "toc tree": [[99, "toc-tree"]], "AIMET Known Issues": [[100, "aimet-known-issues"]], "AIMET Model Compression": [[101, "aimet-model-compression"]], "Use Case": [[101, "use-case"]], "Compression ratio selection": [[101, "compression-ratio-selection"]], "Model Compression": [[101, "model-compression"]], "Optional techniques to get better compression results": [[101, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[101, "rank-rounding"]], "Per-layer Fine-tuning": [[101, "per-layer-fine-tuning"]], "FAQs": [[101, "faqs"], [104, "faqs"]], "References": [[101, "references"], [104, "references"]], "Model Guidelines for PyTorch": [[102, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[103, "aimet-model-quantization"]], "AIMET Quantization Features": [[103, "aimet-quantization-features"]], "Debugging/Analysis Tools": [[103, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[103, "aimet-quantization-workflow"]], "PyTorch": [[103, "pytorch"], [113, "pytorch"]], "Debugging Guidelines": [[103, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[104, "aimet-post-training-quantization-techniques"]], "User Flow": [[104, "user-flow"]], "Cross-Layer Equalization API": [[104, "cross-layer-equalization-api"]], "AIMET QuantAnalyzer": [[105, "aimet-quantanalyzer"]], "Requirements": [[105, "requirements"]], "Detailed Analysis Descriptions": [[105, "detailed-analysis-descriptions"]], "QuantAnalyzer API": [[105, "quantanalyzer-api"]], "AIMET Quantization Aware Training": [[106, "aimet-quantization-aware-training"]], "QAT workflow": [[106, "qat-workflow"]], "QAT modes": [[106, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[106, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[107, "quantization-simulation-configuration"]], "Configuration File Structure": [[107, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[107, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[108, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[109, "aimet-quantization-simulation"]], "QuantSim Workflow": [[109, "quantsim-workflow"]], "Simulating Quantization Noise": [[109, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[109, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[109, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[109, "configuring-quantization-simulation-ops"]], "Quantization Simulation APIs": [[109, "quantization-simulation-apis"]], "Frequently Asked Questions": [[109, "frequently-asked-questions"]], "AIMET Release Notes": [[110, "aimet-release-notes"]], "1.22.2": [[110, "id1"]], "1.22.1": [[110, "id2"]], "1.22.0": [[110, "id3"]], "1.21.0": [[110, "id4"]], "1.20.0": [[110, "id5"]], "1.19.1.py37": [[110, "py37"]], "1.19.1": [[110, "id6"]], "1.18.0.py37": [[110, "id7"]], "1.18.0": [[110, "id8"]], "1.17.0.py37": [[110, "id9"]], "1.17.0": [[110, "id10"]], "1.16.2.py37": [[110, "id11"]], "1.16.2": [[110, "id12"]], "1.16.1.py37": [[110, "id13"]], "1.16.1": [[110, "id14"]], "1.16.0": [[110, "id15"]], "1.14.0": [[110, "id16"]], "1.13.0": [[110, "id17"]], "AIMET Spatial SVD": [[111, "aimet-spatial-svd"]], "AIMET Visualization": [[112, "aimet-visualization"]], "Design": [[112, "design"]], "Compression": [[112, "compression"]], "Starting a Bokeh Server Session:": [[112, "starting-a-bokeh-server-session"]], "How to use the tool": [[112, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[113, "aimet-visualization-for-quantization"]], "Quantization": [[113, "quantization"]], "TensorFlow": [[113, "tensorflow"]], "AIMET Weight SVD": [[114, "aimet-weight-svd"]], "AIMET Winnowing": [[115, "aimet-winnowing"]], "Winnowing Overview": [[115, "winnowing-overview"]], "How Winnowing Works": [[115, "how-winnowing-works"]]}, "indexentries": {"quantscheme (class in aimet_common.defs)": [[28, "aimet_common.defs.QuantScheme"], [51, "aimet_common.defs.QuantScheme"], [68, "aimet_common.defs.QuantScheme"]], "post_training_percentile (aimet_common.defs.quantscheme attribute)": [[28, "aimet_common.defs.QuantScheme.post_training_percentile"], [51, "aimet_common.defs.QuantScheme.post_training_percentile"], [68, "aimet_common.defs.QuantScheme.post_training_percentile"]], "post_training_tf (aimet_common.defs.quantscheme attribute)": [[28, "aimet_common.defs.QuantScheme.post_training_tf"], [51, "aimet_common.defs.QuantScheme.post_training_tf"], [68, "aimet_common.defs.QuantScheme.post_training_tf"]], "post_training_tf_enhanced (aimet_common.defs.quantscheme attribute)": [[28, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [51, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [68, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"]], "training_range_learning_with_tf_enhanced_init (aimet_common.defs.quantscheme attribute)": [[28, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [51, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [68, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"]], "training_range_learning_with_tf_init (aimet_common.defs.quantscheme attribute)": [[28, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [51, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [68, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"]], "reestimate_bn_stats() (in module aimet_tensorflow.keras.bn_reestimation)": [[29, "aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"]], "compressionscheme (class in aimet_common.defs)": [[30, "aimet_common.defs.CompressionScheme"]], "costmetric (class in aimet_common.defs)": [[30, "aimet_common.defs.CostMetric"]], "modulecompratiopair (class in aimet_tensorflow.keras.defs)": [[30, "aimet_tensorflow.keras.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_tensorflow.keras.defs)": [[30, "aimet_tensorflow.keras.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_tensorflow.keras.defs)": [[30, "aimet_tensorflow.keras.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_tensorflow.keras.defs)": [[30, "aimet_tensorflow.keras.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_tensorflow.keras.defs)": [[30, "aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode"]], "auto (aimet_tensorflow.keras.defs.spatialsvdparameters.mode attribute)": [[30, "aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode.auto"]], "channel_pruning (aimet_common.defs.compressionscheme attribute)": [[30, "aimet_common.defs.CompressionScheme.channel_pruning"]], "mac (aimet_common.defs.costmetric attribute)": [[30, "aimet_common.defs.CostMetric.mac"]], "manual (aimet_tensorflow.keras.defs.spatialsvdparameters.mode attribute)": [[30, "aimet_tensorflow.keras.defs.SpatialSvdParameters.Mode.manual"]], "memory (aimet_common.defs.costmetric attribute)": [[30, "aimet_common.defs.CostMetric.memory"]], "spatial_svd (aimet_common.defs.compressionscheme attribute)": [[30, "aimet_common.defs.CompressionScheme.spatial_svd"]], "weight_svd (aimet_common.defs.compressionscheme attribute)": [[30, "aimet_common.defs.CompressionScheme.weight_svd"]], "callbackfunc (class in aimet_common.defs)": [[33, "aimet_common.defs.CallbackFunc"], [45, "aimet_common.defs.CallbackFunc"], [59, "aimet_common.defs.CallbackFunc"]], "prepare_model() (in module aimet_tensorflow.keras.model_preparer)": [[35, "aimet_tensorflow.keras.model_preparer.prepare_model"]], "adaroundparameters (class in aimet_torch.adaround.adaround_weight)": [[51, "aimet_torch.adaround.adaround_weight.AdaroundParameters"]], "apply_adaround() (in module aimet_torch.adaround.adaround_weight.adaround)": [[51, "aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"]], "check_model_arch() (in module aimet_torch.arch_checker.arch_checker.archchecker)": [[52, "aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"]], "autoquant (class in aimet_torch.auto_quant)": [[53, "aimet_torch.auto_quant.AutoQuant"]], "fold_all_batch_norms_to_scale() (in module aimet_torch.batch_norm_fold)": [[54, "aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_torch.bn_reestimation)": [[54, "aimet_torch.bn_reestimation.reestimate_bn_stats"]], "activationtype (class in aimet_common.defs)": [[55, "aimet_common.defs.ActivationType"]], "convbninfotype (class in aimet_common.bias_correction)": [[55, "aimet_common.bias_correction.ConvBnInfoType"]], "quantparams (class in aimet_torch.quantsim)": [[55, "aimet_torch.quantsim.QuantParams"]], "correct_bias() (in module aimet_torch.bias_correction)": [[55, "aimet_torch.bias_correction.correct_bias"]], "no_activation (aimet_common.defs.activationtype attribute)": [[55, "aimet_common.defs.ActivationType.no_activation"]], "relu (aimet_common.defs.activationtype attribute)": [[55, "aimet_common.defs.ActivationType.relu"]], "relu6 (aimet_common.defs.activationtype attribute)": [[55, "aimet_common.defs.ActivationType.relu6"]], "channelpruningparameters (class in aimet_torch.defs)": [[56, "aimet_torch.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_torch.defs)": [[56, "aimet_torch.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_torch.defs)": [[56, "aimet_torch.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_torch.defs)": [[56, "aimet_torch.defs.ChannelPruningParameters.Mode"]], "greedyselectionparameters (class in aimet_common.defs)": [[56, "aimet_common.defs.GreedySelectionParameters"]], "modelcompressor (class in aimet_torch.compress)": [[56, "aimet_torch.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_torch.defs)": [[56, "aimet_torch.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_torch.defs)": [[56, "aimet_torch.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_torch.defs)": [[56, "aimet_torch.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[56, "aimet_torch.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_torch.defs)": [[56, "aimet_torch.defs.SpatialSvdParameters.Mode"]], "weightsvdparameters (class in aimet_torch.defs)": [[56, "aimet_torch.defs.WeightSvdParameters"]], "weightsvdparameters.automodeparams (class in aimet_torch.defs)": [[56, "aimet_torch.defs.WeightSvdParameters.AutoModeParams"]], "weightsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[56, "aimet_torch.defs.WeightSvdParameters.ManualModeParams"]], "weightsvdparameters.mode (class in aimet_torch.defs)": [[56, "aimet_torch.defs.WeightSvdParameters.Mode"]], "auto (aimet_torch.defs.channelpruningparameters.mode attribute)": [[56, "aimet_torch.defs.ChannelPruningParameters.Mode.auto"]], "auto (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[56, "aimet_torch.defs.SpatialSvdParameters.Mode.auto"]], "auto (aimet_torch.defs.weightsvdparameters.mode attribute)": [[56, "aimet_torch.defs.WeightSvdParameters.Mode.auto"]], "compress_model() (aimet_torch.compress.modelcompressor static method)": [[56, "aimet_torch.compress.ModelCompressor.compress_model"]], "manual (aimet_torch.defs.channelpruningparameters.mode attribute)": [[56, "aimet_torch.defs.ChannelPruningParameters.Mode.manual"]], "manual (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[56, "aimet_torch.defs.SpatialSvdParameters.Mode.manual"]], "manual (aimet_torch.defs.weightsvdparameters.mode attribute)": [[56, "aimet_torch.defs.WeightSvdParameters.Mode.manual"]], "equalize_model() (in module aimet_torch.cross_layer_equalization)": [[57, "aimet_torch.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_torch.layer_output_utils)": [[58, "aimet_torch.layer_output_utils.LayerOutputUtil"]], "namingscheme (class in aimet_torch.layer_output_utils)": [[58, "aimet_torch.layer_output_utils.NamingScheme"]], "onnx (aimet_torch.layer_output_utils.namingscheme attribute)": [[58, "aimet_torch.layer_output_utils.NamingScheme.ONNX"]], "pytorch (aimet_torch.layer_output_utils.namingscheme attribute)": [[58, "aimet_torch.layer_output_utils.NamingScheme.PYTORCH"]], "torchscript (aimet_torch.layer_output_utils.namingscheme attribute)": [[58, "aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"]], "generate_layer_outputs() (aimet_torch.layer_output_utils.layeroutpututil method)": [[58, "aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "evalcallbackfactory (class in aimet_torch.amp.mixed_precision_algo)": [[59, "aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory"]], "quantizergroup (class in aimet_torch.amp.quantizer_groups)": [[59, "aimet_torch.amp.quantizer_groups.QuantizerGroup"]], "choose_mixed_precision() (in module aimet_torch.mixed_precision)": [[59, "aimet_torch.mixed_precision.choose_mixed_precision"]], "get_active_quantizers() (aimet_torch.amp.quantizer_groups.quantizergroup method)": [[59, "aimet_torch.amp.quantizer_groups.QuantizerGroup.get_active_quantizers"]], "get_candidate() (aimet_torch.amp.quantizer_groups.quantizergroup method)": [[59, "aimet_torch.amp.quantizer_groups.QuantizerGroup.get_candidate"]], "get_input_quantizer_modules() (aimet_torch.amp.quantizer_groups.quantizergroup method)": [[59, "aimet_torch.amp.quantizer_groups.QuantizerGroup.get_input_quantizer_modules"]], "set_quantizers_to_candidate() (aimet_torch.amp.quantizer_groups.quantizergroup method)": [[59, "aimet_torch.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate"]], "sqnr() (aimet_torch.amp.mixed_precision_algo.evalcallbackfactory method)": [[59, "aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory.sqnr"]], "to_list() (aimet_torch.amp.quantizer_groups.quantizergroup method)": [[59, "aimet_torch.amp.quantizer_groups.QuantizerGroup.to_list"]], "prepare_model() (in module aimet_torch.model_preparer)": [[61, "aimet_torch.model_preparer.prepare_model"]], "adaptermetadata (class in aimet_torch.peft)": [[64, "aimet_torch.peft.AdapterMetaData"]], "peftquantutils (class in aimet_torch.peft)": [[64, "aimet_torch.peft.PeftQuantUtils"]], "disable_lora_adapters() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.disable_lora_adapters"]], "enable_adapter_and_load_weights() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.enable_adapter_and_load_weights"]], "export_adapter_weights() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.export_adapter_weights"]], "freeze_base_model() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.freeze_base_model"]], "freeze_base_model_activation_quantizers() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.freeze_base_model_activation_quantizers"]], "freeze_base_model_param_quantizers() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.freeze_base_model_param_quantizers"]], "get_fp_lora_layer() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.get_fp_lora_layer"]], "get_quantized_lora_layer() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.get_quantized_lora_layer"]], "quantize_lora_scale_with_fixed_range() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.quantize_lora_scale_with_fixed_range"]], "replace_lora_layers_with_quantizable_layers() (aimet_torch.peft method)": [[64, "aimet_torch.peft.replace_lora_layers_with_quantizable_layers"]], "set_bitwidth_for_lora_adapters() (aimet_torch.peft.peftquantutils method)": [[64, "aimet_torch.peft.PeftQuantUtils.set_bitwidth_for_lora_adapters"]], "track_lora_meta_data() (aimet_torch.peft method)": [[64, "aimet_torch.peft.track_lora_meta_data"]], "clssetinfo (class in aimet_torch.cross_layer_equalization)": [[65, "aimet_torch.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_torch.cross_layer_equalization)": [[65, "aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_torch.cross_layer_equalization.highbiasfold)": [[65, "aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"], [65, "id0"]], "fold_all_batch_norms() (in module aimet_torch.batch_norm_fold)": [[65, "aimet_torch.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_torch.batch_norm_fold)": [[65, "aimet_torch.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"]], "callbackfunc (class in aimet_common.utils)": [[66, "aimet_common.utils.CallbackFunc"]], "quantanalyzer (class in aimet_torch.quant_analyzer)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.analyze"]], "check_model_sensitivity_to_quantization() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"]], "enable_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"]], "export_per_layer_encoding_min_max_range() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"]], "export_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"]], "export_per_layer_stats_histogram() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"]], "perform_per_layer_analysis_by_disabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"]], "perform_per_layer_analysis_by_enabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[66, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"]], "quantizationsimmodel (class in aimet_torch.quantsim)": [[68, "aimet_torch.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_torch.quantsim.quantizationsimmodel method)": [[68, "aimet_torch.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_torch.quantsim.quantizationsimmodel method)": [[68, "aimet_torch.quantsim.QuantizationSimModel.export"]], "load_checkpoint() (aimet_torch.quantsim method)": [[68, "aimet_torch.quantsim.load_checkpoint"]], "save_checkpoint() (aimet_torch.quantsim method)": [[68, "aimet_torch.quantsim.save_checkpoint"]], "scatterdense (class in aimet_torch.nn.modules.custom)": [[69, "aimet_torch.nn.modules.custom.ScatterDense"]], "sparsetensorwrapper (class in aimet_torch.nn.modules.custom)": [[69, "aimet_torch.nn.modules.custom.SparseTensorWrapper"]], "visualizecompression (class in aimet_torch.visualize_serialized_data)": [[70, "aimet_torch.visualize_serialized_data.VisualizeCompression"]], "display_comp_ratio_plot() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[70, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"]], "display_eval_scores() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[70, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"]], "visualize_changes_after_optimization() (in module aimet_torch.visualize_model)": [[71, "aimet_torch.visualize_model.visualize_changes_after_optimization"]], "visualize_relative_weight_ranges_to_identify_problematic_layers() (in module aimet_torch.visualize_model)": [[71, "aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"]], "visualize_weight_ranges() (in module aimet_torch.visualize_model)": [[71, "aimet_torch.visualize_model.visualize_weight_ranges"]], "fakequantizationmixin (class in aimet_torch.v2.nn)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.fakequantizationmixin method)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.fakequantizationmixin method)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.fakequantizationmixin method)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.from_module"]], "implements() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[77, "aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"]], "quantizationmixin (class in aimet_torch.v2.nn)": [[78, "aimet_torch.v2.nn.QuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.quantizationmixin method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.quantizationmixin method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.quantizationmixin class method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.from_module"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[78, "aimet_torch.v2.nn.QuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[78, "aimet_torch.v2.nn.QuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[78, "aimet_torch.v2.nn.QuantizationMixin.param_quantizers"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[78, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "quantize (class in aimet_torch.v2.quantization.affine)": [[79, "aimet_torch.v2.quantization.affine.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine)": [[79, "aimet_torch.v2.quantization.affine.QuantizeDequantize"]], "aimet_torch.v2.quantization.affine": [[79, "module-aimet_torch.v2.quantization.affine"]], "dequantize() (in module aimet_torch.v2.quantization.affine)": [[79, "aimet_torch.v2.quantization.affine.dequantize"]], "module": [[79, "module-aimet_torch.v2.quantization.affine"], [81, "module-aimet_torch.v2.quantization.float"]], "quantize() (in module aimet_torch.v2.quantization.affine)": [[79, "aimet_torch.v2.quantization.affine.quantize"]], "quantize_dequantize() (in module aimet_torch.v2.quantization.affine)": [[79, "aimet_torch.v2.quantization.affine.quantize_dequantize"]], "floatquantizedequantize (class in aimet_torch.v2.quantization.float)": [[80, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"], [81, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.float)": [[80, "aimet_torch.v2.quantization.float.QuantizeDequantize"], [81, "aimet_torch.v2.quantization.float.QuantizeDequantize"]], "aimet_torch.v2.quantization.float": [[81, "module-aimet_torch.v2.quantization.float"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[82, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[82, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[82, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[82, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[82, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[82, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[82, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[82, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "visualize_stats() (in module aimet_torch.v2.visualization_tools)": [[83, "aimet_torch.v2.visualization_tools.visualize_stats"]], "set_activation_quantizers_to_float() (in module aimet_torch.v2.quantsim.config_utils)": [[84, "aimet_torch.v2.quantsim.config_utils.set_activation_quantizers_to_float"]], "set_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[84, "aimet_torch.v2.quantsim.config_utils.set_blockwise_quantization_for_weights"]], "set_grouped_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[84, "aimet_torch.v2.quantsim.config_utils.set_grouped_blockwise_quantization_for_weights"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[85, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[85, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[85, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[85, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "gptvqparameters (class in aimet_torch.gptvq.defs)": [[87, "aimet_torch.gptvq.defs.GPTVQParameters"]], "apply_gptvq() (in module aimet_torch.gptvq.gptvq_weight.gptvq)": [[87, "aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq"]], "basequantizationmixin (class in aimet_torch.v2.nn.base)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin.forward"]], "input_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[89, "aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[90, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "allow_overwrite() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[90, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})