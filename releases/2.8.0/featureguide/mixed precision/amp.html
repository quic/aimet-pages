<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Automatic quantization" href="../autoquant.html" /><link rel="prev" title="Manual mixed precision" href="mmp.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Automatic mixed precision - AIMET</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../_static/aimet-furo.css?v=22b0637d" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">AIMET</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">AIMET</span>
  
</a><div class="doc-versions" data-toggle="doc-versions" role="note" aria-label="versions">

  <span class="doc-current-version" data-toggle="doc-current-version">
    Version: 2.8.0
  </span>
  <br>
  <span class="doc-other-versions" data-toggle="doc-other-versions">
        <a href="https://quic.github.io/aimet-pages/releases/latest/versions.html">Other versions</a>
  </span>

</div><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/quick-start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../userguide/index.html">User Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of User Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/quantization_tools.html">AIMET features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/quantization_workflow.html">Quantization workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/debugging_guidelines.html">Debugging guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/on_target_inference.html">On-target inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../quantsim/index.html">Quantization Simulation Guide</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Quantization Simulation Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../quantsim/calibration.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../quantsim/qat.html">QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../quantsim/blockwise.html">Blockwise quantization</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Feature Guide</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Feature Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../adaround.html">Adaptive rounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../seq_mse.html">Sequential MSE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bnf.html">Batch norm folding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cle.html">Cross-layer equalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../adascale.html">AdaScale</a></li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Mixed precision</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Mixed precision</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mmp.html">Manual mixed precision</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Automatic mixed precision</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../autoquant.html">Automatic quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bn.html">Batch norm re-estimation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../analysis%20tools/index.html">Analysis tools</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Analysis tools</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../analysis%20tools/interactive_visualization.html">Interactive visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../analysis%20tools/quant_analyzer.html">Quantization analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../analysis%20tools/layer_output_generation.html">Layer output generation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../compression/index.html">Compression</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Compression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../compression/feature_guidebook.html">Compression guidebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/greedy_compression_ratio_selection.html">Greedy compression ratio selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/visualization_compression.html">Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../compression/channel_pruning.html">Channel pruning</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Channel pruning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../compression/winnowing.html">Winnowing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../quantized%20LoRa/index.html">Quantized LoRa</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Quantized LoRa</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../quantized%20LoRa/qw_lora.html">QW-LoRa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quantized%20LoRa/qwa_lora.html">QWA-LoRa</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../omniquant.html">OmniQuant</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../apiref/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../release_notes.html">Release Notes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../external/index.html">External Resources</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of External Resources</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="http://www.qualcomm.com/developer/artificial-intelligence#overview">Qualcomm AI Stack</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/quic/ai-hub-models/">Qualcomm Hub Models</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/quic/ai-hub-apps/">Qualcomm Hub Apps</a></li>
<li class="toctree-l2"><a class="reference external" href="https://aihub.qualcomm.com/">Qualcomm AI Hub</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>

</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="automatic-mixed-precision">
<span id="featureguide-amp"></span><h1>Automatic mixed precision<a class="headerlink" href="#automatic-mixed-precision" title="Link to this heading">¶</a></h1>
<p>This technique helps choose per-layer integer bit-widths to retain model accuracy when run on
fixed-point runtimes like <a class="reference external" href="https://www.qualcomm.com/developer/software/qualcomm-ai-engine-direct-sdk">Qualcomm® AI Engine Direct</a>.</p>
<p>As an example, say a particular model is not meeting a desired accuracy target when run in INT8.
The Auto Mixed Precision (AMP) feature will find a minimal set of layers that need to run on higher
precision, INT16 for example, to get to the desired quantized accuracy.</p>
<p>Choosing a higher precision for some layers necessarily involves a trade-off: lower inferences/sec
for higher accuracy and vice-versa. The AMP feature will generate a pareto curve that can guide
the user to decide the right operating point for this tradeoff.</p>
<section id="context">
<h2>Context<a class="headerlink" href="#context" title="Link to this heading">¶</a></h2>
<p>For performing AMP, a user needs to start with a PyTorch, TensorFlow or ONNX model and create a
Quantization Simulation model <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code>. This QuantSim model, along with an
allowable accuracy drop, is passed to the API.</p>
<p>The function changes the QuantSim Sim model in place with different quantizers having different
bit-widths. This QuantSim model can be either exported or evaluated to get a quantization accuracy.</p>
<a class="reference internal image-reference" href="../../_images/automatic_mixed_precision_1.png"><img alt="../../_images/automatic_mixed_precision_1.png" src="../../_images/automatic_mixed_precision_1.png" style="width: 900px;" />
</a>
</section>
<section id="mixed-precision-algorithm">
<h2>Mixed Precision Algorithm<a class="headerlink" href="#mixed-precision-algorithm" title="Link to this heading">¶</a></h2>
<p>The algorithm involves 4 phases:</p>
<a class="reference internal image-reference" href="../../_images/automatic_mixed_precision_2.png"><img alt="../../_images/automatic_mixed_precision_2.png" src="../../_images/automatic_mixed_precision_2.png" style="width: 700px;" />
</a>
<section id="find-layer-groups">
<h3>1) Find layer groups<a class="headerlink" href="#find-layer-groups" title="Link to this heading">¶</a></h3>
<blockquote>
<div><p>Layer Groups are defined as a group of layers grouped together based on certain rules.
This helps in reducing search space over which the mixed precision algorithm operates.
It also ensures that we search only over the valid bit-width settings for parameters and activations.</p>
</div></blockquote>
<a class="reference internal image-reference" href="../../_images/automatic_mixed_precision_3.png"><img alt="../../_images/automatic_mixed_precision_3.png" src="../../_images/automatic_mixed_precision_3.png" style="width: 900px;" />
</a>
</section>
<section id="perform-sensitivity-analysis-phase-1">
<h3>2) Perform sensitivity analysis (Phase 1)<a class="headerlink" href="#perform-sensitivity-analysis-phase-1" title="Link to this heading">¶</a></h3>
<blockquote>
<div><p>In this phase the algorithm performs a per-layer group sensitivity analysis.
This will identify how sensitive is the model if we choose a lower quantization bit-width for a particular layer group.
The sensitivity analysis yields an accuracy list which is cached and can be re-used again by the algorithm.</p>
<p>Below is an example of a list generated using sensitivity analysis:</p>
<a class="reference internal image-reference" href="../../_images/accuracy_list.png"><img alt="../../_images/accuracy_list.png" src="../../_images/accuracy_list.png" style="width: 900px;" />
</a>
</div></blockquote>
</section>
<section id="create-a-pareto-front-list-phase-2">
<h3>3) Create a Pareto-front list (Phase 2)<a class="headerlink" href="#create-a-pareto-front-list-phase-2" title="Link to this heading">¶</a></h3>
<blockquote>
<div><p>A Pareto curve is a trade-off curve that describes how accuracy varies given a bit-ops target and vice versa.
The AMP algorithm yields a Pareto front curve which consists of layer groups changed up to that point, relative bit-ops (relative to starting bit-ops),
accuracy of the model, and the bit-width to which the layer group was changed to.</p>
<p>An example of a Pareto list:</p>
<a class="reference internal image-reference" href="../../_images/pareto.png"><img alt="../../_images/pareto.png" src="../../_images/pareto.png" style="width: 900px;" />
</a>
<p>Bit-ops are computed as</p>
<p><span class="math notranslate nohighlight">\(Bit-ops = Mac(op) * Bitwidth(parameter) * Bitwidth(Activation)\)</span></p>
<p>The Pareto list can be used for plotting a Pareto curve. A Bokeh plot for Pareto curve is generated and saved in the results directory.</p>
<a class="reference internal image-reference" href="../../_images/pareto_curve.png"><img alt="../../_images/pareto_curve.png" src="../../_images/pareto_curve.png" style="width: 900px;" />
</a>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A user can pass two different evaluation callbacks for phase 1 and phase 2. Since phase 1 is measuring sensitivity
of each quantizer group, we can pass a smaller representative dataset for phase 1 for evaluation, or even use an indirect measure
such as SQNR which can be computed faster than but correlates well with the real evaluation metric.</p>
</div>
<p>It is recommended to use the complete dataset for evaluation in phase 2.</p>
</section>
<section id="reduce-bit-width-convert-op-overhead-phase-3">
<h3>4) Reduce Bit-width Convert Op Overhead (Phase 3)<a class="headerlink" href="#reduce-bit-width-convert-op-overhead-phase-3" title="Link to this heading">¶</a></h3>
<p>Convert Ops are introduced in the mixed-precision model for transition between Ops that are assigned different activation
bit-widths or data types (float vs int). These Convert Ops contribute to the inference time along with bit-operations of Ops.
In this phase the algorithm derives a mixed-precision solution having less Convert Op overhead w.r.t. to original solution
keeping the mixed-precision accuracy intact. The algorithm produces mixed-precision solutions for a range of alpha values
(0.0, 0.2, 0.4, 0.6, 0.8, 1.0) where the alpha represents fraction of original Convert Op overhead allowed for respective solution.</p>
</section>
</section>
<section id="use-cases">
<h2>Use Cases<a class="headerlink" href="#use-cases" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>Choosing a very high accuracy drop (equivalent to setting allowed_accuracy_drop as None):</p></li>
</ol>
<p>AIMET allows a user to save intermediate states for computation of the Pareto list. Therefore, if a user computes a Pareto
list corresponding to an accuracy drop of None, they can view the complete profile of how model accuracy will vary as bit-ops vary.</p>
<p>Thereafter, a user can visualize the Pareto curve plot and choose an optimal point for accuracy. The algorithm can be re-run with
the new accuracy drop to get a sim model with the required accuracy.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Pareto list is not modified during the second run.</p>
</div>
<ol class="arabic simple" start="2">
<li><p>Choosing a lower accuracy drop and then continuing to compute pareto list from this point if more accuracy drop is acceptable:</p></li>
</ol>
<p>To enable this a user can use the clean_start parameter in the API. If clean_start is set to False then the Pareto list will
start computation from the last point where it left off.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>It is recommended to set the clean_start parameter to False to use cached results for both use cases.</p></li>
<li><p>If the model or candidate bit-widths change, the user needs to do a clean start.</p></li>
</ul>
</div>
</section>
<section id="workflow">
<h2>Workflow<a class="headerlink" href="#workflow" title="Link to this heading">¶</a></h2>
<section id="code-example">
<h3>Code example<a class="headerlink" href="#code-example" title="Link to this heading">¶</a></h3>
<section id="step-1">
<h4>Step 1<a class="headerlink" href="#step-1" title="Link to this heading">¶</a></h4>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-0">
PyTorch</label><div class="sd-tab-content docutils">
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.batch_norm_fold</span><span class="w"> </span><span class="kn">import</span> <span class="n">fold_all_batch_norms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationDataType</span><span class="p">,</span> <span class="n">CallbackFunc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.v1.mixed_precision</span><span class="w"> </span><span class="kn">import</span> <span class="n">choose_mixed_precision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.quantsim</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationSimModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.amp.mixed_precision_algo</span><span class="w"> </span><span class="kn">import</span> <span class="n">GreedyMixedPrecisionAlgo</span>
</pre></div>
</div>
<p><strong>Load the model, define forward_pass and evaluation callbacks</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># General setup that can be changed as needed</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">PATH_TO_IMAGENET</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageNet</span><span class="p">(</span><span class="n">PATH_TO_IMAGENET</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">fold_all_batch_norms</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Callback function to pass calibration data through the model</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward_pass</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">batches</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">batch</span> <span class="o">&gt;=</span> <span class="n">batches</span><span class="p">:</span>
                <span class="k">break</span>

<span class="c1"># Basic ImageNet evaluation function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-1">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;2&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.applications.resnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResNet50</span><span class="p">,</span> <span class="n">preprocess_input</span><span class="p">,</span> <span class="n">decode_predictions</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.quantsim</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationSimModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">CallbackFunc</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="p">,</span> <span class="n">QuantScheme</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.batch_norm_fold</span><span class="w"> </span><span class="kn">import</span> <span class="n">fold_all_batch_norms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.mixed_precision</span><span class="w"> </span><span class="kn">import</span> <span class="n">choose_mixed_precision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.amp.mixed_precision_algo</span><span class="w"> </span><span class="kn">import</span> <span class="n">GreedyMixedPrecisionAlgo</span>

</pre></div>
</div>
<p><strong>Load the model, define forward_pass and evaluation callbacks</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">)</span>

<span class="c1"># Perform batch norm folding</span>
<span class="n">_</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">fold_all_batch_norms</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">center_crop</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform the center corp on the images.</span>
<span class="sd">    :param image: List of images as tensors which we need to center corp. Expects the image size of 256 x 256.</span>
<span class="sd">    :return: Center corped images of size 224 x 224</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">img_height</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">img_width</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">crop_length</span> <span class="o">=</span> <span class="mi">224</span>
    <span class="n">start_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_height</span> <span class="o">-</span> <span class="n">crop_length</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">start_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_width</span> <span class="o">-</span> <span class="n">crop_length</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">cropped_image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[:,</span>  <span class="n">start_x</span><span class="p">:(</span><span class="n">img_width</span> <span class="o">-</span> <span class="n">start_x</span><span class="p">),</span> <span class="n">start_y</span><span class="p">:(</span><span class="n">img_height</span> <span class="o">-</span> <span class="n">start_y</span><span class="p">),</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">cropped_image</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_eval_func</span><span class="p">(</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">50000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper Function returns an evaluation function which performs the forward pass on the specified model</span>
<span class="sd">     with given dataset parameters</span>
<span class="sd">    :param dataset_dir: Directrory from where the dataset images needs to be loaded.</span>
<span class="sd">    :param batch_size: Batch size to be used in dataloader</span>
<span class="sd">    :param num_iterations: Optional parameter stating total number of images to be used.</span>
<span class="sd">    Default set to 50000, which is size of the validation set of imagenet dataset.</span>
<span class="sd">    :return: returns a evaluation function which can be used to evaluate the model&#39;s accuracy on the preset dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">func_wrapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; Evaluation Function which is return from the parent function. Performs the forward pass on the model with the given dataset and retuerns the acuracy.&quot;&quot;&quot;</span>

        <span class="n">validation_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
            <span class="n">directory</span><span class="o">=</span><span class="n">dataset_dir</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="s1">&#39;inferred&#39;</span><span class="p">,</span>
            <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># If no iterations specified, set to full validation set</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">iterations</span><span class="p">:</span>
            <span class="n">iterations</span> <span class="o">=</span> <span class="n">num_iterations</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">top1</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">validation_ds</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">label</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="n">validation_ds</span><span class="o">.</span><span class="n">class_names</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">label</span><span class="p">]</span>
            <span class="n">cnt</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">decode_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
            <span class="n">top1</span> <span class="o">+=</span> <span class="n">cnt</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;=</span> <span class="n">iterations</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">top1</span><span class="o">/</span><span class="n">total</span>
    <span class="k">return</span> <span class="n">func_wrapper</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_data_loader_wrapper</span><span class="p">(</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function which returns a method calling which will give a data loader.</span>
<span class="sd">    :param dataset_dir: Directrory from where the dataset images needs to be loaded.</span>
<span class="sd">    :param batch_size: Batch size to be used in dataloader</span>
<span class="sd">    :param is_training: Default to False. It is used to set the shuffle flag for the data loader.</span>
<span class="sd">    :return: Returns a wrapper function which will return a dataloader.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dataloader_wrapper</span><span class="p">():</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
            <span class="n">directory</span><span class="o">=</span><span class="n">dataset_dir</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="s1">&#39;inferred&#39;</span><span class="p">,</span>
            <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span> <span class="o">=</span> <span class="n">is_training</span><span class="p">,</span>
            <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">center_crop</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">dataloader_wrapper</span>

<span class="c1"># get the evaluation function</span>
<span class="c1"># We will use this function to for forward pass callback as well.</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">dataset_dir</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># path to dataset directory.</span>
<span class="n">eval_func</span> <span class="o">=</span> <span class="n">get_eval_func</span><span class="p">(</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># Calculate the Original Model accuracy</span>
<span class="n">org_top1</span> <span class="o">=</span> <span class="n">eval_func</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Model Accuracy: &quot;</span><span class="p">,</span> <span class="n">org_top1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-2">
ONNX</label><div class="sd-tab-content docutils">
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">onnx</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">onnxsim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">MobileNet_V2_Weights</span><span class="p">,</span> <span class="n">mobilenet_v2</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_onnx.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_onnx.quantsim</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationSimModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationDataType</span><span class="p">,</span> <span class="n">CallbackFunc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_onnx.mixed_precision</span><span class="w"> </span><span class="kn">import</span> <span class="n">choose_mixed_precision</span>
</pre></div>
</div>
<p><strong>Instantiate a PyTorch model, convert to ONNX graph, define forward_pass and evaluation callbacks</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pt_model</span> <span class="o">=</span> <span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">MobileNet_V2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">)</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="c1"># Modify file_path as you wish, we are using temporary directory for now</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;/tmp&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;mobilenet_v2.onnx&#39;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="n">pt_model</span><span class="p">,</span>
    <span class="p">(</span><span class="n">dummy_input</span><span class="p">,),</span>
    <span class="n">file_path</span><span class="p">,</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">],</span>
    <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">],</span>
    <span class="n">dynamic_axes</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">},</span>
        <span class="s1">&#39;output&#39;</span><span class="p">:</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="c1"># Load exported ONNX model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
<span class="c1"># End of loading the model</span>

<span class="c1"># Prepare model with onnx-simplifier</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">onnxsim</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ONNX Simplifier failed. Proceeding with unsimplified model&#39;</span><span class="p">)</span>
<span class="c1"># End of prepare model</span>

<span class="c1"># Set up dataloader</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
    <span class="s1">&#39;ILSVRC/imagenet-1k&#39;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CustomDataLoader</span><span class="p">(</span><span class="n">DataLoader</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">unlabeled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unlabeled</span> <span class="o">=</span> <span class="n">unlabeled</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_iteration</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">:</span>
            <span class="n">start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_iteration</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_iteration</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unlabeled</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span>


<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">transforms</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">))</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">examples</span>


<span class="n">dataset</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">NUM_CALIBRATION_SAMPLES</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">NUM_EVAL_SAMPLES</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">unlabeled_data_loader</span> <span class="o">=</span> <span class="n">CustomDataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">NUM_CALIBRATION_SAMPLES</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">eval_data_loader</span> <span class="o">=</span> <span class="n">CustomDataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">NUM_EVAL_SAMPLES</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">),</span> <span class="n">unlabeled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="c1"># End of setting up dataloader</span>

<span class="k">def</span><span class="w"> </span><span class="nf">forward_pass</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
    <span class="n">input_name</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
    <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">unlabeled_data_loader</span><span class="p">):</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">inputs</span><span class="p">})</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
    <span class="n">correct_predictions</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_samples</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">eval_data_loader</span><span class="p">):</span>
        <span class="n">input_name</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="n">pred_probs</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">inputs</span><span class="p">})</span>
        <span class="n">pred_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct_predictions</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred_labels</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">total_samples</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct_predictions</span> <span class="o">/</span> <span class="n">total_samples</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-2">
<h4>Step 2<a class="headerlink" href="#step-2" title="Link to this heading">¶</a></h4>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-3">
PyTorch</label><div class="sd-tab-content docutils">
<p><strong>Quantization with mixed precision</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">default_bitwidth</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># ((activation bitwidth, activation data type), (param bitwidth, param data type))</span>
<span class="n">candidates</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
             <span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
             <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">))]</span>
<span class="c1"># Allowed accuracy drop in absolute value</span>
<span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># Implies 50% drop</span>

<span class="n">eval_callback_for_phase_1</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">evaluate</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="n">data_loader</span><span class="p">)</span>
<span class="n">eval_callback_for_phase_2</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">evaluate</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="n">data_loader</span><span class="p">)</span>

<span class="n">calibration_batches</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">forward_pass_call_back</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">forward_pass</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="n">calibration_batches</span><span class="p">)</span>

<span class="c1"># Create quant sim</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                           <span class="n">default_param_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span>
                           <span class="n">default_output_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span>
                           <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_pass</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="n">calibration_batches</span><span class="p">)</span>

<span class="c1"># Enable phase-3 (optional)</span>
<span class="n">GreedyMixedPrecisionAlgo</span><span class="o">.</span><span class="n">ENABLE_CONVERT_OP_REDUCTION</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Call the mixed precision algo with clean start = True i.e. new accuracy list and pareto list will be generated</span>
<span class="c1"># If set to False then pareto front list and accuracy list will be loaded from the provided directory path</span>
<span class="c1"># A allowed_accuracy_drop can be specified to export the final model with reference to the pareto list</span>
<span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                           <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                           <span class="n">clean_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_call_back</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>

<span class="c1"># Set clean_start to False to start from an existing cache</span>
<span class="c1"># Set allowed_accuracy_drop to 0.9 to export the 90% drop point in pareto list</span>
<span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                           <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                           <span class="n">clean_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_call_back</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="p">),</span> <span class="n">dummy_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-4">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>Quantization with regular mixed precision</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">default_bitwidth</span> <span class="o">=</span> <span class="mi">16</span>
<span class="c1"># Set the candidates for the mixed precision algorithm</span>
<span class="c1"># Candidate format given below</span>
<span class="c1"># ((activation bitwidth, activation data type), (param bitwidth, param data type))</span>
<span class="c1"># e.g. ((16, QuantizationDataType.int), (16, QuantizationDataType.int)),</span>
<span class="n">candidate</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
             <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">))]</span>

<span class="c1"># get the quantized model object</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                           <span class="n">default_output_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span>
                           <span class="n">default_param_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,)</span>

<span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>


<span class="c1"># The allowed accuracy drop represents the amount of accuracy drop we are accepting</span>
<span class="c1"># to trade for a lower precision, faster model.</span>
<span class="c1"># 0.09 represents we are accepting upto 9% accuracy drop from the baseline.</span>
<span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.09</span>

<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">forward_pass_callback</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>

<span class="c1"># Enable phase-3 (optional)</span>
<span class="n">GreedyMixedPrecisionAlgo</span><span class="o">.</span><span class="n">ENABLE_CONVERT_OP_REDUCTION</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1"># Note: supported candidates ((8,int), (8,int)) &amp; ((16,int), (8,int))</span>

<span class="c1"># Call the mixed precision wrapper with appropriate parameters</span>
<span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">eval_callback</span><span class="p">,</span> <span class="n">eval_callback</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="s2">&quot;./cmp_res&quot;</span><span class="p">,</span>
                                           <span class="n">clean_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_callback</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mixed Precision Model Accuracy: &quot;</span><span class="p">,</span> <span class="n">eval_func</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">filename_prefix</span><span class="o">=</span><span class="s1">&#39;mixed_preision_quant_model&#39;</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-5">
ONNX</label><div class="sd-tab-content docutils">
<p><strong>Quantization with mixed precision</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define parameters to pass to mixed precision algo</span>
<span class="n">default_bitwidth</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># ((activation bitwidth, activation data type), (param bitwidth, param data type))</span>
<span class="n">candidates</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
             <span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
             <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">))]</span>
<span class="c1"># Allowed accuracy drop in absolute value</span>
<span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="c1"># Implies 50% drop</span>

<span class="n">eval_callback_for_phase_1</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">evaluate</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">eval_callback_for_phase_2</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">evaluate</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">forward_pass_callback</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">forward_pass</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Create quant sim</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">,</span> <span class="n">default_activation_bw</span><span class="o">=</span><span class="n">default_bitwidth</span><span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Call the mixed precision algo with clean start = True i.e. new accuracy list and pareto list will be generated</span>
<span class="c1"># If set to False then pareto front list and accuracy list will be loaded from the provided directory path</span>
<span class="c1"># A allowed_accuracy_drop can be specified to export the final model with reference to the pareto list</span>
<span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                           <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                           <span class="n">clean_start</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_callback</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>

<span class="c1"># Set clean_start to False to start from an existing cache</span>
<span class="c1"># Set allowed_accuracy_drop to 0.9 to export the 90% drop point in pareto list</span>
<span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">pareto_front_list</span> <span class="o">=</span> <span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">candidates</span><span class="p">,</span> <span class="n">eval_callback_for_phase_1</span><span class="p">,</span>
                                           <span class="n">eval_callback_for_phase_2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span> <span class="n">results_dir</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
                                           <span class="n">clean_start</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_callback</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pareto_front_list</span><span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="api">
<h2>API<a class="headerlink" href="#api" title="Link to this heading">¶</a></h2>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-6">
PyTorch</label><div class="sd-tab-content docutils">
<p><strong>Top-level API for Automatic mixed precision</strong></p>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_torch.mixed_precision.choose_mixed_precision">
<span class="sig-prename descclassname"><span class="pre">aimet_torch.mixed_precision.</span></span><span class="sig-name descname"><span class="pre">choose_mixed_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/v2/mixed_precision.html#choose_mixed_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.mixed_precision.choose_mixed_precision" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To enable phase-3 set the attribute GreedyMixedPrecisionAlgo.ENABLE_CONVERT_OP_REDUCTION = True</p>
</div>
<p>Currently only two candidates are supported - ((8,int), (8,int)) &amp; ((16,int), (8,int))</p>
<p><strong>Quantizer Groups definition</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.amp.quantizer_groups.</span></span><span class="sig-name descname"><span class="pre">QuantizerGroup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supported_kernel_ops=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/quantizer_groups.html#QuantizerGroup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup" title="Link to this definition">¶</a></dt>
<dd><p>Group of modules and quantizers</p>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.get_active_quantizers">
<span class="sig-name descname"><span class="pre">get_active_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/quantizer_groups.html#QuantizerGroup.get_active_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_active_quantizers" title="Link to this definition">¶</a></dt>
<dd><p>Find all active tensor quantizers associated with this quantizer group</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.get_candidate">
<span class="sig-name descname"><span class="pre">get_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/quantizer_groups.html#QuantizerGroup.get_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_candidate" title="Link to this definition">¶</a></dt>
<dd><p>Gets Activation &amp; parameter bitwidth
:type name_to_quantizer_dict: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>
:param name_to_quantizer_dict: Gets module from module name
:rtype: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]</span>
:return: Tuple of Activation, parameter bitwidth and data type</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.get_input_quantizer_modules">
<span class="sig-name descname"><span class="pre">get_input_quantizer_modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/quantizer_groups.html#QuantizerGroup.get_input_quantizer_modules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_input_quantizer_modules" title="Link to this definition">¶</a></dt>
<dd><p>helper method to get the module names corresponding to input_quantizers</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate">
<span class="sig-name descname"><span class="pre">set_quantizers_to_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/quantizer_groups.html#QuantizerGroup.set_quantizers_to_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate" title="Link to this definition">¶</a></dt>
<dd><p>Sets a quantizer group to a given candidate bitwidth
:type name_to_quantizer_dict: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>
:param name_to_quantizer_dict: Gets module from module name
:type candidate: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]</span>
:param candidate: candidate with act and param bw and data types</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.quantizer_groups.QuantizerGroup.to_list">
<span class="sig-name descname"><span class="pre">to_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/quantizer_groups.html#QuantizerGroup.to_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.to_list" title="Link to this definition">¶</a></dt>
<dd><p>Converts quantizer group to a list
:rtype: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]</span>
:return: List containing input/output quantizers &amp; weight quantizers</p>
</dd></dl>

</dd></dl>

<p><strong>CallbackFunc Definition</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_common.defs.CallbackFunc">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_common.defs.</span></span><span class="sig-name descname"><span class="pre">CallbackFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func_callback_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_common/defs.html#CallbackFunc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_common.defs.CallbackFunc" title="Link to this definition">¶</a></dt>
<dd><p>Class encapsulating call back function and it’s arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – Callable Function</p></li>
<li><p><strong>func_callback_args</strong> – Arguments passed to the callable function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.amp.mixed_precision_algo.</span></span><span class="sig-name descname"><span class="pre">EvalCallbackFactory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/mixed_precision_algo.html#EvalCallbackFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory" title="Link to this definition">¶</a></dt>
<dd><p>Factory class for various built-in eval callbacks</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></span>) – Data loader to be used for evaluation</p></li>
<li><p><strong>forward_fn</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]]</span>) – Function that runs forward pass and returns the output tensor.
This function is expected to take 1) a model and 2) a single batch
yielded from the data loader, and return a single torch.Tensor object
which represents the output of the model.
The default forward function is roughly equivalent to
<code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">model,</span> <span class="pre">batch:</span> <span class="pre">model(batch)</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory.sqnr">
<span class="sig-name descname"><span class="pre">sqnr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/_base/amp/mixed_precision_algo.html#EvalCallbackFactory.sqnr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory.sqnr" title="Link to this definition">¶</a></dt>
<dd><p>Returns SQNR eval callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num_samples</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Number of samples used for evaluation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A callback function that evaluates the input model’s SQNR
between fp32 outputs and fake-quantized outputs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<input id="sd-tab-item-7" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-7">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>Top-level API for Regular AMP</strong></p>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.mixed_precision.choose_mixed_precision">
<span class="sig-prename descclassname"><span class="pre">aimet_tensorflow.keras.mixed_precision.</span></span><span class="sig-name descname"><span class="pre">choose_mixed_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_accuracy_drop</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_search_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AMPSearchAlgo.Binary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase1_optimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/mixed_precision.html#choose_mixed_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.mixed_precision.choose_mixed_precision" title="Link to this definition">¶</a></dt>
<dd><p>High-level API to perform in place Mixed Precision evaluation on the given sim model. A pareto list is created and
a curve for Accuracy vs BitOps is saved under the results directory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantized sim model</p></li>
<li><p><strong>input_shape</strong> – tuple or list of tuples of input shape to the model</p></li>
<li><p><strong>starting_op_names</strong> – List of starting op names of the model</p></li>
<li><p><strong>output_op_names</strong> – List of output op names of the model</p></li>
<li><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]]</span>) – <p>List of tuples for all possible bitwidth values for activations and parameters
Suppose the possible combinations are-
((Activation bitwidth - 8, Activation data type - int), (Parameter bitwidth - 16, parameter data type - int))
((Activation bitwidth - 16, Activation data type - float), (Parameter bitwidth - 16, parameter data type - float))
candidates will be [((8, QuantizationDataType.int), (16, QuantizationDataType.int)),</p>
<blockquote>
<div><p>((16, QuantizationDataType.float), (16, QuantizationDataType.float))]</p>
</div></blockquote>
</p></li>
<li><p><strong>eval_callback_for_phase1</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – An object of CallbackFunc class which takes in Eval function (callable) and eval
function parameters. This evaluation callback used to measure sensitivity of each
quantizer group during phase 1. The phase 1 involves finding accuracy list/sensitivity of each
module. Therefore, a user might want to run the phase 1 with a smaller dataset</p></li>
<li><p><strong>eval_callback_for_phase2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – An object of CallbackFunc class which takes in Eval function (callable) and eval
function parameters. Evaluation callback used to get accuracy of quantized model
for phase 2 calculations. The phase 2 involves finding pareto front curve</p></li>
<li><p><strong>allowed_accuracy_drop</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Maximum allowed drop in accuracy from FP32 baseline. The pareto front curve is plotted only till the point where the allowable
accuracy drop is met. To get a complete plot for picking points on the curve, the user
can set the allowable accuracy drop to None.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Path to save results and cache intermediate results</p></li>
<li><p><strong>clean_start</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – If true, any cached information from previous runs will be deleted prior to starting the
mixed-precision analysis. If false, prior cached information will be used if applicable. Note
it is the user’s responsibility to set this flag to true if anything in the model or
quantization parameters changes compared to the previous run.</p></li>
<li><p><strong>forward_pass_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – An object of CallbackFunc class which takes in Forward pass function (callable) and its
function parameters. Forward pass callback used to compute quantization encodings</p></li>
<li><p><strong>amp_search_algo</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">AMPSearchAlgo</span></code></span>) – A valid value from the Enum AMPSearchAlgo. Defines the search algorithm to be used for
the phase 2 of AMP. Default to BruteForce for regular AMP.</p></li>
<li><p><strong>phase1_optimize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – If user set this parameter to false then phase1 default logic will be executed else optimized logic will be executed.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup" title="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Pareto front list containing a list of (Relative bit ops wrt baseline candidate, eval score, quantizer group
and the candidate being used in each step). The Pareto front list can be used for plotting a pareto front
curve which provides information regarding how bit ops vary w.r.t. accuracy. If the allowable accuracy drop
is set to 100% then a user can use the pareto front curve to pick points and re-run,
None if we early exit the mixed precision algorithm.</p>
</dd>
</dl>
</dd></dl>

<p><strong>Top-level API for Fast AMP (AMP 2.0)</strong></p>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.mixed_precision.choose_fast_mixed_precision">
<span class="sig-prename descclassname"><span class="pre">aimet_tensorflow.keras.mixed_precision.</span></span><span class="sig-name descname"><span class="pre">choose_fast_mixed_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader_wrapper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_accuracy_drop</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_search_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AMPSearchAlgo.Binary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase1_optimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/mixed_precision.html#choose_fast_mixed_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.mixed_precision.choose_fast_mixed_precision" title="Link to this definition">¶</a></dt>
<dd><p>High-level API to perform in place Mixed Precision evaluation on the given sim model. A pareto list is created and
a curve for Accuracy vs BitOps is saved under the results directory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantized sim model</p></li>
<li><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]]</span>) – <p>List of tuples for all possible bitwidth values for activations and parameters
Suppose the possible combinations are-
((Activation bitwidth - 8, Activation data type - int), (Parameter bitwidth - 16, parameter data type - int))
((Activation bitwidth - 16, Activation data type - float), (Parameter bitwidth - 16, parameter data type - float))
candidates will be [((8, QuantizationDataType.int), (16, QuantizationDataType.int)),</p>
<blockquote>
<div><p>((16, QuantizationDataType.float), (16, QuantizationDataType.float))]</p>
</div></blockquote>
</p></li>
<li><p><strong>data_loader_wrapper</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – A Callable function which when called should return a dataloader to be used to do phase 1 forward pass.</p></li>
<li><p><strong>eval_callback_for_phase2</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – An object of CallbackFunc class which takes in Eval function (callable) and eval
function parameters. Evaluation callback used to get accuracy of quantized model
for phase 2 calculations. The phase 2 involves finding pareto front curve</p></li>
<li><p><strong>allowed_accuracy_drop</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Maximum allowed drop in accuracy from FP32 baseline. The pareto front curve is plotted only till the point where the allowable
accuracy drop is met. To get a complete plot for picking points on the curve, the user
can set the allowable accuracy drop to None.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Path to save results and cache intermediate results</p></li>
<li><p><strong>clean_start</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – If true, any cached information from previous runs will be deleted prior to starting the
mixed-precision analysis. If false, prior cached information will be used if applicable. Note
it is the user’s responsibility to set this flag to true if anything in the model or
quantization parameters changes compared to the previous run.</p></li>
<li><p><strong>forward_pass_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – An object of CallbackFunc class which takes in Forward pass function (callable) and its
function parameters. Forward pass callback used to compute quantization encodings</p></li>
<li><p><strong>forward_pass_callback_2</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>]</span>) – forward pass callback function which will take an input model and inputs and perform forward pass
on it and return the output nupy ndarray of the last layer. Can be kept None if the model works with the standard model.predict() forward pass</p></li>
<li><p><strong>amp_search_algo</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">AMPSearchAlgo</span></code></span>) – A valid value from the Enum AMPSearchAlgo. Defines the search algorithm to be used for
the phase 2 of AMP. Default to Interpolation for fast AMP.</p></li>
<li><p><strong>phase1_optimize</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – If user set this parameter to false then phase1 default logic will be executed else optimized logic will be executed.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup" title="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Pareto front list containing a list of (Relative bit ops wrt baseline candidate, eval score, quantizer group
and the candidate being used in each step). The Pareto front list can be used for plotting a pareto front
curve which provides information regarding how bit ops vary w.r.t. accuracy. If the allowable accuracy drop
is set to 100% then a user can use the pareto front curve to pick points and re-run,
None if we early exit the mixed precision algorithm.</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To enable phase-3 set the attribute GreedyMixedPrecisionAlgo.ENABLE_CONVERT_OP_REDUCTION = True</p>
</div>
<p>Currently only two candidates are supported - ((8,int), (8,int)) &amp; ((16,int), (8,int))</p>
<p><strong>Quantizer Groups definition</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_tensorflow.keras.amp.quantizer_groups.</span></span><span class="sig-name descname"><span class="pre">QuantizerGroup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_quantizers=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup" title="Link to this definition">¶</a></dt>
<dd><p>Group of modules and quantizers</p>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_active_param_quantizers">
<span class="sig-name descname"><span class="pre">get_active_param_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup.get_active_param_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_active_param_quantizers" title="Link to this definition">¶</a></dt>
<dd><p>Find all active param tensor quantizers associated with this quantizer group
:type name_to_quantizer_dict: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>
:param name_to_quantizer_dict: Contains mapping of module name to sim.quantizer_config object</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">TensorQuantizer</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_active_quantizers">
<span class="sig-name descname"><span class="pre">get_active_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup.get_active_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_active_quantizers" title="Link to this definition">¶</a></dt>
<dd><p>Find all active tensor quantizers associated with this quantizer group</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">TensorQuantizer</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_candidate">
<span class="sig-name descname"><span class="pre">get_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup.get_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_candidate" title="Link to this definition">¶</a></dt>
<dd><p>Gets Activation &amp; parameter bitwidth
:type name_to_quantizer_dict: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>
:param name_to_quantizer_dict: Gets module from module name
:rtype: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]</span>
:return: Tuple of Activation, parameter bitwidth and data type</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.lookup_quantizer">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lookup_quantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quantizer_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup.lookup_quantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.lookup_quantizer" title="Link to this definition">¶</a></dt>
<dd><p>Returns the quantizer layer corresponding to the name
:quantizer_name: Name of the quantizer
:name_to_quantizer_dict: Dictionary of mappings from quantizer name to quantizer layer</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate">
<span class="sig-name descname"><span class="pre">set_quantizers_to_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup.set_quantizers_to_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate" title="Link to this definition">¶</a></dt>
<dd><p>Sets a quantizer group to a given candidate bitwidth
:type name_to_quantizer_dict: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>
:param name_to_quantizer_dict: Gets module from module name
:type candidate: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]</span>
:param candidate: candidate with act and param bw and data types</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.to_list">
<span class="sig-name descname"><span class="pre">to_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/amp/quantizer_groups.html#QuantizerGroup.to_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.to_list" title="Link to this definition">¶</a></dt>
<dd><p>Converts quantizer group to a list
:rtype: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]</span>
:return: List containing input/output quantizers &amp; weight quantizers</p>
</dd></dl>

</dd></dl>

<p><strong>CallbackFunc Definition</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="id0">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_common.defs.</span></span><span class="sig-name descname"><span class="pre">CallbackFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func_callback_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_common/defs.html#CallbackFunc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition">¶</a></dt>
<dd><p>Class encapsulating call back function and it’s arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – Callable Function</p></li>
<li><p><strong>func_callback_args</strong> – Arguments passed to the callable function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<input id="sd-tab-item-8" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-8">
ONNX</label><div class="sd-tab-content docutils">
<p><strong>Top-level API</strong></p>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_onnx.mixed_precision.choose_mixed_precision">
<span class="sig-prename descclassname"><span class="pre">aimet_onnx.mixed_precision.</span></span><span class="sig-name descname"><span class="pre">choose_mixed_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback_for_phase2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allowed_accuracy_drop</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clean_start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_all_amp_candidates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase1_optimize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amp_search_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">AMPSearchAlgo.Binary</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/mixed_precision.html#choose_mixed_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.mixed_precision.choose_mixed_precision" title="Link to this definition">¶</a></dt>
<dd><p>High-level API to perform in place Mixed Precision evaluation on the given sim model. A pareto list is created and
a curve for Accuracy vs BitOps is saved under the results directory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantized sim model</p></li>
<li><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]]</span>) – <p>List of tuples for all possible bitwidth values for activations and parameters
Suppose the possible combinations are-
((Activation bitwidth - 8, Activation data type - int), (Parameter bitwidth - 16, parameter data type - int))
((Activation bitwidth - 16, Activation data type - float), (Parameter bitwidth - 16, parameter data type - float))
candidates will be [((8, QuantizationDataType.int), (16, QuantizationDataType.int)),</p>
<blockquote>
<div><p>((16, QuantizationDataType.float), (16, QuantizationDataType.float))]</p>
</div></blockquote>
</p></li>
<li><p><strong>eval_callback_for_phase1</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceSession</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Callable object used to measure sensitivity of each
quantizer group during phase 1. The phase 1 involves finding accuracy list/sensitivity of each
module. Therefore, a user might want to run the phase 1 with a smaller dataset</p></li>
<li><p><strong>eval_callback_for_phase2</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceSession</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Callale object used to get accuracy of quantized model
for phase 2 calculations. The phase 2 involves finding pareto front curve</p></li>
<li><p><strong>allowed_accuracy_drop</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Maximum allowed drop in accuracy from FP32 baseline. The pareto front curve is plotted only till the point where the allowable
accuracy drop is met. To get a complete plot for picking points on the curve, the user
can set the allowable accuracy drop to None.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Path to save results and cache intermediate results</p></li>
<li><p><strong>clean_start</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – If true, any cached information from previous runs will be deleted prior to starting the
mixed-precision analysis. If false, prior cached information will be used if applicable. Note
it is the user’s responsibility to set this flag to true if anything in the model or
quantization parameters changes compared to the previous run.</p></li>
<li><p><strong>forward_pass_callback</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceSession</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]</span>) – Callable object used to compute quantization encodings</p></li>
<li><p><strong>use_all_amp_candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Using the “supported_kernels” field in the config file (under defaults
and op_type sections), a list of supported candidates can be specified. All the AMP candidates
which are passed through the “candidates” field may not be supported based on the data passed
through “supported_kernels”. When the field “use_all_amp_candidates” is set to True, the AMP
algorithm will ignore the “supported_kernels” in the config file and continue to use all candidates.</p></li>
<li><p><strong>amp_search_algo</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">AMPSearchAlgo</span></code></span>) – A valid value from the Enum AMPSearchAlgo. Defines the search algorithm to be used for
the phase 2 of AMP.</p></li>
</ul>
</dd>
<dt class="field-even">Phase1_optimize<span class="colon">:</span></dt>
<dd class="field-even"><p>If user set this parameter to false then phase1 default logic will be executed else optimized logic will be executed.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup" title="aimet_onnx.amp.quantizer_groups.QuantizerGroup"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pareto front list containing information including Bitops, QuantizerGroup candidates and
corresponding eval scores. The Pareto front list can be used for plotting a pareto front curve which
provides information regarding how bit ops vary w.r.t. accuracy. If the allowable accuracy drop is set to
100% then a user can use the pareto front curve to pick points and re-run,
None if we early exit the mixed precision algorithm.</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is recommended to use onnx-simplifier before applying mixed-precision.</p>
</div>
<p><strong>Quantizer Groups definition</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_onnx.amp.quantizer_groups.</span></span><span class="sig-name descname"><span class="pre">QuantizerGroup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter_quantizers=&lt;factory&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_quantizers=&lt;factory&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup" title="Link to this definition">¶</a></dt>
<dd><p>Group of modules and quantizers</p>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_activation_quantizers">
<span class="sig-name descname"><span class="pre">get_activation_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup.get_activation_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_activation_quantizers" title="Link to this definition">¶</a></dt>
<dd><p>Gets activation quantizers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name_to_quantizer_dict</strong> – Gets module from module name</p>
</dd>
</dl>
<p>:return List of activation quantizers</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_active_quantizers">
<span class="sig-name descname"><span class="pre">get_active_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup.get_active_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_active_quantizers" title="Link to this definition">¶</a></dt>
<dd><p>Find all active tensor quantizers associated with this quantizer group</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name_to_quantizer_dict</strong> – Gets module from module name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">QcQuantizeOp</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of active quantizers</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_candidate">
<span class="sig-name descname"><span class="pre">get_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup.get_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_candidate" title="Link to this definition">¶</a></dt>
<dd><p>Gets Activation &amp; parameter bitwidth</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name_to_quantizer_dict</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>) – Gets module from module name</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of Activation, parameter bitwidth and data type</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_param_quantizers">
<span class="sig-name descname"><span class="pre">get_param_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup.get_param_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_param_quantizers" title="Link to this definition">¶</a></dt>
<dd><p>Gets parameter quantizers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name_to_quantizer_dict</strong> – Gets module from module name</p>
</dd>
</dl>
<p>:return List of parameter quantizers</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate">
<span class="sig-name descname"><span class="pre">set_quantizers_to_candidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_to_quantizer_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">candidate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup.set_quantizers_to_candidate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate" title="Link to this definition">¶</a></dt>
<dd><p>Sets a quantizer group to a given candidate bitwidth</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name_to_quantizer_dict</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span>) – Gets module from module name</p></li>
<li><p><strong>candidate</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]</span>) – candidate with act and param bw and data types</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.quantizer_groups.QuantizerGroup.to_list">
<span class="sig-name descname"><span class="pre">to_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/quantizer_groups.html#QuantizerGroup.to_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.to_list" title="Link to this definition">¶</a></dt>
<dd><p>Converts quantizer group to a list</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List containing input/output quantizers &amp; weight quantizers</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<p><strong>CallbackFunc Definition</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="id1">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_common.defs.</span></span><span class="sig-name descname"><span class="pre">CallbackFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func_callback_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_common/defs.html#CallbackFunc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id1" title="Link to this definition">¶</a></dt>
<dd><p>Class encapsulating call back function and it’s arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – Callable Function</p></li>
<li><p><strong>func_callback_args</strong> – Arguments passed to the callable function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="aimet_onnx.amp.mixed_precision_algo.EvalCallbackFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_onnx.amp.mixed_precision_algo.</span></span><span class="sig-name descname"><span class="pre">EvalCallbackFactory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/mixed_precision_algo.html#EvalCallbackFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.mixed_precision_algo.EvalCallbackFactory" title="Link to this definition">¶</a></dt>
<dd><p>Factory class for various built-in eval callbacks</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></span>) – Data loader to be used for evaluation</p></li>
<li><p><strong>forward_fn</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceSession</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]]</span>) – Function that runs forward pass and returns the output tensor.
This function is expected to take 1) a model 2) List of starting op names
3) List of output op names and 4) batch yielded from the data set, and
return a single tf.Tensor (or np.ndarray) object which represents the output of the model.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.amp.mixed_precision_algo.EvalCallbackFactory.sqnr">
<span class="sig-name descname"><span class="pre">sqnr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/amp/mixed_precision_algo.html#EvalCallbackFactory.sqnr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.amp.mixed_precision_algo.EvalCallbackFactory.sqnr" title="Link to this definition">¶</a></dt>
<dd><p>Returns SQNR eval callback.
NOTE: sim object is required to enable/disable quantizer_info objects associated with quant ops.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantized sim model</p></li>
<li><p><strong>num_samples</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Number of samples used for evaluation</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceSession</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A callback function that evaluates model SQNR between fp32_outputs and quantized outputs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../autoquant.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Automatic quantization</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="mmp.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Manual mixed precision</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Qualcomm Innovation Center, Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/quic/aimet" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Automatic mixed precision</a><ul>
<li><a class="reference internal" href="#context">Context</a></li>
<li><a class="reference internal" href="#mixed-precision-algorithm">Mixed Precision Algorithm</a><ul>
<li><a class="reference internal" href="#find-layer-groups">1) Find layer groups</a></li>
<li><a class="reference internal" href="#perform-sensitivity-analysis-phase-1">2) Perform sensitivity analysis (Phase 1)</a></li>
<li><a class="reference internal" href="#create-a-pareto-front-list-phase-2">3) Create a Pareto-front list (Phase 2)</a></li>
<li><a class="reference internal" href="#reduce-bit-width-convert-op-overhead-phase-3">4) Reduce Bit-width Convert Op Overhead (Phase 3)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#use-cases">Use Cases</a></li>
<li><a class="reference internal" href="#workflow">Workflow</a><ul>
<li><a class="reference internal" href="#code-example">Code example</a><ul>
<li><a class="reference internal" href="#step-1">Step 1</a></li>
<li><a class="reference internal" href="#step-2">Step 2</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#api">API</a><ul>
<li><a class="reference internal" href="#aimet_torch.mixed_precision.choose_mixed_precision"><code class="docutils literal notranslate"><span class="pre">choose_mixed_precision()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a><ul>
<li><a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_active_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_active_quantizers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_candidate"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_candidate()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.get_input_quantizer_modules"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_input_quantizer_modules()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.set_quantizers_to_candidate()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.amp.quantizer_groups.QuantizerGroup.to_list"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.to_list()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#aimet_common.defs.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory"><code class="docutils literal notranslate"><span class="pre">EvalCallbackFactory</span></code></a><ul>
<li><a class="reference internal" href="#aimet_torch.amp.mixed_precision_algo.EvalCallbackFactory.sqnr"><code class="docutils literal notranslate"><span class="pre">EvalCallbackFactory.sqnr()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.mixed_precision.choose_mixed_precision"><code class="docutils literal notranslate"><span class="pre">choose_mixed_precision()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.mixed_precision.choose_fast_mixed_precision"><code class="docutils literal notranslate"><span class="pre">choose_fast_mixed_precision()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a><ul>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_active_param_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_active_param_quantizers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_active_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_active_quantizers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.get_candidate"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_candidate()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.lookup_quantizer"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.lookup_quantizer()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.set_quantizers_to_candidate()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup.to_list"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.to_list()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.mixed_precision.choose_mixed_precision"><code class="docutils literal notranslate"><span class="pre">choose_mixed_precision()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a><ul>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_activation_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_activation_quantizers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_active_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_active_quantizers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_candidate"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_candidate()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.get_param_quantizers"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.get_param_quantizers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.set_quantizers_to_candidate"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.set_quantizers_to_candidate()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.quantizer_groups.QuantizerGroup.to_list"><code class="docutils literal notranslate"><span class="pre">QuantizerGroup.to_list()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id1"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.amp.mixed_precision_algo.EvalCallbackFactory"><code class="docutils literal notranslate"><span class="pre">EvalCallbackFactory</span></code></a><ul>
<li><a class="reference internal" href="#aimet_onnx.amp.mixed_precision_algo.EvalCallbackFactory.sqnr"><code class="docutils literal notranslate"><span class="pre">EvalCallbackFactory.sqnr()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=8a448e45"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>