

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET PyTorch Quantization SIM API &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.16.1</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.16.1</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../user_guide/index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../user_guide/index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET PyTorch Quantization SIM API</a><ul>
<li><a class="reference internal" href="#top-level-api">Top-level API</a></li>
<li><a class="reference internal" href="#enum-definition">Enum Definition</a></li>
<li><a class="reference internal" href="#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-pytorch-quantization-sim-api">
<span id="api-torch-quantsim"></span><h1>AIMET PyTorch Quantization SIM API<a class="headerlink" href="#aimet-pytorch-quantization-sim-api" title="Permalink to this headline">¶</a></h1>
<p>AIMET Quantization Sim requires the model definitions to use certain constructs and avoid others. These constraints are
described in detail <a class="reference internal" href="torch_model_guidelines.html#api-torch-model-validator"><span class="std std-ref">here</span></a>.</p>
<p>AIMET also includes a Model Validator tool to allow the users to check their model definition and find constructs that
might need to be replaced. Please see the API and usage examples for this tool also on the same page.</p>
<div class="section" id="top-level-api">
<h2>Top-level API<a class="headerlink" href="#top-level-api" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="aimet_torch.quantsim.QuantizationSimModel">
<em class="property">class </em><code class="sig-prename descclassname">aimet_torch.quantsim.</code><code class="sig-name descname">QuantizationSimModel</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">dummy_input</em>, <em class="sig-param">quant_scheme=&lt;QuantScheme.post_training_tf_enhanced: 2&gt;</em>, <em class="sig-param">rounding_mode='nearest'</em>, <em class="sig-param">default_output_bw=8</em>, <em class="sig-param">default_param_bw=8</em>, <em class="sig-param">in_place=False</em>, <em class="sig-param">config_file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quantsim.QuantizationSimModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements mechanism to add quantization simulations ops to a model. This allows for off-target simulation of
inference accuracy. Also allows the model to be fine-tuned to counter the effects of quantization.</p>
<p>Constructor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – Model to add simulation ops to</p></li>
<li><p><strong>dummy_input</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Dummy input to the model. Used to parse model graph. If the model has more than one input,
pass a tuple. User is expected to place the tensors on the appropriate device.</p></li>
<li><p><strong>quant_scheme</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <a class="reference internal" href="#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a>]) – Quantization scheme. Supported options are ‘tf_enhanced’ or ‘tf’ or using Quant Scheme Enum
QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced</p></li>
<li><p><strong>rounding_mode</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Rounding mode. Supported options are ‘nearest’ or ‘stochastic’</p></li>
<li><p><strong>default_output_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Default bitwidth (4-31) to use for quantizing layer inputs and outputs</p></li>
<li><p><strong>default_param_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Default bitwidth (4-31) to use for quantizing layer parameters</p></li>
<li><p><strong>in_place</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – If True, then the given ‘model’ is modified in-place to add quant-sim nodes.
Only suggested use of this option is when the user wants to avoid creating a copy of the model</p></li>
<li><p><strong>config_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Path to Configuration file for model quantizers</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>The following API can be used to Compute Encodings for Model</strong></p>
<dl class="method">
<dt id="aimet_torch.quantsim.QuantizationSimModel.compute_encodings">
<code class="sig-prename descclassname">QuantizationSimModel.</code><code class="sig-name descname">compute_encodings</code><span class="sig-paren">(</span><em class="sig-param">forward_pass_callback</em>, <em class="sig-param">forward_pass_callback_args</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quantsim.QuantizationSimModel.compute_encodings" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes encodings for all quantization sim nodes in the model. It is also used to find initial encodings for
Range Learning</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>forward_pass_callback</strong> – A callback function that simply runs forward passes on the model. This callback
function should use representative data for the forward pass, so the calculated encodings work for all
data samples. This callback internally chooses the number of data samples it wants to use for calculating
encodings.</p></li>
<li><p><strong>forward_pass_callback_args</strong> – These argument(s) are passed to the forward_pass_callback as-is. Up to
the user to determine the type of this parameter. E.g. could be simply an integer representing the number
of data samples to use. Or could be a tuple of parameters or an object representing something more complex.
If set to None, forward_pass_callback will be invoked with no parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>The following APIs can be used to save and restore the quantized model</strong></p>
<dl class="method">
<dt id="aimet_torch.quantsim.save_checkpoint">
<code class="sig-prename descclassname">quantsim.</code><code class="sig-name descname">save_checkpoint</code><span class="sig-paren">(</span><em class="sig-param">file_path</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quantsim.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>This API provides a way for the user to save a checkpoint of the quantized model which can
be loaded at a later point to continue fine-tuning e.g.
See also load_checkpoint()</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_sim_model</strong> (<a class="reference internal" href="#aimet_torch.quantsim.QuantizationSimModel" title="aimet_torch.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a>) – QuantizationSimModel to save checkpoint for</p></li>
<li><p><strong>file_path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path to the file where you want to save the checkpoint</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<dl class="method">
<dt id="aimet_torch.quantsim.load_checkpoint">
<code class="sig-prename descclassname">quantsim.</code><code class="sig-name descname">load_checkpoint</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quantsim.load_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the quantized model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path to the file where you want to save the checkpoint</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#aimet_torch.quantsim.QuantizationSimModel" title="aimet_torch.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A new instance of the QuantizationSimModel created after loading the checkpoint</p>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>The following API can be used to Export the Model to target</strong></p>
<dl class="method">
<dt id="aimet_torch.quantsim.QuantizationSimModel.export">
<code class="sig-prename descclassname">QuantizationSimModel.</code><code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">filename_prefix</em>, <em class="sig-param">dummy_input</em>, <em class="sig-param">onnx_export_args=&lt;aimet_torch.onnx_utils.OnnxExportApiArgs object&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quantsim.QuantizationSimModel.export" title="Permalink to this definition">¶</a></dt>
<dd><p>This method exports out the quant-sim model so it is ready to be run on-target.</p>
<p>Specifically, the following are saved</p>
<ol class="arabic simple">
<li><p>The sim-model is exported to a regular PyTorch model without any simulation ops</p></li>
<li><p>The quantization encodings are exported to a separate JSON-formatted file that can
then be imported by the on-target runtime (if desired)</p></li>
<li><p>Optionally, An equivalent model in ONNX format is exported. In addition, nodes in the ONNX model are named
the same as the corresponding PyTorch module names. This helps with matching ONNX node to their quant
encoding from #2.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – path where to store model pth and encodings</p></li>
<li><p><strong>filename_prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Prefix to use for filenames of the model pth and encodings files</p></li>
<li><p><strong>dummy_input</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Dummy input to the model. Used to parse model graph. It is required for the dummy_input to
be placed on CPU.</p></li>
<li><p><strong>onnx_export_args</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">OnnxExportApiArgs</span></code>]) – optional export argument with onnx specific overrides if not provide export via</p></li>
</ul>
</dd>
</dl>
<p>torchscript graph
:return: None</p>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p>Encoding format is described in the <a class="reference internal" href="quantization_encoding_specification.html#api-quantization-encoding-spec"><span class="std std-ref">Quantization Encoding Specification</span></a></p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="enum-definition">
<h2>Enum Definition<a class="headerlink" href="#enum-definition" title="Permalink to this headline">¶</a></h2>
<p><strong>Quant Scheme Enum</strong></p>
<dl class="class">
<dt id="aimet_common.defs.QuantScheme">
<em class="property">class </em><code class="sig-prename descclassname">aimet_common.defs.</code><code class="sig-name descname">QuantScheme</code><a class="headerlink" href="#aimet_common.defs.QuantScheme" title="Permalink to this definition">¶</a></dt>
<dd><p>Enumeration of Quant schemes</p>
<dl class="attribute">
<dt id="aimet_common.defs.QuantScheme.post_training_tf">
<code class="sig-name descname">post_training_tf</code><em class="property"> = 1</em><a class="headerlink" href="#aimet_common.defs.QuantScheme.post_training_tf" title="Permalink to this definition">¶</a></dt>
<dd><p>Tf scheme</p>
</dd></dl>

<dl class="attribute">
<dt id="aimet_common.defs.QuantScheme.post_training_tf_enhanced">
<code class="sig-name descname">post_training_tf_enhanced</code><em class="property"> = 2</em><a class="headerlink" href="#aimet_common.defs.QuantScheme.post_training_tf_enhanced" title="Permalink to this definition">¶</a></dt>
<dd><p>Tf- enhanced scheme</p>
</dd></dl>

</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">aimet_torch.examples</span> <span class="kn">import</span> <span class="n">mnist_torch_model</span>
<span class="c1"># Quantization related import</span>
<span class="kn">from</span> <span class="nn">aimet_torch.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span>
</pre></div>
</div>
<p><strong>Evaluation function</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">eval_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">use_cuda</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is intended to be the user-defined model evaluation function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s eval function does not</span>
<span class="sd">    match this signature, please create a simple wrapper.</span>

<span class="sd">    Note: Honoring the number of iterations is not absolutely necessary.</span>
<span class="sd">    However if all evaluations run over an entire epoch of validation data,</span>
<span class="sd">    the runtime for AIMET compression will obviously be higher.</span>

<span class="sd">    :param model: Model to evaluate</span>
<span class="sd">    :param eval_iterations: Number of iterations to use for evaluation.</span>
<span class="sd">            None for entire epoch.</span>
<span class="sd">    :param use_cuda: If true, evaluate using gpu acceleration</span>
<span class="sd">    :return: single float number (accuracy) representing model&#39;s performance</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">.5</span>
</pre></div>
</div>
<p><strong>Quantize and fine-tune a trained model</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quantize_model</span><span class="p">(</span><span class="n">trainer_function</span><span class="p">):</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">mnist_torch_model</span><span class="o">.</span><span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">))</span>

    <span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dummy_input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
                               <span class="n">config_file</span><span class="o">=</span><span class="s1">&#39;../../../TrainingExtensions/common/src/python/aimet_common/quantsim_config/&#39;</span>
                                           <span class="s1">&#39;default_config.json&#39;</span><span class="p">)</span>

    <span class="c1"># Quantize the untrained MNIST model</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">evaluate_model</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Fine-tune the model&#39;s parameter using training</span>
    <span class="n">trainer_function</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">sim</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Export the model</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="o">=</span><span class="s1">&#39;quantized_mnist&#39;</span><span class="p">,</span> <span class="n">dummy_input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.16.1</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>