

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET Features Guidebook &#8212; AI Model Efficiency Toolkit Documentation: ver tf-gpu_1.16.0</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AI Model Efficiency Toolkit Documentation: ver tf-gpu_1.16.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET Features Guidebook</a><ul>
<li><a class="reference internal" href="#quantization">Quantization</a></li>
<li><a class="reference internal" href="#compression">Compression</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-features-guidebook">
<span id="ug-guidebook"></span><h1>AIMET Features Guidebook<a class="headerlink" href="#aimet-features-guidebook" title="Permalink to this headline">¶</a></h1>
<p>AIMET supports various neural network quantization and compression techniques. This document provides typical workflows in order to quantize or compress a network using AIMET. A more in-depth discussion on various techniques and their usage is provided in <a class="reference internal" href="index.html#ug-index"><span class="std std-ref">User Guide</span></a></p>
<div class="section" id="quantization">
<h2>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline">¶</a></h2>
<p>The steps described in the following diagram are recommended to quantize a full precision trained model. At high level, the steps are:</p>
<img alt="../_images/flow_feature_guidebook.PNG" src="../_images/flow_feature_guidebook.PNG" />
<ol class="arabic simple">
<li><p>Quantize a model and evaluate accuracy.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>A model can be quantized by simulating quantization ops in the model as described in <a class="reference internal" href="quantization_sim.html#ug-quantsim"><span class="std std-ref">Quantization Simulation</span></a> . Accuracy can be evaluated in AIMET or the model can be quantized by a target SDK/inference application like Tensorflow-lite or Qualcomm Neural Processing SDK.</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>If accuracy of quantized model is not acceptable, analyze model performance using following steps:</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Inspect model weights using <a class="reference internal" href="visualization_quant.html#ug-quantization-visualization"><span class="std std-ref">Visualization tools</span></a> and determine if model may benefit from post-training quantization techniques namely Cross Layer Equalization (CLE) and Bias Correction (BC). Details on CLE and BC, including requirements on when these techniques are applicable, are provided on the page, <a class="reference internal" href="post_training_quant_techniques.html#ug-post-training-quantization"><span class="std std-ref">Post-training techniques</span></a>.</p></li>
<li><p>AIMET also provides ability to evaluate a model by quantizing weights while keeping activations in full precision or vice versa. This is recommended to determine what affects quantized model performance  weight quantization, activation quantization or both. Post-training techniques may help if weight quantization is an issue.</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Apply post-training techniques CLE and BC, if applicable, and evaluate model performance.</p></li>
<li><p>Model retraining/fine-tuning is recommended if activation quantization is an issue or when post-training techniques do not provide satisfactory performance. Retraining/Fine-tuning process inserts fake-quantization ops in the model and retrains the model for few epochs to alleviate quantization noise and improve model performance. Details on fine-tuning are provided <a class="reference internal" href="quantization_sim.html#ug-quantsim"><span class="std std-ref">here</span></a>.</p></li>
</ol>
</div>
<div class="section" id="compression">
<h2>Compression<a class="headerlink" href="#compression" title="Permalink to this headline">¶</a></h2>
<p>AIMET supports network compression using following techniques: Weight SVD, Spatial SVD (SSVD) and Channel Pruning (CP). These techniques are intended for Multiply-and-Accumulate (MAC) reduction of convolution layers in a neural network. Based on a configured desired MAC reduction ratio, i.e., MACs in compress model to MACs in uncompressed model, the compression algorithms automatically compress each individual convolution layer in the network to approximately reach the overall desired MAC reduction. Note that the actual on-target inference latency performance of a model depends on several factors MACs, memory and memory bandwidth, quantization, etc. Therefore, the improvement in runtime latency based on MAC reduction based compression may vary depending on the specific model architecture. Performance results for some typical models are provided in <a class="reference external" href="https://quic.github.io/aimet-pages/index.html">https://quic.github.io/aimet-pages/index.html</a>.
For best performance, a combination of spatial SVD followed by channel pruning is recommended.  At high level, following steps should be performed to compress a network using SSVD + CP combination:</p>
<img alt="../_images/compression_flow.png" src="../_images/compression_flow.png" />
<ol class="arabic simple">
<li><p>Determine the target compression ratio (C), which is the ratio of MACs in final compressed model to the MACs in the original uncompressed model. For example, target compression ratio = 0.5 indicates that the final model MACs are half of the original model MACs.</p></li>
<li><p>Perform compression using Spatial SVD technique as follows:</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Since the target compression ratio C is for the final SSVD+CP compressed model, the compression that should be targeted or can be achieved via SSVD is unknown apriori. As a result, few target compression ratios   (Cssvd)need to be tried out. Choose few Cssvd &gt; C targets and perform SSVD. E.g., if C = 0.5, Cssvd = {0.5,0.65, 0.75} can be used typically. This would result in three SSVD compressed models.</p></li>
<li><p>For each of the SSVD compressed model obtained from previous step, perform fine-tuning to improve model accuracy. Guidelines on fine-tuning are provided here [].</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Pick a model (or few models) that provide high accuracy from step 2b. For example, if the tolerable accuracy drop SSVD+CP compression relative to the original uncompressed model is X %  (X = Accuracy of uncompressed model (%)  Accuracy of compressed model (%)) , then a model(s) that has accuracy within few % (X-5 %)of the original uncompressed model accuracy should be selected to avoid very large drop in accuracy after CP step.</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Note that if step 2b results in very large accuracy drop or  drop well within tolerable accuracy drop, then step 2a/2b should be revisited first by appropriately adjusting the compression ratios.</p></li>
</ol>
</div></blockquote>
<ol class="arabic simple" start="4">
<li><p>Perform compression using Channel Pruning   technique as follows:</p></li>
</ol>
<blockquote>
<div><ol class="loweralpha simple">
<li><p>Perform compression with few target compression ratios (Ccp). One can set the compression ratio(s) based on the Cssvd of the model obtained from SSVD step 3 such that Cssvd * Ccp is approximately equal to C.</p></li>
<li><p>Perform fine-tuning to improve model accuracy.</p></li>
</ol>
</div></blockquote>
<p>5.      In the final step, a model is selected with MAC ratio relative to the original uncompressed model is close to C and also meets user’s accuracy requirements.
For example, for Resnet-50 results provided on <a class="reference external" href="https://quic.github.io/aimet-pages/index.html">https://quic.github.io/aimet-pages/index.html</a>, Csvd = 0.75 and Ccp = 0.66 were used to achieve overall compression C=0.5.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AI Model Efficiency Toolkit Documentation: ver tf-gpu_1.16.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>