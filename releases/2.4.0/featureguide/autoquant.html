<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Batch norm re-estimation" href="bn.html" /><link rel="prev" title="Automatic mixed precision" href="mixed%20precision/amp.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Automatic quantization - AIMET</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../_static/aimet-furo.css?v=22b0637d" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">AIMET</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">AIMET</span>
  
</a><div class="doc-versions" data-toggle="doc-versions" role="note" aria-label="versions">

  <span class="doc-current-version" data-toggle="doc-current-version">
    Version: 2.4.0
  </span>
  <br>
  <span class="doc-other-versions" data-toggle="doc-other-versions">
        <a href="https://quic.github.io/aimet-pages/releases/latest/versions.html">Other versions</a>
  </span>

</div><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install/quick-start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../userguide/index.html">User Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of User Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../userguide/quantization_tools.html">AIMET features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../userguide/quantization_workflow.html">Quantization workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../userguide/debugging_guidelines.html">Debugging guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../userguide/on_target_inference.html">On-target inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../quantsim/index.html">Quantization Simulation Guide</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Quantization Simulation Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../quantsim/calibration.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quantsim/qat.html">QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quantsim/blockwise.html">Blockwise quantization</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Feature Guide</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Feature Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="adaround.html">Adaptive rounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq_mse.html">Sequential MSE</a></li>
<li class="toctree-l2"><a class="reference internal" href="bnf.html">Batch norm folding</a></li>
<li class="toctree-l2"><a class="reference internal" href="cle.html">Cross-layer equalization</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="mixed%20precision/index.html">Mixed precision</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Mixed precision</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="mixed%20precision/mmp.html">Manual mixed precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="mixed%20precision/amp.html">Automatic mixed precision</a></li>
</ul>
</li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Automatic quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="bn.html">Batch norm re-estimation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="analysis%20tools/index.html">Analysis tools</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Analysis tools</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="analysis%20tools/interactive_visualization.html">Interactive visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="analysis%20tools/quant_analyzer.html">Quantization analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="analysis%20tools/layer_output_generation.html">Layer output generation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="compression/index.html">Compression</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Compression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="compression/feature_guidebook.html">Compression guidebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="compression/greedy_compression_ratio_selection.html">Greedy compression ratio selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="compression/visualization_compression.html">Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="compression/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="compression/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="compression/channel_pruning.html">Channel pruning</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Channel pruning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="compression/winnowing.html">Winnowing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="quantized%20LoRa/index.html">Quantized LoRa</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Quantized LoRa</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="quantized%20LoRa/qw_lora.html">QW-LoRa</a></li>
<li class="toctree-l3"><a class="reference internal" href="quantized%20LoRa/qwa_lora.html">QWA-LoRa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../apiref/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apiref/torch/index.html">aimet_torch</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of aimet_torch</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/migration_guide.html">Migrate to aimet_torch 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/quantsim.html">aimet_torch.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/adaround.html">aimet_torch.adaround</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apiref/torch/nn.html">aimet_torch.nn</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of aimet_torch.nn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizationMixin.html">QuantizationMixin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveAvgPool1d.html">QuantizedAdaptiveAvgPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveAvgPool2d.html">QuantizedAdaptiveAvgPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveAvgPool3d.html">QuantizedAdaptiveAvgPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveMaxPool1d.html">QuantizedAdaptiveMaxPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveMaxPool2d.html">QuantizedAdaptiveMaxPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveMaxPool3d.html">QuantizedAdaptiveMaxPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAlphaDropout.html">QuantizedAlphaDropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAvgPool1d.html">QuantizedAvgPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAvgPool2d.html">QuantizedAvgPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedAvgPool3d.html">QuantizedAvgPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedBCELoss.html">QuantizedBCELoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedBCEWithLogitsLoss.html">QuantizedBCEWithLogitsLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedBatchNorm1d.html">QuantizedBatchNorm1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedBatchNorm2d.html">QuantizedBatchNorm2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedBatchNorm3d.html">QuantizedBatchNorm3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedBilinear.html">QuantizedBilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCELU.html">QuantizedCELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCTCLoss.html">QuantizedCTCLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedChannelShuffle.html">QuantizedChannelShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCircularPad1d.html">QuantizedCircularPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCircularPad2d.html">QuantizedCircularPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCircularPad3d.html">QuantizedCircularPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConstantPad1d.html">QuantizedConstantPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConstantPad2d.html">QuantizedConstantPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConstantPad3d.html">QuantizedConstantPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConv1d.html">QuantizedConv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConv2d.html">QuantizedConv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConv3d.html">QuantizedConv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConvTranspose1d.html">QuantizedConvTranspose1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConvTranspose2d.html">QuantizedConvTranspose2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedConvTranspose3d.html">QuantizedConvTranspose3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCosineEmbeddingLoss.html">QuantizedCosineEmbeddingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCosineSimilarity.html">QuantizedCosineSimilarity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedCrossEntropyLoss.html">QuantizedCrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedDropout.html">QuantizedDropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedDropout1d.html">QuantizedDropout1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedDropout2d.html">QuantizedDropout2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedDropout3d.html">QuantizedDropout3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedELU.html">QuantizedELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedEmbedding.html">QuantizedEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedEmbeddingBag.html">QuantizedEmbeddingBag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedFeatureAlphaDropout.html">QuantizedFeatureAlphaDropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedFlatten.html">QuantizedFlatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedFold.html">QuantizedFold</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedFractionalMaxPool2d.html">QuantizedFractionalMaxPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedFractionalMaxPool3d.html">QuantizedFractionalMaxPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedGELU.html">QuantizedGELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedGLU.html">QuantizedGLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedGRU.html">QuantizedGRU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedGRUCell.html">QuantizedGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedGaussianNLLLoss.html">QuantizedGaussianNLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedGroupNorm.html">QuantizedGroupNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedHardshrink.html">QuantizedHardshrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedHardsigmoid.html">QuantizedHardsigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedHardswish.html">QuantizedHardswish</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedHardtanh.html">QuantizedHardtanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedHingeEmbeddingLoss.html">QuantizedHingeEmbeddingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedHuberLoss.html">QuantizedHuberLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedInstanceNorm1d.html">QuantizedInstanceNorm1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedInstanceNorm2d.html">QuantizedInstanceNorm2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedInstanceNorm3d.html">QuantizedInstanceNorm3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedKLDivLoss.html">QuantizedKLDivLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedL1Loss.html">QuantizedL1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLPPool1d.html">QuantizedLPPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLPPool2d.html">QuantizedLPPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLSTM.html">QuantizedLSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLSTMCell.html">QuantizedLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLayerNorm.html">QuantizedLayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLeakyReLU.html">QuantizedLeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLinear.html">QuantizedLinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLocalResponseNorm.html">QuantizedLocalResponseNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLogSigmoid.html">QuantizedLogSigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedLogSoftmax.html">QuantizedLogSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMSELoss.html">QuantizedMSELoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMarginRankingLoss.html">QuantizedMarginRankingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMaxPool1d.html">QuantizedMaxPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMaxPool2d.html">QuantizedMaxPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMaxPool3d.html">QuantizedMaxPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMaxUnpool1d.html">QuantizedMaxUnpool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMaxUnpool2d.html">QuantizedMaxUnpool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMaxUnpool3d.html">QuantizedMaxUnpool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMish.html">QuantizedMish</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMultiLabelMarginLoss.html">QuantizedMultiLabelMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMultiLabelSoftMarginLoss.html">QuantizedMultiLabelSoftMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedMultiMarginLoss.html">QuantizedMultiMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedNLLLoss.html">QuantizedNLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedNLLLoss2d.html">QuantizedNLLLoss2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedPReLU.html">QuantizedPReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedPairwiseDistance.html">QuantizedPairwiseDistance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedPixelShuffle.html">QuantizedPixelShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedPixelUnshuffle.html">QuantizedPixelUnshuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedPoissonNLLLoss.html">QuantizedPoissonNLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedRNN.html">QuantizedRNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedRNNCell.html">QuantizedRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedRReLU.html">QuantizedRReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReLU.html">QuantizedReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReLU6.html">QuantizedReLU6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReflectionPad1d.html">QuantizedReflectionPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReflectionPad2d.html">QuantizedReflectionPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReflectionPad3d.html">QuantizedReflectionPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReplicationPad1d.html">QuantizedReplicationPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReplicationPad2d.html">QuantizedReplicationPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedReplicationPad3d.html">QuantizedReplicationPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSELU.html">QuantizedSELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSiLU.html">QuantizedSiLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSigmoid.html">QuantizedSigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSmoothL1Loss.html">QuantizedSmoothL1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftMarginLoss.html">QuantizedSoftMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftmax.html">QuantizedSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftmax2d.html">QuantizedSoftmax2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftmin.html">QuantizedSoftmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftplus.html">QuantizedSoftplus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftshrink.html">QuantizedSoftshrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedSoftsign.html">QuantizedSoftsign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedTanh.html">QuantizedTanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedTanhshrink.html">QuantizedTanhshrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedThreshold.html">QuantizedThreshold</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedTripletMarginLoss.html">QuantizedTripletMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedTripletMarginWithDistanceLoss.html">QuantizedTripletMarginWithDistanceLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedUnflatten.html">QuantizedUnflatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedUnfold.html">QuantizedUnfold</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedUpsample.html">QuantizedUpsample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedUpsamplingBilinear2d.html">QuantizedUpsamplingBilinear2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedUpsamplingNearest2d.html">QuantizedUpsamplingNearest2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedZeroPad1d.html">QuantizedZeroPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedZeroPad2d.html">QuantizedZeroPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.nn.QuantizedZeroPad3d.html">QuantizedZeroPad3d</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../apiref/torch/quantization.html">aimet_torch.quantization</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of aimet_torch.quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.QuantizedTensorBase.html">QuantizedTensorBase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.QuantizedTensor.html">QuantizedTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.DequantizedTensor.html">DequantizedTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.affine.Quantize.html">Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.affine.QuantizeDequantize.html">QuantizeDequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.float.FloatQuantizeDequantize.html">FloatQuantizeDequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.affine.quantize.html">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.affine.quantize_dequantize.html">quantize_dequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../apiref/torch/generated/aimet_torch.quantization.affine.dequantize.html">dequantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/seq_mse.html">aimet_torch.seq_mse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/lpbq.html">aimet_torch.quantsim.config_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/bnf.html">aimet_torch.batch_norm_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/cle.html">aimet_torch.cross_layer_equalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/model_preparer.html">aimet_torch.model_preparer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/model_validator.html">aimet_torch.model_validator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/mp.html">aimet_torch.mixed_precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/quant_analyzer.html">aimet_torch.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/autoquant.html">aimet_torch.autoquant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/bn.html">aimet_torch.bn_reestimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/interactive_visualization.html">aimet_torch.visualization_tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/layer_output_generation.html">aimet_torch.layer_output_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/peft_lora.html">aimet_torch.peft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/compress.html">aimet_torch.compress</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/v1/quantsim.html">aimet_torch.v1.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/v1/adaround.html">aimet_torch.v1.adaround</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/v1/seq_mse.html">aimet_torch.v1.seq_mse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/v1/quant_analyzer.html">aimet_torch.v1.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/v1/autoquant.html">aimet_torch.v1.autoquant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/torch/v1/amp.html">aimet_torch.v1.amp</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apiref/tensorflow/index.html">aimet_tensorflow</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of aimet_tensorflow</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/quantsim.html">aimet_tensorflow.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/adaround.html">aimet_tensorflow.adaround</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/bnf.html">aimet_tensorflow.batch_norm_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/cle.html">aimet_tensorflow.cross_layer_equalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/amp.html">aimet_tensorflow.mixed_precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/quant_analyzer.html">aimet_tensorflow.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/autoquant.html">aimet_tensorflow.auto_quant_v2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/layer_output_generation.html">aimet_tensorflow.layer_output_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/model_preparer.html">aimet_tensorflow.model_preparer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/tensorflow/compress.html">aimet_tensorflow.compress</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../apiref/onnx/index.html">aimet_onnx</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of aimet_onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/quantsim.html">aimet_onnx.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/adaround.html">aimet_onnx.adaround</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/seq_mse.html">aimet_onnx.seq_mse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/lpbq.html">aimet_onnx.quantsim.set_grouped_blockwise_quantization_for_weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/bnf.html">aimet_onnx.batch_norm_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/cle.html">aimet_onnx.cross_layer_equalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/amp.html">aimet_onnx.mixed_precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/quant_analyzer.html">aimet_onnx.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../apiref/onnx/layer_output_generation.html">aimet_onnx.layer_output_utils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a></li>
</ul>

</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="automatic-quantization">
<span id="featureguide-autoquant"></span><h1>Automatic quantization<a class="headerlink" href="#automatic-quantization" title="Link to this heading">¶</a></h1>
<section id="context">
<h2>Context<a class="headerlink" href="#context" title="Link to this heading">¶</a></h2>
<p>AIMET toolkit offers a suite of post-training quantization (PTQ) techniques. Often,
applying these techniques in a specific sequence results in better quantized accuracy and performance.</p>
<p>The automatic quantization (AutoQuant) feature analyzes your trained model, determines the best
sequence of AIMET PTQ quantization techniques, and applies these techniques. You can specify the
tolerable accuracy drop in the AutoQuant API. As soon as this threshold accuracy is
reached, AutoQuant stops applying PTQ quantization techniques.</p>
<p>Without the AutoQuant feature, you must manually try combinations of AIMET quantization techniques.
This manual process is error-prone and time-consuming.</p>
</section>
<section id="workflow">
<h2>Workflow<a class="headerlink" href="#workflow" title="Link to this heading">¶</a></h2>
<p>The AutoQuant workflow is shown in the following figure.</p>
<a class="reference internal image-reference" href="../_images/auto_quant_1.png"><img alt="../_images/auto_quant_1.png" src="../_images/auto_quant_1.png" style="height: 450px;" />
</a>
<p>Before entering the optimization workflow, AutoQuant prepares by:</p>
<ol class="arabic simple">
<li><p>Checking the validity of the model and converting the model into an AIMET quantization-friendly format (<cite>Prepare Model</cite>).</p></li>
<li><p>Selecting the best-performing quantization scheme for the given model (<cite>QuantScheme Selection</cite>)</p></li>
</ol>
<p>After the preparation steps, AutoQuant proceeds to try four PTQ techniques:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="bnf.html#featureguide-bnf"><span class="std std-ref">BatchNorm folding</span></a></p></li>
<li><p><a class="reference internal" href="cle.html#featureguide-cle"><span class="std std-ref">Cross-layer equalization (CLE)</span></a></p></li>
<li><p><a class="reference internal" href="adaround.html#featureguide-adaround"><span class="std std-ref">Adaptive rounding (Adaround)</span></a> (if enabled)</p></li>
<li><p><a class="reference internal" href="mixed%20precision/amp.html#featureguide-amp"><span class="std std-ref">Automatic Mixed Precision (AMP)</span></a> (if enabled)</p></li>
</ol>
<p>These techniques are applied in a best-effort manner until the model meets the allowed accuracy drop.
If applying AutoQuant fails to satisfy the evaluation goal, AutoQuant returns the model that gave
the best results.</p>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">¶</a></h2>
<p>There are no special prerequisites to using AutoQuant. It can be applied to most models.</p>
<section id="procedure">
<h3>Procedure<a class="headerlink" href="#procedure" title="Link to this heading">¶</a></h3>
<section id="step-1">
<h4>Step 1<a class="headerlink" href="#step-1" title="Link to this heading">¶</a></h4>
<p>Load the model for automatic quantization.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-0">
PyTorch</label><div class="sd-tab-content docutils">
<div class="tab-heading docutils container">
<p>In the following code example, the model is MobileNetV2.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">mobilenet_v2</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-1">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="tab-heading docutils container">
<p>In the following code example, the model is MobileNetV2.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationDataType</span><span class="p">,</span> <span class="n">QuantScheme</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.quantsim_config.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_path_for_per_channel_config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.adaround_weight</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdaroundParameters</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.auto_quant_v2</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoQuantWithAutoMixedPrecision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">applications</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">preprocessing</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.applications</span><span class="w"> </span><span class="kn">import</span> <span class="n">mobilenet_v2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">applications</span><span class="o">.</span><span class="n">MobileNetV2</span><span class="p">()</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-2">
ONNX</label><div class="sd-tab-content docutils">
<p>AutoQuant is not supported in aimet-onnx</p>
</div>
</div>
</section>
<section id="step-2">
<h4>Step 2<a class="headerlink" href="#step-2" title="Link to this heading">¶</a></h4>
<p>Prepare the dataset.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-3">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">num_batches</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">labeled_data</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;imagenet-1k&#39;</span><span class="p">,</span> <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
<span class="n">labeled_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">labeled_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span>
    <span class="s1">&#39;ILSVRC/imagenet-1k&#39;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s1">&#39;validation&#39;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">transforms</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">examples</span>


<span class="n">dataset</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">EVAL_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">CALIBRATION_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">32</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CustomDataLoader</span><span class="p">(</span><span class="n">DataLoader</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">:</span>
            <span class="n">str_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_index</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_index</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch_index</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="n">str_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span>


<span class="n">unlabelled_data_loader</span> <span class="o">=</span> <span class="n">CustomDataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">CALIBRATION_DATASET_SIZE</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">unlabeled_data</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;imagenet-1k&#39;</span><span class="p">,</span> <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;unlabeled&quot;</span><span class="p">)</span>
<span class="n">unlabeled_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">unlabeled_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">num_batches</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>

</pre></div>
</div>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-4">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">imagenet_dataset</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">directory</span><span class="o">=</span><span class="s1">&#39;&lt;your_imagenet_validation_data_path&gt;&#39;</span><span class="p">,</span>
    <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">imagenet_dataset</span> <span class="o">=</span> <span class="n">imagenet_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">mobilenet_v2</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">NUM_CALIBRATION_SAMPLES</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">unlabeled_dataset</span> <span class="o">=</span> <span class="n">imagenet_dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">NUM_CALIBRATION_SAMPLES</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">x</span>
<span class="p">)</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">imagenet_dataset</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">NUM_CALIBRATION_SAMPLES</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-5">
ONNX</label><div class="sd-tab-content docutils">
<p>AutoQuant is not supported in aimet-onnx</p>
</div>
</div>
</section>
<section id="step-3">
<h4>Step 3<a class="headerlink" href="#step-3" title="Link to this heading">¶</a></h4>
<p>Prepare the evaluation callback.</p>
<p>For your model, implement the evaluation callback to serve your own goals, maintaining the function signature.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-6">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span>

<span class="k">def</span><span class="w"> </span><span class="nf">eval_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">num_of_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">data_loader</span> <span class="o">=</span> <span class="n">CustomDataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">EVAL_DATASET_SIZE</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">num_of_samples</span><span class="p">:</span>
        <span class="n">iterations</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_of_samples</span> <span class="o">/</span> <span class="n">data_loader</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">iterations</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
    <span class="n">batch_cntr</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">acc_top1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">input_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
        <span class="n">pred_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">acc_top1</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred_labels</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span>

        <span class="n">batch_cntr</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">batch_cntr</span> <span class="o">&gt;</span> <span class="n">iterations</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="n">acc_top1</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">acc_top1</span>

</pre></div>
</div>
</div>
<input id="sd-tab-item-7" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-7">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">eval_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="c1"># Model should be compiled before evaluation</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="o">.</span><span class="n">CategoricalAccuracy</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">acc</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-8" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-8">
ONNX</label><div class="sd-tab-content docutils">
<p>AutoQuant is not supported in aimet-onnx</p>
</div>
</div>
</section>
<section id="step-4">
<h4>Step 4<a class="headerlink" href="#step-4" title="Link to this heading">¶</a></h4>
<p>Create the AutoQuant object.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-9" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-9">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.auto_quant</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoQuantWithAutoMixedPrecision</span>

<span class="n">auto_quant</span> <span class="o">=</span> <span class="n">AutoQuantWithAutoMixedPrecision</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="n">unlabelled_data_loader</span><span class="p">,</span> <span class="n">eval_callback</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-10" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-10">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">auto_quant</span> <span class="o">=</span> <span class="n">AutoQuantWithAutoMixedPrecision</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">eval_callback</span><span class="p">,</span>
    <span class="n">unlabeled_dataset</span><span class="p">,</span>
    <span class="n">param_bw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">output_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf</span><span class="p">,</span>
    <span class="n">config_file</span><span class="o">=</span><span class="n">get_path_for_per_channel_config</span><span class="p">(),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-11" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-11">
ONNX</label><div class="sd-tab-content docutils">
<p>AutoQuant is not supported in aimet-onnx</p>
</div>
</div>
</section>
<section id="step-5">
<h4>Step 5<a class="headerlink" href="#step-5" title="Link to this heading">¶</a></h4>
<p>Set AdaRound parameters.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-12" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-12">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.adaround.adaround_weight</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdaroundParameters</span>

<span class="n">ADAROUND_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">adaround_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">iterations</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ADAROUND_DATASET_SIZE</span> <span class="o">/</span> <span class="n">BATCH_SIZE</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">adaround_params</span> <span class="o">=</span> <span class="n">AdaroundParameters</span><span class="p">(</span>
    <span class="n">adaround_data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">adaround_data_loader</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_adaround_params</span><span class="p">(</span><span class="n">adaround_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-13" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-13">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">adaround_params</span> <span class="o">=</span> <span class="n">AdaroundParameters</span><span class="p">(</span>
    <span class="n">unlabeled_dataset</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="n">NUM_CALIBRATION_SAMPLES</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
<span class="p">)</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_adaround_params</span><span class="p">(</span><span class="n">adaround_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-14" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-14">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">adaround_params</span> <span class="o">=</span> <span class="n">AdaroundParameters</span><span class="p">(</span>
    <span class="n">unlabeled_data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">unlabeled_data_loader</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_adaround_params</span><span class="p">(</span><span class="n">adaround_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-6">
<h4>Step 6<a class="headerlink" href="#step-6" title="Link to this heading">¶</a></h4>
<p>Set AMP parameters.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-15" name="sd-tab-set-5" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-15">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationDataType</span>

<span class="n">W8A8</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># A: int8</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># W: int8</span>
<span class="p">)</span>
<span class="n">W8A16</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># A: int16</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># W: int8</span>
<span class="p">)</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_mixed_precision_params</span><span class="p">(</span><span class="n">candidates</span><span class="o">=</span><span class="p">[</span><span class="n">W8A16</span><span class="p">,</span> <span class="n">W8A8</span><span class="p">])</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-16" name="sd-tab-set-5" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-16">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">W4A8</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># A: int8</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># W: int4</span>
<span class="p">)</span>
<span class="n">W8A8</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># A: int8</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># W: int8</span>
<span class="p">)</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_mixed_precision_params</span><span class="p">(</span><span class="n">candidates</span><span class="o">=</span><span class="p">[</span><span class="n">W4A8</span><span class="p">,</span> <span class="n">W8A8</span><span class="p">])</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-17" name="sd-tab-set-5" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-17">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">W4A8</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># A: int8</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># W: int4</span>
<span class="p">)</span>
<span class="n">W8A8</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># A: int8</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>  <span class="c1"># W: int8</span>
<span class="p">)</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_mixed_precision_params</span><span class="p">(</span><span class="n">candidates</span><span class="o">=</span><span class="p">[</span><span class="n">W4A8</span><span class="p">,</span> <span class="n">W8A8</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-7">
<h4>Step 7<a class="headerlink" href="#step-7" title="Link to this heading">¶</a></h4>
<p>Run AutoQuant.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-18" name="sd-tab-set-6" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-18">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span><span class="p">,</span> <span class="n">initial_accuracy</span> <span class="o">=</span> <span class="n">auto_quant</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimized_accuracy</span><span class="p">,</span> <span class="n">encoding_path</span><span class="p">,</span> <span class="n">pareto_front</span> <span class="o">=</span> <span class="n">auto_quant</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Quantized Accuracy (before optimization): </span><span class="si">{</span><span class="n">initial_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- Quantized Accuracy (after optimization):  </span><span class="si">{</span><span class="n">optimized_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-19" name="sd-tab-set-6" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-19">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span><span class="p">,</span> <span class="n">initial_accuracy</span> <span class="o">=</span> <span class="n">auto_quant</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimized_accuracy</span><span class="p">,</span> <span class="n">encoding_path</span><span class="p">,</span> <span class="n">pareto_front</span> <span class="o">=</span> <span class="n">auto_quant</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
    <span class="n">allowed_accuracy_drop</span><span class="o">=</span><span class="mf">0.01</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Quantized Accuracy (before optimization): </span><span class="si">{</span><span class="n">initial_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Quantized Accuracy (after optimization):  </span><span class="si">{</span><span class="n">optimized_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>- Quantized Accuracy (before optimization): 0.0235
- Quantized Accuracy (after optimization):  0.7164
</pre></div>
</div>
</div>
<input id="sd-tab-item-20" name="sd-tab-set-6" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-20">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span><span class="p">,</span> <span class="n">initial_accuracy</span> <span class="o">=</span> <span class="n">auto_quant</span><span class="o">.</span><span class="n">run_inference</span><span class="p">()</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimized_accuracy</span><span class="p">,</span> <span class="n">encoding_path</span><span class="p">,</span> <span class="n">pareto_front</span> <span class="o">=</span> <span class="n">auto_quant</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
    <span class="n">allowed_accuracy_drop</span><span class="o">=</span><span class="mf">0.01</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Quantized Accuracy (before optimization): </span><span class="si">{</span><span class="n">initial_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;- Quantized Accuracy (after optimization):  </span><span class="si">{</span><span class="n">optimized_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="script-output highlight-none notranslate"><div class="highlight"><pre><span></span>- Quantized Accuracy (before optimization): 0.0235
- Quantized Accuracy (after optimization):  0.7164
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="api">
<h2>API<a class="headerlink" href="#api" title="Link to this heading">¶</a></h2>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-21" name="sd-tab-set-7" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-21">
PyTorch</label><div class="sd-tab-content docutils">
<p><strong>Top-level API</strong></p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.auto_quant.</span></span><span class="sig-name descname"><span class="pre">AutoQuantWithAutoMixedPrecision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quant_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">QuantScheme.post_training_tf_enhanced</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/tmp'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_prepare_required</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Integrate and apply post-training quantization techniques.</p>
<p>AutoQuant includes 1) batchnorm folding, 2) cross-layer equalization,
3) Adaround, and 4) Automatic Mixed Precision (if enabled).
These techniques will be applied in a best-effort manner until the model
meets the evaluation goal given as allowed_accuracy_drop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></span>) – Model to be quantized. Assumes model is on the correct device</p></li>
<li><p><strong>dummy_input</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</span>) – Dummy input for the model. Assumes that dummy_input is on the correct device</p></li>
<li><p><strong>data_loader</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></span>) – A collection that iterates over an unlabeled dataset, used for computing encodings</p></li>
<li><p><strong>eval_callback</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – Function that calculates the evaluation score</p></li>
<li><p><strong>param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Parameter bitwidth</p></li>
<li><p><strong>output_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Output bitwidth</p></li>
<li><p><strong>quant_scheme</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../apiref/torch/v1/quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a></span>) – Quantization scheme</p></li>
<li><p><strong>rounding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Rounding mode</p></li>
<li><p><strong>config_file</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Path to configuration file for model quantizers</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results of PTQ techniques</p></li>
<li><p><strong>cache_id</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – ID associated with cache results</p></li>
<li><p><strong>strict_validation</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Flag set to True by default.hen False, AutoQuant will proceed with execution and handle errors internally if possible. This may produce unideal or unintuitive results.</p></li>
<li><p><strong>model_prepare_required</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Flag set to True by default.If False, AutoQuant will skip model prepare block in the pipeline.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">run_inference</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.run_inference"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Creates a quantization model and performs inference</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<a class="reference internal" href="../apiref/torch/quantsim.html#aimet_torch.QuantizationSimModel" title="aimet_torch.v2.quantsim.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>QuantizationSimModel, model accuracy as float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">optimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowed_accuracy_drop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.optimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Integrate and apply post-training quantization techniques.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>allowed_accuracy_drop</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Maximum allowed accuracy drop</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <a class="reference internal" href="mixed%20precision/amp.html#aimet_torch.amp.quantizer_groups.QuantizerGroup" title="aimet_torch._base.amp.quantizer_groups.QuantizerGroup"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of  (best model, eval score, encoding path, pareto front).
Pareto front is None if AMP is not enabled or AutoQuant exits
without performing AMP.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_adaround_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adaround_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.set_adaround_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Set Adaround parameters.
If this method is not called explicitly by the user, AutoQuant will use
<cite>data_loader</cite> (passed to <cite>__init__</cite>) for Adaround.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>adaround_params</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters" title="aimet_torch._base.adaround.adaround_weight.AdaroundParameters"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></span>) – Adaround parameters.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_export_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">onnx_export_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">propagate_encodings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.set_export_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Set parameters for QuantizationSimModel.export.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onnx_export_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">OnnxExportApiArgs</span></code></span>) – optional export argument with onnx specific overrides
if not provide export via torchscript graph</p></li>
<li><p><strong>propagate_encodings</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>]</span>) – If True, encoding entries for intermediate ops
(when one PyTorch ops results in multiple ONNX nodes) are filled with
the same BW and data_type as the output tensor for that series of ops.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_mixed_precision_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples_for_phase_1=128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn=&lt;function</span> <span class="pre">_default_forward_fn&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples_for_phase_2=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.set_mixed_precision_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Set mixed precision parameters.
NOTE: Automatic mixed precision will NOT be enabled unless this method
is explicitly called by the user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]]</span>) – List of tuples of candidate bitwidths and datatypes.</p></li>
<li><p><strong>num_samples_for_phase_1</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Number of samples to be used for performance
evaluation in AMP phase 1.</p></li>
<li><p><strong>forward_fn</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – Function that runs forward pass and returns the output tensor.
which will be used for SQNR compuatation in phase 1.
This function is expected to take 1) a model and 2) a single batch
yielded from the data loader, and return a single torch.Tensor object
which represents the output of the model.
The default forward function is roughly equivalent to
<code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">model,</span> <span class="pre">batch:</span> <span class="pre">model(batch)</span></code></p></li>
<li><p><strong>num_samples_for_phase_2</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Number of samples to be used for performance
evaluation in AMP phase 2.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_model_preparer_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">modules_to_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concrete_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.set_model_preparer_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Set parameters for model preparer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>modules_to_exclude</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</span>) – List of modules to exclude when tracing.</p></li>
<li><p><strong>concrete_args</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code>]]</span>) – Parameter for model preparer. Allows you to partially specialize
your function, whether it’s to remove control flow or data structures. If the
model has control flow, torch.fx won’t be able to trace the model. Check
torch.fx.symbolic_trace API in detail.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_quant_scheme_candidates</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.get_quant_scheme_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Return the candidates for quant scheme search.
During <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimize()</span></code>, the candidate with the highest accuracy
will be selected among them.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantSchemePair</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code>]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Candidates for quant scheme search</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_quant_scheme_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/v2/auto_quant.html#AutoQuantWithAutoMixedPrecision.set_quant_scheme_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Set candidates for quant scheme search.
During <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimize()</span></code>, the candidate with the highest accuracy
will be selected among them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantSchemePair</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code>]</span>) – Candidates for quant scheme search</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<input id="sd-tab-item-22" name="sd-tab-set-7" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-22">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>Top-level API</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_tensorflow.keras.auto_quant_v2.</span></span><span class="sig-name descname"><span class="pre">AutoQuantWithAutoMixedPrecision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quant_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">QuantScheme.post_training_tf_enhanced</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/tmp'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict_validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision" title="Link to this definition">¶</a></dt>
<dd><p>Integrate and apply post-training quantization techniques.</p>
<p>AutoQuant includes 1) batchnorm folding, 2) cross-layer equalization,
3) Adaround, and 4) Automatic Mixed Precision (if enabled).
These techniques will be applied in a best-effort manner until the model
meets the evaluation goal given as allowed_accuracy_drop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></span>) – Model to be quantized. Assumes model is on the correct device</p></li>
<li><p><strong>eval_callback</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span>) – A function that maps model and the number samples
to the evaluation score. This callback is expected to return a
scalar value representing the model performance evaluated
against exactly <cite>N</cite> samples, where <cite>N</cite> is the number of samples
passed as the second argument of this callback.
NOTE: If <cite>N</cite> is None, the model is expected to be evaluated against
the whole evaluation dataset.</p></li>
<li><p><strong>dataset</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">DatasetV2</span></code></span>) – An unlabeled dataset for encoding computation.
By default, this dataset will be also used for Adaround unless
otherwise specified by <cite>self.set_adaround_params</cite></p></li>
<li><p><strong>param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Parameter bitwidth</p></li>
<li><p><strong>output_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Output bitwidth</p></li>
<li><p><strong>quant_scheme</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../apiref/torch/v1/quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a></span>) – Quantization scheme</p></li>
<li><p><strong>rounding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Rounding mode</p></li>
<li><p><strong>config_file</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Path to configuration file for model quantizers</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results of PTQ techniques</p></li>
<li><p><strong>cache_id</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – ID associated with cache results</p></li>
<li><p><strong>strict_validation</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code></span>) – Flag set to True by default.hen False, AutoQuant will proceed with execution and handle errors internally if possible. This may produce unideal or unintuitive results.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.run_inference">
<span class="sig-name descname"><span class="pre">run_inference</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision.run_inference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.run_inference" title="Link to this definition">¶</a></dt>
<dd><p>Creates a quantization model and performs inference</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<a class="reference internal" href="../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>QuantizationSimModel, model accuracy as float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.optimize">
<span class="sig-name descname"><span class="pre">optimize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">allowed_accuracy_drop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision.optimize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.optimize" title="Link to this definition">¶</a></dt>
<dd><p>Integrate and apply post-training quantization techniques.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>allowed_accuracy_drop</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></span>) – Maximum allowed accuracy drop</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <a class="reference internal" href="mixed%20precision/amp.html#aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup" title="aimet_tensorflow.keras.amp.quantizer_groups.QuantizerGroup"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizerGroup</span></code></a>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of  (best model, eval score, encoding path, pareto front).
Pareto front is None if AMP is not enabled or AutoQuant exits
without performing AMP.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_adaround_params">
<span class="sig-name descname"><span class="pre">set_adaround_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adaround_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision.set_adaround_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_adaround_params" title="Link to this definition">¶</a></dt>
<dd><p>Set Adaround parameters.
If this method is not called explicitly by the user, AutoQuant will use
<cite>dataset</cite> (passed to <cite>__init__</cite>) for Adaround.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>adaround_params</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="adaround.html#aimet_tensorflow.keras.adaround_weight.AdaroundParameters" title="aimet_tensorflow.keras.adaround_weight.AdaroundParameters"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a></span>) – Adaround parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_mixed_precision_params">
<span class="sig-name descname"><span class="pre">set_mixed_precision_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples_for_phase_1=128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn=&lt;function</span> <span class="pre">_default_forward_fn&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples_for_phase_2=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision.set_mixed_precision_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_mixed_precision_params" title="Link to this definition">¶</a></dt>
<dd><p>Set mixed precision parameters.
NOTE: Automatic mixed precision will NOT be enabled unless this method
is explicitly called by the user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>], <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationDataType</span></code>]]]</span>) – List of tuples of candidate bitwidths and datatypes.</p></li>
<li><p><strong>num_samples_for_phase_1</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Number of samples to be used for performance
evaluation in AMP phase 1.</p></li>
<li><p><strong>forward_fn</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – Function that runs forward pass and returns the output tensor.
which will be used for SQNR compuatation in phase 1.
This function is expected to take 1) a model and 2) a single batch
yielded from the dataset, and return a single torch.Tensor object
which represents the output of the model.</p></li>
<li><p><strong>num_samples_for_phase_2</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]</span>) – Number of samples to be used for performance
evaluation in AMP phase 2.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.get_quant_scheme_candidates">
<span class="sig-name descname"><span class="pre">get_quant_scheme_candidates</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision.get_quant_scheme_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.get_quant_scheme_candidates" title="Link to this definition">¶</a></dt>
<dd><p>Return the candidates for quant scheme search.
During <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimize()</span></code>, the candidate with the highest accuracy
will be selected among them.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantSchemePair</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code>]</span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Candidates for quant scheme search</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_quant_scheme_candidates">
<span class="sig-name descname"><span class="pre">set_quant_scheme_candidates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">candidates</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_tensorflow/keras/auto_quant_v2.html#AutoQuantWithAutoMixedPrecision.set_quant_scheme_candidates"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_quant_scheme_candidates" title="Link to this definition">¶</a></dt>
<dd><p>Set candidates for quant scheme search.
During <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimize()</span></code>, the candidate with the highest accuracy
will be selected among them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>candidates</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantSchemePair</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">...</span></code>]</span>) – Candidates for quant scheme search</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<input id="sd-tab-item-23" name="sd-tab-set-7" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-23">
ONNX</label><div class="sd-tab-content docutils">
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="bn.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Batch norm re-estimation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="mixed%20precision/amp.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Automatic mixed precision</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Qualcomm Innovation Center, Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/quic/aimet" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Automatic quantization</a><ul>
<li><a class="reference internal" href="#context">Context</a></li>
<li><a class="reference internal" href="#workflow">Workflow</a></li>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a><ul>
<li><a class="reference internal" href="#procedure">Procedure</a><ul>
<li><a class="reference internal" href="#step-1">Step 1</a></li>
<li><a class="reference internal" href="#step-2">Step 2</a></li>
<li><a class="reference internal" href="#step-3">Step 3</a></li>
<li><a class="reference internal" href="#step-4">Step 4</a></li>
<li><a class="reference internal" href="#step-5">Step 5</a></li>
<li><a class="reference internal" href="#step-6">Step 6</a></li>
<li><a class="reference internal" href="#step-7">Step 7</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#api">API</a><ul>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision</span></code></a><ul>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.run_inference"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision.run_inference()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.optimize"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision.optimize()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_adaround_params"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision.set_adaround_params()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_mixed_precision_params"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision.set_mixed_precision_params()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.get_quant_scheme_candidates"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision.get_quant_scheme_candidates()</span></code></a></li>
<li><a class="reference internal" href="#aimet_tensorflow.keras.auto_quant_v2.AutoQuantWithAutoMixedPrecision.set_quant_scheme_candidates"><code class="docutils literal notranslate"><span class="pre">AutoQuantWithAutoMixedPrecision.set_quant_scheme_candidates()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=8a448e45"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>