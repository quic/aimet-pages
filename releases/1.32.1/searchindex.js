Search.setIndex({"docnames": ["Examples/onnx/quantization/adaround", "Examples/onnx/quantization/cle", "Examples/onnx/quantization/quantsim", "Examples/tensorflow/compression/channel_pruning", "Examples/tensorflow/compression/spatial_svd", "Examples/tensorflow/compression/spatial_svd_channel_pruning", "Examples/tensorflow/quantization/adaround", "Examples/tensorflow/quantization/autoquant", "Examples/tensorflow/quantization/bn_reestimation", "Examples/tensorflow/quantization/cle_bc", "Examples/tensorflow/quantization/keras/adaround", "Examples/tensorflow/quantization/keras/autoquant", "Examples/tensorflow/quantization/keras/bn_reestimation", "Examples/tensorflow/quantization/keras/keras_transformer_qat", "Examples/tensorflow/quantization/keras/model_preparer", "Examples/tensorflow/quantization/keras/qat", "Examples/tensorflow/quantization/keras/qat_range_learning", "Examples/tensorflow/quantization/keras/quant_analyzer", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq", "Examples/tensorflow/quantization/keras/quantsim_cle", "Examples/tensorflow/quantization/qat", "Examples/tensorflow/quantization/qat_range_learning", "Examples/tensorflow/quantization/quant_analyzer", "Examples/torch/compression/channel_pruning", "Examples/torch/compression/spatial_svd", "Examples/torch/compression/spatial_svd_channel_pruning", "Examples/torch/quantization/adaround", "Examples/torch/quantization/autoquant", "Examples/torch/quantization/bn_reestimation", "Examples/torch/quantization/cle_bc", "Examples/torch/quantization/qat", "Examples/torch/quantization/qat_range_learning", "Examples/torch/quantization/quant_analyzer", "api_docs/convert_tf_sess_to_keras", "api_docs/index", "api_docs/keras", "api_docs/keras_adaround", "api_docs/keras_batchnorm_re_estimation", "api_docs/keras_compression", "api_docs/keras_cross_layer_equalization", "api_docs/keras_layer_output_generation", "api_docs/keras_model_guidelines", "api_docs/keras_model_preparer", "api_docs/keras_primitive_apis_cle", "api_docs/keras_quant_analyzer", "api_docs/keras_quantization", "api_docs/keras_quantsim", "api_docs/onnx", "api_docs/onnx_adaround", "api_docs/onnx_auto_quant", "api_docs/onnx_cross_layer_equalization", "api_docs/onnx_layer_output_generation", "api_docs/onnx_quant_analyzer", "api_docs/onnx_quantization", "api_docs/onnx_quantsim", "api_docs/quantization_encoding_specification", "api_docs/tensorflow", "api_docs/tensorflow_adaround", "api_docs/tensorflow_auto_quant", "api_docs/tensorflow_batchnorm_re_estimation", "api_docs/tensorflow_bias_correction", "api_docs/tensorflow_compress", "api_docs/tensorflow_cross_layer_equalization", "api_docs/tensorflow_layer_output_generation", "api_docs/tensorflow_model_guidelines", "api_docs/tensorflow_primitive_apis_cle", "api_docs/tensorflow_quant_analyzer", "api_docs/tensorflow_quantization", "api_docs/tensorflow_quantsim", "api_docs/tensorflow_visualization_quantization", "api_docs/torch", "api_docs/torch_adaround", "api_docs/torch_architecture_checker", "api_docs/torch_auto_quant", "api_docs/torch_batchnorm_re_estimation", "api_docs/torch_bias_correction", "api_docs/torch_compress", "api_docs/torch_cross_layer_equalization", "api_docs/torch_layer_output_generation", "api_docs/torch_model_guidelines", "api_docs/torch_model_preparer", "api_docs/torch_model_validator", "api_docs/torch_multi_gpu", "api_docs/torch_primitive_apis_cle", "api_docs/torch_quant_analyzer", "api_docs/torch_quantization", "api_docs/torch_quantsim", "api_docs/torch_visualization_compression", "api_docs/torch_visualization_quantization", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/examples", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["Examples/onnx/quantization/adaround.ipynb", "Examples/onnx/quantization/cle.ipynb", "Examples/onnx/quantization/quantsim.ipynb", "Examples/tensorflow/compression/channel_pruning.ipynb", "Examples/tensorflow/compression/spatial_svd.ipynb", "Examples/tensorflow/compression/spatial_svd_channel_pruning.ipynb", "Examples/tensorflow/quantization/adaround.ipynb", "Examples/tensorflow/quantization/autoquant.ipynb", "Examples/tensorflow/quantization/bn_reestimation.ipynb", "Examples/tensorflow/quantization/cle_bc.ipynb", "Examples/tensorflow/quantization/keras/adaround.ipynb", "Examples/tensorflow/quantization/keras/autoquant.ipynb", "Examples/tensorflow/quantization/keras/bn_reestimation.ipynb", "Examples/tensorflow/quantization/keras/keras_transformer_qat.ipynb", "Examples/tensorflow/quantization/keras/model_preparer.ipynb", "Examples/tensorflow/quantization/keras/qat.ipynb", "Examples/tensorflow/quantization/keras/qat_range_learning.ipynb", "Examples/tensorflow/quantization/keras/quant_analyzer.ipynb", "Examples/tensorflow/quantization/keras/quantsim_adaround_pcq.ipynb", "Examples/tensorflow/quantization/keras/quantsim_cle.ipynb", "Examples/tensorflow/quantization/qat.ipynb", "Examples/tensorflow/quantization/qat_range_learning.ipynb", "Examples/tensorflow/quantization/quant_analyzer.ipynb", "Examples/torch/compression/channel_pruning.ipynb", "Examples/torch/compression/spatial_svd.ipynb", "Examples/torch/compression/spatial_svd_channel_pruning.ipynb", "Examples/torch/quantization/adaround.ipynb", "Examples/torch/quantization/autoquant.ipynb", "Examples/torch/quantization/bn_reestimation.ipynb", "Examples/torch/quantization/cle_bc.ipynb", "Examples/torch/quantization/qat.ipynb", "Examples/torch/quantization/qat_range_learning.ipynb", "Examples/torch/quantization/quant_analyzer.ipynb", "api_docs/convert_tf_sess_to_keras.rst", "api_docs/index.rst", "api_docs/keras.rst", "api_docs/keras_adaround.rst", "api_docs/keras_batchnorm_re_estimation.rst", "api_docs/keras_compression.rst", "api_docs/keras_cross_layer_equalization.rst", "api_docs/keras_layer_output_generation.rst", "api_docs/keras_model_guidelines.rst", "api_docs/keras_model_preparer.rst", "api_docs/keras_primitive_apis_cle.rst", "api_docs/keras_quant_analyzer.rst", "api_docs/keras_quantization.rst", "api_docs/keras_quantsim.rst", "api_docs/onnx.rst", "api_docs/onnx_adaround.rst", "api_docs/onnx_auto_quant.rst", "api_docs/onnx_cross_layer_equalization.rst", "api_docs/onnx_layer_output_generation.rst", "api_docs/onnx_quant_analyzer.rst", "api_docs/onnx_quantization.rst", "api_docs/onnx_quantsim.rst", "api_docs/quantization_encoding_specification.rst", "api_docs/tensorflow.rst", "api_docs/tensorflow_adaround.rst", "api_docs/tensorflow_auto_quant.rst", "api_docs/tensorflow_batchnorm_re_estimation.rst", "api_docs/tensorflow_bias_correction.rst", "api_docs/tensorflow_compress.rst", "api_docs/tensorflow_cross_layer_equalization.rst", "api_docs/tensorflow_layer_output_generation.rst", "api_docs/tensorflow_model_guidelines.rst", "api_docs/tensorflow_primitive_apis_cle.rst", "api_docs/tensorflow_quant_analyzer.rst", "api_docs/tensorflow_quantization.rst", "api_docs/tensorflow_quantsim.rst", "api_docs/tensorflow_visualization_quantization.rst", "api_docs/torch.rst", "api_docs/torch_adaround.rst", "api_docs/torch_architecture_checker.rst", "api_docs/torch_auto_quant.rst", "api_docs/torch_batchnorm_re_estimation.rst", "api_docs/torch_bias_correction.rst", "api_docs/torch_compress.rst", "api_docs/torch_cross_layer_equalization.rst", "api_docs/torch_layer_output_generation.rst", "api_docs/torch_model_guidelines.rst", "api_docs/torch_model_preparer.rst", "api_docs/torch_model_validator.rst", "api_docs/torch_multi_gpu.rst", "api_docs/torch_primitive_apis_cle.rst", "api_docs/torch_quant_analyzer.rst", "api_docs/torch_quantization.rst", "api_docs/torch_quantsim.rst", "api_docs/torch_visualization_compression.rst", "api_docs/torch_visualization_quantization.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/examples.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["Adaptive Rounding (AdaRound)", "Cross-Layer Equalization (CLE)", "Quantization Simulation", "Model Compression Using Channel Pruning", "Model compression Using Spatial SVD", "Model Compression Using Spatial SVD Followed by Channel Pruning", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Adaptive Rounding (Adaround)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Quantization-Aware Training with a Keras Transformer Model", "Keras Model Preparer", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Quantsim and Adaround - Per Channel Quantization (PCQ)", "Cross-Layer Equalization (CLE) with QuantSim", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Model compression using Channel Pruning", "Model compression using Spatial SVD", "Model compression using Spatial SVD followed by Channel Pruning", "Adaptive Rounding (AdaRound)", "AutoQuant", "Quantization-Aware Training with BatchNorm Re-estimation", "Cross-Layer Equalization (CLE) and Bias Correction (BC)", "Quantization-Aware Training", "Quantization-Aware Training with Range Learning", "Quant Analyzer", "Using AIMET Tensorflow APIs with Keras Models", "Welcome to AI Model Efficiency Toolkit API Docs!", "AIMET Keras APIs", "AIMET Keras AdaRound API", "AIMET Keras BatchNorm Re-estimation APIs", "AIMET Keras Compression API", "AIMET Keras Cross Layer Equalization APIs", "AIMET Keras Layer Output Generation API", "Keras Model Guidelines", "Model Preparer API", "AIMET Keras Cross Layer Equalization Primitive API", "AIMET Keras Quant Analyzer API", "AIMET Keras Quantization APIs", "AIMET Keras Quantization SIM API", "AIMET ONNX APIs", "AIMET ONNX AdaRound API", "AIMET ONNX AutoQuant API", "AIMET ONNX Cross Layer Equalization APIs", "AIMET ONNX Layer Output Generation API", "AIMET ONNX Quant Analyzer API", "AIMET ONNX Quantization APIs", "AIMET ONNX Quantization SIM API", "Encoding Format Specification", "AIMET TensorFlow APIs", "AIMET TensorFlow AdaRound API", "AIMET TensorFlow AutoQuant API", "AIMET TensorFlow BatchNorm Re-estimation APIs", "AIMET TensorFlow Bias Correction API", "AIMET TensorFlow Compression API", "AIMET TensorFlow Cross Layer Equalization APIs", "AIMET Tensorflow Layer Output Generation API", "TensorFlow Model Guidelines", "AIMET TensorFlow Cross Layer Equalization Primitive API", "AIMET Tensorflow Quant Analyzer API", "AIMET TensorFlow Quantization APIs", "AIMET TensorFlow Quantization SIM API", "AIMET Visualization for Quantization for TensorFlow API", "AIMET PyTorch APIs", "AIMET PyTorch AdaRound API", "Architecture Checker API", "AIMET PyTorch AutoQuant API", "AIMET PyTorch BatchNorm Re-estimation APIs", "AIMET PyTorch Bias Correction API", "AIMET PyTorch Compression API", "AIMET PyTorch Cross Layer Equalization APIs", "AIMET PyTorch Layer Output Generation API", "PyTorch Model Guidelines", "Model Preparer API", "Model Validator Utility", "PyTorch Multi-GPU support", "AIMET PyTorch Cross Layer Equalization Primitive API", "AIMET PyTorch Quant Analyzer API", "AIMET PyTorch Quantization APIs", "AIMET PyTorch Quantization SIM API", "AIMET Visualization Compression API", "AIMET Visualization for Quantization API", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Examples", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"show": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48, 57, 58, 59, 62, 68, 69, 71, 72, 73, 74, 77, 81, 84, 86, 88, 100, 105, 109], "work": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 46, 48, 54, 59, 66, 68, 71, 81, 82, 86, 95, 98, 102, 103, 105, 108], "code": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 93], "how": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48, 54, 55, 57, 58, 59, 62, 68, 71, 72, 73, 74, 75, 77, 81, 84, 86, 98, 102, 105, 106, 109, 110], "us": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 91, 95, 96, 97, 98, 99, 100, 103, 105, 106, 107, 108, 109, 110, 111, 114], "aimet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 41, 42, 55, 64, 72, 79, 80, 81, 82, 100, 103, 108], "perform": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 17, 18, 19, 22, 23, 24, 25, 26, 29, 32, 33, 36, 37, 39, 44, 48, 50, 52, 55, 57, 58, 59, 60, 61, 62, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 88, 94, 95, 96, 97, 99, 102, 104, 105, 106, 107, 109], "featur": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 41, 42, 43, 45, 50, 55, 64, 65, 71, 77, 79, 80, 81, 82, 83, 85, 86, 93, 94, 95, 98, 102, 105, 106, 110, 111, 113, 114], "typic": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 58, 71, 86, 97, 104, 106, 107, 108, 110, 113], "nearest": [0, 1, 6, 9, 10, 13, 15, 16, 18, 19, 26, 29, 44, 46, 54, 58, 60, 66, 68, 73, 75, 86, 93], "techniqu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 38, 39, 45, 48, 49, 50, 53, 57, 58, 60, 61, 62, 67, 71, 73, 75, 76, 77, 84, 85, 93, 94, 96, 97, 100, 104, 106, 107, 109, 110, 111, 112, 115], "achiev": [0, 3, 4, 5, 6, 7, 8, 10, 16, 18, 23, 24, 25, 26, 27, 38, 61, 76, 90, 93, 97, 99, 112, 115], "when": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 46, 50, 55, 61, 64, 66, 73, 76, 77, 79, 80, 84, 85, 86, 93, 100, 102, 104, 105, 106, 107, 108, 109, 110, 113, 114, 116], "weight": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 38, 42, 43, 44, 45, 46, 52, 53, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 71, 75, 81, 83, 84, 85, 86, 88, 93, 95, 97, 102, 104, 105, 106, 107, 108, 109, 110, 114], "valu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 52, 55, 57, 58, 61, 65, 66, 71, 75, 76, 78, 80, 83, 84, 86, 93, 99, 102, 104, 105, 106, 107, 110, 112, 114, 115], "integ": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 84, 86, 93, 104, 106], "optim": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 44, 45, 46, 49, 53, 54, 57, 61, 67, 71, 72, 73, 76, 85, 86, 87, 88, 93, 94, 100, 102, 104, 107, 110, 111, 113], "loss": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 36, 44, 46, 52, 57, 66, 71, 84, 86, 93, 100, 104, 106, 110], "function": [0, 1, 3, 4, 5, 6, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 93, 99, 102, 103, 104, 106, 110, 111, 113, 114], "unlabel": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 49, 52, 54, 58, 66, 68, 71, 73, 84, 86, 93, 104, 106, 110], "data": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 43, 44, 46, 48, 49, 52, 54, 57, 58, 61, 65, 66, 68, 71, 73, 74, 75, 76, 80, 82, 84, 86, 87, 93, 95, 101, 104, 105, 106, 107, 109, 110], "decid": [0, 1, 2, 6, 10, 18, 23, 24, 25, 26, 29, 30, 31, 32, 93, 113], "whether": [0, 1, 2, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 45, 51, 61, 63, 73, 78, 80, 81, 85, 93, 107], "specif": [0, 6, 7, 8, 10, 11, 12, 14, 18, 20, 21, 26, 28, 30, 31, 38, 42, 46, 60, 61, 68, 73, 76, 86, 93, 94, 95, 97, 100, 102, 103, 104, 105, 108, 111], "closer": [0, 6, 10, 18, 26, 93], "farther": [0, 6, 26], "one": [0, 3, 4, 5, 6, 9, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31, 32, 43, 55, 60, 61, 64, 65, 68, 71, 72, 73, 80, 81, 83, 86, 90, 96, 98, 102, 107, 108, 111, 112, 115], "abl": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 42, 73, 80, 81, 84, 93, 113, 114], "while": [0, 1, 3, 4, 5, 6, 9, 10, 13, 16, 18, 19, 23, 24, 25, 26, 29, 38, 58, 61, 71, 76, 93, 99, 103, 104, 107, 109, 110, 113], "low": [0, 3, 4, 5, 6, 9, 10, 18, 23, 25, 26, 29, 93, 95, 102, 104, 105, 109], "bit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 55, 68, 71, 84, 89, 93, 95, 104, 109, 110, 111], "width": [0, 1, 2, 6, 10, 18, 26, 28, 29, 30, 31, 32, 55, 84, 93, 109, 110, 112, 115, 116], "cover": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 86, 95, 108, 110], "follow": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 50, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 110, 112, 115, 116], "instanti": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 79, 82, 107, 113], "fake": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 71, 86], "op": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 33, 38, 43, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 81, 86, 104, 108, 111], "insert": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 71, 80, 86, 104, 110], "simuat": [0, 1, 6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31], "get": [0, 1, 2, 3, 4, 5, 7, 12, 13, 14, 15, 16, 17, 23, 24, 25, 33, 38, 40, 43, 51, 60, 61, 62, 63, 65, 68, 69, 72, 76, 78, 80, 86, 88, 89, 90, 91, 93, 96, 104, 114], "score": [0, 1, 2, 8, 12, 15, 16, 27, 28, 38, 58, 61, 71, 73, 76, 84, 87, 99, 102, 113], "post": [0, 1, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31, 45, 53, 54, 55, 58, 67, 68, 73, 85, 93, 94, 100, 102, 107, 110, 111], "finetun": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 54, 59, 68, 86], "design": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 81, 105], "state": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 64, 102], "art": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "result": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 42, 44, 58, 61, 66, 71, 73, 76, 84, 86, 93, 94, 96, 97, 100, 105, 106, 107, 108, 110], "For": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 51, 52, 54, 57, 58, 59, 61, 62, 63, 68, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 84, 86, 88, 89, 90, 91, 93, 96, 97, 98, 99, 100, 101, 102, 104, 106, 108, 110, 113, 116], "rel": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 38, 61, 69, 76, 88, 97, 104, 109, 114], "friendli": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 94, 104, 105], "like": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 39, 42, 43, 62, 71, 77, 83, 86, 100, 102, 104, 106, 107, 108, 113], "resnet18": [0, 1, 2, 7, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 59, 71, 73, 74, 77, 83, 84, 86, 87, 88], "also": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 44, 46, 52, 55, 57, 58, 60, 66, 68, 71, 79, 80, 84, 86, 96, 97, 98, 99, 104, 106, 108, 109, 110, 111, 113, 114, 116], "some": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 38, 42, 43, 45, 46, 61, 65, 68, 71, 76, 80, 83, 85, 86, 88, 93, 97, 99, 102, 103, 104, 105, 107, 109, 110], "paramet": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 40, 42, 43, 44, 45, 46, 52, 53, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 93, 95, 96, 102, 103, 104, 105, 106, 107, 108, 114], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 51, 52, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 93, 94, 95, 96, 97, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 116], "deliber": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "chosen": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 98, 102], "have": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 50, 52, 55, 61, 65, 66, 71, 72, 77, 78, 80, 81, 84, 86, 88, 91, 99, 102, 104, 105, 106, 109, 110], "execut": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 73, 80, 87, 98, 99, 113], "more": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 43, 44, 46, 48, 49, 50, 52, 55, 57, 58, 60, 61, 62, 65, 66, 68, 71, 72, 73, 75, 76, 77, 81, 83, 84, 86, 89, 96, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 113, 114], "quickli": [0, 1, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 99], "reli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "imagenet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 54, 58, 59, 60, 62, 65, 68, 69, 71, 74, 75, 86, 98], "task": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 113, 114], "imag": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 58, 66, 73, 75, 84, 89, 93, 98, 106], "classif": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 102], "If": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 41, 42, 43, 46, 55, 57, 58, 60, 61, 62, 64, 65, 66, 68, 71, 73, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 94, 103, 104, 105, 106, 108, 109, 113, 114, 116], "you": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 58, 61, 64, 68, 71, 73, 76, 80, 82, 86, 90, 91, 98, 99, 103, 112, 115], "alreadi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 86, 90, 99, 109], "version": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 51, 71, 80, 86, 89, 90, 91, 98, 100], "readili": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "avail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 39, 62, 71, 80, 86, 89, 103, 106, 108, 109], "otherwis": [0, 6, 26, 58, 81, 86, 90, 91, 109], "download": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 89, 90, 91], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 87, 88, 89, 93, 96, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 113, 116], "appropri": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 71, 76, 83, 86, 89, 90, 91, 97, 98, 99, 102, 109], "locat": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 98], "e": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 45, 46, 52, 54, 55, 57, 66, 68, 71, 75, 84, 86, 95, 97, 100, 107, 109, 116], "g": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 71, 84, 86, 90, 95, 97, 100, 109, 116], "http": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 80, 89, 90, 91, 97, 98, 105, 111, 113], "net": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 98], "org": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 80, 90, 91, 98, 105], "challeng": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "lsvrc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "2012": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "index": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 73, 84, 97, 111], "php": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 98], "note1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "The": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 42, 43, 44, 46, 48, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 89, 91, 93, 94, 95, 96, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116], "dataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48, 49, 52, 54, 66, 68, 71, 73, 74, 84, 98, 106], "provid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 42, 43, 44, 45, 48, 53, 54, 55, 57, 58, 61, 66, 67, 68, 71, 72, 73, 81, 84, 85, 86, 87, 90, 91, 93, 97, 98, 99, 102, 104, 105, 106, 108, 109, 110, 113, 114, 116], "characterist": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "subfold": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "sampl": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 46, 52, 54, 55, 57, 58, 60, 61, 65, 66, 68, 71, 73, 75, 84, 86, 96, 104, 105, 106, 107, 110], "val": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "valid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 44, 52, 54, 61, 62, 65, 66, 68, 71, 75, 76, 84, 85, 86, 94, 104, 111], "pleas": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 44, 46, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 66, 68, 71, 73, 74, 75, 76, 77, 81, 84, 86, 89, 90, 91, 93, 96, 98, 100, 102, 106, 110], "see": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 39, 42, 46, 48, 49, 50, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 77, 84, 86, 96, 99, 100, 102, 104, 108, 109, 110, 112, 113, 114, 115], "descript": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 103], "detail": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 61, 71, 73, 80, 86, 96, 98, 99, 100, 102, 104, 109, 110, 113, 114], "A": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 38, 43, 44, 46, 52, 58, 61, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 86, 87, 88, 97, 104, 106, 107, 108, 109, 110], "subdirectori": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "per": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 44, 52, 55, 59, 61, 65, 66, 74, 76, 78, 84, 86, 95, 104, 105, 106, 108, 109, 110, 111], "class": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 40, 41, 42, 43, 44, 46, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 75, 76, 78, 79, 80, 81, 83, 84, 86, 87], "file": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 44, 46, 57, 58, 61, 64, 66, 68, 71, 72, 73, 75, 76, 84, 86, 87, 89, 90, 91, 104, 106, 107, 110, 111, 114], "each": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 43, 55, 57, 61, 65, 69, 71, 72, 75, 76, 81, 83, 84, 86, 87, 88, 89, 90, 91, 96, 97, 98, 99, 104, 105, 106, 107, 108, 109, 110, 114, 116], "note2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "To": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 42, 46, 48, 49, 50, 57, 58, 60, 61, 62, 68, 71, 73, 75, 76, 77, 84, 86, 89, 95, 98, 99, 102, 103, 106, 108, 109, 110, 113, 114], "speed": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 71, 76, 102, 105, 111], "up": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 44, 46, 52, 57, 61, 64, 66, 68, 71, 76, 84, 86, 91, 102, 107, 108, 110, 116], "mai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 55, 71, 73, 80, 86, 93, 97, 102, 104, 105, 106, 108, 109, 110], "reduc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 96, 102, 105, 109, 111, 116], "subset": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 44, 52, 60, 65, 66, 84, 93, 95, 106, 116], "entir": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 60, 61, 66, 76, 84, 99, 102], "ilsvrc2012": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "ha": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 43, 44, 50, 52, 57, 60, 64, 65, 66, 71, 72, 73, 76, 77, 80, 81, 83, 84, 86, 88, 97, 98, 99, 102, 105, 107, 110, 113, 116], "1000": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 52, 54, 58, 66, 68, 71, 73, 75, 76, 84, 86, 93, 105, 106], "50": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 61, 68, 76, 97], "But": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 80, 86, 93, 102], "purpos": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 86, 108], "run": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 42, 44, 45, 46, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 63, 66, 68, 72, 73, 74, 76, 78, 80, 81, 86, 90, 95, 100, 102, 104, 105, 106, 110, 111, 113], "could": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 44, 46, 52, 55, 57, 66, 68, 71, 79, 84, 86, 96, 116], "exercis": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "left": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 99, 116], "reader": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "necessari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 44, 52, 58, 61, 71, 73, 76, 84, 86, 113], "edit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 54, 55, 65, 68, 71, 86], "cell": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "below": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 39, 40, 41, 42, 43, 50, 51, 55, 60, 61, 62, 63, 65, 66, 71, 77, 78, 79, 90, 91, 94, 95, 104, 105, 108, 109, 110, 116], "specifi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 46, 55, 58, 61, 66, 68, 71, 76, 84, 86, 88, 90, 91, 94, 102, 108, 110, 114], "directori": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 40, 44, 58, 61, 63, 66, 69, 73, 76, 78, 84, 88, 98, 114], "where": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 46, 55, 57, 58, 61, 68, 71, 76, 79, 80, 86, 95, 99, 106, 107, 112, 115, 116], "save": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 43, 44, 46, 51, 57, 58, 61, 63, 64, 65, 66, 68, 69, 71, 73, 76, 78, 83, 84, 86, 88, 94, 110, 114], "dataset_dir": [0, 1, 2, 7, 9, 10, 11, 12, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38], "path": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 44, 46, 51, 57, 58, 61, 63, 66, 68, 71, 73, 75, 76, 78, 80, 84, 86, 87, 90, 91, 98], "replac": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 54, 59, 62, 65, 68, 71, 74, 75, 80, 83, 86, 90, 105, 110], "real": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 58, 73], "loop": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 80, 109], "doe": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 42, 44, 50, 52, 57, 61, 66, 76, 77, 79, 80, 84, 99, 101, 104, 109], "ani": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 41, 42, 43, 44, 45, 46, 52, 61, 65, 66, 68, 71, 73, 74, 76, 79, 80, 81, 83, 84, 85, 86, 90, 91, 93, 94, 98, 108, 111], "limit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 64, 101], "written": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 103, 104], "Not": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 82, 84, 93, 99], "realli": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 40, 42, 51, 52, 58, 59, 61, 63, 71, 72, 74, 75, 78, 80, 81, 84, 86, 88, 90, 91, 99, 102, 104, 105, 108, 109, 110, 114], "later": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 86, 89], "modifi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 43, 46, 51, 65, 80, 83, 86, 90, 91, 104, 110, 111, 116], "user": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 41, 42, 43, 44, 45, 52, 54, 55, 59, 61, 64, 65, 66, 74, 76, 79, 80, 82, 83, 85, 87, 88, 90, 93, 94, 97, 98, 102, 104, 106, 107, 108, 109, 110, 111, 113, 114], "quantizationsim": [0, 1, 2, 6, 7, 8, 9, 10, 11, 13, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 71, 82], "which": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 42, 43, 45, 51, 52, 55, 57, 60, 61, 63, 66, 68, 71, 72, 75, 76, 78, 80, 81, 83, 85, 86, 88, 93, 94, 95, 97, 99, 102, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115], "still": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 41, 104, 109], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 51, 52, 54, 55, 57, 60, 61, 62, 63, 65, 66, 68, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 94, 95, 97, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115], "place": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 46, 60, 62, 65, 66, 68, 71, 75, 77, 83, 86, 107, 108], "origin": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 42, 51, 61, 63, 68, 76, 78, 80, 86, 96, 97, 102, 104, 105, 106, 107, 110, 113], "do": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 42, 46, 68, 71, 80, 82, 88, 91, 102, 106, 110], "infer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 45, 46, 49, 52, 53, 54, 55, 57, 67, 68, 71, 73, 85, 86, 95, 97, 100, 105, 107, 110, 111], "put": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "interfac": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 89], "method": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 40, 46, 58, 61, 63, 64, 68, 73, 75, 78, 80, 86, 90, 91, 99, 102, 104, 109, 110], "should": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 46, 48, 49, 52, 54, 55, 58, 60, 61, 64, 66, 68, 71, 73, 76, 78, 79, 80, 84, 85, 86, 90, 91, 97, 102, 108, 113, 116], "your": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 49, 54, 59, 68, 71, 73, 74, 75, 80, 81, 86, 89, 90, 91, 98, 103], "exist": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 71, 86, 90, 104, 110], "routin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 71, 86], "import": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 86, 87, 88, 91, 95, 96, 109], "torch": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 98, 103, 111], "onnxruntim": [0, 1, 2, 49, 51, 52], "ort": [0, 1, 2, 49], "common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 58, 61, 68, 86, 90, 109, 114], "image_net_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59], "util": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 42, 43, 44, 46, 57, 58, 59, 60, 64, 65, 66, 68, 72, 73, 83, 86, 87, 95, 98, 104], "image_net_evalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 66], "imagenetevalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 66], "image_net_data_load": [0, 1, 2, 23, 25, 26, 28, 29, 30, 31, 32], "imagenetdataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32], "imagenetdatapipelin": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59, 71, 74, 75, 86], "staticmethod": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 80], "def": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 41, 42, 43, 44, 46, 48, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 87, 88], "get_val_dataload": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 71, 75, 86], "return": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 94, 99, 100, 106, 110], "data_load": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 48, 49, 54, 68, 71, 73, 75, 76, 86], "image_s": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 66, 73], "batch_siz": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 44, 49, 52, 54, 57, 58, 60, 61, 66, 68, 71, 73, 76, 84, 86], "is_train": [0, 1, 2, 23, 25, 26, 28, 29, 30, 31, 32], "fals": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 46, 51, 54, 55, 57, 58, 60, 61, 63, 64, 66, 68, 72, 73, 75, 76, 80, 81, 86, 103, 108], "num_work": [0, 1, 2, 23, 24, 25, 26, 28, 29, 30, 31, 32], "sess": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 38, 58, 59, 60, 61, 62, 65, 68, 69], "inferencesess": [0, 1, 2, 49, 51, 52], "float": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 44, 46, 49, 52, 55, 57, 58, 61, 66, 68, 71, 73, 75, 76, 84, 86, 104, 106, 109, 110, 114], "given": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 39, 43, 46, 55, 58, 60, 61, 62, 64, 65, 68, 69, 71, 73, 74, 76, 77, 83, 86, 94, 96, 99, 100, 102, 105, 112, 113, 115], "its": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 42, 69, 98, 100, 104, 106, 110, 116], "top": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 60, 96, 113], "param": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 38, 39, 43, 44, 46, 48, 49, 52, 54, 57, 60, 61, 65, 66, 68, 71, 73, 76, 84, 86, 87, 108], "iter": [0, 1, 2, 3, 4, 5, 6, 10, 11, 12, 18, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 38, 44, 49, 52, 57, 60, 61, 66, 71, 73, 76, 84, 93, 105], "none": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40, 42, 43, 44, 46, 48, 49, 51, 52, 54, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 87, 88, 91, 113], "go": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 42, 59, 71, 74, 86, 90, 91, 98, 113], "load": [0, 1, 2, 13, 33, 40, 43, 46, 51, 59, 60, 62, 63, 64, 65, 68, 69, 71, 74, 75, 76, 78, 80, 81, 86, 102], "pretrain": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 59, 71, 73, 74, 77, 83, 84, 86, 87, 88, 106, 107, 110], "torchvis": [0, 1, 2, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 73, 74, 77, 83, 84, 86, 87, 88], "similarli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 86, 109], "instead": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 71, 79, 80, 81, 86, 104, 105], "differ": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 38, 58, 61, 76, 80, 96, 98, 99, 102, 104, 105, 107, 108, 109, 110], "framework": [0, 1, 2, 34, 54, 100, 104, 108, 110], "altogeth": [0, 1, 2, 108], "input_shap": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 39, 41, 44, 49, 52, 54, 58, 59, 60, 61, 62, 65, 69, 71, 73, 75, 76, 77, 80, 83, 84, 86, 87], "224": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 44, 46, 49, 52, 54, 58, 59, 60, 61, 62, 65, 66, 69, 71, 73, 75, 77, 78, 83, 84, 86, 87, 88], "shape": [0, 1, 2, 12, 13, 14, 18, 26, 28, 29, 30, 31, 32, 33, 41, 42, 61, 72, 76, 77, 80, 81, 83, 106], "channel": [0, 1, 2, 9, 15, 16, 19, 24, 26, 28, 29, 30, 31, 32, 38, 55, 59, 69, 72, 74, 84, 88, 95, 97, 98, 99, 101, 102, 105, 106, 108, 109, 110, 111, 112, 114, 115, 116], "x": [0, 1, 2, 10, 13, 14, 17, 18, 22, 26, 28, 29, 30, 31, 32, 38, 41, 42, 46, 64, 68, 72, 79, 80, 81, 89, 97, 103, 106], "height": [0, 1, 2, 13, 26, 28, 29, 30, 31, 32, 112, 115, 116], "dummy_input": [0, 1, 2, 26, 27, 28, 29, 30, 31, 32, 37, 40, 49, 51, 52, 54, 71, 72, 73, 77, 78, 79, 83, 84, 86], "randn": [0, 1, 2, 27, 46, 49, 52, 54, 71, 73, 80, 81, 84, 86], "filenam": [0, 1, 2, 15, 16, 46, 57, 61, 68, 71, 86, 91], "resnet": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 38, 58, 59, 97], "18": [0, 1, 2], "pt_model": [0, 1, 2], "true": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 43, 46, 48, 55, 60, 61, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 80, 81, 83, 84, 86, 87, 88, 103, 108], "export": [0, 1, 2, 6, 9, 10, 13, 18, 20, 21, 26, 29, 30, 31, 40, 44, 46, 51, 52, 54, 55, 59, 63, 66, 68, 71, 73, 74, 78, 79, 84, 86, 90, 91, 95, 98, 100, 102, 103, 104, 107, 110, 111], "eval": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 44, 49, 52, 57, 58, 61, 66, 71, 73, 75, 76, 77, 80, 82, 83, 84, 86, 87, 88, 99, 102, 113], "export_param": [0, 1, 2], "do_constant_fold": [0, 1, 2], "input_nam": [0, 1, 2, 86], "input": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 33, 38, 40, 41, 42, 44, 49, 51, 52, 54, 58, 59, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 96, 102, 106, 108, 110, 112, 113, 115, 116], "output_nam": [0, 1, 2, 86], "output": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 38, 41, 42, 44, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 72, 73, 75, 79, 80, 81, 84, 85, 86, 88, 96, 102, 105, 106, 108, 110, 111, 112, 115, 116], "dynamic_ax": [0, 1, 2], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 42, 46, 49, 54, 57, 58, 61, 66, 68, 71, 72, 73, 75, 76, 80, 81, 83, 86, 87, 89, 90, 91, 93, 97, 99, 103, 108], "load_model": [0, 1, 2, 40], "cpu": [0, 1, 2, 3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 61, 71, 73, 74, 78, 80, 83, 86, 88, 89, 90, 91, 104, 111], "cuda": [0, 1, 2, 3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 73, 74, 75, 76, 84, 86, 87, 89, 91], "devic": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 40, 51, 63, 71, 73, 74, 75, 78, 80, 83, 86, 87, 88, 110], "environ": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 89, 98], "chang": [0, 1, 2, 3, 4, 5, 8, 9, 12, 13, 15, 16, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 45, 55, 71, 73, 79, 80, 85, 86, 88, 93, 102, 106, 107, 108, 110, 114, 116], "logic": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32, 111], "forc": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32], "placement": [0, 1, 2, 23, 24, 25, 26, 29, 30, 31, 32, 108], "need": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 40, 41, 42, 43, 46, 52, 55, 61, 63, 65, 71, 75, 76, 78, 82, 83, 84, 86, 90, 94, 97, 102, 104, 105, 106, 107, 108, 110, 111, 113, 114], "cudnn_conv_algo_search": [0, 1, 2], "fix": [0, 1, 2, 55, 81, 100, 104, 109, 110, 111], "default": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 42, 44, 46, 57, 58, 60, 61, 66, 68, 71, 73, 75, 76, 80, 84, 86, 91, 93, 99, 102, 108, 110, 111, 113], "avoid": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 46, 52, 71, 79, 84, 86, 97], "everi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 44, 52, 57, 63, 66, 71, 78, 84, 86, 99, 102, 107, 114], "cudaexecutionprovid": [0, 1, 2], "get_available_provid": [0, 1, 2], "cpuexecutionprovid": [0, 1, 2], "use_cuda": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 48, 51, 54, 57, 60, 61, 63, 66, 68, 71, 74, 76, 86], "els": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 43, 49, 74, 80, 81, 105], "let": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 71, 80, 86], "session": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 36, 38, 49, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 87], "point": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 42, 43, 44, 45, 52, 53, 55, 66, 67, 75, 83, 84, 85, 86, 100, 102, 104, 106, 109, 110, 114], "32": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 33, 36, 41, 42, 44, 49, 55, 57, 58, 61, 66, 71, 72, 80, 81, 90, 91, 109], "print": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 49, 61, 68, 71, 72, 73, 76, 80, 81, 86, 91, 104, 106], "befor": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 40, 41, 42, 43, 45, 49, 51, 60, 63, 64, 65, 71, 73, 78, 83, 85, 86, 88, 93, 94, 95, 102, 104, 107, 113, 114], "quantizationsimmodel": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 37, 40, 43, 46, 48, 51, 54, 57, 59, 63, 68, 71, 73, 74, 78, 84, 86, 93, 95], "batchnorm": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 39, 42, 43, 45, 50, 58, 62, 64, 65, 72, 73, 75, 77, 83, 88, 94, 105, 116], "bn": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 37, 43, 60, 62, 64, 65, 67, 75, 83, 85, 104, 111], "These": [0, 1, 2, 6, 9, 10, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 33, 36, 46, 57, 58, 68, 73, 86, 90, 91, 94, 95, 96, 97, 103, 104, 105, 106, 109, 110], "adjac": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 108], "convolut": [0, 1, 2, 3, 4, 5, 6, 9, 10, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 38, 42, 43, 61, 65, 72, 95, 97, 102, 109], "cannot": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 72, 80, 81], "thei": [0, 1, 2, 3, 4, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 43, 61, 65, 80, 83, 85, 108, 113], "why": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 109], "On": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 55, 89], "runtim": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 46, 54, 55, 61, 68, 71, 76, 86, 97, 100, 102, 104, 106, 108, 110, 111], "tflite": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "snapdragon": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "neural": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 94, 97, 100, 102, 104, 107, 109, 110, 115], "process": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 38, 40, 51, 61, 63, 68, 71, 78, 86, 87, 94, 100, 102, 104, 105, 110], "sdk": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 100], "etc": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 55, 61, 64, 71, 86, 90, 91, 97, 104], "practic": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86, 102], "so": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 44, 46, 52, 57, 61, 66, 68, 71, 76, 80, 81, 82, 84, 86, 91, 103, 106, 113], "sec": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "speedup": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "sinc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 54, 71, 86, 95, 97, 99, 110], "unnecessari": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 116], "perspect": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "mathemat": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 79], "equival": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 32, 71, 79, 86], "produc": [0, 1, 2, 6, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 55, 73, 80, 99, 106, 113], "same": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 40, 42, 51, 57, 63, 71, 73, 78, 80, 81, 84, 86, 95, 105, 108, 110, 114], "howev": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 41, 42, 61, 71, 76, 86, 104, 105, 107, 108, 110], "increas": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 23, 25, 26, 29, 30, 31, 38, 61, 76, 88, 99, 105, 108], "rang": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 26, 27, 28, 29, 30, 42, 44, 52, 59, 66, 68, 69, 71, 73, 74, 80, 84, 86, 88, 93, 95, 98, 99, 104, 105, 106, 107, 109, 110, 111, 114], "tensor": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 40, 42, 45, 46, 53, 54, 55, 57, 60, 66, 67, 68, 71, 72, 73, 76, 77, 78, 79, 80, 83, 84, 85, 86, 93, 96, 103, 104, 106, 108, 109, 110, 111, 112, 115], "neg": [0, 1, 2, 6, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "impact": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 99, 109], "especi": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 89, 104, 107, 109], "int8": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 107, 110, 114], "lower": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 99, 104, 109], "precis": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 55, 71, 104], "want": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 40, 43, 46, 51, 58, 63, 65, 66, 68, 71, 78, 80, 83, 85, 86, 90], "target": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40, 42, 46, 49, 51, 54, 55, 59, 61, 63, 68, 71, 74, 76, 78, 86, 95, 97, 99, 100, 102, 104, 109, 110, 111], "behavior": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 80, 100], "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 37, 38, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 80, 84, 86, 97, 98, 107, 113], "call": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 37, 38, 39, 41, 42, 43, 52, 55, 58, 61, 62, 65, 71, 73, 76, 77, 80, 83, 84, 86, 95, 102, 104, 106, 108, 110, 111, 112, 115], "aimet_onnx": [0, 1, 2, 48, 49, 50, 51, 52, 54, 89, 90, 91], "batch_norm_fold": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 37, 43, 59, 60, 65, 74, 83, 88], "fold_all_batch_norms_to_weight": [0, 1, 2], "_": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 33, 36, 40, 42, 43, 44, 51, 52, 54, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 73, 78, 84, 89, 90, 91], "now": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 42, 71, 80, 81, 86, 104, 111, 116], "basic": [0, 1, 2, 8, 9, 12, 13, 15, 16, 19, 20, 21, 28, 29, 30, 31, 71, 86, 91], "mean": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 45, 59, 71, 74, 86, 88, 96, 108, 110], "graph": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 55, 57, 58, 60, 61, 62, 64, 65, 68, 69, 71, 72, 73, 80, 83, 86, 87, 103, 104, 110, 113], "configur": [0, 1, 2, 6, 8, 9, 12, 13, 15, 16, 20, 21, 26, 28, 29, 30, 31, 36, 44, 55, 57, 58, 71, 73, 75, 84, 86, 97, 101, 111], "them": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 46, 52, 60, 66, 71, 73, 80, 81, 84, 86, 93, 116], "few": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 86, 97, 104, 109, 110], "explain": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 71, 86, 96, 102, 105, 110, 116], "quant_schem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 54, 55, 57, 66, 68, 71, 73, 75, 84, 86], "set": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 42, 43, 48, 49, 54, 55, 57, 58, 60, 61, 64, 65, 68, 71, 73, 76, 80, 81, 83, 84, 86, 91, 93, 97, 99, 100, 102, 103, 105, 106, 107, 108, 109, 110, 116], "quantschem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 54, 57, 58, 59, 66, 68, 71, 73, 74, 75, 84, 86, 94], "post_training_tf_enhanc": [0, 1, 2, 6, 8, 9, 12, 13, 15, 17, 19, 20, 22, 26, 28, 29, 30, 32, 36, 44, 46, 52, 55, 57, 58, 66, 68, 71, 73, 75, 84, 86], "support": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 15, 19, 20, 21, 22, 28, 29, 30, 31, 33, 34, 38, 39, 41, 42, 44, 46, 54, 57, 58, 61, 62, 64, 66, 68, 71, 75, 76, 79, 80, 84, 86, 89, 96, 97, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 115, 116], "option": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 43, 44, 46, 49, 57, 58, 60, 61, 66, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 86, 88, 91, 93, 98, 106, 108, 110, 113], "tf_enhanc": [0, 1, 2, 8, 9, 12, 13, 15, 19, 20, 28, 29, 30, 46, 60, 68, 75], "tf": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 75, 84, 90, 106, 110, 111], "quant": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 28, 29, 30, 31, 36, 45, 46, 54, 57, 60, 68, 71, 73, 75, 85, 86, 95], "scheme": [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 36, 38, 44, 46, 54, 57, 58, 60, 61, 66, 68, 71, 73, 75, 76, 78, 84, 86, 94, 95, 99, 102, 106], "enum": [0, 1, 2, 8, 9, 12, 13, 15, 19, 20, 28, 29, 30, 38, 61, 75, 76], "post_training_tf": [0, 1, 2, 8, 9, 10, 12, 13, 15, 18, 19, 20, 28, 29, 30, 36, 44, 46, 54, 55, 57, 58, 66, 68, 71, 75, 84, 86], "default_activation_bw": [0, 1, 2, 48, 52, 54], "8": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32, 36, 43, 44, 46, 48, 52, 54, 55, 57, 58, 61, 66, 68, 71, 73, 75, 76, 80, 81, 84, 86, 87, 91, 104, 116], "essenti": [0, 1, 2, 8, 9, 12, 13, 15, 16, 19, 20, 21, 28, 29, 30, 31], "ask": [0, 1, 2, 6, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 28, 29, 30, 31, 32], "all": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 37, 39, 41, 42, 43, 46, 52, 55, 59, 61, 62, 65, 66, 68, 71, 74, 75, 76, 80, 81, 83, 84, 86, 88, 90, 96, 99, 102, 105, 106, 108, 109], "activ": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 41, 42, 43, 44, 46, 52, 54, 55, 60, 65, 66, 68, 71, 72, 75, 79, 80, 83, 84, 86, 104, 106, 107, 108, 109, 110], "default_param_bw": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 48, 52, 54, 57, 58, 66, 68, 71, 84, 86], "In": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 38, 41, 42, 44, 45, 49, 52, 55, 58, 61, 64, 71, 72, 73, 76, 79, 80, 81, 84, 85, 86, 93, 94, 97, 99, 102, 104, 105, 107, 108, 110, 114, 116], "case": [0, 2, 13, 14, 17, 22, 32, 44, 49, 52, 55, 58, 65, 73, 79, 80, 81, 84, 90, 91, 99, 105, 107, 108], "custom": [0, 2, 13, 16, 27, 42, 46, 55, 80, 98, 109, 110], "compil": [0, 2, 11, 12, 13, 17, 33, 44, 46], "via": [0, 2, 42, 73, 97, 100, 110], "user_onnx_lib": [0, 2], "custom_op1": [0, 2], "custom_op2": [0, 2], "There": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 78, 81, 86, 89, 93, 103, 105, 107, 113, 114], "other": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 43, 61, 65, 79, 80, 83, 86, 89, 99, 101, 102, 104, 106, 109, 110, 111], "check": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 40, 42, 44, 45, 51, 52, 63, 66, 72, 73, 78, 79, 80, 81, 84, 85, 86, 94, 104, 107, 109], "api": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 41, 79, 82, 90, 93, 94, 98, 100, 103, 104, 106, 108, 111, 113], "document": [0, 1, 2, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 34, 87, 97, 98, 100, 111], "refer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 60, 71, 75, 78, 85, 86, 93, 98, 100, 104, 106, 107, 108, 110], "copi": [0, 4, 5, 6, 26, 29, 30, 31, 42, 46, 86, 88, 98, 110], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "quantsim": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 20, 21, 26, 28, 29, 30, 31, 36, 40, 46, 48, 51, 52, 54, 57, 59, 63, 68, 71, 74, 75, 78, 84, 86, 98, 104, 107, 108, 111], "deepcopi": [0, 88], "even": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 86, 104], "though": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 86, 108], "ad": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 55, 61, 68, 71, 81, 86, 101, 104, 108, 111], "node": [0, 1, 2, 6, 8, 9, 10, 12, 13, 18, 20, 21, 26, 29, 30, 31, 46, 61, 68, 71, 72, 73, 79, 80, 86, 107, 110], "readi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 46, 68, 71, 86, 109], "yet": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 86], "find": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 43, 61, 65, 71, 75, 81, 83, 86, 88, 99, 104, 106, 107, 110], "scale": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 37, 39, 43, 50, 55, 59, 62, 65, 71, 74, 77, 83, 86, 95, 104, 105, 106, 107, 110], "offset": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 44, 52, 55, 66, 71, 84, 86, 104, 106, 107, 110], "pass": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 40, 42, 43, 44, 46, 48, 51, 52, 54, 57, 58, 60, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 86, 100, 103, 104, 105, 106, 107, 109, 110, 111, 113], "through": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 61, 71, 75, 80, 84, 86, 88, 90, 91, 105, 106, 110, 113, 114], "collect": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 73, 84, 86, 96, 106], "statist": [0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 37, 38, 44, 45, 52, 59, 61, 66, 67, 69, 71, 74, 76, 84, 85, 86, 88, 95, 104, 106, 114], "calcul": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 46, 57, 58, 61, 65, 66, 68, 71, 73, 83, 86, 99, 105, 106, 110], "sometim": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 71, 86, 96, 102, 105, 106], "calibr": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 44, 48, 52, 54, 66, 68, 71, 84, 86, 104, 106, 107, 109, 110], "simpli": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 36, 44, 46, 52, 57, 66, 68, 71, 80, 84, 86, 116], "fairli": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "simpl": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 36, 44, 52, 57, 61, 66, 71, 76, 80, 84, 86, 104, 116], "loader": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 44, 52, 54, 66, 68, 71, 74, 75, 84, 86, 93], "extract": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86, 105], "don": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 80, 86, 93], "t": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 71, 73, 80, 82, 86, 90, 93], "metric": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 44, 46, 61, 71, 76, 86, 106, 110], "just": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 66, 71, 86, 110, 113, 116], "ignor": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 60, 61, 62, 65, 71, 75, 76, 80, 86], "pointer": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "regard": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "veri": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 71, 86, 95, 97, 102, 106, 114, 116], "small": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 71, 86, 95, 100, 104], "percentag": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "1m": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "onli": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 40, 41, 46, 48, 51, 52, 54, 60, 61, 63, 64, 68, 71, 72, 75, 78, 79, 80, 82, 83, 84, 86, 89, 90, 91, 95, 101, 104, 106, 107, 108, 111, 116], "500": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30, 31, 32, 49, 71, 76, 86, 93, 105, 106], "It": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 39, 42, 43, 44, 49, 52, 55, 61, 62, 65, 66, 71, 76, 80, 83, 84, 86, 95, 98, 99, 104, 105, 108, 113, 114, 116], "benefici": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86, 93, 106, 107], "well": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 52, 61, 66, 71, 72, 81, 84, 86, 97, 102, 104, 105, 106, 110, 112], "distribut": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 33, 38, 61, 71, 76, 86, 105, 109, 110], "look": [0, 1, 2, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 42, 60, 71, 86, 113], "definit": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 41, 45, 79, 80, 85, 104], "extrem": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "scenario": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86, 95, 102, 104, 116], "dark": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "light": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "pictur": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86, 96, 100], "captur": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 40, 51, 63, 71, 78, 80, 86, 99], "night": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86], "might": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 55, 71, 86, 102, 106], "give": [0, 1, 2, 6, 8, 9, 10, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 71, 86, 112, 115], "ideal": [0, 1, 2, 4, 5, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 71, 86], "mani": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 29, 30, 31, 32, 80, 93, 105, 110], "wai": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 38, 61, 76, 78, 86, 89, 98, 99], "pass_calibration_data": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 48, 54, 68, 71, 86], "get_input": [0, 1, 2], "name": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 16, 17, 20, 21, 22, 32, 33, 38, 40, 42, 51, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 75, 78, 84, 86, 90, 105, 110, 111, 113], "batch_cntr": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 49], "input_data": [0, 1, 2, 26, 28, 29, 30, 31, 32, 36, 49, 54, 57, 61, 66, 68, 71, 86], "target_data": [0, 1, 2, 26, 28, 29, 30, 31, 32, 71, 86], "inputs_batch": [0, 1, 2, 26, 28, 29, 30, 31, 32, 71, 86], "numpi": [0, 1, 2, 7, 8, 14, 33, 36, 38, 44, 46, 49, 52, 54, 57, 58, 61, 66], "break": [0, 1, 2, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 38, 49, 54, 68, 71, 86], "abov": [0, 1, 2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 44, 52, 57, 61, 66, 71, 76, 80, 82, 84, 86, 90, 91, 94, 95, 98, 99, 100, 102, 103, 105, 109, 110, 116], "subsequ": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31, 71, 86, 103, 105, 107, 108], "compute_encod": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 36, 46, 54, 57, 68, 71, 86], "forward_pass_callback": [0, 1, 2, 6, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 52, 57, 66, 68, 84, 86], "forward_pass_callback_arg": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 46, 48, 68, 71, 86], "first": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 38, 42, 45, 60, 61, 71, 80, 85, 97, 102, 104, 107, 113], "u": [0, 1, 2, 6, 8, 9, 10, 13, 18, 20, 21, 26, 29, 30, 31, 71, 90, 109], "saw": [0, 1, 2, 6, 8, 9, 10, 18, 20, 21, 26, 29, 30, 31], "describ": [0, 6, 10, 18, 26, 46, 55, 68, 71, 80, 86, 104, 105, 109, 110], "over": [0, 42, 49, 61, 73, 76, 84, 93, 99, 102, 114], "learn": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 36, 37, 38, 39, 46, 48, 49, 50, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 77, 84, 86, 95, 98, 102, 104, 107, 110, 111], "vector": [0, 6, 10, 18, 26, 71], "compli": [0, 26, 29, 30, 31, 32, 71, 86], "signatur": [0, 3, 4, 5, 23, 24, 25, 36, 38, 44, 49, 52, 57, 61, 66, 76, 84], "expect": [0, 3, 4, 5, 8, 12, 23, 24, 25, 28, 38, 41, 43, 44, 46, 48, 52, 54, 58, 60, 61, 65, 66, 68, 71, 72, 76, 80, 81, 83, 84, 86, 102, 104, 106], "num_batch": [0, 1, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 22, 26, 27, 28, 29, 32, 36, 44, 48, 49, 52, 57, 58, 59, 66, 71, 73, 74, 84], "number": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 37, 38, 42, 44, 46, 52, 57, 58, 59, 61, 66, 68, 71, 74, 75, 76, 80, 84, 86, 90, 93, 99, 100, 102, 107, 110, 111, 113, 116], "around": [0, 6, 10, 13, 18, 26, 44, 52, 54, 58, 66, 68, 71, 84, 86, 103], "2000": [0, 6, 7, 9, 10, 11, 18, 26, 27, 29, 49, 58, 71, 73], "size": [0, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 18, 26, 42, 46, 54, 58, 60, 61, 66, 68, 71, 72, 73, 81, 84, 86, 93, 102, 103, 112, 115], "translat": [0, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 71], "64": [0, 6, 10, 18, 26, 41, 42, 44, 52, 54, 58, 66, 68, 71, 84, 86, 89, 93], "default_num_iter": [0, 6, 10, 18, 26, 27, 36, 48, 57, 71], "10000": [0, 6, 7, 10, 11, 18, 26, 36, 57, 71, 93], "strongli": [0, 6, 10, 18, 26, 42, 71, 80], "recommend": [0, 2, 6, 10, 14, 18, 26, 27, 38, 42, 44, 52, 61, 66, 71, 72, 76, 84, 89, 93, 95, 97, 104, 109], "o": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 61, 68, 76], "adaround_weight": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 49, 57, 58, 71, 73], "adaroundparamet": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 49, 57, 58, 71, 73], "satisfi": [0, 27, 80, 94], "requir": [0, 2, 3, 4, 5, 14, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 36, 37, 38, 39, 42, 43, 44, 46, 48, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 74, 75, 76, 77, 78, 79, 80, 83, 84, 86, 87, 88, 93, 95, 97, 102, 104, 105, 108, 110], "deriv": [0, 55], "form": [0, 17, 22, 32, 33, 42, 98], "arrai": [0, 8], "__init__": [0, 14, 27, 41, 42, 58, 72, 73, 76, 79, 80, 81], "self": [0, 14, 27, 41, 42, 58, 61, 72, 73, 76, 79, 80, 81], "_torch_data_load": 0, "_iter": 0, "__iter__": 0, "__next__": 0, "next": [0, 1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 43, 65, 71, 83, 86, 90, 109], "__len__": [0, 27, 73, 84], "len": [0, 13, 27, 38, 49, 71, 73, 80], "forward_fn": [0, 8, 12, 28, 48, 71, 74], "makedir": [0, 3, 4, 5, 8, 9, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31], "exist_ok": [0, 3, 4, 5, 8, 9, 10, 12, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31], "ada_model": [0, 6, 10, 18, 26], "apply_adaround": [0, 6, 10, 18, 26, 36, 48, 57, 71], "filename_prefix": [0, 6, 8, 9, 10, 12, 18, 19, 20, 21, 26, 28, 29, 30, 31, 36, 46, 57, 68, 71, 86], "default_quant_schem": [0, 6, 10, 18, 26, 36, 57, 58, 71], "after": [0, 1, 3, 4, 6, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 36, 37, 43, 49, 57, 59, 60, 62, 65, 71, 73, 74, 80, 81, 83, 84, 86, 88, 93, 94, 95, 97, 102, 104, 107, 109, 113, 114], "again": [0, 1, 3, 4, 5, 6, 9, 10, 18, 19, 23, 24, 25, 26, 29, 106, 107, 113], "note": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 31, 42, 43, 44, 46, 49, 50, 51, 52, 54, 58, 61, 65, 66, 68, 73, 76, 77, 82, 83, 84, 86, 90, 91, 96, 97, 99, 100, 102, 103, 104, 106], "two": [0, 1, 3, 4, 5, 6, 9, 10, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 42, 43, 60, 61, 65, 76, 80, 81, 83, 89, 99, 100, 102, 104, 105, 106, 107, 110, 112, 113, 114, 115], "thing": [0, 6, 10, 18, 26, 104], "understand": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 104, 108, 113, 114], "biwidth": [0, 6, 10, 18, 26], "must": [0, 6, 10, 12, 13, 15, 16, 17, 18, 22, 26, 32, 42, 61, 71, 95, 100, 101, 106, 108, 116], "bitwidth": [0, 6, 10, 18, 26, 44, 46, 55, 57, 58, 66, 68, 71, 73, 75, 84, 86, 95, 104, 109, 110], "wa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 38, 40, 51, 55, 61, 63, 71, 76, 78, 96, 102, 108], "freez": [0, 6, 10, 18, 26, 36, 57, 71, 93], "set_and_freeze_param_encod": [0, 6, 10, 18, 26, 36, 48, 57, 71], "been": [0, 3, 4, 5, 6, 7, 10, 11, 12, 13, 18, 19, 23, 24, 25, 26, 27, 42, 71, 81, 88, 104, 107, 110, 116], "down": [0, 1, 6, 9, 10, 18, 19, 26, 29, 55, 71], "base": [0, 6, 7, 8, 10, 11, 12, 18, 26, 27, 28, 36, 37, 48, 54, 57, 60, 61, 68, 71, 84, 86, 90, 96, 97, 104], "initi": [0, 6, 10, 16, 17, 18, 20, 21, 22, 26, 30, 31, 32, 36, 57, 60, 68, 71, 86, 93, 107, 109, 110], "intern": [0, 6, 7, 10, 11, 13, 14, 18, 26, 42, 66, 68, 71, 73, 86, 102, 104, 105, 108], "NOT": [0, 6, 10, 18, 26, 71, 95, 116], "frozen": [0, 6, 10, 18, 26, 71], "alter": [0, 6, 10, 18, 26, 71], "reflect": [0, 6, 26, 104, 110], "encoding_path": [0, 6, 7, 10, 11, 18, 26, 27, 36, 49, 57, 58, 71, 73], "join": [0, 6, 10, 15, 16, 18, 26, 27, 61, 68, 76, 87], "newli": [0, 6, 26], "updat": [0, 3, 4, 5, 6, 8, 9, 10, 15, 16, 18, 19, 20, 21, 22, 26, 29, 30, 31, 55, 59, 60, 62, 64, 65, 71, 72, 86, 87, 91, 98, 104, 105, 107, 110, 111], "depend": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 61, 80, 90, 91, 97, 98, 99, 104, 108, 111], "observ": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 88, 99, 102, 104, 105, 106, 107, 110], "slight": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31], "gain": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31, 96, 102], "serv": [0, 6, 26, 44, 49, 52, 58, 73, 84, 113], "try": [0, 3, 4, 5, 6, 7, 9, 10, 11, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31, 38, 61, 72, 76, 87, 94, 96, 99, 102, 104, 109], "workflow": [0, 6, 26, 97, 100], "against": [0, 3, 4, 5, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 44, 52, 58, 66, 84, 88], "choic": [0, 1, 3, 4, 5, 6, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 44, 55, 102, 110], "plai": [0, 3, 4, 5, 6, 9, 10, 18, 20, 21, 23, 24, 25, 26, 29, 30, 31], "best": [0, 3, 4, 5, 6, 7, 9, 10, 11, 18, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 58, 73, 94, 97, 102, 104, 110], "step": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 43, 49, 59, 64, 65, 71, 73, 74, 80, 84, 86, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 109, 110], "would": [0, 3, 4, 5, 6, 8, 9, 10, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 39, 42, 62, 71, 77, 86, 97, 102, 108, 111, 113], "take": [0, 6, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 43, 58, 61, 71, 76, 83, 86, 100, 102, 104, 105, 107, 108, 109, 116], "without": [0, 6, 7, 9, 10, 11, 13, 16, 18, 19, 20, 21, 26, 27, 29, 30, 31, 46, 68, 71, 86, 94, 104, 107, 110, 116], "resnet18_after_adaround": [0, 6, 26], "illustr": [0, 6, 10, 18, 26, 68, 86, 93, 99, 104, 112, 115], "invok": [0, 6, 10, 18, 26, 33, 36, 38, 43, 45, 57, 60, 61, 62, 65, 71, 76, 84, 85, 86, 102, 104, 113, 114], "As": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 79, 86, 94, 96, 97, 99, 102, 104, 105, 106, 110, 112, 115], "indic": [0, 3, 4, 5, 6, 10, 18, 23, 24, 25, 26, 27, 38, 43, 55, 60, 61, 64, 65, 73, 76, 97, 116], "make": [0, 6, 8, 10, 12, 13, 18, 26, 28, 33, 37, 41, 43, 45, 59, 60, 64, 65, 79, 82, 85, 99, 102, 103, 104, 110], "faster": [0, 3, 4, 5, 6, 7, 10, 11, 12, 18, 23, 24, 25, 26, 27, 93, 100, 107], "hope": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "addit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 59, 86, 94, 104, 107, 108, 111], "resourc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "doc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 80, 106, 108, 113], "know": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "qat": [0, 1, 6, 9, 10, 13, 18, 19, 26, 29, 37, 54, 57, 59, 68, 71, 74, 82, 85, 93, 95, 98, 100, 104, 109, 110, 111], "showcas": [1, 9, 17, 19, 22, 29, 32], "appli": [1, 3, 4, 5, 8, 9, 12, 13, 19, 23, 24, 25, 27, 28, 29, 36, 38, 39, 43, 45, 48, 57, 58, 61, 62, 65, 71, 73, 75, 76, 81, 83, 85, 88, 93, 94, 95, 98, 99, 102, 104, 105, 107, 108, 109, 110, 111, 113, 114], "aim": [1, 3, 4, 5, 8, 9, 12, 19, 23, 24, 25, 28, 29, 37], "improv": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 34, 68, 71, 86, 97, 104, 107, 109, 114], "help": [1, 3, 4, 5, 6, 7, 9, 17, 19, 20, 21, 22, 29, 32, 62, 65, 72, 81, 86, 88, 93, 99, 102, 104, 105, 106, 109, 113, 114], "recov": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 100, 109, 110], "sensit": [1, 9, 19, 29, 44, 45, 52, 53, 66, 67, 84, 85, 99, 104, 106, 109, 110, 111], "oppos": [1, 9, 19, 29, 104, 108], "about": [1, 8, 9, 14, 19, 28, 29, 36, 38, 39, 43, 46, 48, 49, 50, 54, 55, 57, 58, 60, 61, 62, 65, 68, 71, 73, 75, 76, 77, 83, 84, 86], "free": [1, 3, 4, 5, 8, 9, 12, 13, 15, 16, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 86, 90, 104, 105, 107], "bia": [1, 8, 12, 19, 39, 43, 50, 62, 65, 67, 72, 77, 80, 81, 83, 85, 93, 96, 104, 105, 108, 109, 111], "correct": [1, 10, 18, 19, 27, 32, 43, 65, 67, 71, 73, 83, 85, 91, 93, 95, 104, 105, 109], "paper": [1, 9, 19, 29, 105], "iccv": [1, 9, 19, 29, 102, 105], "2019": [1, 9, 19, 29, 105], "arxiv": [1, 9, 19, 29, 105], "ab": [1, 9, 19, 29, 105], "1906": [1, 9, 19, 29, 105], "04721": [1, 9, 19, 29, 105], "norm": [1, 9, 19, 29, 43, 59, 65, 72, 74, 83, 93, 95, 104, 105, 106], "conv": [1, 3, 4, 5, 6, 7, 8, 9, 12, 19, 20, 21, 22, 29, 33, 37, 43, 57, 59, 60, 61, 65, 71, 74, 75, 80, 83, 88, 101, 108, 111, 112, 115, 116], "immedi": [1, 9, 19, 27, 29], "consecut": [1, 9, 19, 29, 43, 65, 83, 104, 105], "correspond": [1, 3, 4, 5, 6, 7, 8, 9, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 33, 36, 37, 40, 43, 57, 59, 60, 63, 65, 71, 74, 78, 83, 84, 86, 91, 96, 99, 104, 106, 116], "high": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 39, 43, 50, 62, 65, 77, 83, 93, 95, 97, 99, 100, 105, 109, 111, 114], "perhap": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "sai": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 80, 102], "upto": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "trainingmod": [1, 2], "preserv": [1, 2, 3, 4, 5, 23, 24, 25, 80], "current": [1, 3, 4, 5, 6, 7, 8, 9, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 38, 42, 46, 61, 65, 66, 68, 72, 76, 81, 82, 96, 100, 101, 102, 103, 108, 112, 115], "comput": [1, 3, 4, 5, 7, 10, 12, 13, 17, 18, 22, 23, 24, 25, 26, 29, 30, 31, 32, 36, 38, 40, 44, 46, 51, 52, 54, 55, 57, 58, 61, 63, 66, 68, 71, 73, 76, 78, 82, 84, 86, 89, 91, 93, 102, 103, 104, 105, 106, 110, 113, 116], "And": [1, 2, 9, 10, 15, 16, 18, 19, 20, 21, 29, 30, 31, 43, 65, 83, 102], "default_output_bw": [1, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 36, 44, 46, 57, 58, 66, 68, 71, 84, 86], "encod": [1, 3, 4, 5, 7, 10, 11, 12, 13, 18, 26, 27, 29, 30, 31, 36, 40, 44, 46, 48, 51, 52, 54, 57, 58, 59, 63, 66, 68, 71, 73, 74, 78, 82, 84, 86, 93, 95, 104, 106, 107, 111], "5": [1, 3, 4, 5, 6, 9, 13, 18, 20, 21, 23, 24, 25, 29, 30, 31, 33, 38, 48, 49, 59, 61, 73, 74, 76, 80, 86, 87, 89, 97, 107, 109], "suffici": [1, 9, 19, 29, 104, 106, 107, 110], "rounding_mod": [1, 9, 10, 13, 15, 16, 18, 19, 29, 44, 46, 54, 66, 68, 73, 86], "round": [1, 9, 18, 19, 29, 36, 38, 44, 45, 46, 53, 57, 58, 60, 61, 66, 67, 68, 73, 75, 76, 85, 86, 93, 98, 104, 106, 110], "mode": [1, 3, 4, 5, 6, 7, 9, 19, 20, 21, 22, 23, 24, 25, 29, 33, 38, 39, 46, 50, 58, 61, 62, 68, 73, 75, 76, 77, 80, 82, 83, 86, 87, 103, 104, 108], "possibl": [1, 7, 9, 11, 14, 19, 27, 29, 41, 42, 46, 68, 73, 79, 81, 86, 106, 108, 109], "stochast": [1, 9, 19, 29, 44, 46, 58, 60, 66, 68, 75, 86], "bias": [1, 9, 19, 29, 104], "interestingli": [1, 9, 19, 29], "procedur": [1, 3, 4, 5, 9, 19, 23, 24, 25, 29, 99, 102], "cl": [1, 9, 19, 29, 43, 62, 65, 83, 111], "skip": [1, 9, 19, 29, 33, 39, 62, 71, 75, 90, 96], "hba": [1, 9, 19, 29], "absorpt": [1, 9, 19, 29], "cross_layer_equ": [1, 9, 19, 29, 39, 43, 50, 60, 62, 65, 77, 83, 88, 103], "equalize_model": [1, 9, 19, 29, 39, 50, 60, 62, 77, 88, 103], "add": [2, 3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 31, 41, 42, 46, 55, 66, 68, 79, 80, 81, 86, 90, 108, 110, 111, 113, 114, 116], "train": [2, 3, 14, 27, 33, 34, 36, 37, 38, 42, 44, 45, 52, 53, 54, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 71, 73, 74, 76, 82, 84, 85, 89, 93, 94, 95, 98, 100, 102, 109, 110, 111], "ml": [2, 13, 15, 16, 20, 21, 30, 31, 34, 86, 102, 104, 105, 113, 114], "order": [2, 3, 4, 5, 8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 41, 43, 45, 64, 65, 79, 81, 83, 85, 86, 90, 91, 95, 96, 97, 104, 107, 110, 114], "estim": [2, 45, 67, 85, 104, 105], "deploi": [2, 110], "acceler": [2, 13, 15, 16, 20, 21, 30, 31, 61, 76, 86, 89, 100, 102], "awar": [2, 37, 45, 59, 68, 74, 82, 93, 95, 98, 100, 104, 109, 110], "adaround": [2, 49, 53, 58, 73, 94, 98, 104, 109, 111], "cross": [2, 45, 53, 58, 60, 67, 73, 75, 82, 85, 88, 93, 94, 98, 103, 104, 105, 106, 114], "equal": [2, 14, 45, 53, 58, 60, 67, 73, 75, 82, 85, 88, 93, 94, 97, 98, 99, 103, 104, 105, 106, 114], "emploi": [2, 30, 31, 71, 86], "act": [2, 15, 16, 19, 84], "regular": [2, 3, 4, 5, 13, 23, 24, 25, 36, 46, 57, 68, 71, 86, 93, 104, 110], "automat": [2, 27, 38, 43, 61, 65, 76, 83, 90, 91, 97, 102, 104, 106, 111], "regist": 2, "oper": [2, 14, 38, 42, 60, 61, 65, 79, 80, 81, 103, 104, 105, 108, 109], "quantizationsimul": 2, "exampl": [3, 13, 14, 27, 41, 72, 79, 81, 82, 93, 97, 99, 100, 104, 106, 108, 110, 111, 116], "brief": [3, 4, 5, 23, 24, 25], "introduct": [3, 4, 5, 23, 24, 25], "guid": [3, 4, 5, 7, 9, 11, 23, 24, 25, 26, 27, 29, 30, 31, 32, 38, 61, 76, 97, 98, 105, 109, 111], "spatial": [3, 23, 33, 97, 98, 99, 101, 102, 111], "svd": [3, 23, 33, 97, 98, 99, 101, 102, 111], "decomposit": [3, 4, 5, 23, 24, 25, 61, 112, 115], "gener": [3, 4, 5, 9, 13, 15, 16, 23, 24, 25, 29, 34, 46, 55, 61, 68, 72, 98, 102, 104, 106, 107, 108, 110], "layer": [3, 4, 5, 7, 13, 22, 23, 24, 25, 33, 36, 37, 38, 41, 42, 44, 45, 46, 52, 53, 57, 58, 59, 61, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 81, 82, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 101, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116], "conv2d": [3, 4, 5, 12, 13, 18, 23, 24, 25, 33, 42, 43, 55, 60, 61, 65, 69, 72, 80, 81, 83, 96, 102, 111, 116], "decompos": [3, 4, 5, 23, 24, 25, 102, 112, 115], "singl": [3, 4, 5, 17, 18, 22, 23, 24, 25, 32, 33, 36, 44, 52, 57, 61, 66, 76, 80, 82, 84, 93, 105], "split": [3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 58], "flattend": [3, 4, 5, 23, 24, 25], "2d": [3, 4, 5, 18, 23, 24, 25], "matrix": [3, 4, 5, 18, 23, 24, 25, 96], "singular": [3, 4, 5, 23, 24, 25, 61, 112, 115], "discard": [3, 4, 5, 23, 24, 25, 52, 66, 84], "least": [3, 4, 5, 23, 24, 25, 93, 96], "signific": [3, 4, 5, 23, 24, 25, 109], "diagon": [3, 4, 5, 23, 24, 25], "matric": [3, 4, 5, 23, 24, 25], "combin": [3, 4, 5, 7, 11, 23, 24, 25, 27, 75, 80, 94, 97, 102, 104, 105], "back": [3, 4, 5, 23, 24, 25, 33, 71, 82, 86, 108], "separ": [3, 4, 5, 20, 21, 23, 24, 25, 30, 31, 42, 43, 46, 57, 68, 71, 80, 81, 83, 86, 95, 106, 109, 111], "magnitud": [3, 4, 5, 23, 24, 25, 96], "feed": [3, 4, 5, 13, 14, 23, 24, 25, 42, 110], "dimens": [3, 4, 5, 23, 24, 25, 102, 109, 112, 115], "reconstruct": [3, 4, 5, 23, 24, 25, 36, 57, 61, 71], "minim": [3, 4, 5, 15, 16, 20, 21, 23, 24, 25, 30, 31, 36, 57, 61, 68, 71, 86, 100, 102, 104, 110], "distanc": [3, 4, 5, 23, 24, 25], "both": [3, 4, 5, 16, 19, 20, 21, 23, 24, 25, 30, 31, 42, 55, 71, 80, 84, 86, 89, 104, 105, 107, 108, 109, 110, 112, 116], "structur": [3, 4, 5, 17, 23, 24, 25, 32, 55, 60, 73, 80, 102], "mac": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87, 97, 102, 112, 115], "memori": [3, 4, 5, 6, 7, 9, 20, 21, 22, 23, 24, 25, 38, 61, 76, 97, 102, 112, 115, 116], "either": [3, 4, 5, 6, 10, 18, 19, 23, 24, 25, 26, 34, 38, 43, 60, 61, 71, 76, 79, 100, 110], "epoch": [3, 4, 5, 6, 8, 9, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 46, 59, 61, 74, 76, 86, 100, 102, 104, 107], "close": [3, 4, 5, 23, 24, 25, 57, 60, 62, 65, 68, 69, 96, 97, 110], "folder": [3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 24, 25, 30, 31, 32, 64, 88, 106], "pipelin": [3, 13, 40, 51, 59, 63, 68, 74, 78, 86, 104, 107, 109, 110], "num_comp_ratio_candid": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "num_eval_iter": [3, 4, 5, 23, 24, 25], "convert": [3, 4, 5, 6, 7, 8, 9, 19, 20, 21, 22, 33, 41, 42, 43, 65, 80, 94, 104, 114], "tfrecord": [3, 4, 5, 6, 7, 8, 9, 15, 16, 20, 21, 22, 26, 61, 66, 68], "contain": [3, 4, 5, 6, 7, 8, 9, 17, 20, 21, 22, 23, 24, 25, 32, 43, 55, 61, 63, 65, 72, 76, 80, 81, 84, 89, 104, 106, 107, 108, 110], "start": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 33, 36, 38, 42, 57, 58, 59, 61, 62, 63, 65, 66, 68, 71, 76, 80, 81, 86, 93, 98, 99, 102, 108, 110], "label": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 20, 21, 22, 27, 38, 44, 52, 58, 66, 68, 71, 73, 84, 86, 106, 107], "tfrecords_dir": [3, 4, 5, 6, 8, 9, 20, 21, 22], "dir": [3, 4, 5, 7, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 91], "disabl": [3, 4, 5, 6, 7, 9, 20, 21, 23, 25, 33, 44, 66, 84, 86, 99, 102, 106, 108, 110], "log": [3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 20, 21, 22, 36, 57, 81, 106], "info": [3, 4, 5, 6, 7, 9, 20, 21, 22, 43, 60, 65, 72, 75, 81, 83, 111], "level": [3, 4, 5, 6, 7, 9, 13, 20, 21, 22, 39, 60, 62, 77, 95, 97, 99, 100, 104, 109, 113], "eager": [3, 4, 5, 6, 7, 9, 20, 21, 22], "verbos": [3, 4, 5, 6, 7, 9, 20, 21, 22], "displai": [3, 4, 5, 6, 7, 9, 13, 20, 21, 22, 98, 106, 113, 114], "erorr": [3, 4, 5, 9, 20, 21], "tensorflow": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 32, 34, 36, 38, 39, 40, 41, 43, 44, 46, 89, 90, 95, 98, 100, 101, 108, 110, 111], "messag": [3, 4, 5, 6, 7, 9, 20, 21, 22, 61], "error": [3, 4, 5, 6, 7, 8, 9, 11, 20, 21, 22, 42, 61, 68, 73, 80, 94, 104, 107, 109, 110], "critic": [3, 4, 5, 6, 7, 9, 20, 21, 22], "tf_cpp_min_log_level": [3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 20, 21, 22], "todo": [3, 4, 5, 9, 20, 21], "compat": [3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 20, 21, 22, 33, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 79, 89], "v1": [3, 4, 5, 6, 7, 8, 9, 15, 16, 20, 21, 22, 33, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69], "abhijit": [3, 4], "disable_eager_execut": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 58], "set_verbos": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22], "type": [3, 4, 5, 6, 7, 8, 9, 11, 12, 17, 20, 21, 22, 23, 24, 25, 27, 30, 31, 33, 36, 37, 38, 39, 43, 44, 46, 52, 57, 58, 59, 61, 62, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 80, 83, 84, 86, 88, 104, 106, 108, 110, 113], "list": [3, 4, 5, 6, 8, 9, 12, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 42, 43, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 88, 91, 99, 101, 103, 108], "image_net_train": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 29, 30, 31], "imagenettrain": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 29, 30, 31], "format_bgr": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "int": [3, 4, 5, 6, 7, 8, 9, 11, 12, 17, 20, 21, 22, 23, 24, 25, 27, 36, 37, 38, 44, 46, 49, 55, 57, 58, 59, 60, 61, 66, 68, 71, 73, 74, 75, 76, 84, 86], "bool": [3, 4, 5, 23, 24, 25, 26, 28, 29, 30, 31, 32, 38, 43, 46, 60, 61, 64, 65, 66, 68, 73, 75, 76, 80, 83, 86], "maximum": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 17, 18, 19, 20, 21, 22, 32, 36, 57, 58, 71, 73, 86], "training_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "keras_learning_phas": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "data_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66, 68], "input_1": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 60, 61, 62, 65, 66], "validation_input": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 66], "update_ops_nam": [3, 4, 5, 6, 8, 9, 20, 21, 59], "str": [3, 4, 5, 6, 8, 9, 20, 21, 33, 38, 40, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 73, 75, 78, 79, 80, 84, 86, 88], "learning_r": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 30, 31, 59, 74, 86], "decay_step": [3, 4, 5, 6, 8, 9, 20, 21, 59], "mostli": [3, 4, 5, 6, 8, 9, 20, 21, 25], "move": [3, 4, 5, 6, 8, 9, 20, 21, 82], "averag": [3, 4, 5, 6, 8, 9, 20, 21], "graphkei": [3, 4, 5, 6, 8, 9, 20, 21, 22], "update_op": [3, 4, 5, 6, 8, 9, 20, 21, 22], "alwai": [3, 4, 5, 6, 8, 9, 20, 21, 61, 89, 99], "dure": [3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32, 36, 37, 38, 42, 57, 61, 65, 68, 71, 73, 76, 86, 87, 93, 100, 102, 104, 107, 108, 110, 113, 114], "rate": [3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 42, 86, 102, 107], "adjust": [3, 4, 5, 6, 7, 8, 9, 20, 21, 29, 36, 57, 58, 71, 72, 86, 95, 96, 97, 104, 105, 109], "decai": [3, 4, 5, 6, 8, 9, 20, 21, 102], "trainer": [3, 4, 5, 6, 8, 9, 20, 21, 23, 24, 25, 28, 30, 31, 38, 61, 76, 98], "num_epoch": [3, 4, 5, 6, 8, 9, 20, 21], "resnet50": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 33, 38, 39, 43, 44, 46, 58, 59, 60, 62, 65, 69], "kera": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 34, 42, 56, 58, 59, 60, 61, 62, 64, 65, 69, 95, 98, 100, 104, 108, 110, 111], "covert": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22], "clear_sess": [3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 33, 36, 59, 60, 62, 65, 69], "releas": [3, 4, 5, 6, 7, 9, 20, 21, 22, 98, 103], "global": [3, 4, 5, 6, 7, 9, 20, 21, 22, 109], "clutter": [3, 4, 5, 6, 7, 9, 20, 21, 22], "old": [3, 4, 5, 6, 7, 9, 20, 21, 22], "By": [3, 4, 5, 6, 8, 9, 12, 20, 21, 22, 26, 28, 29, 30, 31, 37, 38, 42, 58, 61, 76, 102, 108, 110], "train_op": [3, 4, 5, 6, 9, 20, 21, 22], "fold": [3, 4, 5, 7, 22, 37, 39, 43, 50, 58, 59, 62, 65, 67, 72, 73, 74, 77, 83, 85, 88, 93, 94, 95, 104, 105, 106, 111], "applic": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 33, 38, 39, 43, 44, 46, 55, 58, 59, 60, 61, 62, 65, 69, 83, 99, 103], "backend": [3, 4, 5, 6, 7, 8, 9, 12, 20, 21, 22, 33, 36, 58, 59, 60, 62, 65, 69], "allow": [3, 4, 5, 6, 7, 9, 11, 13, 20, 21, 22, 27, 38, 40, 42, 45, 46, 51, 53, 55, 58, 61, 63, 67, 73, 76, 78, 79, 80, 85, 86, 94, 100, 102, 104, 106, 107, 108, 109, 110, 111, 113], "easili": [3, 4, 5, 6, 7, 9, 20, 21, 22, 61, 76], "read": [3, 4, 5, 6, 7, 9, 20, 21, 22, 106], "eventu": [3, 4, 5, 6, 7, 9, 20, 21, 22], "aimet_tensorflow": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 89, 90, 91], "update_keras_bn_ops_trainable_flag": [3, 4, 5, 6, 7, 9, 20, 21, 22, 58, 64], "load_save_path": [3, 4, 5, 6, 7, 9, 20, 21, 22, 58, 64], "trainabl": [3, 4, 5, 6, 9, 16, 20, 21, 22, 31, 64, 68, 104], "add_image_net_computational_nodes_in_graph": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "an": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 42, 44, 46, 52, 54, 55, 57, 58, 59, 60, 61, 62, 66, 68, 71, 73, 74, 75, 76, 77, 79, 80, 81, 84, 86, 89, 93, 94, 96, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 114, 116], "softmax": [3, 4, 5, 6, 7, 9, 13, 14, 20, 21, 22, 33, 42, 57, 60, 61, 62, 65], "add_computational_nodes_in_graph": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "get_sess": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 58, 59, 60, 62, 65, 69], "creat": [3, 4, 5, 7, 11, 13, 17, 22, 32, 33, 36, 38, 42, 43, 44, 46, 49, 51, 52, 57, 58, 59, 61, 64, 65, 66, 68, 71, 73, 74, 76, 80, 82, 83, 84, 86, 88, 93, 95, 102, 103, 104, 107, 110], "within": [3, 4, 5, 6, 7, 9, 13, 21, 33, 97, 106, 110], "images_class": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 59], "identifi": [3, 4, 5, 6, 7, 9, 20, 21, 22, 75, 81, 90, 91, 98, 106, 109, 111, 116], "input_op_nam": [3, 4, 5, 6, 7, 8, 9, 20, 21, 33, 38, 58, 59, 60, 61, 62, 65], "output_op_nam": [3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 33, 38, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68], "starting_op_nam": [3, 4, 5, 6, 7, 9, 20, 21, 22, 57, 58, 59, 63, 68], "append": [3, 4, 5, 8, 43, 65, 76], "test": [3, 4, 5, 6, 7, 9, 12, 13, 14, 20, 21, 22, 44, 52, 59, 66, 68, 72, 74, 84, 91], "is_gpu_avail": [3, 4, 5, 6, 7, 9, 20, 21, 22], "cuda_onli": [3, 4, 5, 6, 7, 9, 20, 21, 22], "": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 36, 38, 39, 41, 42, 43, 44, 46, 49, 52, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 68, 71, 73, 74, 75, 76, 80, 83, 84, 86, 88, 91, 97, 101, 102, 104, 105, 106, 107, 109, 110, 113, 114, 116], "determin": [3, 4, 5, 8, 13, 23, 24, 25, 27, 36, 38, 44, 46, 52, 55, 57, 61, 62, 65, 66, 68, 71, 76, 84, 86, 94, 97, 102, 104, 105, 106], "fp32": [3, 4, 5, 12, 13, 22, 23, 24, 25, 32, 40, 44, 51, 63, 66, 78, 84, 93, 100, 105, 106, 107, 109, 110], "defin": [3, 4, 5, 9, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 36, 41, 42, 44, 45, 49, 52, 55, 57, 58, 61, 64, 66, 71, 73, 76, 79, 80, 81, 84, 85, 86, 103, 104, 106, 108, 110], "target_comp_ratio": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "desir": [3, 4, 5, 23, 24, 25, 38, 46, 52, 61, 68, 76, 84, 86, 90, 91, 97, 102, 104, 109], "compess": [3, 4, 5], "ratio": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87, 96, 97, 113], "denot": [3, 4, 5, 23, 24, 25, 38, 94], "20": [3, 4, 5, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 36, 38, 42, 55, 57, 61, 71, 86, 93, 107], "80": [3, 4, 5, 38], "pre": [3, 4, 5, 15, 16, 40, 51, 63, 78, 89, 90, 91, 98, 100, 105], "9": [3, 4, 5, 23, 25, 26, 29, 30, 31, 32, 38, 61, 71, 80, 86, 91, 109], "10": [3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 36, 38, 41, 42, 43, 46, 57, 60, 61, 68, 74, 76, 80, 81, 86, 87, 89, 90, 91, 99, 102, 107], "part": [3, 4, 5, 23, 24, 25, 42, 44, 49, 52, 58, 66, 73, 82, 84, 102, 104, 105, 106], "variou": [3, 4, 5, 7, 11, 17, 22, 23, 24, 25, 27, 32, 38, 61, 76, 94, 97, 102, 104, 109, 110, 111, 114], "measur": [3, 4, 5, 23, 24, 25, 27, 38, 61, 76, 84], "tri": [3, 4, 5, 23, 24, 25, 97, 104], "33": [3, 4, 5, 23, 24, 25], "66": [3, 4, 5, 23, 24, 25, 97], "00": [3, 4, 5, 23, 24, 25], "higher": [3, 4, 5, 23, 24, 25, 61, 71, 76, 95, 99, 107, 109], "candid": [3, 4, 5, 23, 24, 25, 38, 39, 60, 61, 62, 73, 76, 99, 102], "granular": [3, 4, 5, 13, 23, 24, 25, 38, 61, 76, 102, 109, 110, 114], "time": [3, 4, 5, 7, 11, 17, 22, 23, 24, 25, 27, 32, 38, 43, 55, 61, 65, 76, 80, 81, 94, 102, 103, 107, 113], "taken": [3, 4, 5, 23, 24, 25, 42, 116], "complet": [3, 4, 5, 7, 11, 22, 23, 24, 25, 27, 38, 95, 109], "modules_to_ignor": [3, 4, 5, 23, 24, 25, 38, 61, 76, 84, 87, 101], "interact": [3, 4, 5, 23, 24, 25], "too": [3, 4, 5, 23, 24, 25], "choss": [3, 4, 5, 23, 24, 25], "auto": [3, 4, 5, 23, 24, 25, 34, 38, 39, 43, 50, 55, 61, 62, 65, 76, 77, 83, 87], "analysi": [3, 4, 5, 13, 23, 24, 25, 27, 38, 44, 52, 61, 66, 76, 84, 102, 109], "much": [3, 4, 5, 7, 11, 16, 21, 23, 24, 25, 31, 116], "altern": [3, 4, 5, 23, 24, 25, 90, 91, 102], "manual": [3, 4, 5, 7, 11, 23, 24, 25, 33, 38, 55, 61, 76, 83, 94, 102], "retriev": [3, 4, 5, 23, 25], "those": [3, 4, 5, 14, 16, 21, 23, 24, 25, 31, 52, 84, 102], "num_reconstruction_sampl": [3, 4, 5, 23, 25, 61, 76], "last": [3, 4, 5, 99, 101, 109], "stage": [3, 4, 5, 94], "map": [3, 4, 5, 7, 10, 11, 12, 15, 16, 18, 22, 44, 46, 55, 58, 65, 81, 106, 108], "linear": [3, 4, 5, 37, 43, 57, 59, 60, 65, 71, 74, 80, 81, 83, 88, 95, 96], "regress": [3, 4, 5, 96], "attempt": [3, 4, 5, 96, 104, 105], "done": [3, 4, 5, 8, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 41, 90, 96, 102, 108, 110, 116], "random": [3, 4, 5, 14, 27, 33, 36, 42, 44, 46, 49, 52, 54, 57, 58, 61, 66, 73, 96, 106], "ridicul": [3, 4, 5, 23, 25], "enabl": [3, 4, 5, 16, 18, 21, 23, 25, 31, 34, 38, 44, 59, 61, 66, 68, 74, 76, 84, 89, 90, 95, 100, 104, 106, 108, 110, 111], "allow_custom_downsample_op": [3, 4, 5, 23, 25, 61, 76], "flag": [3, 4, 5, 23, 25, 43, 60, 64, 65, 73, 80, 86], "downsampl": [3, 4, 5, 23, 25], "consid": [3, 4, 5, 13, 23, 25, 65, 72, 93, 99, 104, 109], "bandwidth": [3, 4, 5, 23, 25, 97], "overhead": [3, 4, 5, 23, 25], "trade": [3, 4, 5, 23, 25, 36, 57, 71], "off": [3, 4, 5, 23, 25, 36, 46, 57, 68, 71, 86, 104, 105, 108], "suggest": [3, 4, 5, 23, 25, 46, 86, 99, 102, 105], "eval_callback": [3, 4, 5, 7, 11, 12, 17, 22, 23, 24, 25, 27, 32, 33, 38, 44, 49, 52, 58, 61, 66, 73, 76, 84, 87], "function_nam": [3, 4, 5, 23, 24, 25], "eval_iter": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87], "batch": [3, 4, 5, 7, 8, 11, 12, 22, 23, 24, 25, 28, 36, 37, 38, 40, 43, 44, 52, 54, 57, 58, 59, 60, 61, 63, 65, 66, 68, 71, 72, 74, 78, 83, 84, 86, 93, 95, 104, 105, 106], "choos": [3, 4, 5, 23, 24, 25, 66, 68, 86, 88, 96, 97, 102], "enough": [3, 4, 5, 23, 24, 25, 72], "trust": [3, 4, 5, 23, 24, 25], "callback": [3, 4, 5, 13, 15, 16, 17, 22, 23, 24, 25, 32, 38, 44, 46, 49, 52, 58, 61, 66, 68, 73, 76, 84, 86, 106, 110], "invoc": [3, 4, 5, 23, 24, 25], "compress_schem": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87], "cost_metr": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87], "actual": [3, 4, 5, 8, 9, 12, 14, 20, 21, 28, 30, 31, 40, 44, 49, 51, 52, 58, 63, 66, 71, 73, 78, 82, 84, 86, 91, 97, 104], "greedi": [3, 4, 5, 102, 113], "select": [3, 4, 5, 36, 57, 60, 71, 73, 86, 88, 94, 97, 106, 110, 113, 116], "among": [3, 4, 5, 71, 73], "reach": [3, 4, 5, 7, 11, 27, 94, 97], "previou": [3, 4, 5, 9, 29, 38, 43, 61, 76, 83, 89, 97, 99, 109], "rule": [3, 4, 5, 46, 66, 68, 108], "thumb": [3, 4, 5], "found": [3, 4, 5, 14, 33, 43, 83, 107, 110], "compressionschem": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87], "costmetr": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87], "greedyselectionparamet": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "channelpruningparamet": [3, 5, 23, 25, 61, 76], "decim": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "greedy_param": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "get_operation_by_nam": [3, 4, 5, 6, 8, 9, 20, 21, 22, 33, 60, 61, 65, 68, 69], "conv1_conv": [3, 4, 5, 69], "auto_param": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "automodeparam": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87], "greedy_select_param": [3, 4, 5, 23, 24, 25, 38, 61, 76], "data_set": [3, 5, 6, 9, 10, 18, 36, 57, 60, 61], "channel_prun": [3, 5, 23, 25, 38, 61, 76], "modelcompressor": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87], "compress_model": [3, 4, 5, 23, 24, 25, 33, 38, 61, 76, 87, 113], "relev": [3, 4, 5, 23, 24, 25], "our": [3, 4, 5, 8, 9, 12, 13, 15, 16, 19, 20, 23, 24, 25, 28, 37, 52, 84, 89, 91, 99, 109, 110], "new": [3, 5, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 32, 41, 42, 43, 55, 62, 65, 71, 79, 80, 86, 90, 104, 108, 111], "final": [3, 5, 8, 12, 13, 15, 16, 17, 22, 28, 32, 38, 42, 61, 76, 81, 87, 96, 97, 99, 107, 109, 113], "compressed_sess": [3, 4, 33], "comp_stat": [3, 4, 23, 24], "working_dir": [3, 4, 5, 33, 61], "fell": [3, 4, 5, 23, 24, 25], "sharpli": [3, 4, 5, 23, 24, 25], "15": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 86, 102, 107], "job": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 86], "hyper": [3, 4, 5, 8, 9, 12, 13, 20, 21, 23, 24, 25, 28, 30, 31, 86, 93, 107], "search": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 34, 36, 57, 71, 73, 86, 99, 107, 108], "good": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 42, 86, 93], "end": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 36, 37, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 80, 81, 84, 86, 102], "drop": [3, 4, 5, 7, 8, 11, 12, 13, 15, 16, 20, 21, 23, 24, 25, 27, 28, 30, 31, 58, 61, 73, 86, 94, 97, 102, 105, 106, 107, 109, 110], "factor": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 43, 65, 83, 86, 97, 102, 105], "feel": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 86, 90], "fit": [3, 4, 5, 8, 12, 13, 15, 16, 20, 21, 23, 24, 25, 28, 30, 31, 33, 38, 46, 61, 76, 86, 99], "reduced_": [3, 4, 5], "accordingli": [3, 4, 5, 58, 90, 91], "compr_graph_all_ops_nam": [3, 4, 5], "get_oper": [3, 4, 5], "update_ops_name_after_cp": [3, 4, 5], "op_nam": [3, 4, 5], "1e": [3, 4, 5, 13, 14, 20, 21, 42, 68, 72, 107], "finetu": [3, 4, 5, 23, 24, 25], "ofcours": [3, 4, 5, 9, 20, 21, 23, 24, 25, 29, 30, 31], "graph_sav": [3, 4, 5, 6, 60, 65, 68], "save_model_to_meta": [3, 4, 5], "meta_path": [3, 4, 5], "finetuned_model": [3, 4, 5, 23, 24], "quantiz": [3, 4, 5, 7, 11, 14, 23, 24, 25, 27, 34, 35, 36, 37, 40, 42, 44, 47, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 66, 70, 71, 73, 74, 78, 79, 80, 82, 84, 93, 94, 95, 97, 98, 100, 102, 106, 111, 113], "pytorch": [4, 5, 9, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 72, 80, 81, 88, 89, 90, 95, 98, 100, 106, 108, 110, 111], "repres": [4, 5, 17, 22, 23, 24, 25, 32, 36, 38, 42, 44, 46, 52, 55, 57, 58, 60, 61, 66, 68, 76, 79, 84, 86, 99, 104, 105, 106, 107, 110], "spatialsvdparamet": [4, 5, 24, 25, 33, 38, 61, 76, 87], "spatial_svd": [4, 5, 24, 25, 33, 38, 61, 76, 87], "comp_accuraci": 4, "ssvd_compressed_sess": 5, "ssvd_comp_stat": [5, 25], "ssvd_finetuned_model": [5, 25], "further": [5, 25, 34, 62, 65, 80, 96, 100, 102, 104, 108], "similar": [5, 16, 21, 25, 31, 105, 107, 110], "out": [5, 7, 11, 14, 25, 42, 44, 45, 46, 52, 53, 66, 67, 68, 80, 84, 85, 86, 94, 97, 102, 106], "ssvd_cp_compressed_sess": 5, "cp_comp_stat": [5, 25], "ok": [5, 25], "fine": [6, 7, 8, 9, 13, 15, 16, 20, 21, 30, 31, 34, 38, 46, 61, 68, 76, 86, 97, 100, 104, 107, 110], "tune": [6, 7, 8, 9, 13, 15, 16, 20, 21, 30, 31, 34, 38, 46, 61, 68, 76, 86, 97, 100, 104, 107, 110], "fold_all_batch_norm": [6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 43, 60, 65, 83, 88], "bn_folded_sess": [6, 9, 20, 21], "maintain": [6, 49], "fresh": 6, "save_and_load_graph": [6, 60, 65], "bn_folded_sess_copi": 6, "With": [6, 14, 16, 17, 21, 22, 31, 32], "enhanc": [6, 16, 17, 21, 22, 31, 32, 44, 54, 66, 68, 84, 106, 110], "input_label_tensor": [6, 8, 9, 20, 21, 22], "get_tensor_by_nam": [6, 7, 8, 9, 20, 21, 22, 57, 58, 68], "train_tensor": [6, 8, 9, 20, 21, 22, 68], "train_tensors_dict": [6, 8, 9, 20, 21, 22], "dict": [6, 8, 9, 20, 21, 22, 38, 43, 46, 60, 61, 65, 73, 75, 76, 78, 79, 80, 83, 84, 86], "fromkei": [6, 8, 9, 20, 21, 22], "eval_output": [6, 8, 9, 20, 21, 22], "top1": [6, 8, 9, 20, 21, 22, 27, 38], "acc": [6, 8, 9, 11, 12, 13, 17, 20, 21, 22, 44], "input_label": [6, 8, 9, 20, 21, 22], "input_label_tensors_dict": [6, 8, 9, 20, 21, 22], "zip": [6, 8, 9, 20, 21, 22, 38, 44, 58], "feed_dict": [6, 7, 8, 9, 20, 21, 22, 57, 58, 63, 68], "as_default": [6, 7, 8, 9, 20, 21, 22, 58, 60, 61, 62, 65, 68, 69], "ensur": [6, 18, 78, 90, 104, 109], "prior": [6, 26, 29, 30, 31, 96, 104, 106], "num_iter": [6, 7, 11, 38], "offer": [7, 11, 27, 52, 68, 84, 94], "suit": [7, 11, 27, 94], "network": [7, 11, 13, 14, 18, 27, 42, 61, 68, 94, 97, 99, 102, 104, 107, 109, 110, 113, 115], "often": [7, 11, 93, 94, 102, 107], "sequenc": [7, 11, 13, 27, 72, 94, 95, 103, 108], "better": [7, 8, 11, 18, 28, 72, 88, 93, 94, 104, 105, 107], "prone": [7, 11, 94], "consum": [7, 11, 19, 27, 55, 94, 102], "analyz": [7, 11, 27, 38, 45, 53, 61, 67, 76, 85, 94, 96, 102, 103, 106, 110, 113, 114], "amount": [7, 11, 17, 22, 27, 32, 94, 108], "toler": [7, 11, 27, 94, 97], "soon": [7, 11, 94], "threshold": [7, 11, 61, 94], "stop": [7, 11, 36, 57, 71, 94], "autom": [7, 11, 26, 29, 30, 31, 32, 45, 71, 79, 80, 85, 86, 94, 104], "input_tensor_nam": [7, 58], "output_tensor_nam": [7, 58], "section": [7, 9, 11, 12, 27, 29, 72, 81, 90, 91, 93, 95, 96, 98, 102, 104, 110], "eval_dataset_s": [7, 11, 12, 27, 49, 58, 73], "5000": [7, 11, 27, 49, 58, 73], "calibration_dataset_s": [7, 11, 27, 49, 58, 73], "_create_sampled_data_load": [7, 11, 27, 73], "_sampled_dataset": [7, 58], "_create_sampled_dataset": [7, 58], "num_sampl": [7, 11, 12, 27, 44, 58, 73], "_graph": [7, 22, 58], "shuffle_buffer_s": [7, 58], "300": [7, 58], "buffer": [7, 58], "shuffle_se": [7, 58], "22222": [7, 58], "shuffl": [7, 10, 18, 33, 38, 58, 76], "buffer_s": [7, 58], "seed": [7, 58, 76], "object": [7, 11, 12, 15, 16, 17, 22, 26, 29, 30, 31, 32, 33, 36, 40, 44, 46, 49, 51, 52, 57, 58, 59, 61, 63, 66, 68, 73, 76, 78, 84, 86, 95, 104, 107, 110], "eval_dataset": [7, 11, 12, 44, 58, 73], "image_dataset": [7, 44, 58], "lambda": [7, 10, 11, 12, 13, 18, 22, 44], "unlabeled_dataset": [7, 11, 12, 17, 22, 44, 58, 66, 73], "argument": [7, 11, 12, 17, 22, 32, 33, 36, 40, 44, 46, 51, 52, 57, 58, 61, 63, 66, 68, 71, 73, 78, 80, 84, 86], "whole": [7, 11, 12, 58, 110], "np": [7, 8, 14, 33, 36, 38, 42, 44, 46, 49, 52, 54, 57, 58, 61, 65, 66], "iterate_tf_dataset": [7, 58], "sampled_dataset": [7, 11, 12, 17, 58], "global_variables_initi": [7, 57, 58, 61], "input_tensor": [7, 10, 18, 19, 33, 42, 54, 57, 58, 68, 80], "output_tensor": [7, 33, 57, 58], "num_correct_predict": [7, 58, 73], "prob": [7, 58], "predict": [7, 17, 38, 40, 44, 58, 61, 73, 104], "argmax": [7, 58, 73], "axi": [7, 17, 22, 32, 55, 58, 106], "sum": [7, 27, 38, 58, 73], "allowed_accuracy_drop": [7, 11, 27, 49, 58, 73], "convei": [7, 11], "seri": [7, 11, 27, 73, 86], "auto_qu": [7, 11, 27, 49, 58, 73], "01": [7, 11, 27, 36, 49, 57, 58, 71, 73, 91, 93], "shown": [7, 11, 17, 22, 32, 43, 65, 79, 82, 93, 102, 105, 106, 109], "adaround_dataset_s": [7, 11, 27, 49, 58, 73], "adaround_dataset": [7, 11, 58], "adaround_param": [7, 11, 27, 49, 58, 73], "set_adaround_param": [7, 11, 27, 49, 58, 73], "associ": [7, 11, 17, 22, 32, 36, 43, 57, 58, 60, 61, 73, 81, 104], "eval_scor": [7, 11, 38, 61, 76, 84], "cle": [7, 11, 27, 39, 60, 62, 77, 82, 85, 93, 98, 104, 109, 111], "standalon": [7, 11, 27, 72, 104], "fashion": [7, 11, 18, 27], "counter": [8, 12, 28, 45, 46, 68, 86], "potenti": [8, 12, 28, 43, 45, 65, 72, 103, 106, 113, 114], "instabl": [8, 12, 28, 45], "batchnrom": [8, 28], "varianc": [8, 12, 28, 45, 105], "recalcul": [8, 12, 28, 37], "stabl": [8, 12, 28, 37, 80, 93], "rather": [8, 12, 28, 37, 80, 113], "than": [8, 12, 13, 28, 37, 38, 43, 55, 61, 65, 71, 72, 76, 80, 81, 83, 86, 101, 107, 113], "noisi": [8, 12, 28, 37], "compar": [8, 12, 13, 14, 15, 16, 17, 22, 28, 32, 61, 72, 80, 88, 106, 107, 114], "focu": [8, 28], "itself": [8, 17, 22, 28, 32, 51, 102, 110, 112, 115], "inform": [8, 28, 43, 55, 61, 65, 75, 81, 83, 104, 106], "accuraci": [8, 12, 13, 17, 22, 27, 28, 32, 34, 36, 38, 40, 46, 49, 51, 57, 58, 61, 63, 68, 71, 73, 76, 78, 86, 93, 94, 97, 99, 100, 102, 104, 105, 106, 107, 109, 110, 111, 114, 116], "line": [8, 54, 59, 68, 69, 71, 74, 75, 86, 88, 98], "difficult": 8, "model_sess_bn_mut": 8, "easier": 8, "bn_mutabl": 8, "modify_sess_bn_mut": 8, "training_tf_placehold": 8, "unlik": [8, 28], "script": [8, 28], "didn": [8, 28], "becaus": [8, 14, 28, 42, 80], "present": [8, 14, 28, 34, 72, 78, 81, 102, 105], "statatist": [8, 28], "json": [8, 12, 17, 19, 22, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "default_config_per_channel": [8, 12], "is_output_quant": [8, 12, 108], "is_quant": [8, 12, 108], "is_symmetr": [8, 12, 55, 108], "strict_symmetr": [8, 12, 108], "unsigned_symmetr": [8, 12, 108], "per_channel_quant": [8, 12, 18, 55, 108], "op_typ": [8, 12, 108], "squeez": [8, 12], "pad": [8, 12, 42, 72, 80, 81], "supergroup": [8, 12, 108, 111], "op_list": [8, 12, 108], "relu": [8, 12, 13, 14, 41, 42, 43, 55, 62, 65, 72, 75, 79, 80, 81, 83, 105, 108, 116], "clip": [8, 12, 108, 110], "gemm": [8, 12, 108], "model_input": [8, 12, 81, 108], "is_input_quant": [8, 12, 108], "model_output": [8, 12, 108], "config_file_path": 8, "tmp": [8, 12, 17, 22, 32, 44, 58, 66, 73, 84], "open": [8, 12], "w": [8, 12, 84, 90, 116], "f": [8, 12, 15, 16, 27, 49, 73, 80, 81, 90, 91], "dump": [8, 12], "training_range_learning_with_tf_init": [8, 12, 16, 21, 28, 31, 36, 57, 68, 71, 86], "config_fil": [8, 12, 17, 18, 22, 32, 44, 46, 52, 66, 68, 73, 75, 84, 86], "5e": [8, 24, 25, 28, 30, 31, 59, 74, 86], "7": [8, 12, 24, 25, 28, 30, 31, 43, 59, 73, 74, 86, 91, 116], "finetuned_accuraci": [8, 28, 30, 31], "helper": [8, 12, 28, 58, 60, 64, 73], "reestimate_bn_stat": [8, 12, 28, 37, 59, 74], "full": [8, 12, 28, 38, 41, 45, 64, 79, 85, 115], "100": [8, 12, 28, 37, 58, 59, 61, 68, 73, 74], "adapt": [8, 12, 18, 28, 45, 67, 74, 85, 93, 98, 104, 106, 111], "forward": [8, 12, 13, 14, 15, 16, 17, 20, 21, 22, 26, 28, 29, 30, 31, 32, 42, 44, 46, 52, 66, 68, 71, 72, 74, 79, 80, 81, 82, 83, 84, 86, 90, 103, 106, 109, 111], "yield": [8, 12, 28, 52, 66, 71, 74, 84, 110], "directli": [8, 12, 16, 28, 37, 49, 82, 84, 106, 110], "bn_reestim": [8, 12, 28, 37, 59, 74], "real_input": 8, "vstack": 8, "from_tensor_slic": [8, 36, 37, 44, 57, 58, 61, 66], "bn_re_restimation_dataset": [8, 59], "start_op_nam": [8, 9, 22, 59, 60, 62, 65, 66], "bn_re_estimation_dataset": [8, 37, 59], "bn_num_batch": [8, 37, 59], "finetuned_accuracy_bn_reestim": [8, 28], "far": [8, 12, 28, 93], "effici": [8, 12, 28, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "fold_all_batch_norms_to_scal": [8, 12, 28, 37, 59, 74], "resnet50_after_qat": [8, 20], "lead": [9, 29, 44, 52, 66, 84, 93, 95, 105, 109, 110], "shift": [9, 29, 67, 85, 105], "training_range_learning_with_tf_enhanced_init": [9, 16, 21, 31, 36, 57, 71, 86], "aimet_cl": [9, 19], "cle_applied_sess": 9, "under": [9, 29, 39, 62, 98, 106, 108, 113, 114], "hood": [9, 29], "correct_bia": [9, 29, 60, 75], "num_quant_sampl": [9, 29, 60, 75], "num_bias_correct_sampl": [9, 29, 60, 75], "bias_correct": [9, 29, 60, 75], "aimet_bc": 9, "quant_param": [9, 60, 75], "quantparam": [9, 29, 60, 75], "quant_mod": [9, 60], "round_mod": [9, 29, 60, 75], "ops_to_ignor": [9, 60], "bias_correction_param": [9, 60], "biascorrectionparam": [9, 60], "56": 9, "16": [9, 12, 15, 16, 29, 36, 38, 46, 54, 55, 57, 68, 71, 80, 86, 93], "after_bc_sess": 9, "biascorrect": [9, 60], "bias_correct_param": [9, 60], "resnet50_after_qat_range_learn": [9, 21], "smaller": [10, 18, 71, 72, 93, 100, 109, 112, 115], "awai": [10, 18, 93], "image_net_dataset": [10, 11, 12, 17, 18, 19], "imagenetdataset": [10, 11, 12, 17, 18, 19], "get_val_dataset": [10, 11, 12, 17, 18, 19], "include_top": [10, 18, 19], "pool": [10, 12, 18, 19], "rest": [10, 15, 16, 18, 19, 33, 109], "sim": [10, 12, 13, 18, 26, 27, 36, 37, 48, 49, 57, 59, 71, 73, 74, 75, 82, 84, 107, 110], "progbar": [10, 15, 16, 18, 19], "preprocess_input": [10, 15, 16, 18, 19, 33, 38], "sim_model": [10, 15, 16, 17, 18, 19, 26, 28, 29, 30, 31, 32, 71, 86], "tf_dataset": [10, 18, 19], "progbar_stat_upd": [10, 15, 16, 18, 19], "preprocess": [10, 13, 18, 38], "image_dataset_from_directori": [10, 18, 38], "ada_round_data": [10, 18], "label_mod": [10, 18, 38], "categor": [10, 18, 38], "image_width": [10, 18], "image_height": [10, 18], "y": [10, 17, 18, 22, 32, 46, 68, 80, 90, 91, 106], "fo": [10, 18, 71], "r": [10, 18, 71, 84], "Of": [10, 18], "cours": [10, 18], "resnet50_after_adaround": 10, "quick": [10, 18, 98], "dictionari": [11, 12, 38, 61, 76, 84, 86, 87, 99, 102, 108], "adam": [11, 12, 13, 15, 16, 17, 44, 46, 68], "categoricalcrossentropi": [11, 12, 17, 44], "categoricalaccuraci": [11, 12, 17, 44], "thi": [12, 13, 14, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 88, 90, 91, 93, 94, 96, 97, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116], "notebook": [12, 13, 14], "i": [12, 13, 14, 33, 34, 36, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116], "6": [12, 13, 14, 36, 42, 49, 57, 61, 71, 73, 80, 86, 107], "simul": [12, 13, 15, 16, 32, 40, 45, 46, 51, 53, 55, 60, 63, 67, 68, 71, 75, 78, 79, 82, 85, 86, 100, 104, 107, 111], "train_dataset_s": 12, "re_estimation_dataset_s": 12, "train_dataset": 12, "re_estimation_dataset": 12, "built": [12, 13, 89, 90], "sequenti": [12, 13, 14, 41, 42, 108, 109], "subclass": [12, 13, 33, 41, 42], "incompat": [12, 13], "therefor": [12, 13, 14, 97, 105], "conv1": [12, 23, 24, 25, 33, 42, 72, 76, 79, 80, 81, 83, 87], "fuse": [12, 108, 110], "maxpooling2d": 12, "conv2": [12, 42, 55, 76, 79, 80, 83], "flatten": [12, 80], "dens": [12, 13, 14, 41, 42, 43], "functional_model": [12, 13, 14], "baselin": [12, 13, 27, 99, 107], "loss_fn": 12, "qsim": [12, 37], "posit": [12, 13, 14, 42], "quantized_callback": [12, 13, 15, 16], "tensorboard": [12, 13, 15, 16], "log_dir": [12, 13, 15, 16], "histori": [12, 13, 15, 16], "validation_data": [12, 13, 15, 16], "reestim": [12, 37], "mnist_after_bn_re_estimation_qat_range_learn": 12, "standard": [13, 15, 16, 20, 21, 30, 31, 80, 86, 88], "1": [13, 33, 36, 37, 38, 42, 43, 46, 48, 49, 52, 54, 57, 58, 59, 60, 61, 64, 68, 71, 72, 73, 74, 76, 77, 78, 80, 81, 83, 84, 86, 87, 88, 89, 90, 99, 101, 102, 103, 104, 108, 109, 110, 112, 115, 116], "dataset": [13, 33, 36, 37, 38, 44, 49, 52, 54, 57, 58, 59, 60, 61, 66, 68, 71, 73, 74, 75, 84, 86, 98, 104, 105, 110], "2": [13, 33, 36, 38, 42, 43, 46, 49, 54, 57, 58, 59, 61, 64, 68, 71, 72, 73, 74, 76, 78, 80, 81, 83, 84, 86, 89, 90, 93, 104, 109, 110], "3": [13, 33, 36, 38, 39, 43, 44, 46, 49, 50, 52, 54, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 86, 87, 88, 89, 97, 104, 107, 109, 116], "evalu": [13, 27, 33, 36, 38, 44, 46, 52, 54, 57, 58, 61, 62, 65, 66, 71, 73, 76, 84, 86, 87, 94, 98, 99, 102, 104, 106, 107, 110, 113], "4": [13, 17, 22, 23, 32, 33, 36, 37, 43, 44, 49, 52, 57, 58, 59, 61, 66, 71, 73, 74, 75, 76, 80, 83, 84, 86, 95, 99, 104, 116], "imdb": 13, "sentiment": 13, "vocab_s": [13, 14, 42], "20000": [13, 14, 42], "20k": 13, "word": 13, "maxlen": [13, 14, 42], "200": [13, 14, 27, 42], "movi": 13, "review": 13, "x_train": [13, 33, 37], "y_train": [13, 33], "x_val": 13, "y_val": 13, "load_data": 13, "num_word": 13, "pad_sequ": 13, "embed_dim": [13, 14, 42], "embed": [13, 14, 42, 80, 86, 102, 109], "token": [13, 14, 42, 109], "num_head": [13, 14, 42], "attent": [13, 14, 42], "head": [13, 14, 42], "ff_dim": [13, 14, 42], "hidden": [13, 14, 42], "insid": [13, 14, 38, 42, 80, 90], "delta": [13, 14, 42, 44, 52, 66, 84, 110], "input_dim": [13, 14, 42], "output_dim": [13, 14, 42], "block": 13, "multiheadattent": [13, 14, 42, 111], "key_dim": [13, 14, 42], "dropout": [13, 14, 42], "layernorm": [13, 14, 42], "epsilon": [13, 14, 42], "globalaveragepooling1d": [13, 14, 42], "functional_callback": 13, "histogram_freq": 13, "sparse_categorical_crossentropi": 13, "128": [13, 66, 80], "wrap": [13, 15, 16, 17, 19, 22, 32, 80], "wrapper": [13, 19, 26, 29, 30, 31, 36, 44, 52, 57, 61, 66, 76, 84], "effect": [13, 15, 16, 20, 21, 30, 31, 36, 37, 46, 57, 59, 68, 71, 74, 86, 95, 104, 106, 108, 110], "visual": [13, 17, 22, 32, 34, 38, 56, 61, 70, 76, 90, 102, 104, 105, 106, 109, 111, 112, 115], "right": [13, 27, 104, 116], "multi": [13, 33, 65, 85, 111], "encount": 13, "access": [13, 26, 29, 30, 31, 90, 104], "mha": [13, 111], "accur": 13, "clone_lay": 13, "clone": [13, 98], "diagram": [13, 95, 99, 102, 110, 112, 115], "m": [13, 89, 90, 91, 98], "onc": [13, 15, 16, 20, 21, 23, 24, 25, 29, 30, 31, 41, 79, 81, 86, 95, 96, 102, 106, 107, 110], "inspect": 13, "1024": [13, 54, 68, 71, 86, 93, 103], "artifact": [13, 15, 16, 40, 51, 63, 69, 78, 90], "3000": 13, "model_after_qat": [13, 15, 16], "anoth": [13, 16, 21, 31, 86, 115, 116], "most": [13, 108], "complex": [13, 36, 44, 46, 52, 57, 66, 68, 84, 86], "elementari": 13, "logdir": 13, "summari": [13, 69, 88, 94], "vanilla": [13, 16, 21, 27, 31, 109], "tool": [14, 44, 66, 84, 102, 105, 114, 116], "sequanti": 14, "build": [14, 42], "dicuss": 14, "text": [14, 42], "transform": [14, 26, 27, 29, 30, 31, 32, 42, 71, 73, 80, 86, 111], "tokenandpositionembed": [14, 42], "transformerblock": [14, 42], "super": [14, 42, 72, 80, 81], "att": [14, 42], "ffn": [14, 42], "layernorm1": [14, 42], "layernorm2": [14, 42], "dropout1": [14, 42], "dropout2": [14, 42], "kwarg": [14, 42], "attn_output": [14, 42], "out1": [14, 42], "ffn_output": [14, 42], "token_emb": [14, 42], "pos_emb": [14, 42], "random_input": [14, 42], "embedding_lay": [14, 42], "transformer_block": [14, 42], "token_and_position_embed": 14, "re": [14, 33, 45, 67, 85, 98, 104], "symmetr": [14, 55, 108, 110], "model_prepar": [14, 26, 28, 29, 30, 31, 32, 42, 44, 71, 74, 80, 84, 86], "prepare_model": [14, 26, 28, 29, 30, 31, 32, 42, 44, 71, 74, 80, 84, 86], "input_lay": [14, 42], "begin": [14, 42, 72, 80, 81, 107, 108], "unwrap": 14, "ident": [14, 41, 79], "total": [14, 38, 99, 110], "get_weight": 14, "_get_original_models_weights_in_functional_model_ord": 14, "assert": [14, 80], "count_param": 14, "output_shap": 14, "textclassif": 14, "what": [14, 110, 113], "architectur": [14, 68, 85, 97], "sort": 14, "model_weights_in_correct_ord": 14, "class_nam": [14, 38], "enumer": [14, 36, 38, 57, 61, 71, 76, 78, 86, 95], "assert_array_equ": 14, "modelprepar": [14, 26, 29, 30, 31, 32, 37, 42, 71, 80, 86], "arthmet": [14, 42], "experss": [14, 42], "tfoplambda": [14, 42], "ressembl": 14, "conv_1": [14, 42], "conv_2": [14, 42], "becuas": [14, 42, 51], "rais": [14, 42, 61, 68], "except": [14, 17, 22, 32, 42], "hopefulli": [14, 19], "min": [15, 16, 18, 44, 52, 55, 66, 68, 84, 88, 106, 110], "max": [15, 16, 18, 44, 52, 55, 66, 68, 84, 88, 102, 105, 106, 110], "keep": [15, 20, 21, 30, 31, 80, 86, 108, 109], "constant": [15, 20, 21, 30, 31, 49, 58, 73, 80, 86, 99, 104], "assign": [15, 16, 55], "dataset_train": [15, 16], "dataset_valid": [15, 16], "respect": [15, 16, 41, 61, 88, 106], "glob": [15, 16], "decode_exampl": [15, 16], "decod": [15, 16], "parse_single_exampl": [15, 16], "fixedlenfeatur": [15, 16], "int64": [15, 16], "string": [15, 16, 55, 108], "image_data": [15, 16], "cast": [15, 16], "int32": [15, 16], "decode_jpeg": [15, 16], "get_imagenet_dataset": [15, 16], "dataset_path": [15, 16], "split_nam": [15, 16], "num_parallel_read": [15, 16], "tfrecorddataset": [15, 16], "glob_nam": [15, 16], "tf_record_fil": [15, 16], "num_parallel_cal": [15, 16], "being": [15, 16, 19, 38, 41, 43, 55, 61, 76, 79, 80, 81, 83, 84], "categorical_crossentropi": [15, 16, 46], "hyperparamet": [15, 16, 107], "henc": 16, "jointli": [16, 20, 21, 30, 31], "ye": [16, 91, 102], "due": [16, 34, 42, 67, 81, 85, 104, 105], "restrict": [16, 103], "prevent": [16, 72, 80, 96], "mention": 16, "kei": [16, 21, 31, 43, 55, 60, 65, 83, 91], "continu": [16, 21, 31, 42, 81, 86, 104, 105, 107, 109], "benefit": [16, 21, 31, 55, 93], "analys": [17, 22, 32, 106], "respond": [17, 22, 32], "One": [17, 22, 26, 29, 30, 31, 32, 44, 46, 60, 66, 68, 97, 102, 112], "second": [17, 22, 32, 42, 58, 71, 108], "anyth": [17, 22, 32], "item": [17, 22, 32, 49, 104], "tupl": [17, 22, 32, 33, 36, 37, 38, 40, 43, 44, 46, 52, 57, 58, 61, 63, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 84, 86], "dummi": [17, 22, 32, 36, 46, 48, 57, 71, 72, 73, 77, 78, 83, 84, 86, 106], "val_dataset": 17, "callbackfunc": [17, 22, 32, 44, 52, 66, 84], "exactli": [17, 22, 32, 58, 110], "multipl": [17, 22, 32, 38, 61, 65, 68, 72, 73, 76, 77, 78, 80, 81, 83, 86, 87, 89, 91, 100, 102, 104, 111], "eval_func": [17, 38, 61, 87], "v": [17, 22, 32, 36, 57, 71, 90, 99], "demonstr": [17, 22, 32], "quant_analyz": [17, 22, 32, 44, 52, 66, 84], "enable_per_layer_mse_loss": [17, 32, 44, 52, 84], "track": [17, 22, 32, 106], "minimum": [17, 22, 32, 36, 57, 71, 80, 86, 88, 89], "histogram": [17, 22, 32, 44, 52, 66, 69, 84, 88, 104, 106, 110, 111], "seen": [17, 22, 32, 105, 106], "results_dir": [17, 22, 32, 44, 52, 58, 66, 69, 73, 84, 88], "html": [17, 22, 32, 80, 84, 90, 91, 97, 106, 111, 114], "plot": [17, 22, 32, 69, 88, 106], "per_layer_quant_en": [17, 32, 106], "per_layer_quant_dis": [17, 32, 106], "min_max_rang": [17, 22, 32, 106], "activations_pdf": [17, 22, 32, 106], "name_": [17, 32, 84], "index_0": [17, 32], "index_1": [17, 32], "index_n": [17, 32], "weights_pdf": [17, 22, 32, 106], "layer1": [17, 32, 43, 65, 83], "param_name_": [17, 22, 32, 84], "channel_index_0": [17, 22, 32], "channel_index_1": [17, 22, 32], "channel_index_n": [17, 32], "layer2": [17, 32, 43, 65, 83], "layern": [17, 32], "per_layer_mse_loss": [17, 32, 106], "sub": [17, 22, 32, 72, 91, 96, 102, 110, 116], "basi": [18, 55, 99, 102], "between": [18, 36, 38, 43, 57, 61, 65, 66, 71, 76, 78, 83, 84, 91, 105, 106, 108, 110], "imagin": 18, "filter": [18, 42], "kernel": [18, 96, 112, 115], "28": [18, 76], "were": [18, 27, 30, 31, 40, 43, 51, 55, 63, 65, 71, 78, 83, 86, 91, 97, 104, 108, 116], "entireti": [18, 42], "contrast": [18, 42], "repeat": [18, 58, 96], "uniqu": 18, "attribut": [18, 42, 80, 106], "conv2d_lay": 18, "kernel_s": [18, 42, 72, 80, 81], "snpe": [18, 19], "qnn": [18, 19], "config": [18, 46, 66, 68, 84, 108, 111], "style": 18, "mismatch": 18, "togeth": [18, 102], "pcq_quantsim_config": 18, "tell": [18, 113], "did": [18, 105], "resnet50_pcq_adaround": 18, "mimic": 19, "cle_applied_model": [19, 39], "yaml": 19, "h5": [19, 40, 100, 104], "savedmodel": 19, "protobuff": 19, "safe": 19, "resnet50_after_cl": 19, "Then": [20, 21, 30, 31, 36, 52, 57, 71, 84, 86], "meta": [20, 33, 61, 63, 68, 100, 104], "No": [22, 75, 81, 104], "func": [22, 84], "func_callback_arg": [22, 52, 66, 84], "data_pipelin": 22, "per_op_quant_en": 22, "per_op_quant_dis": 22, "quant_op_name0": 22, "quant_op_name1": 22, "quant_op_namen": 22, "op1": 22, "channel_index_x": 22, "op2": 22, "channel_index_i": 22, "opn": 22, "channel_index_z": 22, "per_op_mse_loss": 22, "nn": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 76, 79, 80, 81, 82, 83, 84, 86, 103, 111], "modul": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 41, 61, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 88, 89, 93, 104, 111, 116], "gpu": [23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 60, 61, 66, 68, 76, 78, 85, 89, 90, 104, 111], "learning_rate_schedul": [23, 24, 25, 28, 30, 31, 74, 86], "schedul": [23, 24, 25, 28, 30, 31, 107], "max_epoch": [23, 24, 25, 28, 30, 31], "is_avail": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 74], "aimet_torch": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 86, 87, 88, 89, 90, 91, 103], "compressed_model": [23, 24, 38, 61, 76], "15e": [23, 25], "prune": [24, 38, 97, 98, 99, 101, 102, 111, 116], "ssvd_compressed_model": 25, "ssvd_cp_compressed_model": 25, "ssvd_cp_finetuned_model": 25, "certain": [26, 29, 30, 31, 32, 71, 79, 80, 84, 86, 102, 103, 104, 108], "guidelin": [26, 29, 30, 31, 32, 34, 45, 48, 54, 56, 58, 68, 71, 80, 85, 93, 97, 107], "rand": [26, 28, 29, 30, 31, 32, 33, 36, 44, 57, 58, 61, 66, 72, 78, 81], "modif": [26, 29, 30, 31], "made": [26, 29, 30, 31, 80, 108], "overrid": [26, 29, 30, 31, 61, 73, 80, 86], "no_grad": [26, 27, 29, 30, 31, 32, 71, 81, 86], "ptq": [27, 58, 73, 100, 104, 106, 107], "success": 27, "care": 27, "non": [27, 72, 80, 110], "expert": 27, "effort": [27, 58, 73, 94], "known": [27, 81, 99, 100], "heurist": [27, 61], "cumul": 27, "until": [27, 58, 73, 94], "val_transform": 27, "compos": [27, 73], "centercrop": 27, "totensor": [27, 73], "normal": [27, 43, 72, 95, 106], "485": 27, "456": 27, "406": 27, "std": 27, "229": 27, "225": 27, "imagenet_dataset": 27, "imagefold": 27, "root": 27, "eaxmpl": 27, "tqdm": 27, "subsetrandomsampl": [27, 73], "in_eval_mod": 27, "get_devic": 27, "_dataset": [27, 73], "logit": 27, "topk": [27, 49], "k": [27, 112], "view_a": 27, "unlabeleddatasetwrapp": [27, 73], "__getitem__": [27, 73], "unlabeled_imagenet_dataset": 27, "unlabeled_imagenet_data_load": 27, "initial_accuraci": [27, 49, 73], "run_infer": [27, 49, 73], "predefin": [27, 99], "empir": [27, 60, 105], "adaround_data_load": [27, 49, 73], "furhter": 27, "optimized_accuraci": [27, 49, 73], "train_load": [28, 74, 76], "images_dir": 28, "resnet18_after_qat": [28, 30, 31], "bc_param": 29, "weight_bw": [29, 75], "act_bw": [29, 75], "resnet18_after_cle_bc": 29, "matter": 32, "involv": [33, 104, 109], "four": [33, 110], "convert_tf_sess_to_kera": 33, "save_tf_session_single_gpu": 33, "sourc": [33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 87, 88, 90, 91, 109], "variabl": [33, 38, 42, 61, 76, 80, 90, 91, 98], "load_tf_sess_variables_to_keras_single_gpu": 33, "compressed_op": 33, "save_session_graph_and_vari": 33, "creation": 33, "compress": [33, 34, 35, 56, 70, 96, 98, 100, 111, 112, 114, 115, 116], "isol": 33, "strategi": 33, "save_as_tf_module_multi_gpu": 33, "loading_path": 33, "saving_path": 33, "load_keras_model_multi_gpu": 33, "funetun": 33, "instanc": [33, 61, 80, 81, 86, 113], "moblinetv1": 33, "convert_tf_session_to_keras_model": 33, "mirroredstrategi": 33, "get_sess_from_keras_model": 33, "mobilnetv1": 33, "compress_sess": 33, "mobilenet": 33, "act_softmax": 33, "saved_model_single_gpu": 33, "correspnd": 33, "set_learning_phas": 33, "saved_model_multi_gpu": 33, "scope": [33, 80], "vgg16": [33, 61], "modulecompratiopair": [33, 38, 61, 76], "compressible_op": 33, "layer_a": 33, "list_of_module_comp_ratio_pair": [33, 38, 61, 76], "manual_param": [33, 61, 76], "manualmodeparam": [33, 38, 61, 76], "pylint": 33, "unus": 33, "to_categor": [33, 46], "rmsprop": 33, "mse": [33, 44, 52, 66, 84, 106, 110], "qualcomm": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "innov": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "center": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "inc": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "ai": [33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "toolkit": [33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "quantsim_config": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "default_config": [33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "softwar": [34, 100, 102], "dramat": 34, "lost": [34, 100], "At": [34, 97, 102], "onnx": [34, 55, 73, 78, 79, 86, 89, 90, 98, 100, 103, 104, 108], "link": [34, 89, 98], "debug": [34, 35, 36, 40, 47, 51, 55, 56, 57, 61, 63, 70, 78, 109], "codebas": 34, "sphinx": 34, "page": [34, 90, 91, 97, 110, 111], "model": [35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116], "default_reg_param": [36, 57, 71], "default_beta_rang": [36, 57, 71], "default_warm_start": [36, 57, 71], "datasetv2": [36, 37, 57, 60, 61], "beta": [36, 57, 71, 93], "anneal": [36, 57, 71], "start_beta": [36, 57, 71], "end_beta": [36, 57, 71], "warm": [36, 57, 71, 93], "period": [36, 57, 71, 93], "zero": [36, 57, 60, 71, 110, 111], "post_training_percentil": [36, 57, 71, 86], "percentil": [36, 57, 71, 86], "absolut": [36, 57, 61, 71, 76, 86], "nois": [36, 57, 67, 71, 85, 86, 104, 105, 106, 107, 108], "aimetlogg": [36, 57], "test_model": [36, 57], "keras_model": [36, 57], "dummy_forward_pass": [36, 57], "intend": [36, 44, 52, 55, 57, 61, 66, 76, 84, 97], "match": [36, 40, 44, 51, 52, 57, 61, 63, 66, 76, 78, 84, 86, 96, 102, 106, 108, 109, 110, 116], "Or": [36, 44, 46, 52, 57, 66, 68, 78, 80, 84, 86, 102], "someth": [36, 44, 46, 52, 57, 66, 68, 84, 86, 102, 113], "apply_adaround_exampl": [36, 48, 57], "set_level_for_all_area": [36, 57], "dataset_s": [36, 57, 66], "possible_batch": [36, 57], "w4a8": [36, 57], "param_bw": [36, 57, 71, 73], "output_bw": [36, 57, 71, 73], "adarounded_model": [36, 71], "adarounded_sess": [36, 57], "grid": [36, 57, 71], "handl": [37, 59, 73, 74], "undo": [37, 59, 74], "upon": [37, 59, 74], "remov": [37, 59, 73, 74, 80, 90, 96, 100, 110, 116], "batch_norm": [37, 43, 59, 65, 74, 83], "qcquantizewrapp": [37, 74], "pair": [37, 38, 43, 61, 65, 74, 75, 76, 83], "got": [37, 65, 74, 80, 83], "prepar": [37, 41, 44, 45, 49, 52, 58, 66, 71, 73, 79, 84, 85, 86, 94, 104, 111], "overal": [38, 61, 71, 76, 86, 97, 102, 109], "algorithm": [38, 55, 60, 61, 76, 97, 99, 102, 109, 116], "pick": [38, 42, 43, 60, 61, 65, 76, 97, 99, 102], "tweak": [38, 43, 61, 65, 76, 83], "compressor": [38, 61, 76], "static": [38, 42, 61, 65, 76, 80, 110], "visualization_url": [38, 61, 76, 87], "callabl": [38, 58, 61, 68, 71, 73, 74, 76, 80, 84], "cost": [38, 61, 76, 99, 102, 107], "url": [38, 61, 76, 87, 90, 91, 98, 113], "appear": [38, 43, 61, 65, 72, 76, 80, 81, 83], "compressionstat": [38, 61, 76], "use_monotonic_fit": [38, 61, 76], "saved_eval_scores_dict": [38, 61, 76, 87], "express": [38, 61, 76], "comp": [38, 61, 76], "greater": [38, 43, 61, 65, 76, 83], "monoton": [38, 61, 76, 99], "pickl": [38, 61, 76], "experi": [38, 61, 76, 102], "union": [38, 40, 42, 43, 46, 61, 62, 63, 65, 68, 71, 72, 73, 75, 76, 77, 78, 83, 84, 86], "rank": [38, 61, 76, 112, 115], "noth": [38, 61, 76], "space": [38, 61, 76], "weight_svd": [38, 61, 76], "comp_ratio": [38, 61, 76], "decode_predict": 38, "aimet_common_def": 38, "aimet_tensorflow_def": 38, "get_eval_func": 38, "50000": 38, "func_wrapp": 38, "validation_d": 38, "inp_data": 38, "img": 38, "pred": [38, 49], "cnt": 38, "b": [38, 59, 74], "aimet_spatial_svd": 38, "evalfunct": 38, "driver": [38, 89, 91], "stat": [38, 61, 74, 76], "three": [39, 62, 80, 94, 97, 114], "comprehens": [39, 62], "detect": [39, 62, 102], "shall": [39, 55, 62], "rtype": [39, 42, 43], "cross_layer_equalization_auto": [39, 62, 77], "individu": [39, 43, 62, 65, 77, 84, 95, 96, 97, 99, 102, 104, 106, 109], "intermedi": [40, 51, 63, 72, 73, 78, 86, 110], "accord": [40, 51, 63, 78, 104, 107, 108, 110], "comparison": [40, 51, 63, 78], "amongst": [40, 51, 63, 78], "miss": [40, 42, 51, 55, 63, 78, 81], "issu": [40, 42, 51, 63, 72, 78, 81, 95, 100, 103, 109, 111, 113, 114], "layer_output_util": [40, 51, 63, 78], "layeroutpututil": [40, 51, 63, 78], "save_dir": 40, "keraslayeroutput": 40, "implement": [40, 44, 46, 49, 52, 58, 63, 66, 73, 78, 84, 86, 103, 109], "constructor": [40, 43, 60, 61, 63, 75, 78, 79, 80, 83, 86], "generate_layer_output": [40, 51, 63, 78], "input_batch": [40, 51, 63, 78], "disk": [40, 63, 78], "obtain": [40, 43, 51, 52, 55, 60, 63, 65, 78, 83, 91, 96, 97, 106, 110], "aimet_export_artifact": [40, 51, 63, 78], "sake": [40, 51, 63, 78], "simplic": [40, 51, 63, 78], "mandatori": [40, 51, 63, 78], "load_encodings_to_sim": [40, 51, 63, 78], "construct": [40, 51, 61, 63, 72, 78, 103], "properli": [40, 51, 63, 78], "get_pre_processed_input": [40, 51, 63, 78], "fp32_layer_output_util": [40, 51, 63, 78], "fp32_layer_output": [40, 51, 63, 78], "quantsim_layer_output_util": [40, 51, 63, 78], "quantsim_layer_output": [40, 51, 63, 78], "sever": [41, 45, 64, 79, 81, 85, 97], "encourag": [41, 42, 45, 79, 80, 85], "format": [41, 43, 46, 57, 60, 61, 65, 68, 71, 84, 86, 89, 94, 101], "get_model": 41, "mix": [41, 60], "reus": [41, 79, 80, 81], "had": [41, 79], "x2": [41, 79, 80], "relu2": [41, 42, 79, 81], "manditori": 42, "submodul": [42, 79], "inherit": 42, "original_model": 42, "pure": [42, 79], "inputlay": 42, "portion": 42, "get_text_classificaiton_model": 42, "model_preparer_two_subclassed_lay": 42, "get_subclass_model_with_functional_lay": 42, "sigmoid": [42, 80], "binary_classifi": 42, "myfunctionalmodel": 42, "my_functional_model": 42, "classifi": 42, "model_preparer_subclassed_model_with_functional_lay": 42, "resembl": 42, "piec": [42, 80], "python": [42, 61, 68, 86, 89, 90, 91], "caus": [42, 103, 109, 110], "trace": [42, 73, 79], "symbol": 42, "touch": 42, "static_patch_count": 42, "guarante": 42, "verifi": [42, 80], "furthermor": 42, "resu": 42, "resblock": 42, "twice": 42, "bad": 42, "bn1": [42, 72, 81, 83], "bn2": 42, "relu1": [42, 79, 81], "plug": [43, 65, 83], "conv2dtranspos": 43, "depthwiseconv2d": [43, 101], "crosslayersc": [43, 60, 65, 83], "scale_model": [43, 65, 83], "clssetinfo": [43, 65], "highbiasfold": [43, 60, 65, 83], "bias_fold": [43, 65, 83], "cls_set_info_list": [43, 65, 83], "bn_layer": [43, 83], "sigma": [43, 65, 83], "element": [43, 55, 65, 83], "model_transform_util": 43, "replace_relu6_with_relu": 43, "cross_layer_equalization_auto_stepwis": [43, 65], "relu6": [43, 62, 65, 75, 83, 105], "model_for_cl": 43, "folded_pair": [43, 65, 83], "bn_dict": [43, 83], "conv_or_linear": 43, "group": [43, 65, 90, 108, 110], "fold_given_batch_norm": [43, 60, 65, 83], "layer_pair": [43, 65, 83], "conv_linear": 43, "is_batch_norm_second": 43, "scale_cls_set": [43, 65, 83], "cls_set": [43, 65, 83], "ndarrai": [43, 63, 65, 83], "cls_pair_1": [43, 65, 83], "cls_pair_2": [43, 65, 83], "hold": [43, 65, 75, 83, 108], "along": [43, 60, 65, 83, 107, 110], "depth": [43, 83, 97, 109], "wise": [43, 76, 83, 84, 109], "clssetlayerpairinfo": [43, 65, 83], "scale_factor": [43, 65, 83], "relu_activation_between_lay": [43, 65, 83], "relat": [43, 60, 61, 62, 65, 75, 76, 83, 106, 110], "whose": [43, 63, 78, 80, 83, 105, 108, 116], "cross_layer_equalization_manu": [43, 65, 83], "get_example_layer_pairs_resnet50_for_fold": 43, "consecutive_layer_list": [43, 65, 83], "get_consecutive_layer_list_from_resnet50_for_sc": [43, 65], "scaling_factor_list": [43, 65, 83], "format_info_for_high_bias_fold": [43, 65], "conv_op_1": [43, 65], "bn_op_1": [43, 65], "conv_op_2": [43, 65], "bn_op_2": [43, 65], "conv_op_3": [43, 65], "bn_op_3": [43, 65], "11": [43, 55, 89, 91], "bn_op": [43, 65], "upstream": [43, 65, 96, 116], "downstream": [43, 55, 65], "usag": [43, 55, 64, 65, 81, 86, 97, 98, 102, 109], "conv_op": [43, 65, 69], "bn_op_with_meta": [43, 65], "_fold_upstream_flag": [43, 65], "boolean": [43, 65], "is_relu_activation_in_cls_set": [43, 65], "fill": [43, 65, 73, 86], "create_cls_set_info_list": [43, 65], "quantanalyz": [44, 52, 53, 66, 67, 84, 104, 111], "pdf": [44, 66, 84, 111], "scalar": [44, 52, 58, 66, 84], "hotspot": [44, 66, 84, 106], "31": [44, 57, 58, 61, 71, 72, 75, 84, 86, 89, 90, 91], "toi": 44, "256": [44, 52, 66, 84, 106], "num_class": [44, 46, 58, 73], "ey": 44, "label_dataset": [44, 58], "own": [44, 49, 52, 54, 58, 59, 66, 68, 71, 73, 74, 75, 84, 86], "goal": [44, 49, 52, 58, 73, 84, 94], "action": [44, 52, 54, 59, 66, 68, 71, 74, 75, 84, 86, 116], "prepared_model": [44, 71, 80, 84, 86], "forward_pass_callback_fn": [44, 52, 66, 84], "eval_callback_fn": [44, 52, 66, 84], "approxim": [44, 52, 66, 84, 93, 97, 105, 106], "quant_analyzer_result": [44, 52, 66, 84], "abil": [45, 53, 67, 85, 111], "hardwar": [45, 53, 67, 85, 88, 104, 105, 110], "in_plac": [46, 86], "default_data_typ": [46, 68, 86], "quantizationdatatyp": [46, 68, 86], "mechan": [46, 80, 86], "custom_object": 46, "convert_to_pb": 46, "store": [46, 57, 60, 65, 68, 71, 86], "pth": [46, 68, 76, 78, 86], "prefix": [46, 57, 61, 68, 71, 86], "quantize_model": [46, 54, 68], "dummy_x": 46, "dummy_i": 46, "randint": [46, 58], "lr": 46, "001": 46, "write": [48, 54, 68, 71, 86], "ada_rounded_model": 48, "math": 49, "auto_quant_v2": [49, 73], "onnx_model": [49, 50, 52, 54], "dummy_data": [49, 52, 54], "astyp": [49, 52, 54], "float32": [49, 52, 54], "Its": 49, "fed": 49, "unlabelled_data_load": 49, "ceil": [49, 71], "num_of_sampl": 49, "evaldataload": 49, "acc_top1": 49, "acc_top5": 49, "batch_avg_top_1_5": 49, "4f": [49, 73], "happen": [50, 77], "dummy_input_dict": 51, "serializetostr": 51, "dir_path": [51, 63, 78], "interest": [52, 84], "create_quantsim_and_encod": 52, "unlabeled_data_load": [52, 73, 84], "_get_unlabled_data_load": [52, 84], "unlabeled_dataset_iter": [52, 73, 84], "autoqu": [53, 67, 85, 98, 104, 107, 111], "unifi": [53, 67, 85], "integr": [53, 58, 67, 73, 82, 85, 104], "max_batch_count": [54, 68, 71, 86], "current_batch_count": [54, 68, 71, 86], "use_symmetric_encod": 54, "forward_pass_funct": 54, "syntax": 55, "usabl": 55, "xx": 55, "yy": 55, "zz": 55, "major": [55, 102], "revis": 55, "minor": [55, 111], "patch": 55, "substanti": 55, "fulli": [55, 61, 101], "bug": [55, 111], "backward": [55, 83], "assum": [55, 73, 90, 91], "activation_encod": 55, "tensor_nam": 55, "param_encod": 55, "constraint": 55, "represent": 55, "depict": 55, "6086959838867188": 55, "109158515930176": 55, "114": 55, "018501389771699905": 55, "21": 55, "558866932988167": 55, "12636379897594452": 55, "12": [55, 89], "010530316270887852": 55, "06318144500255585": 55, "06268782913684845": 55, "127": 55, "0004936049808748066": 55, "fc1": [55, 80], "05589814856648445": 55, "05546144023537636": 55, "0004367042565718293": 55, "184721499681473": 55, "10788747668266296": 55, "0089906234367221": 55, "conv2d_1": [55, 61], "1020304188132286": 55, "10380396991968155": 55, "008650330936207491": 55, "readvariableop": [55, 68], "1462666392326355": 55, "1451239287853241": 55, "126": 55, "0011427081098743512": 55, "08333279937505722": 55, "08268175274133682": 55, "0006510374592799766": 55, "includ": [55, 58, 73, 86, 89, 95, 102, 104, 106, 108, 110, 111], "field": 55, "dtype": [55, 80], "datatyp": 55, "snippet": [55, 80], "highlight": [55, 105, 113, 114], "quantizer_arg": 55, "activation_bitwidth": 55, "param_bitwidth": 55, "popul": [55, 60], "broken": 55, "occur": [55, 61, 68], "who": 55, "knowledg": 55, "default_config_fil": [57, 58, 71], "conv2d_input": 57, "reset_default_graph": [57, 63, 68], "init": [57, 61], "get_default_graph": 57, "default_rounding_mod": 58, "manner": [58, 73, 94], "meet": [58, 73, 89, 94, 97, 99], "datasetv1": [58, 59, 66], "unless": [58, 75, 91, 116], "n": [58, 84, 111], "andoutput": 58, "fp32_sess": 58, "cache_id": [58, 73], "explicitli": [58, 73, 116], "preced": [59, 74, 108], "var": [59, 74, 91], "load_fp32_model": [59, 74], "imagenetpipelin": [59, 74], "quant_sim": [59, 74, 86], "main": [60, 95, 108, 111, 114], "reference_model": 60, "conv_bn_dict": [60, 75], "perform_only_empirical_bias_corr": [60, 75], "convbninfotyp": 60, "find_all_convs_bn_with_activ": 60, "nest": 60, "graphsearchutil": [60, 65], "biasutil": [60, 65], "bias_correction_empir": 60, "biascorrectparam": 60, "fc1000": [60, 62, 65], "_new_sess": 60, "analyt": [60, 105, 113, 114], "bias_correction_empirical_analyt": 60, "bias_correction_after_cl": 60, "sess_after_cl": 60, "bias_correction_per_lay": 60, "corrected_model": 60, "layer_name_to_be_correct": 60, "analytical_bias_correction_per_lay": 60, "preceeding_bn_layer_info": 60, "is_first_conv": 60, "bc": [60, 93], "preceed": [60, 95], "bias_correction_single_layer_empir": 60, "initialize_model_with_bia": 60, "example_conv_lay": 60, "res2a_branch2a": [60, 65], "bias_correction_single_layer_analyt": 60, "convs_bn_activation_info_dict": 60, "sure": [60, 99, 103], "preceding_bn_layer_info": 60, "tar": 61, "train_model": [61, 76], "train_flag": [61, 76], "channels_last": 61, "downsamplelay": 61, "upsamplelay": 61, "teh": [61, 116], "evaluate_model": [61, 76], "honor": [61, 76], "obvious": [61, 76], "spatial_svd_auto_mod": [61, 76], "block1_conv1": 61, "compr_model_sess": 61, "pretti": [61, 76], "spatial_svd_manual_mod": [61, 76], "block1_conv2": 61, "channel_pruning_auto_mod": [61, 76], "channel_pruning_manual_mod": [61, 76], "block1_conv2_op": 61, "block2_conv2_op": 61, "block2_conv2": 61, "checkpoint": [61, 68, 86, 104], "output_fil": 61, "svd_graph": 61, "svd_type": 61, "num_lay": 61, "layer_rank": 61, "num_rank": 61, "no_evalu": 61, "layer_selection_threshold": 61, "connect": [61, 96, 101, 115], "balanc": [61, 102], "multipli": [61, 97], "accumul": [61, 97], "footprint": 61, "ssvd": [61, 97], "length": 61, "compression_point": 61, "valueerror": [61, 68], "compress_net": 61, "eval_nam": 61, "run_graph": 61, "evaluate_graph": [61, 68], "default_eval_func": [61, 68], "error_margin": 61, "avg": 61, "graph_ev": [61, 68], "prototyp": 61, "accept": [61, 105, 109], "degrad": [61, 102], "invalid": [61, 80], "runtimeerror": 61, "tfrecord_gener": 61, "tf_gen": [61, 68], "mnistpars": [61, 68], "weight_svd_auto_mod": [61, 76], "alloc": [61, 68], "wish": [61, 68, 90, 91], "tfrecordgener": [61, 68], "mnist": [61, 68, 76], "parser": [61, 68], "mnist_sav": [61, 68], "95": 61, "pretty_print": 61, "weight_svd_manual_mod": [61, 76], "matmul_1": 61, "connectedgraph": [62, 65, 81], "hbf": [62, 65, 93], "new_sess": 62, "wherein": [63, 78], "saver": 63, "import_meta_graph": 63, "restor": [63, 86, 109], "trainbl": 64, "recompil": 64, "temp": 64, "clean": 64, "recurr": [64, 111], "rnn": [64, 111], "lstm": [64, 111], "graph_util": 65, "after_relu_replace_sess": 65, "find_and_replace_relu6_with_relu": 65, "after_bn_fold_sess": 65, "after_cls_sess": 65, "after_hbf_sess": 65, "updated_sess": 65, "map_cls_sets_to_new_sess": 65, "tf_names_op_dict": 65, "get_layer_pairs_resnet50_for_fold": 65, "after_fold_sess": 65, "graph_search": 65, "bn2a_branch2a": 65, "cond": 65, "fusedbatchnorm_1": 65, "res2a_branch2b": 65, "bn2a_branch2b": 65, "res2a_branch2c": 65, "bn2a_branch2c": 65, "conv1_op": 65, "conv1_depthwise_op": 65, "conv1_pointwise_op": 65, "temp_cl": 65, "model_start_op_nam": 66, "model_output_op_nam": 66, "learnt": 68, "orig_sess": 68, "quantisim": 68, "tutori": 68, "load_model_from_meta": 68, "reshape_input": 68, "dense_1": 68, "biasadd": 68, "trainingextens": [68, 86], "src": [68, 86], "quantization_aware_training_range_learn": 68, "parser2": 68, "generator2": 68, "cross_entropi": 68, "xent": 68, "train_step": 68, "simultan": 68, "fc1_w": 68, "matmul": [68, 111], "perf": 68, "ce": 68, "adamoptim": 68, "tempadam": 68, "initialize_uninitialized_var": 68, "read_data_set": 68, "one_hot": 68, "next_batch": 68, "plotting_util": 69, "visualize_weight_ranges_single_lay": 69, "scatter": [69, 88], "bokeh": [69, 87, 88], "visualize_relative_weight_ranges_single_lay": 69, "publish": [69, 87, 88], "visualizing_weight_ranges_for_single_lay": 69, "visualiza": 69, "visualizing_relative_weight_ranges_for_single_lay": 69, "param_bw_override_list": 71, "ignore_quant_ops_list": 71, "pars": [71, 83, 86], "affect": [71, 95, 108, 116], "commonli": 71, "10k": 71, "15k": 71, "get_train_dataload": [71, 74], "quantized_resnet18": [71, 86], "experiment": [72, 102, 108], "arch_check": 72, "archcheck": 72, "check_model_arch": 72, "result_dir": 72, "_node_check_dict": 72, "record": [72, 84], "fail": [72, 80, 81, 94, 103, 104], "arch_checker_report": 72, "dotted_name_op": 72, "nodeerrorreportobject": 72, "archcheckerreport": 72, "condit": [72, 80, 81], "less": [72, 96, 99], "modelwithnotenoughchannel": 72, "prelu": 72, "stride": [72, 80, 81], "batchnorm2d": [72, 81, 83], "example_check_for_number_of_conv_channel": 72, "fewer": 72, "logger": [72, 81], "_check_conv_channel_32_bas": 72, "_check_conv_channel_larger_than_32": 72, "layer_nam": [72, 84], "modelwithprelu": 72, "prelu1": 72, "example_check_for_non_performant_activ": 72, "num_paramet": 72, "_activation_check": 72, "modelwithnonfoldablebn": 72, "foldabl": 72, "avg_pool1": 72, "avgpool2d": 72, "example_check_for_standalone_bn": 72, "averagepool": 72, "ep": 72, "05": [72, 91], "momentum": 72, "affin": 72, "track_running_stat": 72, "_check_batch_norm_fold": 72, "strict_valid": 73, "id": [73, 87, 90, 113], "cach": [73, 91], "hen": 73, "proce": 73, "unid": 73, "unintuit": 73, "get_quant_scheme_candid": 73, "highest": [73, 99], "_quantschemepair": 73, "set_export_param": 73, "onnx_export_arg": [73, 78, 86], "propagate_encod": [73, 86], "onnxexportapiarg": [73, 78, 86], "torchscript": [73, 78, 86], "entri": [73, 86, 108], "bw": [73, 79, 86], "data_typ": [73, 86], "set_model_preparer_param": 73, "modules_to_exclud": [73, 80], "module_classes_to_exclud": [73, 80], "concrete_arg": [73, 80], "exclud": [73, 80, 81, 84], "partial": [73, 80], "special": [73, 80], "control": [73, 80, 110], "flow": [73, 80, 82, 95, 104, 107, 109, 110], "fx": 73, "won": [73, 80], "symbolic_trac": [73, 80], "set_quant_scheme_candid": 73, "_subset_sampl": 73, "sampler": 73, "fp32_model": 73, "fakedata": 73, "eval_data_load": 73, "dim": 73, "deprec": [73, 104], "dummy_input_on_cpu": 73, "dummy_input_on_gpu": 73, "layers_to_ignor": 75, "remain": [75, 99, 104, 105, 110], "calc": 75, "corr": 75, "irrespect": 75, "fact": 75, "elig": 75, "input_bn": 75, "output_bn": 75, "in_activation_typ": 75, "no_activ": 75, "out_activation_typ": 75, "hode": 75, "mobilenetv2": [75, 83], "512": 75, "module_prop_dict": 75, "find_all_conv_bn_with_activ": 75, "weightsvdparamet": 76, "tarrankselectionparamet": 76, "num_rank_indic": 76, "rank_select_schem": 76, "select_param": 76, "rankselectschem": 76, "mnist_trained_on_gpu": 76, "rank_select": 76, "mnist_torch_model": 76, "dataloadermnist": 76, "_layer_db": 76, "ture": 76, "batch_callback": 76, "spatial_svd_auto_mode_with_layerwise_finetun": 76, "naming_schem": 78, "namingschem": 78, "consist": [78, 94, 110, 116], "numer": 78, "onnx_util": 78, "pythonpath": [78, 98], "successfulli": [78, 103], "map_loc": 78, "model_torch": 78, "convers": [79, 109], "onnx_file_nam": 79, "jit": 79, "traceabl": [79, 80], "stateless": 79, "former": 79, "retrain": 79, "whenev": 79, "image_rgb": 79, "rgb_output": 79, "image_bw": 79, "bw_output": 79, "rgb": 79, "elementwis": [80, 111], "unrol": 80, "independ": [80, 109], "duplic": 80, "graphmodul": 80, "modelwithfunctionalrelu": 80, "9216": 80, "fc2": 80, "model_preparer_functional_exampl": 80, "allclos": 80, "modelwithreusedrelu": 80, "model_preparer_reused_exampl": 80, "modelwithelementwiseaddop": 80, "x1": 80, "model_preparer_elementwise_add_exampl": 80, "dynam": [80, 105, 110, 111, 114], "statement": [80, 103], "branch": [80, 98, 108], "weren": 80, "traceerror": 80, "workaround": [80, 103], "problem": [80, 109], "across": [80, 105, 106], "Such": 80, "concret": 80, "truli": 80, "custom_function_not_to_be_trac": 80, "call_funct": 80, "__torch_function__": 80, "sqrt": 80, "modelwithnontorchfunct": 80, "model_transform": 80, "tracer": 80, "is_leaf_modul": 80, "leaf": [80, 111], "expos": [80, 93], "module_to_exclud": 80, "examin": 80, "custommodul": 80, "softplu": 80, "custommodel": 80, "arang": 80, "traceback": 80, "typeerror": 80, "receiv": 80, "proxi": 80, "layout": 80, "pin_memori": 80, "requires_grad": 80, "problemat": [80, 109, 114], "determinist": 80, "hard": 80, "do_not_trace_m": 80, "share": [81, 91], "modelwithreusednod": 81, "inplac": 81, "2592": 81, "view": [81, 100, 103, 113], "model_valid": 81, "modelvalid": 81, "validate_example_model": 81, "validate_model": 81, "validate_for_reused_modul": 81, "0x7f127685a598": 81, "resolv": 81, "warn": [81, 104], "redefin": 81, "distinct": 81, "rewrit": [81, 103], "modelwithoutreusednod": 81, "rerun": 81, "0x7ff577373598": 81, "validate_for_missing_modul": 81, "0x7ff5703eff28": 81, "modelwithfunctionallinear": 81, "0x7f9dd9bd90d0": 81, "matmul_8": 81, "reason": 81, "op_type_map": 81, "recogn": [81, 108, 110], "functional_op": 81, "modelwithoutfunctionallinear": 81, "parallel": 82, "dataparallel": [82, 85], "doesn": 82, "forth": 82, "conv1d": [83, 111], "convtranspose2d": 83, "batchnorm1d": 83, "cross_layer_equalization_auto_step_by_step": 83, "conv_bn": 83, "replace_modules_of_type1_with_type2": 83, "layer_list": 83, "clspairinfo": 83, "depthwis": [83, 95, 111], "cross_layer_equalization_depthwise_lay": 83, "encapsul": 84, "check_model_sensitivity_to_quant": 84, "perform_per_layer_analysis_by_enabling_quant_wrapp": 84, "occurr": [84, 96], "perform_per_layer_analysis_by_disabling_quant_wrapp": 84, "export_per_layer_encoding_min_max_rang": 84, "esults_dir": 84, "pcq": [84, 95, 106], "wrapped_module_nam": 84, "param_nam": 84, "export_per_layer_stats_histogram": 84, "ctivations_pdf": 84, "eights_pdf": 84, "am": 84, "channel_index": 84, "export_per_layer_mse_loss": 84, "tap": 84, "checker": 85, "concern": 85, "save_checkpoint": 86, "file_path": 86, "load_checkpoint": 86, "quant_sim_model": 86, "export_to_torchscript": 86, "use_embedded_encod": 86, "export_model": 86, "opset_vers": 86, "enable_onnx_check": 86, "fakequ": 86, "forward_pass_arg": 86, "arg": 86, "quatiz": 86, "unction": 86, "visualize_serialized_data": 87, "visualizecompress": [87, 113], "server": [87, 98], "tabl": [87, 98, 99, 103, 113], "display_eval_scor": [87, 113], "saved_eval_scores_dict_path": 87, "display_comp_ratio_plot": [87, 113], "comp_ratio_list_path": 87, "pkl": 87, "start_bokeh_server_sess": 87, "model_compression_with_visu": 87, "65": [87, 91, 97], "resnet18_eval_scor": 87, "comp_ratios_file_path": 87, "greedy_selection_comp_ratios_list": 87, "eval_scores_path": 87, "compression_visu": 87, "termin": [87, 98], "visualize_model": 88, "visualize_relative_weight_ranges_to_identify_problematic_lay": 88, "selected_lay": 88, "figur": [88, 93, 99, 109, 116], "visualize_weight_rang": 88, "deviat": 88, "visualize_changes_after_optim": 88, "old_model": 88, "new_model": 88, "visualize_changes_in_model_after_and_before_cl": 88, "visualiz": 88, "model_copi": 88, "visualize_weight_ranges_model": 88, "usual": [88, 107], "visualize_relative_weight_ranges_model": 88, "pypi": 89, "intel": 89, "x86": 89, "processor": 89, "linux": [89, 91], "ubuntu": [89, 91], "22": [89, 91], "04": [89, 91], "lt": [89, 91], "pip": [89, 90, 91, 98], "apt": [89, 90, 91], "liblapack": [89, 90, 91], "python3": [89, 90, 91, 98], "variant": [89, 91, 107, 110], "latest": [89, 90], "whl": [89, 90, 91], "host": [89, 90, 91, 111, 113], "github": [89, 90, 91, 97, 98, 111], "com": [89, 90, 91, 98, 111], "quic": [89, 90, 91, 97, 98, 111], "13": [89, 90], "torch_gpu_": 89, "cp38": [89, 91], "linux_x86_64": [89, 90, 91], "torch_cpu_": 89, "tf_gpu_": 89, "tf_cpu_": 89, "14": 89, "onnx_gpu_": 89, "onnx_cpu_": 89, "brows": 89, "torch_gpu": [89, 90, 91], "torch_cpu": [89, 90, 91], "tf_gpu": [89, 90, 91], "tf_cpu": [89, 90, 91], "onnx_gpu": [89, 90, 91], "onnx_cpu": [89, 90, 91], "package_prefix": 89, "platform": [89, 104], "setup": 89, "bash": [89, 90], "command": [89, 90, 91, 98, 113], "shell": 89, "nvidia": [89, 90, 91], "card": 89, "capabl": [89, 113, 114], "docker": 89, "455": 89, "newer": 89, "cudnn": 89, "machin": [89, 90, 102], "develop": [89, 90, 91], "click": 89, "instruct": [90, 91, 98], "variant_str": [90, 91], "ONE": [90, 91], "pt113": 90, "aimet_vari": [90, 91], "workspac": [90, 98], "absolute_path_to_workspac": [90, 98], "docker_image_nam": 90, "codelinaro": 90, "dev": [90, 91], "docker_container_nam": 90, "any_nam": 90, "any_tag": 90, "jenkin": 90, "dockerfil": 90, "p": 90, "grep": 90, "kill": 90, "rm": 90, "passwd": 90, "ro": 90, "home": 90, "mnt": 90, "entrypoint": 90, "bin": [90, 91], "hostnam": 90, "filesystem": 90, "port": [90, 113], "port_id": 90, "project": [90, 91], "sudo": [90, 91, 98], "tag": [90, 91, 98, 111], "release_tag": [90, 91, 98], "download_url": [90, 91], "suffix": [90, 91], "wheel_file_suffix": [90, 91], "cp310": [90, 91], "pend": [90, 91, 98], "pip3": [90, 91], "h": [90, 91, 98, 115, 116], "usr": [90, 91], "lib": [90, 91], "dist": [90, 91], "torch_stabl": [90, 91], "OR": [90, 91], "envsetup": [90, 91], "sh": [90, 91], "local": [91, 113], "requisit": 91, "upgrad": 91, "wget": 91, "gnupg2": 91, "visit": [91, 100], "archiv": 91, "exact": [91, 95], "date": 91, "repo": [91, 98], "ubuntu2204": 91, "x86_64": 91, "pin": 91, "mv": 91, "prefer": [91, 102], "d": 91, "repositori": 91, "600": 91, "local_instal": 91, "local_11": 91, "520": 91, "61": 91, "1_amd64": 91, "deb": 91, "adv": 91, "fetch": 91, "3bf863cc": 91, "pub": 91, "dpkg": 91, "cp": [91, 97], "keyr": 91, "gpg": 91, "echo": 91, "515": 91, "torch_gpu_pt113": 91, "torch_cpu_pt113": 91, "cp36": 91, "cp36m": 91, "cp37": 91, "cp37m": 91, "py3": 91, "wheel": 91, "cat": 91, "reqs_deb_common": 91, "txt": 91, "xarg": 91, "reqs_deb_torch_common": 91, "reqs_deb_onnx_common": 91, "reqs_deb_tf_gpu": 91, "reqs_deb_torch_gpu": 91, "reqs_deb_onnx_gpu": 91, "uninstal": 91, "post1": 91, "onnxruntime_v": 91, "c": [91, 97], "__version__": 91, "ln": 91, "gnu": 91, "libjpeg": 91, "chose": 91, "bnf": 93, "coupl": 93, "moder": 93, "enter": 94, "preprat": 94, "mainli": 94, "decreas": 95, "oscil": 95, "presenc": 96, "residu": 96, "discuss": [97, 109, 110], "reduct": 97, "uncompress": 97, "latenc": 97, "vari": [97, 99, 105, 114], "io": [97, 111], "half": 97, "unknown": 97, "apriori": 97, "cssvd": 97, "75": 97, "2b": 97, "larg": [97, 107, 112, 115], "2a": 97, "revisit": 97, "ccp": 97, "csvd": 97, "becom": [98, 105], "familiar": 98, "browsabl": 98, "metapackag": 98, "ip": 98, "browser": 98, "past": 98, "mkdir": 98, "cd": 98, "packag": [98, 111], "git": 98, "www": 98, "navig": 98, "launch": 98, "ipynb": 98, "extens": 98, "therein": 98, "assess": 99, "column": 99, "unmodifi": 99, "strict": [99, 108, 110], "curv": 99, "core": 99, "interpol": 99, "met": 99, "binari": 99, "solut": [99, 107, 109], "lesser": [99, 102], "fall": [99, 108], "drstical": 99, "edg": 100, "incur": [100, 106], "hw": 100, "redund": 100, "product": 100, "technologi": 100, "subsidiari": 100, "dilat": 101, "librari": 102, "guidebook": [102, 104], "advic": 102, "phase": [102, 104], "nomin": 102, "fc": 102, "term": [102, 112, 113, 114, 115], "notic": 102, "sharp": 102, "respons": 102, "carefulli": 102, "slow": 102, "searcher": 102, "strike": 102, "xiangyu": 102, "zhang": 102, "jianhua": 102, "zou": 102, "kaim": 102, "he": 102, "jian": 102, "sun": 102, "deep": 102, "ieee": [102, 105], "transact": 102, "pattern": 102, "intellig": 102, "vol": 102, "38": 102, "pp": 102, "1943": 102, "1955": 102, "oct": 102, "2016": 102, "yihui": 102, "confer": [102, 105], "vision": [102, 105], "venic": 102, "2017": 102, "1398": 102, "1406": 102, "jaderberg": 102, "andrea": 102, "vedaldi": 102, "andrew": 102, "zisserman": 102, "expans": 102, "british": 102, "jan": 102, "2014": 102, "andrei": 102, "kuzmin": 102, "marku": [102, 105], "nagel": [102, 105], "saurabh": 102, "pitr": 102, "sandeep": 102, "pendyam": 102, "tijmen": [102, 105], "blankevoort": [102, 105], "taxonomi": 102, "primit": 103, "slice": 103, "bilinear": 103, "upsampl": 103, "129": 103, "align_corn": 103, "deconvolut": 103, "deeplabv3": 103, "address": [103, 109, 113], "introduc": [104, 108, 110], "advantag": 104, "fast": 104, "easi": [104, 106], "gap": 104, "robust": 104, "longer": [104, 107], "account": [104, 107, 109], "advis": [104, 108], "prep": 104, "align": 104, "retri": 104, "hand": 104, "satisfactori": [104, 109], "bring": 104, "onto": 104, "pb": 104, "trial": 104, "particular": [104, 108], "seem": 104, "bat": 104, "surround": 105, "big": 105, "discrep": 105, "wide": 105, "significantli": 105, "quantizaion": 105, "bottleneck": [105, 109], "hybrid": 105, "approach": [105, 110], "mart": 105, "van": 105, "baalen": 105, "seoul": 105, "octob": 105, "rune": 106, "situat": 106, "pinpoint": 106, "culprit": 106, "toss": 106, "outlier": [106, 110], "monitor": 106, "contribut": [106, 109], "mitig": [107, 110], "come": [107, 110], "accompani": 107, "throughout": [107, 108, 114], "themselv": 107, "aid": 107, "converg": 107, "divid": 107, "six": 108, "overrul": 108, "turn": 108, "empti": 108, "omit": 108, "asymmetr": [108, 110], "asid": 108, "govern": 108, "unsign": [108, 110], "convent": 108, "member": 108, "whatev": 108, "earlier": 108, "diagnost": 109, "strictli": 109, "insight": [109, 113, 114], "underperform": 109, "tackl": 109, "underli": 109, "chart": 109, "saniti": 109, "behav": 109, "ofth": 109, "kept": 109, "toward": 109, "uneven": 109, "inner": 109, "bert": 109, "reveal": 109, "resort": 109, "revert": 109, "power": 109, "ultim": 110, "ingest": 110, "000": 110, "dequant": 110, "dequantiz": 110, "hook": 110, "intercept": 110, "q": 110, "clamp": 110, "vice": 110, "versa": 110, "equat": 110, "textrm": 110, "dfrac": 110, "quad": 110, "strong": 110, "excess": 110, "signal": 110, "sqnr": 110, "squar": 110, "qmin": 110, "qmax": 110, "satur": 110, "erro": 110, "alongsid": 110, "wherea": 110, "ones": 110, "sign": 110, "slim": 111, "backslash": 111, "user_guid": 111, "api_doc": 111, "quantizablemultiheadattent": 111, "kyuykim": 111, "mangal": 111, "geunle": 111, "correctli": 111, "klhsieh": 111, "akhobar": 111, "resid": 111, "ashvkuma": 111, "fp16": 111, "convtranspose1d": 111, "concat": 111, "stand": [111, 112, 115], "adaptiveround": 111, "gru": 111, "instal": 111, "\ud835\udc5a": [112, 115], "\ud835\udc5b": [112, 115], "\u210e": [112, 115], "\ud835\udc64": [112, 115], "\ud835\udc58": [112, 115], "larger": [112, 115], "degre": [112, 115], "assist": [113, 114], "progress": [113, 114], "computation": [113, 114], "heavi": [113, 114], "websocket": 113, "listen": 113, "5006": 113, "lot": 114, "lose": 116, "pictori": 116, "volum": 116, "hxwx8": 116, "hxwx5": 116, "propag": 116, "That": 116, "green": 116, "color": 116, "side": 116, "pink": 116, "orang": 116}, "objects": {"aimet_common.bias_correction": [[75, 0, 1, "", "ConvBnInfoType"]], "aimet_common.defs": [[75, 0, 1, "", "ActivationType"], [61, 0, 1, "", "CompressionScheme"], [61, 0, 1, "", "CostMetric"], [76, 0, 1, "", "GreedySelectionParameters"], [86, 0, 1, "", "QuantScheme"]], "aimet_common.defs.ActivationType": [[75, 1, 1, "", "no_activation"], [75, 1, 1, "", "relu"], [75, 1, 1, "", "relu6"]], "aimet_common.defs.CompressionScheme": [[61, 1, 1, "", "channel_pruning"], [61, 1, 1, "", "spatial_svd"], [61, 1, 1, "", "weight_svd"]], "aimet_common.defs.CostMetric": [[61, 1, 1, "", "mac"], [61, 1, 1, "", "memory"]], "aimet_common.defs.QuantScheme": [[86, 1, 1, "", "post_training_percentile"], [86, 1, 1, "", "post_training_tf"], [86, 1, 1, "", "post_training_tf_enhanced"], [86, 1, 1, "", "training_range_learning_with_tf_enhanced_init"], [86, 1, 1, "", "training_range_learning_with_tf_init"]], "aimet_common.utils": [[84, 0, 1, "", "CallbackFunc"]], "aimet_tensorflow.adaround.adaround_weight.Adaround": [[57, 2, 1, "", "apply_adaround"]], "aimet_tensorflow.adaround.adaround_weight": [[57, 0, 1, "", "AdaroundParameters"]], "aimet_tensorflow.auto_quant": [[58, 0, 1, "", "AutoQuant"]], "aimet_tensorflow.auto_quant.AutoQuant": [[58, 3, 1, "", "apply"], [58, 3, 1, "", "set_adaround_params"]], "aimet_tensorflow.batch_norm_fold": [[65, 2, 1, "", "fold_all_batch_norms"], [59, 2, 1, "", "fold_all_batch_norms_to_scale"], [65, 2, 1, "", "fold_given_batch_norms"]], "aimet_tensorflow.bias_correction.BiasCorrection": [[60, 2, 1, "", "analytical_bias_correction_per_layer"], [60, 2, 1, "", "bias_correction_per_layer"], [60, 2, 1, "", "correct_bias"]], "aimet_tensorflow.bias_correction": [[60, 2, 1, "", "BiasCorrectionParams"], [60, 0, 1, "", "QuantParams"]], "aimet_tensorflow.bn_reestimation": [[59, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.compress": [[61, 0, 1, "", "ModelCompressor"]], "aimet_tensorflow.compress.ModelCompressor": [[61, 3, 1, "", "compress_model"]], "aimet_tensorflow.cross_layer_equalization": [[65, 0, 1, "", "ClsSetInfo"], [62, 2, 1, "", "equalize_model"]], "aimet_tensorflow.cross_layer_equalization.ClsSetInfo": [[65, 0, 1, "", "ClsSetLayerPairInfo"], [65, 3, 1, "", "map_cls_sets_to_new_session"]], "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling": [[65, 2, 1, "", "scale_cls_sets"], [65, 2, 1, "", "scale_model"]], "aimet_tensorflow.cross_layer_equalization.HighBiasFold": [[65, 2, 1, "id0", "bias_fold"]], "aimet_tensorflow.defs": [[61, 0, 1, "", "ChannelPruningParameters"], [61, 0, 1, "", "ModuleCompRatioPair"], [61, 0, 1, "", "SpatialSvdParameters"]], "aimet_tensorflow.defs.ChannelPruningParameters": [[61, 0, 1, "", "AutoModeParams"], [61, 0, 1, "", "ManualModeParams"], [61, 0, 1, "", "Mode"]], "aimet_tensorflow.defs.ChannelPruningParameters.Mode": [[61, 1, 1, "", "auto"], [61, 1, 1, "", "manual"]], "aimet_tensorflow.defs.SpatialSvdParameters": [[61, 0, 1, "", "AutoModeParams"], [61, 0, 1, "", "ManualModeParams"], [61, 0, 1, "", "Mode"]], "aimet_tensorflow.defs.SpatialSvdParameters.Mode": [[61, 1, 1, "", "auto"], [61, 1, 1, "", "manual"]], "aimet_tensorflow.keras.batch_norm_fold": [[43, 2, 1, "", "fold_all_batch_norms"], [37, 2, 1, "", "fold_all_batch_norms_to_scale"], [43, 2, 1, "", "fold_given_batch_norms"]], "aimet_tensorflow.keras.bn_reestimation": [[37, 2, 1, "", "reestimate_bn_stats"]], "aimet_tensorflow.keras.compress": [[38, 0, 1, "", "ModelCompressor"]], "aimet_tensorflow.keras.compress.ModelCompressor": [[38, 3, 1, "", "compress_model"]], "aimet_tensorflow.keras.cross_layer_equalization": [[43, 0, 1, "", "ClsSetInfo"], [39, 2, 1, "", "equalize_model"]], "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo": [[43, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling": [[43, 2, 1, "", "scale_cls_sets"], [43, 2, 1, "", "scale_model"]], "aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold": [[43, 2, 1, "id0", "bias_fold"]], "aimet_tensorflow.keras.layer_output_utils": [[40, 0, 1, "", "LayerOutputUtil"]], "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil": [[40, 3, 1, "", "generate_layer_outputs"]], "aimet_tensorflow.keras.model_preparer": [[42, 2, 1, "", "prepare_model"]], "aimet_tensorflow.keras.quant_analyzer": [[44, 0, 1, "", "QuantAnalyzer"]], "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer": [[44, 3, 1, "", "analyze"]], "aimet_tensorflow.keras.quantsim": [[46, 0, 1, "", "QuantizationSimModel"]], "aimet_tensorflow.keras.quantsim.QuantizationSimModel": [[46, 3, 1, "", "compute_encodings"], [46, 3, 1, "", "export"]], "aimet_tensorflow.layer_output_utils": [[63, 0, 1, "", "LayerOutputUtil"]], "aimet_tensorflow.layer_output_utils.LayerOutputUtil": [[63, 3, 1, "", "generate_layer_outputs"]], "aimet_tensorflow.plotting_utils": [[69, 2, 1, "", "visualize_relative_weight_ranges_single_layer"], [69, 2, 1, "", "visualize_weight_ranges_single_layer"]], "aimet_tensorflow.quant_analyzer": [[66, 0, 1, "", "QuantAnalyzer"]], "aimet_tensorflow.quant_analyzer.QuantAnalyzer": [[66, 3, 1, "", "analyze"]], "aimet_tensorflow.quantsim": [[68, 0, 1, "", "QuantizationSimModel"]], "aimet_tensorflow.quantsim.QuantizationSimModel": [[68, 3, 1, "", "compute_encodings"], [68, 3, 1, "", "export"]], "aimet_tensorflow.svd": [[61, 0, 1, "", "Svd"]], "aimet_tensorflow.svd.Svd": [[61, 3, 1, "", "compress_net"]], "aimet_tensorflow.utils.convert_tf_sess_to_keras": [[33, 2, 1, "", "load_keras_model_multi_gpu"], [33, 2, 1, "", "load_tf_sess_variables_to_keras_single_gpu"], [33, 2, 1, "", "save_as_tf_module_multi_gpu"], [33, 2, 1, "", "save_tf_session_single_gpu"]], "aimet_tensorflow.utils.graph": [[64, 2, 1, "", "update_keras_bn_ops_trainable_flag"]], "aimet_torch.adaround.adaround_weight.Adaround": [[71, 2, 1, "", "apply_adaround"]], "aimet_torch.adaround.adaround_weight": [[71, 0, 1, "", "AdaroundParameters"]], "aimet_torch.arch_checker.arch_checker.ArchChecker": [[72, 2, 1, "", "check_model_arch"]], "aimet_torch.auto_quant": [[73, 0, 1, "", "AutoQuant"]], "aimet_torch.auto_quant.AutoQuant": [[73, 3, 1, "", "get_quant_scheme_candidates"], [73, 3, 1, "", "optimize"], [73, 3, 1, "", "run_inference"], [73, 3, 1, "", "set_adaround_params"], [73, 3, 1, "", "set_export_params"], [73, 3, 1, "", "set_model_preparer_params"], [73, 3, 1, "", "set_quant_scheme_candidates"]], "aimet_torch.batch_norm_fold": [[83, 2, 1, "", "fold_all_batch_norms"], [74, 2, 1, "", "fold_all_batch_norms_to_scale"], [83, 2, 1, "", "fold_given_batch_norms"]], "aimet_torch.bias_correction": [[75, 2, 1, "", "correct_bias"]], "aimet_torch.bn_reestimation": [[74, 2, 1, "", "reestimate_bn_stats"]], "aimet_torch.compress": [[76, 0, 1, "", "ModelCompressor"]], "aimet_torch.compress.ModelCompressor": [[76, 3, 1, "", "compress_model"]], "aimet_torch.cross_layer_equalization": [[83, 0, 1, "", "ClsSetInfo"], [77, 2, 1, "", "equalize_model"]], "aimet_torch.cross_layer_equalization.ClsSetInfo": [[83, 0, 1, "", "ClsSetLayerPairInfo"]], "aimet_torch.cross_layer_equalization.CrossLayerScaling": [[83, 2, 1, "", "scale_cls_sets"], [83, 2, 1, "", "scale_model"]], "aimet_torch.cross_layer_equalization.HighBiasFold": [[83, 2, 1, "id0", "bias_fold"]], "aimet_torch.defs": [[76, 0, 1, "", "ChannelPruningParameters"], [76, 0, 1, "", "ModuleCompRatioPair"], [76, 0, 1, "", "SpatialSvdParameters"], [76, 0, 1, "", "TarRankSelectionParameters"], [76, 0, 1, "", "WeightSvdParameters"]], "aimet_torch.defs.ChannelPruningParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.ChannelPruningParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.defs.SpatialSvdParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.SpatialSvdParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.defs.WeightSvdParameters": [[76, 0, 1, "", "AutoModeParams"], [76, 0, 1, "", "ManualModeParams"], [76, 0, 1, "", "Mode"]], "aimet_torch.defs.WeightSvdParameters.Mode": [[76, 1, 1, "", "auto"], [76, 1, 1, "", "manual"]], "aimet_torch.layer_output_utils": [[78, 0, 1, "", "LayerOutputUtil"], [78, 0, 1, "", "NamingScheme"]], "aimet_torch.layer_output_utils.LayerOutputUtil": [[78, 3, 1, "", "generate_layer_outputs"]], "aimet_torch.layer_output_utils.NamingScheme": [[78, 1, 1, "", "ONNX"], [78, 1, 1, "", "PYTORCH"], [78, 1, 1, "", "TORCHSCRIPT"]], "aimet_torch.model_preparer": [[80, 2, 1, "", "prepare_model"]], "aimet_torch.quant_analyzer": [[84, 0, 1, "", "QuantAnalyzer"]], "aimet_torch.quant_analyzer.QuantAnalyzer": [[84, 3, 1, "", "analyze"], [84, 3, 1, "", "check_model_sensitivity_to_quantization"], [84, 3, 1, "", "enable_per_layer_mse_loss"], [84, 3, 1, "", "export_per_layer_encoding_min_max_range"], [84, 3, 1, "", "export_per_layer_mse_loss"], [84, 3, 1, "", "export_per_layer_stats_histogram"], [84, 3, 1, "", "perform_per_layer_analysis_by_disabling_quant_wrappers"], [84, 3, 1, "", "perform_per_layer_analysis_by_enabling_quant_wrappers"]], "aimet_torch.quantsim": [[75, 0, 1, "", "QuantParams"], [86, 0, 1, "", "QuantizationSimModel"], [86, 3, 1, "", "load_checkpoint"], [86, 3, 1, "", "save_checkpoint"]], "aimet_torch.quantsim.QuantizationSimModel": [[86, 3, 1, "", "compute_encodings"], [86, 3, 1, "", "export"]], "aimet_torch.visualize_model": [[88, 2, 1, "", "visualize_changes_after_optimization"], [88, 2, 1, "", "visualize_relative_weight_ranges_to_identify_problematic_layers"], [88, 2, 1, "", "visualize_weight_ranges"]], "aimet_torch.visualize_serialized_data": [[87, 0, 1, "", "VisualizeCompression"]], "aimet_torch.visualize_serialized_data.VisualizeCompression": [[87, 3, 1, "", "display_comp_ratio_plot"], [87, 3, 1, "", "display_eval_scores"]]}, "objtypes": {"0": "py:class", "1": "py:attribute", "2": "py:function", "3": "py:method"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "attribute", "Python attribute"], "2": ["py", "function", "Python function"], "3": ["py", "method", "Python method"]}, "titleterms": {"adapt": [0, 6, 10, 26, 48, 71], "round": [0, 6, 10, 26, 48, 71, 102], "adaround": [0, 6, 7, 10, 11, 18, 26, 27, 36, 48, 57, 71, 93], "overal": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 96], "flow": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 105], "what": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "notebook": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 39, 57, 58, 59, 62, 68, 71, 73, 74, 77, 84, 86, 98], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "dataset": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 75, 91, 111], "exampl": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 87, 88, 98], "evalu": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "train": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 86, 104, 105, 107], "pipelin": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55, 75, 91, 111], "convert": [0, 1, 2, 14], "an": [0, 1, 2], "fp32": [0, 1, 2, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31], "pytorch": [0, 1, 2, 55, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 91, 103, 104, 114], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 41, 42, 64, 79, 80, 81, 100, 102, 103, 104], "onnx": [0, 1, 2, 47, 48, 49, 50, 51, 52, 53, 54, 91], "": [0, 1, 2], "baselin": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31], "accuraci": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 29, 30, 31], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 55], "creat": [0, 1, 2, 6, 8, 9, 10, 12, 14, 15, 16, 18, 19, 20, 21, 26, 27, 28, 29, 30, 31], "quantiz": [0, 1, 2, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29, 30, 31, 32, 45, 46, 53, 54, 67, 68, 69, 75, 85, 86, 88, 104, 105, 107, 108, 109, 110, 114], "simul": [0, 1, 2, 6, 8, 9, 10, 18, 19, 20, 21, 26, 28, 29, 30, 31, 108, 110], "determin": [0, 1, 2, 6, 7, 9, 10, 11, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31, 110], "fold": [0, 1, 2, 6, 8, 9, 10, 12, 15, 16, 18, 19, 20, 21, 26, 28, 29, 30, 31], "batch": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "normal": [0, 1, 2, 6, 9, 10, 15, 16, 18, 19, 20, 21, 26, 29, 30, 31], "layer": [0, 1, 2, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 26, 28, 29, 30, 31, 32, 39, 40, 43, 50, 51, 60, 62, 63, 65, 77, 78, 83, 99, 102], "sim": [0, 1, 2, 6, 8, 9, 15, 16, 19, 20, 21, 28, 29, 30, 31, 46, 54, 68, 86], "comput": [0, 2, 6, 8, 9, 15, 16, 19, 20, 21], "encod": [0, 2, 6, 8, 9, 15, 16, 17, 19, 20, 21, 22, 32, 55, 110], "4": [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 25, 26, 28, 29, 30, 31, 55], "appli": [0, 6, 7, 10, 11, 17, 18, 22, 26, 32], "summari": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "cross": [1, 9, 19, 29, 39, 43, 50, 62, 65, 77, 83], "equal": [1, 9, 19, 29, 39, 43, 50, 62, 65, 77, 83], "cle": [1, 9, 19, 29, 43, 65], "compress": [3, 4, 5, 23, 24, 25, 38, 61, 76, 87, 97, 99, 102, 113], "us": [3, 4, 5, 23, 24, 25, 33, 43, 65, 90, 93, 102, 104, 113], "channel": [3, 4, 5, 18, 23, 25, 61, 76, 96], "prune": [3, 4, 5, 23, 25, 61, 76, 96], "load": [3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "find": [3, 4, 5, 23, 24, 25], "fine": [3, 4, 5, 23, 24, 25, 102], "tune": [3, 4, 5, 23, 24, 25, 102], "post": [3, 4, 5, 23, 24, 25, 91, 104, 105], "spatial": [4, 5, 24, 25, 38, 61, 76, 112], "svd": [4, 5, 24, 25, 38, 61, 76, 112, 115], "follow": [5, 25], "after": [5, 15, 16, 25], "get": [6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31, 100, 102], "score": [6, 9, 10, 18, 19, 20, 21, 26, 29, 30, 31], "autoqu": [7, 11, 27, 49, 58, 73, 94], "pretrain": [7, 11, 15, 16, 17, 27], "defin": [7, 11, 12, 27], "constant": [7, 11, 12, 27], "helper": [7, 11, 27, 43, 65], "function": [7, 11, 12, 14, 27, 33], "prepar": [7, 11, 12, 14, 42, 80], "unlabel": 7, "callback": [7, 11, 12], "5": [7, 8, 11, 12, 15, 16, 19, 28, 55], "option": [7, 11, 27, 102], "set": [7, 11, 27, 90], "paramet": [7, 11, 27, 36, 38, 48, 57, 60, 61, 71, 76, 110], "run": [7, 11, 27, 52, 84, 98], "awar": [8, 12, 13, 15, 16, 20, 21, 28, 30, 31, 86, 107], "batchnorm": [8, 12, 28, 37, 59, 74], "re": [8, 12, 28, 37, 59, 74, 95], "estim": [8, 12, 28, 37, 59, 74, 95], "rewrit": 8, "perform": [8, 12, 15, 16, 20, 21, 28, 30, 31, 43, 65], "qat": [8, 12, 15, 16, 20, 21, 28, 30, 31, 86, 107], "reestim": [8, 28, 59, 74], "statist": [8, 17, 22, 28, 32], "export": [8, 12, 15, 16, 19, 28], "bia": [9, 29, 60, 75], "correct": [9, 29, 60, 75], "bc": [9, 29], "instanti": 12, "kera": [12, 13, 14, 33, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46], "quantizationsim": [12, 15, 16], "transform": 13, "subclass": 14, "show": 14, "similar": 14, "differ": 14, "between": 14, "origin": 14, "discuss": 14, "limit": [14, 37, 42, 80], "compil": [15, 16], "6": [15, 16, 55], "valid": [15, 16, 81], "7": [15, 16], "rang": [16, 17, 21, 22, 31, 32], "learn": [16, 21, 31], "quant": [17, 22, 32, 44, 52, 66, 84], "analyz": [17, 22, 32, 44, 52, 66, 84], "quantanalyz": [17, 22, 32, 106], "per": [17, 18, 22, 32, 60, 99, 102], "analysi": [17, 22, 32, 104, 106], "enabl": [17, 22, 32], "disabl": [17, 22, 32], "wrapper": [17, 32], "min": [17, 22, 32], "max": [17, 22, 32], "pdf": [17, 22, 32], "mse": [17, 22, 32], "loss": [17, 22, 32], "quantsim": [18, 19, 110], "pcq": 18, "op": [22, 110], "object": 27, "infer": 27, "optim": 27, "aimet": [33, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116], "tensorflow": [33, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 91, 104, 114], "api": [33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88], "introduct": [33, 37, 38, 39, 43, 50, 59, 61, 62, 65, 74, 76, 77, 83], "code": [33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 87, 88, 98], "util": [33, 52, 81, 84], "welcom": 34, "ai": [34, 100], "effici": [34, 100], "toolkit": [34, 100], "doc": 34, "indic": 34, "tabl": 34, "user": [36, 39, 46, 48, 49, 50, 57, 58, 60, 62, 68, 71, 73, 75, 77, 84, 86, 100, 105], "guid": [36, 39, 46, 48, 49, 50, 57, 58, 60, 62, 68, 71, 73, 75, 77, 84, 86, 100], "link": [36, 37, 39, 46, 48, 49, 50, 57, 58, 59, 60, 62, 68, 71, 73, 74, 75, 77, 84, 86], "top": [36, 37, 38, 40, 42, 44, 46, 48, 49, 51, 52, 54, 57, 58, 59, 61, 63, 66, 68, 69, 71, 73, 74, 76, 78, 80, 84, 86, 87, 88], "level": [36, 37, 38, 40, 42, 43, 44, 46, 48, 49, 51, 52, 54, 57, 58, 59, 61, 63, 65, 66, 68, 69, 71, 73, 74, 76, 78, 80, 83, 84, 86, 87, 88], "enum": [36, 57, 71, 78, 86], "definit": [36, 38, 57, 61, 71, 76, 78, 83, 86], "greedi": [38, 61, 76, 99], "select": [38, 61, 76, 96, 99, 102], "configur": [38, 61, 76, 108, 110], "primit": [39, 43, 62, 65, 77, 83], "output": [40, 51, 63, 78], "gener": [40, 51, 63, 78], "guidelin": [41, 64, 79, 86, 103, 104], "higher": [43, 65, 83], "lower": [43, 65, 83], "custom": [43, 65], "datatyp": [43, 65], "method": [43, 65], "manual": [43, 65], "mode": [43, 65, 107], "specif": [52, 55, 84], "format": 55, "version": 55, "0": [55, 111], "up": 55, "file": [55, 108], "bn": [59, 74, 95], "input": 60, "type": 60, "data": 60, "weight": [61, 69, 76, 96, 115], "visual": [69, 87, 88, 113, 114], "tensor": 69, "architectur": 72, "checker": 72, "html": 72, "report": 72, "content": 72, "convbninfotyp": 75, "activationtyp": 75, "param": 75, "empir": 75, "analyt": 75, "tar": 76, "torch": [80, 91], "fx": 80, "symbol": 80, "trace": 80, "multi": 82, "gpu": [82, 91], "support": 82, "clssetinfo": 83, "instal": [89, 90, 91, 98, 100], "quick": 89, "releas": [89, 90, 91, 100, 111], "packag": [89, 90, 91], "system": 89, "requir": [89, 106], "advanc": 89, "instruct": 89, "docker": 90, "variant": 90, "prebuilt": 90, "imag": 90, "build": 90, "local": 90, "start": [90, 100, 113], "contain": 90, "from": [90, 91], "pypi": [90, 91], "environ": [90, 91], "setup": [90, 91], "prerequisit": 91, "13": [91, 111], "common": [91, 93], "debian": 91, "replac": 91, "pillow": 91, "simd": 91, "onnxruntim": 91, "step": 91, "case": [93, 102, 104], "terminologi": 93, "overview": [94, 95, 99, 100, 102, 105, 106, 107, 108, 110, 113, 114, 116], "workflow": [94, 95, 104, 107, 110], "procedur": 96, "winnow": [96, 116], "reconstruct": 96, "featur": [97, 100, 104, 109], "guidebook": [97, 109], "brows": 98, "jupyt": 98, "download": 98, "relat": 98, "ratio": [99, 102], "how": [99, 108, 113, 116], "work": [99, 116], "explor": 99, "inform": 100, "toc": 100, "tree": 100, "known": 101, "issu": 101, "techniqu": [102, 105], "better": 102, "result": 102, "rank": 102, "faq": [102, 105], "refer": [102, 105], "debug": 104, "tool": [104, 113], "detail": 106, "descript": 106, "recommend": 107, "structur": 108, "individu": 108, "section": 108, "nois": 110, "scheme": 110, "frequent": 110, "ask": 110, "question": 110, "note": 111, "22": 111, "21": 111, "20": 111, "19": 111, "py37": 111, "18": 111, "17": 111, "16": 111, "14": 111, "design": 113, "bokeh": 113, "server": 113, "session": 113}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Adaptive Rounding (AdaRound)": [[0, "Adaptive-Rounding-(AdaRound)"], [6, "Adaptive-Rounding-(AdaRound)"], [26, "Adaptive-Rounding-(AdaRound)"]], "Overall flow": [[0, "Overall-flow"], [1, "Overall-flow"], [2, "Overall-flow"], [3, "Overall-flow"], [4, "Overall-flow"], [5, "Overall-flow"], [6, "Overall-flow"], [7, "Overall-flow"], [8, "Overall-flow"], [9, "Overall-flow"], [10, "Overall-flow"], [11, "Overall-flow"], [12, "Overall-flow"], [13, "Overall-flow"], [14, "Overall-flow"], [15, "Overall-flow"], [16, "Overall-flow"], [17, "Overall-flow"], [18, "Overall-flow"], [19, "Overall-flow"], [20, "Overall-flow"], [21, "Overall-flow"], [22, "Overall-flow"], [23, "Overall-flow"], [24, "Overall-flow"], [25, "Overall-flow"], [26, "Overall-flow"], [27, "Overall-flow"], [28, "Overall-flow"], [29, "Overall-flow"], [30, "Overall-flow"], [31, "Overall-flow"], [32, "Overall-flow"]], "What this notebook is not": [[0, "What-this-notebook-is-not"], [1, "What-this-notebook-is-not"], [2, "What-this-notebook-is-not"], [3, "What-this-notebook-is-not"], [4, "What-this-notebook-is-not"], [5, "What-this-notebook-is-not"], [6, "What-this-notebook-is-not"], [7, "What-this-notebook-is-not"], [8, "What-this-notebook-is-not"], [9, "What-this-notebook-is-not"], [10, "What-this-notebook-is-not"], [11, "What-this-notebook-is-not"], [15, "What-this-notebook-is-not"], [16, "What-this-notebook-is-not"], [17, "What-this-notebook-is-not"], [18, "What-this-notebook-is-not"], [19, "What-this-notebook-is-not"], [20, "What-this-notebook-is-not"], [21, "What-this-notebook-is-not"], [22, "What-this-notebook-is-not"], [23, "What-this-notebook-is-not"], [24, "What-this-notebook-is-not"], [25, "What-this-notebook-is-not"], [26, "What-this-notebook-is-not"], [27, "What-this-notebook-is-not"], [28, "What-this-notebook-is-not"], [29, "What-this-notebook-is-not"], [30, "What-this-notebook-is-not"], [31, "What-this-notebook-is-not"], [32, "What-this-notebook-is-not"]], "Dataset": [[0, "Dataset"], [1, "Dataset"], [2, "Dataset"], [3, "Dataset"], [4, "Dataset"], [5, "Dataset"], [6, "Dataset"], [7, "Dataset"], [8, "Dataset"], [9, "Dataset"], [10, "Dataset"], [11, "Dataset"], [12, "Dataset"], [15, "Dataset"], [16, "Dataset"], [17, "Dataset"], [18, "Dataset"], [19, "Dataset"], [20, "Dataset"], [21, "Dataset"], [22, "Dataset"], [23, "Dataset"], [24, "Dataset"], [25, "Dataset"], [26, "Dataset"], [27, "Dataset"], [28, "Dataset"], [29, "Dataset"], [30, "Dataset"], [31, "Dataset"], [32, "Dataset"]], "1. Example evaluation and training pipeline": [[0, "1.-Example-evaluation-and-training-pipeline"], [1, "1.-Example-evaluation-and-training-pipeline"], [4, "1.-Example-evaluation-and-training-pipeline"], [5, "1.-Example-evaluation-and-training-pipeline"], [7, "1.-Example-evaluation-and-training-pipeline"], [8, "1.-Example-evaluation-and-training-pipeline"], [9, "1.-Example-evaluation-and-training-pipeline"], [10, "1.-Example-evaluation-and-training-pipeline"], [11, "1.-Example-evaluation-and-training-pipeline"], [17, "1.-Example-evaluation-and-training-pipeline"], [18, "1.-Example-evaluation-and-training-pipeline"], [19, "1.-Example-evaluation-and-training-pipeline"], [20, "1.-Example-evaluation-and-training-pipeline"], [22, "1.-Example-evaluation-and-training-pipeline"], [23, "1.-Example-evaluation-and-training-pipeline"], [24, "1.-Example-evaluation-and-training-pipeline"], [25, "1.-Example-evaluation-and-training-pipeline"], [26, "1.-Example-evaluation-and-training-pipeline"], [28, "1.-Example-evaluation-and-training-pipeline"], [29, "1.-Example-evaluation-and-training-pipeline"], [30, "1.-Example-evaluation-and-training-pipeline"], [31, "1.-Example-evaluation-and-training-pipeline"], [32, "1.-Example-evaluation-and-training-pipeline"]], "2. Convert an FP32 PyTorch model to ONNX and evaluate the model\u2019s baseline FP32 accuracy": [[0, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [1, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"], [2, "2.-Convert-an-FP32-PyTorch-model-to-ONNX-and-evaluate-the-model's-baseline-FP32-accuracy"]], "3. Create a quantization simulation model and determine quantized accuracy": [[0, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [1, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [2, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [6, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [9, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [10, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [18, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [19, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [20, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [21, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [26, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [29, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [30, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"], [31, "3.-Create-a-quantization-simulation-model-and-determine-quantized-accuracy"]], "Fold Batch Normalization layers": [[0, "Fold-Batch-Normalization-layers"], [1, "Fold-Batch-Normalization-layers"], [2, "Fold-Batch-Normalization-layers"], [6, "Fold-Batch-Normalization-layers"], [9, "Fold-Batch-Normalization-layers"], [10, "Fold-Batch-Normalization-layers"], [15, "Fold-Batch-Normalization-layers"], [16, "Fold-Batch-Normalization-layers"], [18, "Fold-Batch-Normalization-layers"], [19, "Fold-Batch-Normalization-layers"], [20, "Fold-Batch-Normalization-layers"], [21, "Fold-Batch-Normalization-layers"], [26, "Fold-Batch-Normalization-layers"], [29, "Fold-Batch-Normalization-layers"], [30, "Fold-Batch-Normalization-layers"], [31, "Fold-Batch-Normalization-layers"]], "Create Quantization Sim Model": [[0, "Create-Quantization-Sim-Model"], [1, "Create-Quantization-Sim-Model"], [2, "Create-Quantization-Sim-Model"], [6, "Create-Quantization-Sim-Model"], [8, "Create-Quantization-Sim-Model"], [9, "Create-Quantization-Sim-Model"], [15, "Create-Quantization-Sim-Model"], [16, "Create-Quantization-Sim-Model"], [19, "Create-Quantization-Sim-Model"], [20, "Create-Quantization-Sim-Model"], [21, "Create-Quantization-Sim-Model"], [28, "Create-Quantization-Sim-Model"], [29, "Create-Quantization-Sim-Model"], [30, "Create-Quantization-Sim-Model"], [31, "Create-Quantization-Sim-Model"]], "Compute Encodings": [[0, "Compute-Encodings"], [2, "Compute-Encodings"], [6, "Compute-Encodings"], [8, "Compute-Encodings"], [9, "Compute-Encodings"], [15, "Compute-Encodings"], [16, "Compute-Encodings"], [19, "Compute-Encodings"], [20, "Compute-Encodings"], [21, "Compute-Encodings"]], "4. Apply Adaround": [[0, "4.-Apply-Adaround"], [10, "4.-Apply-Adaround"], [18, "4.-Apply-Adaround"], [26, "4.-Apply-Adaround"]], "Summary": [[0, "Summary"], [1, "Summary"], [2, "Summary"], [3, "Summary"], [4, "Summary"], [5, "Summary"], [6, "Summary"], [7, "Summary"], [8, "Summary"], [9, "Summary"], [10, "Summary"], [11, "Summary"], [12, "Summary"], [14, "Summary"], [15, "Summary"], [16, "Summary"], [18, "Summary"], [19, "Summary"], [20, "Summary"], [21, "Summary"], [23, "Summary"], [24, "Summary"], [25, "Summary"], [26, "Summary"], [27, "Summary"], [28, "Summary"], [29, "Summary"], [30, "Summary"], [31, "Summary"]], "Cross-Layer Equalization (CLE)": [[1, "Cross-Layer-Equalization-(CLE)"]], "4. 1 Cross Layer Equalization": [[1, "4.-1-Cross-Layer-Equalization"], [9, "4.-1-Cross-Layer-Equalization"], [29, "4.-1-Cross-Layer-Equalization"]], "Quantization Simulation": [[2, "Quantization-Simulation"]], "1. Example evaluation pipeline": [[2, "1.-Example-evaluation-pipeline"]], "Model Compression Using Channel Pruning": [[3, "Model-Compression-Using-Channel-Pruning"]], "2. Load the model and evaluate it to find the baseline accuracy": [[3, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [4, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [5, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [23, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [24, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"], [25, "2.-Load-the-model-and-evaluate-it-to-find-the-baseline-accuracy"]], "3. Compress the model and fine-tune": [[3, "3.-Compress-the-model-and-fine-tune"], [4, "3.-Compress-the-model-and-fine-tune"], [5, "3.-Compress-the-model-and-fine-tune"], [23, "3.-Compress-the-model-and-fine-tune"], [24, "3.-Compress-the-model-and-fine-tune"], [25, "3.-Compress-the-model-and-fine-tune"]], "3.1. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[3, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [4, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [5, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [23, "3.1.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.2. Fine-tune the model": [[3, "3.2.-Fine-tune-the-model"], [4, "3.2.-Fine-tune-the-model"], [23, "3.2.-Fine-tune-the-model"], [24, "3.2.-Fine-tune-the-model"]], "Model compression Using Spatial SVD": [[4, "Model-compression-Using-Spatial-SVD"]], "Model Compression Using Spatial SVD Followed by Channel Pruning": [[5, "Model-Compression-Using-Spatial-SVD-Followed-by-Channel-Pruning"]], "3.2. Fine-tune the model after Spatial SVD": [[5, "3.2.-Fine-tune-the-model-after-Spatial-SVD"], [25, "3.2.-Fine-tune-the-model-after-Spatial-SVD"]], "3.3. Compress model using Channel Pruning and evaluate it to find post-compression accuracy": [[5, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"], [25, "3.3.-Compress-model-using-Channel-Pruning-and-evaluate-it-to-find-post-compression-accuracy"]], "3.4. Fine-tune the model after Channel Pruning": [[5, "3.4.-Fine-tune-the-model-after-Channel-Pruning"], [25, "3.4.-Fine-tune-the-model-after-Channel-Pruning"]], "1. Example Evaluation and Training Pipeline": [[6, "1.-Example-Evaluation-and-Training-Pipeline"], [21, "1.-Example-Evaluation-and-Training-Pipeline"]], "2. Load the model and evaluate to get a baseline FP32 accuracy score": [[6, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [9, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [10, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [18, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [19, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [20, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [21, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [26, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [29, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [30, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"], [31, "2.-Load-the-model-and-evaluate-to-get-a-baseline-FP32-accuracy-score"]], "4. Apply AdaRound": [[6, "4.-Apply-AdaRound"]], "AutoQuant": [[7, "AutoQuant"], [11, "AutoQuant"], [27, "AutoQuant"]], "2. Load a pretrained FP32 model": [[7, "2.-Load-a-pretrained-FP32-model"], [11, "2.-Load-a-pretrained-FP32-model"], [15, "2.-Load-a-pretrained-FP32-model"], [16, "2.-Load-a-pretrained-FP32-model"], [17, "2.-Load-a-pretrained-FP32-model"], [27, "2.-Load-a-pretrained-FP32-model"]], "3. Determine the baseline FP32 accuracy": [[7, "3.-Determine-the-baseline-FP32-accuracy"], [11, "3.-Determine-the-baseline-FP32-accuracy"], [15, "3.-Determine-the-baseline-FP32-accuracy"], [16, "3.-Determine-the-baseline-FP32-accuracy"]], "4. Define Constants and Helper functions": [[7, "4.-Define-Constants-and-Helper-functions"], [11, "4.-Define-Constants-and-Helper-functions"]], "Prepare unlabeled dataset": [[7, "Prepare-unlabeled-dataset"]], "Prepare the evaluation callback function": [[7, "Prepare-the-evaluation-callback-function"], [11, "Prepare-the-evaluation-callback-function"], [12, "Prepare-the-evaluation-callback-function"]], "5. Apply AutoQuant": [[7, "5.-Apply-AutoQuant"], [11, "5.-Apply-AutoQuant"]], "Optionally set AdaRound Parameters": [[7, "Optionally-set-AdaRound-Parameters"], [11, "Optionally-set-AdaRound-Parameters"]], "Run AutoQuant": [[7, "Run-AutoQuant"], [11, "Run-AutoQuant"]], "Quantization-Aware Training with BatchNorm Re-estimation": [[8, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [12, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"], [28, "Quantization-Aware-Training-with-BatchNorm-Re-estimation"]], "2. Load FP32 model": [[8, "2.-Load-FP32-model"], [28, "2.-Load-FP32-model"]], "BatchNorm Rewriter": [[8, "BatchNorm-Rewriter"]], "3. Create a quantization simulation model and Perform QAT": [[8, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"], [28, "3.-Create-a-quantization-simulation-model-and-Perform-QAT"]], "Perform QAT": [[8, "Perform-QAT"], [28, "Perform-QAT"]], "4. Perform BatchNorm Reestimation": [[8, "4.-Perform-BatchNorm-Reestimation"], [28, "4.-Perform-BatchNorm-Reestimation"]], "Re-estimate BatchNorm Statistics": [[8, "Re-estimate-BatchNorm-Statistics"], [28, "Re-estimate-BatchNorm-Statistics"]], "Fold BatchNorm Layers": [[8, "Fold-BatchNorm-Layers"], [12, "Fold-BatchNorm-Layers"], [28, "Fold-BatchNorm-Layers"]], "5. Export Model": [[8, "5.-Export-Model"], [12, "5.-Export-Model"], [28, "5.-Export-Model"]], "Cross-Layer Equalization (CLE) and Bias Correction (BC)": [[9, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"], [29, "Cross-Layer-Equalization-(CLE)-and-Bias-Correction-(BC)"]], "4. 2 Bias Correction": [[9, "4.-2-Bias-Correction"], [29, "4.-2-Bias-Correction"]], "Adaptive Rounding (Adaround)": [[10, "Adaptive-Rounding-(Adaround)"]], "1. Instantiate the example evaluation and training pipeline": [[12, "1.-Instantiate-the-example-evaluation-and-training-pipeline"]], "2. Define Constants and Datasets Prepare": [[12, "2.-Define-Constants-and-Datasets-Prepare"]], "2. Create the model in Keras": [[12, "2.-Create-the-model-in-Keras"]], "3. Train and evaluate the model": [[12, "3.-Train-and-evaluate-the-model"]], "4. Create a QuantizationSim Model": [[12, "4.-Create-a-QuantizationSim-Model"]], "5. Perform QAT": [[12, "5.-Perform-QAT"], [15, "5.-Perform-QAT"], [16, "5.-Perform-QAT"]], "Quantization-Aware Training with a Keras Transformer Model": [[13, "Quantization-Aware-Training-with-a-Keras-Transformer-Model"]], "Keras Model Preparer": [[14, "Keras-Model-Preparer"]], "1. Creating a Keras model with subclass layers": [[14, "1.-Creating-a-Keras-model-with-subclass-layers"]], "2. Converting the Keras model with subclass layers to a Keras model with functional layers": [[14, "2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers"]], "3. Showing similarities and differences between the original and converted models": [[14, "3.-Showing-similarities-and-differences-between-the-original-and-converted-models"]], "4. Discussing the limitations of the Keras Model Preparer": [[14, "4.-Discussing-the-limitations-of-the-Keras-Model-Preparer"]], "Quantization-Aware Training": [[15, "Quantization-Aware-Training"], [20, "Quantization-Aware-Training"], [30, "Quantization-Aware-Training"]], "Example evaluation and training pipeline": [[15, "Example-evaluation-and-training-pipeline"], [16, "Example-evaluation-and-training-pipeline"]], "1. Load the dataset": [[15, "1.-Load-the-dataset"], [16, "1.-Load-the-dataset"]], "4. Create a QuantizationSim Model and determine quantized accuracy": [[15, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"], [16, "4.-Create-a-QuantizationSim-Model-and-determine-quantized-accuracy"]], "Compile the model": [[15, "Compile-the-model"], [16, "Compile-the-model"]], "Evaluate the performance of the quantized model": [[15, "Evaluate-the-performance-of-the-quantized-model"], [16, "Evaluate-the-performance-of-the-quantized-model"]], "6. Evaluate validation accuracy after QAT": [[15, "6.-Evaluate-validation-accuracy-after-QAT"], [16, "6.-Evaluate-validation-accuracy-after-QAT"]], "7. Export the encodings": [[15, "7.-Export-the-encodings"], [16, "7.-Export-the-encodings"]], "Quantization-Aware Training with Range Learning": [[16, "Quantization-Aware-Training-with-Range-Learning"], [21, "Quantization-Aware-Training-with-Range-Learning"], [31, "Quantization-Aware-Training-with-Range-Learning"]], "Quant Analyzer": [[17, "Quant-Analyzer"], [22, "Quant-Analyzer"], [32, "Quant-Analyzer"]], "3. Apply QuantAnalyzer to the model": [[17, "3.-Apply-QuantAnalyzer-to-the-model"], [22, "3.-Apply-QuantAnalyzer-to-the-model"], [32, "3.-Apply-QuantAnalyzer-to-the-model"]], "Per-layer analysis by enabling/disabling quantization wrappers": [[17, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"], [32, "Per-layer-analysis-by-enabling/disabling-quantization-wrappers"]], "Encoding min/max ranges": [[17, "Encoding-min/max-ranges"], [22, "Encoding-min/max-ranges"], [32, "Encoding-min/max-ranges"]], "PDF of statistics": [[17, "PDF-of-statistics"], [22, "PDF-of-statistics"], [32, "PDF-of-statistics"]], "Per-layer MSE loss": [[17, "Per-layer-MSE-loss"], [32, "Per-layer-MSE-loss"]], "Quantsim and Adaround - Per Channel Quantization (PCQ)": [[18, "Quantsim-and-Adaround---Per-Channel-Quantization-(PCQ)"]], "Cross-Layer Equalization (CLE) with QuantSim": [[19, "Cross-Layer-Equalization-(CLE)-with-QuantSim"]], "4 Cross Layer Equalization": [[19, "4-Cross-Layer-Equalization"]], "5 Exporting": [[19, "5-Exporting"]], "4. Perform QAT": [[20, "4.-Perform-QAT"], [21, "4.-Perform-QAT"], [30, "4.-Perform-QAT"], [31, "4.-Perform-QAT"]], "2. Load the model": [[22, "2.-Load-the-model"], [32, "2.-Load-the-model"]], "Per op analysis by enabling/disabling quantization ops": [[22, "Per-op-analysis-by-enabling/disabling-quantization-ops"]], "Per op MSE loss": [[22, "Per-op-MSE-loss"]], "Model compression using Channel Pruning": [[23, "Model-compression-using-Channel-Pruning"]], "Model compression using Spatial SVD": [[24, "Model-compression-using-Spatial-SVD"]], "3.1. Compress model using Spatial SVD and evaluate it to find post-compression accuracy": [[24, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"], [25, "3.1.-Compress-model-using-Spatial-SVD-and-evaluate-it-to-find-post-compression-accuracy"]], "Model compression using Spatial SVD followed by Channel Pruning": [[25, "Model-compression-using-Spatial-SVD-followed-by-Channel-Pruning"]], "1. Define Constants and Helper functions": [[27, "1.-Define-Constants-and-Helper-functions"]], "3. Run AutoQuant": [[27, "3.-Run-AutoQuant"]], "Create AutoQuant Object": [[27, "Create-AutoQuant-Object"]], "Run AutoQuant Inference": [[27, "Run-AutoQuant-Inference"]], "Set AdaRound Parameters (optional)": [[27, "Set-AdaRound-Parameters-(optional)"]], "Run AutoQuant Optimization": [[27, "Run-AutoQuant-Optimization"]], "Using AIMET Tensorflow APIs with Keras Models": [[33, "using-aimet-tensorflow-apis-with-keras-models"]], "Introduction": [[33, "introduction"], [37, "introduction"], [38, "introduction"], [39, "introduction"], [43, "introduction"], [50, "introduction"], [59, "introduction"], [61, "introduction"], [62, "introduction"], [65, "introduction"], [74, "introduction"], [76, "introduction"], [77, "introduction"], [83, "introduction"]], "APIs": [[33, "apis"]], "Code Example": [[33, "code-example"], [37, "code-example"], [39, "code-example"], [40, "code-example"], [50, "code-example"], [51, "code-example"], [62, "code-example"], [63, "code-example"], [66, "code-example"], [77, "code-example"], [78, "code-example"]], "Utility Functions": [[33, "utility-functions"]], "Welcome to AI Model Efficiency Toolkit API Docs!": [[34, "welcome-to-ai-model-efficiency-toolkit-api-docs"]], "Indices and tables": [[34, "indices-and-tables"]], "AIMET Keras APIs": [[35, "aimet-keras-apis"]], "AIMET Keras AdaRound API": [[36, "aimet-keras-adaround-api"]], "User Guide Link": [[36, "user-guide-link"], [39, "user-guide-link"], [46, "user-guide-link"], [48, "user-guide-link"], [49, "user-guide-link"], [50, "user-guide-link"], [57, "user-guide-link"], [58, "user-guide-link"], [60, "user-guide-link"], [62, "user-guide-link"], [68, "user-guide-link"], [71, "user-guide-link"], [73, "user-guide-link"], [75, "user-guide-link"], [77, "user-guide-link"], [84, "user-guide-link"], [86, "user-guide-link"]], "Examples Notebook Link": [[36, "examples-notebook-link"], [37, "examples-notebook-link"], [39, "examples-notebook-link"], [57, "examples-notebook-link"], [58, "examples-notebook-link"], [59, "examples-notebook-link"], [62, "examples-notebook-link"], [68, "examples-notebook-link"], [71, "examples-notebook-link"], [73, "examples-notebook-link"], [74, "examples-notebook-link"], [77, "examples-notebook-link"], [84, "examples-notebook-link"], [86, "examples-notebook-link"]], "Top-level API": [[36, "top-level-api"], [40, "top-level-api"], [42, "top-level-api"], [44, "top-level-api"], [46, "top-level-api"], [48, "top-level-api"], [49, "top-level-api"], [51, "top-level-api"], [52, "top-level-api"], [54, "top-level-api"], [57, "top-level-api"], [58, "top-level-api"], [63, "top-level-api"], [66, "top-level-api"], [68, "top-level-api"], [71, "top-level-api"], [73, "top-level-api"], [78, "top-level-api"], [80, "top-level-api"], [84, "top-level-api"], [86, "top-level-api"]], "Adaround Parameters": [[36, "adaround-parameters"], [48, "adaround-parameters"], [57, "adaround-parameters"], [71, "adaround-parameters"]], "Enum Definition": [[36, "enum-definition"], [57, "enum-definition"], [71, "enum-definition"], [78, "enum-definition"], [86, "enum-definition"]], "Code Examples": [[36, "code-examples"], [38, "code-examples"], [42, "code-examples"], [44, "code-examples"], [46, "code-examples"], [49, "code-examples"], [52, "code-examples"], [54, "code-examples"], [57, "code-examples"], [58, "code-examples"], [61, "code-examples"], [68, "code-examples"], [73, "code-examples"], [76, "code-examples"], [80, "code-examples"], [84, "code-examples"], [87, "code-examples"], [88, "code-examples"]], "AIMET Keras BatchNorm Re-estimation APIs": [[37, "aimet-keras-batchnorm-re-estimation-apis"]], "Top-level APIs": [[37, "top-level-apis"], [59, "top-level-apis"], [74, "top-level-apis"]], "Limitations": [[37, "limitations"], [42, "limitations"]], "AIMET Keras Compression API": [[38, "aimet-keras-compression-api"]], "Top-level API for Compression": [[38, "top-level-api-for-compression"], [61, "top-level-api-for-compression"], [76, "top-level-api-for-compression"]], "Greedy Selection Parameters": [[38, "greedy-selection-parameters"], [61, "greedy-selection-parameters"], [76, "greedy-selection-parameters"]], "Spatial SVD Configuration": [[38, "spatial-svd-configuration"], [61, "spatial-svd-configuration"], [76, "spatial-svd-configuration"]], "Configuration Definitions": [[38, "configuration-definitions"], [61, "configuration-definitions"], [76, "configuration-definitions"]], "AIMET Keras Cross Layer Equalization APIs": [[39, "aimet-keras-cross-layer-equalization-apis"]], "Cross Layer Equalization API": [[39, "cross-layer-equalization-api"], [50, "cross-layer-equalization-api"], [62, "cross-layer-equalization-api"], [77, "cross-layer-equalization-api"]], "Primitive APIs": [[39, "primitive-apis"], [62, "primitive-apis"], [77, "primitive-apis"]], "AIMET Keras Layer Output Generation API": [[40, "aimet-keras-layer-output-generation-api"]], "Keras Model Guidelines": [[41, "keras-model-guidelines"]], "Model Preparer API": [[42, "model-preparer-api"], [80, "model-preparer-api"]], "AIMET Keras Cross Layer Equalization Primitive API": [[43, "aimet-keras-cross-layer-equalization-primitive-api"]], "Higher Level APIs for Cross Layer Equalization": [[43, "higher-level-apis-for-cross-layer-equalization"], [65, "higher-level-apis-for-cross-layer-equalization"], [83, "higher-level-apis-for-cross-layer-equalization"]], "Code Examples for Higher Level APIs": [[43, "code-examples-for-higher-level-apis"], [65, "code-examples-for-higher-level-apis"], [83, "code-examples-for-higher-level-apis"]], "Lower Level APIs for Cross Layer Equalization": [[43, "lower-level-apis-for-cross-layer-equalization"], [65, "lower-level-apis-for-cross-layer-equalization"], [83, "lower-level-apis-for-cross-layer-equalization"]], "Custom Datatype used": [[43, "custom-datatype-used"], [65, "custom-datatype-used"]], "Code Example for Lower level APIs": [[43, "code-example-for-lower-level-apis"], [65, "code-example-for-lower-level-apis"]], "Example helper methods to perform CLE in manual mode": [[43, "example-helper-methods-to-perform-cle-in-manual-mode"], [65, "example-helper-methods-to-perform-cle-in-manual-mode"]], "AIMET Keras Quant Analyzer API": [[44, "aimet-keras-quant-analyzer-api"]], "AIMET Keras Quantization APIs": [[45, "aimet-keras-quantization-apis"]], "AIMET Keras Quantization SIM API": [[46, "aimet-keras-quantization-sim-api"]], "AIMET ONNX APIs": [[47, "aimet-onnx-apis"]], "AIMET ONNX AdaRound API": [[48, "aimet-onnx-adaround-api"]], "Code Example - Adaptive Rounding (AdaRound)": [[48, "code-example-adaptive-rounding-adaround"], [71, "code-example-adaptive-rounding-adaround"]], "AIMET ONNX AutoQuant API": [[49, "aimet-onnx-autoquant-api"]], "AIMET ONNX Cross Layer Equalization APIs": [[50, "aimet-onnx-cross-layer-equalization-apis"]], "AIMET ONNX Layer Output Generation API": [[51, "aimet-onnx-layer-output-generation-api"]], "AIMET ONNX Quant Analyzer API": [[52, "aimet-onnx-quant-analyzer-api"]], "Run specific utility": [[52, "run-specific-utility"], [84, "run-specific-utility"]], "AIMET ONNX Quantization APIs": [[53, "aimet-onnx-quantization-apis"]], "AIMET ONNX Quantization SIM API": [[54, "aimet-onnx-quantization-sim-api"]], "Encoding Format Specification": [[55, "encoding-format-specification"]], "1. Versioning": [[55, "versioning"]], "2. Version 0.4.0 (up to)": [[55, "version-0-4-0-up-to"]], "2.1. Encoding Specification": [[55, "encoding-specification"]], "2.2. Encoding File Example for PyTorch": [[55, "encoding-file-example-for-pytorch"]], "2.3. Encoding File Example for TensorFlow": [[55, "encoding-file-example-for-tensorflow"]], "3. Version 0.5.0": [[55, "version-0-5-0"]], "3.1. Encoding Specification": [[55, "id1"]], "3.2. Encoding File Example for PyTorch": [[55, "id2"]], "3.3. Encoding File Example for TensorFlow": [[55, "id3"]], "4. Version 0.6.1": [[55, "version-0-6-1"]], "4.1. Encoding Specification": [[55, "id4"]], "AIMET TensorFlow APIs": [[56, "aimet-tensorflow-apis"]], "AIMET TensorFlow AdaRound API": [[57, "aimet-tensorflow-adaround-api"]], "AIMET TensorFlow AutoQuant API": [[58, "aimet-tensorflow-autoquant-api"]], "AIMET TensorFlow BatchNorm Re-estimation APIs": [[59, "aimet-tensorflow-batchnorm-re-estimation-apis"]], "Code Example - BN-Reestimation": [[59, "code-example-bn-reestimation"], [74, "code-example-bn-reestimation"]], "AIMET TensorFlow Bias Correction API": [[60, "aimet-tensorflow-bias-correction-api"]], "Bias Correction API": [[60, "bias-correction-api"], [75, "bias-correction-api"]], "Input Parameter Types": [[60, "input-parameter-types"]], "Data Input Type": [[60, "data-input-type"]], "Code Examples for Bias Correction": [[60, "code-examples-for-bias-correction"]], "Bias Correction Per Layer API": [[60, "bias-correction-per-layer-api"]], "Code Example for Per-Layer Bias Correction": [[60, "code-example-for-per-layer-bias-correction"]], "AIMET TensorFlow Compression API": [[61, "aimet-tensorflow-compression-api"]], "Channel Pruning Configuration": [[61, "channel-pruning-configuration"], [76, "channel-pruning-configuration"]], "Weight SVD Top-level API": [[61, "weight-svd-top-level-api"]], "Code Examples for Weight SVD": [[61, "code-examples-for-weight-svd"]], "AIMET TensorFlow Cross Layer Equalization APIs": [[62, "aimet-tensorflow-cross-layer-equalization-apis"]], "AIMET Tensorflow Layer Output Generation API": [[63, "aimet-tensorflow-layer-output-generation-api"]], "TensorFlow Model Guidelines": [[64, "tensorflow-model-guidelines"]], "AIMET TensorFlow Cross Layer Equalization Primitive API": [[65, "aimet-tensorflow-cross-layer-equalization-primitive-api"]], "AIMET Tensorflow Quant Analyzer API": [[66, "aimet-tensorflow-quant-analyzer-api"]], "AIMET TensorFlow Quantization APIs": [[67, "aimet-tensorflow-quantization-apis"]], "AIMET TensorFlow Quantization SIM API": [[68, "aimet-tensorflow-quantization-sim-api"]], "AIMET Visualization for Quantization for TensorFlow API": [[69, "aimet-visualization-for-quantization-for-tensorflow-api"]], "Top-level API for Visualization of Weight tensors": [[69, "top-level-api-for-visualization-of-weight-tensors"]], "Code Examples for Visualization of Weight tensors": [[69, "code-examples-for-visualization-of-weight-tensors"]], "AIMET PyTorch APIs": [[70, "aimet-pytorch-apis"]], "AIMET PyTorch AdaRound API": [[71, "aimet-pytorch-adaround-api"]], "Architecture Checker API": [[72, "architecture-checker-api"]], "HTML report content": [[72, "id1"]], "AIMET PyTorch AutoQuant API": [[73, "aimet-pytorch-autoquant-api"]], "AIMET PyTorch BatchNorm Re-estimation APIs": [[74, "aimet-pytorch-batchnorm-re-estimation-apis"]], "AIMET PyTorch Bias Correction API": [[75, "aimet-pytorch-bias-correction-api"]], "ConvBnInfoType": [[75, "convbninfotype"]], "ActivationType": [[75, "activationtype"]], "Quantization Params": [[75, "quantization-params"]], "Code Example #1 Empirical Bias Correction": [[75, "code-example-1-empirical-bias-correction"]], "Code Example #2 Analytical + Empirical Bias correction": [[75, "code-example-2-analytical-empirical-bias-correction"]], "AIMET PyTorch Compression API": [[76, "aimet-pytorch-compression-api"]], "TAR Selection Parameters": [[76, "tar-selection-parameters"]], "Weight SVD Configuration": [[76, "weight-svd-configuration"]], "AIMET PyTorch Cross Layer Equalization APIs": [[77, "aimet-pytorch-cross-layer-equalization-apis"]], "AIMET PyTorch Layer Output Generation API": [[78, "aimet-pytorch-layer-output-generation-api"]], "PyTorch Model Guidelines": [[79, "pytorch-model-guidelines"]], "Limitations of torch.fx symbolic trace API": [[80, "limitations-of-torch-fx-symbolic-trace-api"]], "Model Validator Utility": [[81, "model-validator-utility"]], "PyTorch Multi-GPU support": [[82, "pytorch-multi-gpu-support"]], "AIMET PyTorch Cross Layer Equalization Primitive API": [[83, "aimet-pytorch-cross-layer-equalization-primitive-api"]], "ClsSetInfo Definition": [[83, "clssetinfo-definition"]], "Code Examples for Lower Level APIs": [[83, "code-examples-for-lower-level-apis"]], "AIMET PyTorch Quant Analyzer API": [[84, "aimet-pytorch-quant-analyzer-api"]], "AIMET PyTorch Quantization APIs": [[85, "aimet-pytorch-quantization-apis"]], "AIMET PyTorch Quantization SIM API": [[86, "aimet-pytorch-quantization-sim-api"]], "Guidelines": [[86, "guidelines"]], "Code Example - Quantization Aware Training (QAT)": [[86, "code-example-quantization-aware-training-qat"]], "AIMET Visualization Compression API": [[87, "aimet-visualization-compression-api"]], "Top-level API Compression": [[87, "top-level-api-compression"]], "AIMET Visualization for Quantization API": [[88, "aimet-visualization-for-quantization-api"]], "Top-level API Quantization": [[88, "top-level-api-quantization"]], "AIMET Installation": [[89, "aimet-installation"]], "Quick Install": [[89, "quick-install"]], "Release Packages": [[89, "release-packages"]], "System Requirements": [[89, "system-requirements"]], "Advanced Installation Instructions": [[89, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[90, "aimet-installation-in-docker"]], "Set variant": [[90, "set-variant"]], "Use prebuilt docker image": [[90, "use-prebuilt-docker-image"]], "Build docker image locally": [[90, "build-docker-image-locally"]], "Start docker container": [[90, "start-docker-container"]], "Install AIMET packages": [[90, "install-aimet-packages"], [91, "install-aimet-packages"]], "From PyPI": [[90, "from-pypi"], [91, "from-pypi"]], "From Release Package": [[90, "from-release-package"], [91, "from-release-package"]], "Environment setup": [[90, "environment-setup"], [91, "environment-setup"]], "AIMET Installation and Setup": [[91, "aimet-installation-and-setup"]], "Install prerequisite packages": [[91, "install-prerequisite-packages"]], "Install GPU packages": [[91, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or TensorFlow": [[91, "install-gpu-packages-for-pytorch-2-1-or-tensorflow"]], "Install GPU packages for PyTorch 1.13 or ONNX": [[91, "install-gpu-packages-for-pytorch-1-13-or-onnx"]], "Install common debian packages": [[91, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[91, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[91, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[91, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[91, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[91, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[91, "post-installation-steps"]], "AIMET AdaRound": [[93, "aimet-adaround"]], "AdaRound Use Cases": [[93, "adaround-use-cases"]], "Common terminology": [[93, "common-terminology"]], "Use Cases": [[93, "use-cases"], [104, "use-cases"]], "AIMET AutoQuant": [[94, "aimet-autoquant"]], "Overview": [[94, "overview"], [95, "overview"], [99, "overview"], [100, "overview"], [102, "overview"], [105, "overview"], [106, "overview"], [107, "overview"], [108, "overview"], [110, "overview"], [113, "overview"], [114, "overview"], [116, "overview"]], "Workflow": [[94, "workflow"], [95, "workflow"]], "AIMET BN Re-estimation": [[95, "aimet-bn-re-estimation"]], "AIMET Channel Pruning": [[96, "aimet-channel-pruning"]], "Overall Procedure": [[96, "overall-procedure"]], "Channel Selection": [[96, "channel-selection"]], "Winnowing": [[96, "winnowing"]], "Weight Reconstruction": [[96, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[97, "aimet-compression-features-guidebook"]], "AIMET Examples": [[98, "aimet-examples"]], "Browse the notebooks": [[98, "browse-the-notebooks"]], "Running the notebooks": [[98, "running-the-notebooks"]], "Install Jupyter": [[98, "install-jupyter"]], "Download the Example notebooks and related code": [[98, "download-the-example-notebooks-and-related-code"]], "Run the notebooks": [[98, "run-the-notebooks"]], "AIMET Greedy Compression Ratio Selection": [[99, "aimet-greedy-compression-ratio-selection"]], "How it works": [[99, "how-it-works"]], "Per-layer Exploration": [[99, "per-layer-exploration"]], "Compression Ratio Selection": [[99, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[100, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[100, "features"]], "Release Information": [[100, "release-information"]], "Installation Guide": [[100, "installation-guide"]], "Getting Started": [[100, "getting-started"]], "toc tree": [[100, "toc-tree"]], "AIMET Known Issues": [[101, "aimet-known-issues"]], "AIMET Model Compression": [[102, "aimet-model-compression"]], "Use Case": [[102, "use-case"]], "Compression ratio selection": [[102, "compression-ratio-selection"]], "Model Compression": [[102, "model-compression"]], "Optional techniques to get better compression results": [[102, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[102, "rank-rounding"]], "Per-layer Fine-tuning": [[102, "per-layer-fine-tuning"]], "FAQs": [[102, "faqs"], [105, "faqs"]], "References": [[102, "references"], [105, "references"]], "Model Guidelines for PyTorch": [[103, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[104, "aimet-model-quantization"]], "AIMET Quantization Features": [[104, "aimet-quantization-features"]], "Post-Training Quantization": [[104, "post-training-quantization"]], "Debugging/Analysis Tools": [[104, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[104, "aimet-quantization-workflow"]], "PyTorch": [[104, "pytorch"], [114, "pytorch"]], "Tensorflow": [[104, "tensorflow"]], "Debugging Guidelines": [[104, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[105, "aimet-post-training-quantization-techniques"]], "User Flow": [[105, "user-flow"]], "AIMET QuantAnalyzer": [[106, "aimet-quantanalyzer"]], "Requirements": [[106, "requirements"]], "Detailed Analysis Descriptions": [[106, "detailed-analysis-descriptions"]], "AIMET Quantization Aware Training": [[107, "aimet-quantization-aware-training"]], "QAT workflow": [[107, "qat-workflow"]], "QAT modes": [[107, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[107, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[108, "quantization-simulation-configuration"]], "Configuration File Structure": [[108, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[108, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[109, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[110, "aimet-quantization-simulation"]], "QuantSim Workflow": [[110, "quantsim-workflow"]], "Simulating Quantization Noise": [[110, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[110, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[110, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[110, "configuring-quantization-simulation-ops"]], "Frequently Asked Questions": [[110, "frequently-asked-questions"]], "AIMET Release Notes": [[111, "aimet-release-notes"]], "1.22.2": [[111, "id1"]], "1.22.1": [[111, "id2"]], "1.22.0": [[111, "id3"]], "1.21.0": [[111, "id4"]], "1.20.0": [[111, "id5"]], "1.19.1.py37": [[111, "py37"]], "1.19.1": [[111, "id6"]], "1.18.0.py37": [[111, "id7"]], "1.18.0": [[111, "id8"]], "1.17.0.py37": [[111, "id9"]], "1.17.0": [[111, "id10"]], "1.16.2.py37": [[111, "id11"]], "1.16.2": [[111, "id12"]], "1.16.1.py37": [[111, "id13"]], "1.16.1": [[111, "id14"]], "1.16.0": [[111, "id15"]], "1.14.0": [[111, "id16"]], "1.13.0": [[111, "id17"]], "AIMET Spatial SVD": [[112, "aimet-spatial-svd"]], "AIMET Visualization": [[113, "aimet-visualization"]], "Design": [[113, "design"]], "Compression": [[113, "compression"]], "Starting a Bokeh Server Session:": [[113, "starting-a-bokeh-server-session"]], "How to use the tool": [[113, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[114, "aimet-visualization-for-quantization"]], "Quantization": [[114, "quantization"]], "TensorFlow": [[114, "tensorflow"]], "AIMET Weight SVD": [[115, "aimet-weight-svd"]], "AIMET Winnowing": [[116, "aimet-winnowing"]], "Winnowing Overview": [[116, "winnowing-overview"]], "How Winnowing Works": [[116, "how-winnowing-works"]]}, "indexentries": {"load_keras_model_multi_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.load_keras_model_multi_gpu"]], "load_tf_sess_variables_to_keras_single_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.load_tf_sess_variables_to_keras_single_gpu"]], "save_as_tf_module_multi_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.save_as_tf_module_multi_gpu"]], "save_tf_session_single_gpu() (in module aimet_tensorflow.utils.convert_tf_sess_to_keras)": [[33, "aimet_tensorflow.utils.convert_tf_sess_to_keras.save_tf_session_single_gpu"]], "adaroundparameters (class in aimet_tensorflow.adaround.adaround_weight)": [[36, "aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"], [57, "aimet_tensorflow.adaround.adaround_weight.AdaroundParameters"]], "quantscheme (class in aimet_common.defs)": [[36, "aimet_common.defs.QuantScheme"], [57, "aimet_common.defs.QuantScheme"], [71, "aimet_common.defs.QuantScheme"], [86, "aimet_common.defs.QuantScheme"]], "post_training_percentile (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_percentile"], [57, "aimet_common.defs.QuantScheme.post_training_percentile"], [71, "aimet_common.defs.QuantScheme.post_training_percentile"], [86, "aimet_common.defs.QuantScheme.post_training_percentile"]], "post_training_tf (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_tf"], [57, "aimet_common.defs.QuantScheme.post_training_tf"], [71, "aimet_common.defs.QuantScheme.post_training_tf"], [86, "aimet_common.defs.QuantScheme.post_training_tf"]], "post_training_tf_enhanced (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [57, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [71, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"], [86, "aimet_common.defs.QuantScheme.post_training_tf_enhanced"]], "training_range_learning_with_tf_enhanced_init (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [57, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [71, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"], [86, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_enhanced_init"]], "training_range_learning_with_tf_init (aimet_common.defs.quantscheme attribute)": [[36, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [57, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [71, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"], [86, "aimet_common.defs.QuantScheme.training_range_learning_with_tf_init"]], "fold_all_batch_norms_to_scale() (in module aimet_tensorflow.keras.batch_norm_fold)": [[37, "aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_tensorflow.keras.bn_reestimation)": [[37, "aimet_tensorflow.keras.bn_reestimation.reestimate_bn_stats"]], "compressionscheme (class in aimet_common.defs)": [[38, "aimet_common.defs.CompressionScheme"], [61, "aimet_common.defs.CompressionScheme"]], "costmetric (class in aimet_common.defs)": [[38, "aimet_common.defs.CostMetric"], [61, "aimet_common.defs.CostMetric"]], "modelcompressor (class in aimet_tensorflow.keras.compress)": [[38, "aimet_tensorflow.keras.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.ModuleCompRatioPair"], [61, "aimet_tensorflow.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters"], [61, "aimet_tensorflow.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_tensorflow.defs)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode"]], "auto (aimet_tensorflow.defs.spatialsvdparameters.mode attribute)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.auto"]], "channel_pruning (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.channel_pruning"], [61, "aimet_common.defs.CompressionScheme.channel_pruning"]], "compress_model() (aimet_tensorflow.keras.compress.modelcompressor static method)": [[38, "aimet_tensorflow.keras.compress.ModelCompressor.compress_model"]], "mac (aimet_common.defs.costmetric attribute)": [[38, "aimet_common.defs.CostMetric.mac"], [61, "aimet_common.defs.CostMetric.mac"]], "manual (aimet_tensorflow.defs.spatialsvdparameters.mode attribute)": [[38, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"], [61, "aimet_tensorflow.defs.SpatialSvdParameters.Mode.manual"]], "memory (aimet_common.defs.costmetric attribute)": [[38, "aimet_common.defs.CostMetric.memory"], [61, "aimet_common.defs.CostMetric.memory"]], "spatial_svd (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.spatial_svd"], [61, "aimet_common.defs.CompressionScheme.spatial_svd"]], "weight_svd (aimet_common.defs.compressionscheme attribute)": [[38, "aimet_common.defs.CompressionScheme.weight_svd"], [61, "aimet_common.defs.CompressionScheme.weight_svd"]], "equalize_model() (in module aimet_tensorflow.keras.cross_layer_equalization)": [[39, "aimet_tensorflow.keras.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_tensorflow.keras.layer_output_utils)": [[40, "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil"]], "generate_layer_outputs() (aimet_tensorflow.keras.layer_output_utils.layeroutpututil method)": [[40, "aimet_tensorflow.keras.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "prepare_model() (in module aimet_tensorflow.keras.model_preparer)": [[42, "aimet_tensorflow.keras.model_preparer.prepare_model"]], "clssetinfo (class in aimet_tensorflow.keras.cross_layer_equalization)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_tensorflow.keras.cross_layer_equalization)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_tensorflow.keras.cross_layer_equalization.highbiasfold)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.HighBiasFold.bias_fold"], [43, "id0"]], "fold_all_batch_norms() (in module aimet_tensorflow.keras.batch_norm_fold)": [[43, "aimet_tensorflow.keras.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_tensorflow.keras.batch_norm_fold)": [[43, "aimet_tensorflow.keras.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_tensorflow.keras.cross_layer_equalization.crosslayerscaling)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_tensorflow.keras.cross_layer_equalization.crosslayerscaling)": [[43, "aimet_tensorflow.keras.cross_layer_equalization.CrossLayerScaling.scale_model"]], "quantanalyzer (class in aimet_tensorflow.keras.quant_analyzer)": [[44, "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_tensorflow.keras.quant_analyzer.quantanalyzer method)": [[44, "aimet_tensorflow.keras.quant_analyzer.QuantAnalyzer.analyze"]], "quantizationsimmodel (class in aimet_tensorflow.keras.quantsim)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_tensorflow.keras.quantsim.quantizationsimmodel method)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_tensorflow.keras.quantsim.quantizationsimmodel method)": [[46, "aimet_tensorflow.keras.quantsim.QuantizationSimModel.export"]], "apply_adaround() (in module aimet_tensorflow.adaround.adaround_weight.adaround)": [[57, "aimet_tensorflow.adaround.adaround_weight.Adaround.apply_adaround"]], "autoquant (class in aimet_tensorflow.auto_quant)": [[58, "aimet_tensorflow.auto_quant.AutoQuant"]], "apply() (aimet_tensorflow.auto_quant.autoquant method)": [[58, "aimet_tensorflow.auto_quant.AutoQuant.apply"]], "set_adaround_params() (aimet_tensorflow.auto_quant.autoquant method)": [[58, "aimet_tensorflow.auto_quant.AutoQuant.set_adaround_params"]], "fold_all_batch_norms_to_scale() (in module aimet_tensorflow.batch_norm_fold)": [[59, "aimet_tensorflow.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_tensorflow.bn_reestimation)": [[59, "aimet_tensorflow.bn_reestimation.reestimate_bn_stats"]], "biascorrectionparams() (in module aimet_tensorflow.bias_correction)": [[60, "aimet_tensorflow.bias_correction.BiasCorrectionParams"]], "quantparams (class in aimet_tensorflow.bias_correction)": [[60, "aimet_tensorflow.bias_correction.QuantParams"]], "analytical_bias_correction_per_layer() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.analytical_bias_correction_per_layer"]], "bias_correction_per_layer() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.bias_correction_per_layer"]], "correct_bias() (in module aimet_tensorflow.bias_correction.biascorrection)": [[60, "aimet_tensorflow.bias_correction.BiasCorrection.correct_bias"]], "channelpruningparameters (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_tensorflow.defs)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode"]], "modelcompressor (class in aimet_tensorflow.compress)": [[61, "aimet_tensorflow.compress.ModelCompressor"]], "svd (class in aimet_tensorflow.svd)": [[61, "aimet_tensorflow.svd.Svd"]], "auto (aimet_tensorflow.defs.channelpruningparameters.mode attribute)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode.auto"]], "compress_model() (aimet_tensorflow.compress.modelcompressor static method)": [[61, "aimet_tensorflow.compress.ModelCompressor.compress_model"]], "compress_net() (aimet_tensorflow.svd.svd method)": [[61, "aimet_tensorflow.svd.Svd.compress_net"]], "manual (aimet_tensorflow.defs.channelpruningparameters.mode attribute)": [[61, "aimet_tensorflow.defs.ChannelPruningParameters.Mode.manual"]], "equalize_model() (in module aimet_tensorflow.cross_layer_equalization)": [[62, "aimet_tensorflow.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_tensorflow.layer_output_utils)": [[63, "aimet_tensorflow.layer_output_utils.LayerOutputUtil"]], "generate_layer_outputs() (aimet_tensorflow.layer_output_utils.layeroutpututil method)": [[63, "aimet_tensorflow.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "update_keras_bn_ops_trainable_flag() (in module aimet_tensorflow.utils.graph)": [[64, "aimet_tensorflow.utils.graph.update_keras_bn_ops_trainable_flag"]], "clssetinfo (class in aimet_tensorflow.cross_layer_equalization)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_tensorflow.cross_layer_equalization)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_tensorflow.cross_layer_equalization.highbiasfold)": [[65, "aimet_tensorflow.cross_layer_equalization.HighBiasFold.bias_fold"], [65, "id0"]], "fold_all_batch_norms() (in module aimet_tensorflow.batch_norm_fold)": [[65, "aimet_tensorflow.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_tensorflow.batch_norm_fold)": [[65, "aimet_tensorflow.batch_norm_fold.fold_given_batch_norms"]], "map_cls_sets_to_new_session() (aimet_tensorflow.cross_layer_equalization.clssetinfo static method)": [[65, "aimet_tensorflow.cross_layer_equalization.ClsSetInfo.map_cls_sets_to_new_session"]], "scale_cls_sets() (in module aimet_tensorflow.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_tensorflow.cross_layer_equalization.crosslayerscaling)": [[65, "aimet_tensorflow.cross_layer_equalization.CrossLayerScaling.scale_model"]], "quantanalyzer (class in aimet_tensorflow.quant_analyzer)": [[66, "aimet_tensorflow.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_tensorflow.quant_analyzer.quantanalyzer method)": [[66, "aimet_tensorflow.quant_analyzer.QuantAnalyzer.analyze"]], "quantizationsimmodel (class in aimet_tensorflow.quantsim)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_tensorflow.quantsim.quantizationsimmodel method)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_tensorflow.quantsim.quantizationsimmodel method)": [[68, "aimet_tensorflow.quantsim.QuantizationSimModel.export"]], "visualize_relative_weight_ranges_single_layer() (in module aimet_tensorflow.plotting_utils)": [[69, "aimet_tensorflow.plotting_utils.visualize_relative_weight_ranges_single_layer"]], "visualize_weight_ranges_single_layer() (in module aimet_tensorflow.plotting_utils)": [[69, "aimet_tensorflow.plotting_utils.visualize_weight_ranges_single_layer"]], "adaroundparameters (class in aimet_torch.adaround.adaround_weight)": [[71, "aimet_torch.adaround.adaround_weight.AdaroundParameters"]], "apply_adaround() (in module aimet_torch.adaround.adaround_weight.adaround)": [[71, "aimet_torch.adaround.adaround_weight.Adaround.apply_adaround"]], "check_model_arch() (in module aimet_torch.arch_checker.arch_checker.archchecker)": [[72, "aimet_torch.arch_checker.arch_checker.ArchChecker.check_model_arch"]], "autoquant (class in aimet_torch.auto_quant)": [[73, "aimet_torch.auto_quant.AutoQuant"]], "get_quant_scheme_candidates() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.get_quant_scheme_candidates"]], "optimize() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.optimize"]], "run_inference() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.run_inference"]], "set_adaround_params() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.set_adaround_params"]], "set_export_params() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.set_export_params"]], "set_model_preparer_params() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.set_model_preparer_params"]], "set_quant_scheme_candidates() (aimet_torch.auto_quant.autoquant method)": [[73, "aimet_torch.auto_quant.AutoQuant.set_quant_scheme_candidates"]], "fold_all_batch_norms_to_scale() (in module aimet_torch.batch_norm_fold)": [[74, "aimet_torch.batch_norm_fold.fold_all_batch_norms_to_scale"]], "reestimate_bn_stats() (in module aimet_torch.bn_reestimation)": [[74, "aimet_torch.bn_reestimation.reestimate_bn_stats"]], "activationtype (class in aimet_common.defs)": [[75, "aimet_common.defs.ActivationType"]], "convbninfotype (class in aimet_common.bias_correction)": [[75, "aimet_common.bias_correction.ConvBnInfoType"]], "quantparams (class in aimet_torch.quantsim)": [[75, "aimet_torch.quantsim.QuantParams"]], "correct_bias() (in module aimet_torch.bias_correction)": [[75, "aimet_torch.bias_correction.correct_bias"]], "no_activation (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.no_activation"]], "relu (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.relu"]], "relu6 (aimet_common.defs.activationtype attribute)": [[75, "aimet_common.defs.ActivationType.relu6"]], "channelpruningparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters"]], "channelpruningparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.AutoModeParams"]], "channelpruningparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.ManualModeParams"]], "channelpruningparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode"]], "greedyselectionparameters (class in aimet_common.defs)": [[76, "aimet_common.defs.GreedySelectionParameters"]], "modelcompressor (class in aimet_torch.compress)": [[76, "aimet_torch.compress.ModelCompressor"]], "modulecompratiopair (class in aimet_torch.defs)": [[76, "aimet_torch.defs.ModuleCompRatioPair"]], "spatialsvdparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters"]], "spatialsvdparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.AutoModeParams"]], "spatialsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.ManualModeParams"]], "spatialsvdparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode"]], "tarrankselectionparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.TarRankSelectionParameters"]], "weightsvdparameters (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters"]], "weightsvdparameters.automodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.AutoModeParams"]], "weightsvdparameters.manualmodeparams (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.ManualModeParams"]], "weightsvdparameters.mode (class in aimet_torch.defs)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode"]], "auto (aimet_torch.defs.channelpruningparameters.mode attribute)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode.auto"]], "auto (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode.auto"]], "auto (aimet_torch.defs.weightsvdparameters.mode attribute)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode.auto"]], "compress_model() (aimet_torch.compress.modelcompressor static method)": [[76, "aimet_torch.compress.ModelCompressor.compress_model"]], "manual (aimet_torch.defs.channelpruningparameters.mode attribute)": [[76, "aimet_torch.defs.ChannelPruningParameters.Mode.manual"]], "manual (aimet_torch.defs.spatialsvdparameters.mode attribute)": [[76, "aimet_torch.defs.SpatialSvdParameters.Mode.manual"]], "manual (aimet_torch.defs.weightsvdparameters.mode attribute)": [[76, "aimet_torch.defs.WeightSvdParameters.Mode.manual"]], "equalize_model() (in module aimet_torch.cross_layer_equalization)": [[77, "aimet_torch.cross_layer_equalization.equalize_model"]], "layeroutpututil (class in aimet_torch.layer_output_utils)": [[78, "aimet_torch.layer_output_utils.LayerOutputUtil"]], "namingscheme (class in aimet_torch.layer_output_utils)": [[78, "aimet_torch.layer_output_utils.NamingScheme"]], "onnx (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.ONNX"]], "pytorch (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.PYTORCH"]], "torchscript (aimet_torch.layer_output_utils.namingscheme attribute)": [[78, "aimet_torch.layer_output_utils.NamingScheme.TORCHSCRIPT"]], "generate_layer_outputs() (aimet_torch.layer_output_utils.layeroutpututil method)": [[78, "aimet_torch.layer_output_utils.LayerOutputUtil.generate_layer_outputs"]], "prepare_model() (in module aimet_torch.model_preparer)": [[80, "aimet_torch.model_preparer.prepare_model"]], "clssetinfo (class in aimet_torch.cross_layer_equalization)": [[83, "aimet_torch.cross_layer_equalization.ClsSetInfo"]], "clssetinfo.clssetlayerpairinfo (class in aimet_torch.cross_layer_equalization)": [[83, "aimet_torch.cross_layer_equalization.ClsSetInfo.ClsSetLayerPairInfo"]], "bias_fold() (in module aimet_torch.cross_layer_equalization.highbiasfold)": [[83, "aimet_torch.cross_layer_equalization.HighBiasFold.bias_fold"], [83, "id0"]], "fold_all_batch_norms() (in module aimet_torch.batch_norm_fold)": [[83, "aimet_torch.batch_norm_fold.fold_all_batch_norms"]], "fold_given_batch_norms() (in module aimet_torch.batch_norm_fold)": [[83, "aimet_torch.batch_norm_fold.fold_given_batch_norms"]], "scale_cls_sets() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[83, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_cls_sets"]], "scale_model() (in module aimet_torch.cross_layer_equalization.crosslayerscaling)": [[83, "aimet_torch.cross_layer_equalization.CrossLayerScaling.scale_model"]], "callbackfunc (class in aimet_common.utils)": [[84, "aimet_common.utils.CallbackFunc"]], "quantanalyzer (class in aimet_torch.quant_analyzer)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer"]], "analyze() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.analyze"]], "check_model_sensitivity_to_quantization() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"]], "enable_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"]], "export_per_layer_encoding_min_max_range() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"]], "export_per_layer_mse_loss() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"]], "export_per_layer_stats_histogram() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"]], "perform_per_layer_analysis_by_disabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"]], "perform_per_layer_analysis_by_enabling_quant_wrappers() (aimet_torch.quant_analyzer.quantanalyzer method)": [[84, "aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"]], "quantizationsimmodel (class in aimet_torch.quantsim)": [[86, "aimet_torch.quantsim.QuantizationSimModel"]], "compute_encodings() (aimet_torch.quantsim.quantizationsimmodel method)": [[86, "aimet_torch.quantsim.QuantizationSimModel.compute_encodings"]], "export() (aimet_torch.quantsim.quantizationsimmodel method)": [[86, "aimet_torch.quantsim.QuantizationSimModel.export"]], "load_checkpoint() (aimet_torch.quantsim method)": [[86, "aimet_torch.quantsim.load_checkpoint"]], "save_checkpoint() (aimet_torch.quantsim method)": [[86, "aimet_torch.quantsim.save_checkpoint"]], "visualizecompression (class in aimet_torch.visualize_serialized_data)": [[87, "aimet_torch.visualize_serialized_data.VisualizeCompression"]], "display_comp_ratio_plot() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[87, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_comp_ratio_plot"]], "display_eval_scores() (aimet_torch.visualize_serialized_data.visualizecompression method)": [[87, "aimet_torch.visualize_serialized_data.VisualizeCompression.display_eval_scores"]], "visualize_changes_after_optimization() (in module aimet_torch.visualize_model)": [[88, "aimet_torch.visualize_model.visualize_changes_after_optimization"]], "visualize_relative_weight_ranges_to_identify_problematic_layers() (in module aimet_torch.visualize_model)": [[88, "aimet_torch.visualize_model.visualize_relative_weight_ranges_to_identify_problematic_layers"]], "visualize_weight_ranges() (in module aimet_torch.visualize_model)": [[88, "aimet_torch.visualize_model.visualize_weight_ranges"]]}})