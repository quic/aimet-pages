Search.setIndex({"docnames": ["_templates/autosummary/class", "_templates/autosummary/function", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.fake_quantization_mixin", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize", "torch_docs/api/quantization/affine/index", "torch_docs/api/quantization/float/FloatQuantizeDequantize", "torch_docs/api/quantization/float/index", "torch_docs/api/quantization/tensor", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/quickstart_guide", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["_templates/autosummary/class.rst", "_templates/autosummary/function.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.fake_quantization_mixin.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.Quantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.QuantizeDequantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.dequantize.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_.rst", "torch_docs/api/quantization/affine/generated/aimet_torch.v2.quantization.affine.quantize_dequantize.rst", "torch_docs/api/quantization/affine/index.rst", "torch_docs/api/quantization/float/FloatQuantizeDequantize.rst", "torch_docs/api/quantization/float/index.rst", "torch_docs/api/quantization/tensor.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.rst", "torch_docs/generated/aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/quickstart_guide.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["&lt;no title&gt;", "&lt;no title&gt;", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "FakeQuantizationMixin", "nn.QuantizationMixin", "Quantize", "QuantizeDequantize", "dequantize", "quantize", "quantize_dequantize", "quantization.affine", "FloatQuantizeDequantize", "quantization.float", "quantization.tensor", "Encoding Analyzers", "Post-Training Quantization", "MinMaxEncodingAnalyzer", "PercentileEncodingAnalyzer", "SqnrEncodingAnalyzer", "Welcome to AI Model Efficiency Toolkit PyTorch API Docs!", "Quantized Modules", "Quantizers", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"name": [0, 1, 3, 6, 23, 24, 37, 42, 43, 45], "escap": [0, 1], "underlin": [0, 1], "qualcomm": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "innov": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "center": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "inc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "ai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "effici": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "toolkit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "quantsim_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "default_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "json": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48], "The": [2, 4, 6, 11, 12, 14, 16, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48], "pytorch": [2, 3, 6, 7, 23, 28, 32, 38, 40, 42, 43], "gpu": [2, 3, 36, 43], "pypi": 2, "ar": [2, 6, 8, 9, 14, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48], "avail": [2, 25, 35, 38, 40, 41], "environ": 2, "meet": [2, 27, 30, 31], "follow": [2, 3, 4, 6, 22, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 42, 44, 47, 48], "64": [2, 21, 26], "bit": [2, 14, 25, 26, 28, 36, 41, 42, 43], "intel": 2, "x86": 2, "compat": [2, 25], "processor": 2, "linux": [2, 4], "ubuntu": [2, 4], "22": [2, 4, 25], "04": [2, 4], "lt": [2, 4], "python": [2, 3, 4], "3": [2, 11, 12, 16, 21, 25, 30, 36, 39, 41, 48], "10": [2, 3, 4, 6, 7, 8, 9, 11, 16, 23, 24, 25, 31, 34, 39], "cuda": [2, 4, 25], "12": [2, 11], "0": [2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 20, 21, 23, 24, 25, 26, 30, 31, 35, 40], "torch": [2, 3, 6, 7, 8, 9, 11, 12, 14, 16, 23, 24, 25, 35, 43], "2": [2, 3, 9, 11, 12, 14, 16, 24, 26, 36, 41, 42], "1": [2, 3, 6, 7, 8, 9, 11, 12, 14, 16, 23, 24, 31, 33, 34, 35, 36, 40, 41, 42, 44, 47, 48], "pip": [2, 3, 4], "apt": [2, 3, 4], "get": [2, 3, 4, 26, 29, 36, 46], "liblapack": [2, 3, 4], "python3": [2, 3, 4], "m": [2, 3, 4], "For": [2, 3, 4, 6, 23, 25, 26, 29, 30, 31, 32, 33, 34, 36, 38, 40, 42, 45, 48], "other": [2, 31, 33, 34, 36, 38, 41, 42, 43], "variant": [2, 4, 39, 42], "latest": [2, 3], "version": [2, 3, 4, 6, 7, 22, 23, 25, 32], "from": [2, 6, 8, 9, 14, 16, 20, 23, 24, 25, 26, 29, 30, 31, 35, 36, 37, 38, 39, 40, 41, 42, 45, 48], "whl": [2, 3, 4], "file": [2, 3, 4, 25, 36, 38, 39, 42, 43, 46], "host": [2, 3, 4, 43, 45], "http": [2, 3, 4, 30, 37, 43, 45], "github": [2, 3, 4, 30, 43], "com": [2, 3, 4, 43], "quic": [2, 3, 4, 30, 43], "13": [2, 3, 8, 11, 24], "11": [2, 4, 11, 16], "x": [2, 14, 16, 23, 25, 30, 35, 38], "download": [2, 3, 4, 25], "31": [2, 3, 4], "aimet_torch": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 23, 24, 25, 35], "torch_gpu_": 2, "cp38": [2, 4], "linux_x86_64": [2, 3, 4], "cpu": [2, 3, 4, 25, 36, 43], "onli": [2, 3, 4, 11, 12, 16, 23, 25, 28, 33, 36, 38, 39, 40, 43, 48], "torch_cpu_": 2, "tensorflow": [2, 3, 22, 28, 32, 33, 40, 42, 43], "aimet_tensorflow": [2, 3, 4], "tf_gpu_": 2, "tf_cpu_": 2, "onnx": [2, 3, 22, 32, 35, 36, 40], "14": [2, 11, 25], "aimet_onnx": [2, 3, 4], "onnx_gpu_": 2, "onnx_cpu_": 2, "previou": [2, 25, 30, 31, 41], "brows": 2, "each": [2, 3, 4, 6, 7, 23, 24, 25, 29, 30, 31, 36, 37, 38, 39, 40, 41, 42, 46, 48], "includ": [2, 7, 28, 34, 36, 38, 40, 42, 43], "multipl": [2, 4, 23, 32, 34, 36, 43], "format": [2, 24, 27, 33], "torch_gpu": [2, 3, 4], "torch_cpu": [2, 3, 4], "tf_gpu": [2, 3, 4], "tf_cpu": [2, 3, 4], "onnx_gpu": [2, 3, 4], "onnx_cpu": [2, 3, 4], "package_prefix": 2, "_": [2, 3, 4, 8, 9, 23, 24, 25], "platform": [2, 36], "setup": 2, "bash": [2, 3], "command": [2, 3, 4, 45], "shell": 2, "nvidia": [2, 3, 4], "card": 2, "comput": [2, 4, 6, 7, 14, 20, 21, 25, 26, 34, 35, 36, 37, 38, 42, 45, 48], "capabl": [2, 23, 45, 46], "5": [2, 8, 9, 11, 12, 14, 23, 24, 30, 39, 41], "later": [2, 25], "docker": 2, "To": [2, 22, 23, 25, 28, 31, 34, 35, 38, 40, 41, 42, 45, 46], "us": [2, 4, 6, 7, 8, 9, 16, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 46], "acceler": [2, 22, 32, 34], "train": [2, 22, 26, 27, 28, 32, 34, 41, 42, 43], "modul": [2, 6, 7, 22, 25, 26, 36, 43, 48], "an": [2, 6, 16, 22, 23, 24, 25, 26, 27, 29, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 46, 48], "enabl": [2, 3, 22, 28, 32, 36, 38, 40, 42, 43], "minimum": [2, 11, 12, 23], "driver": [2, 4], "455": 2, "i": [2, 3, 4, 6, 7, 11, 12, 14, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48], "alwai": [2, 31], "recommend": [2, 26, 28, 30, 36, 41], "especi": [2, 36, 39, 41], "newer": 2, "both": [2, 7, 11, 12, 23, 36, 37, 39, 40, 41, 42, 44, 48], "cudnn": 2, "more": [2, 23, 25, 29, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46], "interfac": 2, "support": [2, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 47, 48], "There": [2, 26, 35, 37, 39, 45, 46], "two": [2, 23, 25, 31, 32, 34, 36, 37, 38, 39, 42, 44, 45, 46, 47], "wai": [2, 25, 31], "On": 2, "your": [2, 3, 4, 35], "machin": [2, 3, 34], "our": [2, 4, 22, 25, 31, 41, 42], "pre": [2, 3, 4, 22, 32, 37], "built": [2, 3], "develop": [2, 3, 4, 7, 23], "imag": [2, 26, 38], "pleas": [2, 3, 4, 22, 25, 26, 29, 32, 34, 38, 42], "click": 2, "appropri": [2, 3, 4, 6, 23, 30, 31, 34, 41], "link": [2, 22], "contain": [2, 6, 16, 23, 25, 36, 38, 39, 40, 42], "thi": [3, 4, 6, 7, 11, 12, 14, 16, 22, 23, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48], "page": [3, 4, 22, 30, 42, 43], "provid": [3, 4, 14, 22, 23, 25, 26, 30, 31, 34, 36, 37, 38, 40, 41, 42, 45, 46, 48], "instruct": [3, 4, 22], "insid": [3, 6, 7, 23, 25], "variant_str": [3, 4], "ONE": [3, 4], "depend": [3, 4, 16, 30, 31, 36, 40, 43], "desir": [3, 4, 25, 30, 34, 36, 41], "pt113": 3, "tf": [3, 38, 42, 43], "export": [3, 4, 22, 28, 32, 34, 35, 36, 39, 42, 43], "aimet_vari": [3, 4], "one": [3, 23, 25, 29, 34, 39, 40, 43, 44, 47], "workspac": 3, "absolute_path_to_workspac": 3, "docker_image_nam": 3, "artifact": [3, 25], "codelinaro": 3, "org": [3, 4, 37], "dev": [3, 4], "docker_container_nam": 3, "any_nam": 3, "note": [3, 4, 25, 29, 30, 31, 32, 34, 35, 36, 38], "feel": 3, "free": [3, 36, 37, 39], "modifi": [3, 4, 36, 42, 43, 48], "need": [3, 25, 27, 30, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46], "you": [3, 4, 31, 35, 44, 47], "want": 3, "If": [3, 4, 6, 7, 8, 9, 11, 12, 14, 21, 23, 24, 25, 27, 35, 36, 37, 38, 40, 41, 45, 46, 48], "skip": [3, 29], "next": [3, 25, 41], "section": [3, 4, 26, 28, 29, 34, 36, 42], "any_tag": 3, "t": [3, 26], "f": [3, 4, 25], "jenkin": 3, "dockerfil": 3, "ensur": [3, 23, 36, 41], "alreadi": [3, 31, 41], "run": [3, 8, 9, 23, 24, 28, 32, 34, 36, 37, 38, 42, 43, 45], "otherwis": [3, 4, 8, 9, 11, 12, 24, 41], "remov": [3, 6, 25, 29, 32, 42, 48], "exist": [3, 6, 36, 42], "new": [3, 8, 9, 24, 25, 36, 40, 43], "p": 3, "grep": 3, "kill": 3, "rm": 3, "u": [3, 41], "id": [3, 45], "user": [3, 22, 23, 26, 27, 30, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46], "g": [3, 22, 25, 28, 30, 32, 41, 48], "v": [3, 31], "etc": [3, 4, 30, 36], "passwd": 3, "ro": 3, "group": [3, 40, 42], "home": 3, "mnt": 3, "entrypoint": 3, "bin": [3, 4, 21], "w": [3, 48], "hostnam": 3, "abov": [3, 4, 22, 27, 28, 31, 32, 34, 35, 37, 41, 42, 48], "base": [3, 6, 7, 8, 9, 11, 12, 14, 21, 23, 24, 29, 30, 36], "filesystem": 3, "add": [3, 23, 25, 40, 42, 43, 45, 46, 48], "all": [3, 6, 7, 23, 25, 29, 31, 34, 37, 38, 40, 41], "order": [3, 4, 6, 25, 28, 29, 30, 36, 39, 42, 46], "access": [3, 36], "replac": [3, 23, 25, 37, 42], "port": [3, 45], "forward": [3, 6, 7, 8, 9, 23, 24, 25, 35, 38, 41, 43], "done": [3, 8, 9, 24, 29, 34, 40, 42, 48], "visual": [3, 34, 36, 37, 38, 41, 43, 44, 47], "api": [3, 25, 26, 27, 32, 35, 36, 38, 40, 43, 45], "can": [3, 4, 6, 8, 9, 16, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47], "achiev": [3, 26, 30, 31, 44, 47], "port_id": 3, "ani": [3, 4, 7, 22, 25, 26, 27, 40, 43], "number": [3, 6, 11, 12, 14, 21, 22, 23, 26, 31, 32, 34, 39, 42, 43, 45, 48], "through": [3, 4, 23, 25, 37, 38, 42, 45, 46], "method": [3, 4, 6, 23, 25, 31, 34, 36, 41, 42], "go": [3, 4, 25, 45], "project": [3, 4], "identifi": [3, 4, 38, 41, 43, 48], "wish": [3, 4], "should": [3, 4, 6, 23, 25, 30, 34, 40, 45, 48], "32": [3, 4, 41], "sudo": [3, 4], "y": [3, 4, 25, 38], "altern": [3, 4, 34], "we": [3, 4, 23, 25, 31, 34, 36, 37, 40, 41, 42, 46], "tag": [3, 4, 43], "below": [3, 4, 8, 9, 11, 12, 23, 24, 25, 27, 28, 36, 37, 40, 41, 42, 48], "release_tag": [3, 4], "step": [3, 11, 12, 25, 26, 27, 28, 29, 30, 31, 34, 36, 37, 39, 41, 42], "url": [3, 4, 45], "download_url": [3, 4], "common": [3, 41, 46], "suffix": [3, 4], "wheel_file_suffix": [3, 4], "cp310": [3, 4], "specifi": [3, 4, 14, 25, 27, 34, 40, 42, 46], "pend": [3, 4], "pip3": [3, 4], "h": [3, 4, 47, 48], "These": [3, 4, 23, 25, 27, 28, 29, 30, 35, 36, 37, 38, 41, 42], "assum": [3, 4], "path": [3, 4], "usr": [3, 4], "lib": [3, 4], "dist": [3, 4], "case": [3, 4, 11, 12, 23, 25, 31, 37, 39, 40], "accordingli": [3, 4], "automat": [3, 4, 30, 34, 36, 38, 43], "torch_stabl": [3, 4], "html": [3, 4, 30, 38, 43, 46], "OR": [3, 4], "variabl": [3, 4, 8, 9, 24], "sourc": [3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 23, 24, 41], "envsetup": [3, 4], "sh": [3, 4], "unless": [4, 48], "local": [4, 45], "basic": [4, 25], "requisit": 4, "updat": [4, 24, 36, 37, 39, 42, 43], "upgrad": 4, "ye": [4, 34], "wget": 4, "gnupg2": 4, "have": [4, 7, 25, 31, 34, 36, 37, 38, 41, 42], "set": [4, 6, 7, 20, 23, 24, 26, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 48], "default": [4, 7, 8, 9, 11, 12, 23, 24, 26, 31, 34, 40, 42, 43, 45], "do": [4, 25, 34, 38, 42], "were": [4, 30, 36, 40, 48], "test": 4, "8": [4, 6, 7, 8, 9, 11, 12, 14, 16, 23, 24, 25, 36, 48], "7": [4, 11, 12, 14, 25, 48], "sub": [4, 29, 34, 42, 48], "correspond": [4, 23, 29, 31, 36, 38, 48], "visit": [4, 22, 32], "archiv": 4, "obtain": [4, 29, 30, 38, 42], "correct": [4, 25, 26, 28, 36, 37, 41], "exact": [4, 23, 28], "up": [4, 34, 39, 40, 42, 48], "date": 4, "repo": 4, "ubuntu2204": 4, "x86_64": 4, "pin": 4, "mv": 4, "prefer": [4, 34], "d": 4, "repositori": 4, "600": 4, "local_instal": 4, "local_11": 4, "520": 4, "61": 4, "05": [4, 11, 12, 25], "1_amd64": 4, "deb": 4, "kei": 4, "adv": 4, "fetch": 4, "3bf863cc": 4, "pub": 4, "dpkg": 4, "cp": [4, 30], "var": 4, "keyr": 4, "gpg": 4, "share": [4, 23], "echo": 4, "list": [4, 11, 12, 21, 23, 24, 31, 33, 35, 40], "515": 4, "65": [4, 30], "01": [4, 11, 12, 26], "torch_gpu_pt113": 4, "torch_cpu_pt113": 4, "cp36": 4, "cp36m": 4, "cp37": 4, "cp37m": 4, "py3": 4, "none": [4, 6, 7, 8, 9, 10, 11, 12, 14, 23, 24, 25, 45], "actual": [4, 30, 36], "wheel": 4, "filenam": 4, "": [4, 6, 7, 22, 23, 24, 25, 30, 33, 34, 36, 37, 38, 39, 41, 42, 45, 46, 48], "cat": 4, "reqs_deb_common": 4, "txt": 4, "xarg": 4, "reqs_deb_torch_common": 4, "reqs_deb_onnx_common": 4, "reqs_deb_tf_gpu": 4, "reqs_deb_torch_gpu": 4, "reqs_deb_onnx_gpu": 4, "option": [4, 7, 8, 9, 21, 24, 25, 26, 38, 40, 42, 45], "uninstal": 4, "cach": 4, "dir": 4, "9": [4, 11, 12, 16, 41], "post1": 4, "onnxruntime_v": 4, "c": [4, 30], "import": [4, 8, 9, 11, 12, 14, 16, 23, 24, 25, 28, 29, 41], "print": [4, 6, 7, 11, 12, 23, 25, 36, 38], "__version__": 4, "ln": 4, "gnu": 4, "libjpeg": 4, "so": [4, 23, 35, 38, 45], "chose": 4, "between": [4, 23, 37, 38, 40, 42], "class": [6, 7, 8, 9, 14, 17, 19, 20, 21, 24, 25], "v2": [6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21, 23, 24, 25], "nn": [6, 8, 9, 22, 23, 24, 25, 35, 43], "arg": [6, 7, 11, 12, 16, 23], "kwarg": [6, 7, 11, 12, 16, 23], "mixin": [6, 7, 23], "implement": [6, 7, 23, 35, 41], "fake": [6, 9, 12, 14, 23, 24, 25], "quantiz": [6, 7, 9, 10, 12, 14, 17, 19, 20, 21, 22, 26, 27, 28, 30, 32, 34, 38, 43, 45], "top": [6, 29, 45], "regular": [6, 7, 23, 26, 36, 42], "specif": [6, 25, 26, 27, 28, 30, 32, 34, 35, 36, 37, 40, 43], "call": [6, 14, 16, 23, 25, 28, 34, 36, 38, 40, 42, 43, 44, 47], "its": [6, 16, 22, 23, 25, 32, 36, 38, 42, 48], "quantized_forward": [6, 23], "place": [6, 7, 39, 40], "inherit": [6, 23], "input": [6, 7, 8, 9, 11, 12, 14, 23, 24, 25, 29, 34, 38, 40, 42, 44, 45, 47, 48], "output": [6, 7, 8, 9, 11, 12, 23, 24, 25, 29, 34, 37, 38, 40, 42, 43, 44, 47, 48], "paramet": [6, 7, 8, 9, 11, 12, 14, 16, 20, 21, 23, 24, 25, 26, 28, 29, 34, 35, 36, 37, 38, 39, 40, 46], "behav": [6, 23, 41], "exactli": [6, 23, 42], "same": [6, 16, 23, 24, 28, 37, 40, 42, 46], "parent": 6, "A": [6, 21, 23, 30, 36, 38, 39, 40, 41, 42], "initi": [6, 8, 9, 14, 23, 24, 26, 39, 41, 42], "scratch": 6, "syntax": 6, "form": 6, "from_modul": 6, "input_quant": [6, 23, 25], "modulelist": [6, 23, 25], "quantizerbas": [6, 7, 23, 24], "object": [6, 7, 16, 21, 23, 24, 25, 28, 36, 39, 42], "appli": [6, 8, 9, 11, 12, 23, 24, 25, 26, 27, 28, 31, 34, 36, 37, 39, 40, 41, 42, 43, 45, 46], "layer": [6, 7, 23, 25, 26, 27, 28, 29, 30, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48], "tensor": [6, 8, 9, 10, 11, 12, 14, 21, 23, 24, 25, 26, 29, 35, 36, 38, 40, 41, 42, 43, 44, 47], "type": [6, 7, 8, 9, 16, 21, 23, 24, 36, 38, 40, 42, 45], "output_quant": [6, 7, 23, 25], "param_quant": [6, 23, 25], "moduledict": [6, 23, 25], "map": [6, 11, 12, 16, 23, 38, 40], "associ": [6, 23, 36], "exampl": [6, 7, 8, 9, 11, 12, 14, 16, 23, 24, 25, 26, 30, 31, 32, 36, 38, 40, 42, 43, 48], "qlinear": [6, 7, 23], "fakequantizedlinear": [6, 23], "in_featur": [6, 23, 25], "out_featur": [6, 23, 25], "20": [6, 26, 39], "bia": [6, 14, 25, 26, 29, 36, 37, 40, 41, 43], "fals": [6, 7, 8, 9, 11, 12, 16, 23, 24, 25, 35, 40], "weight": [6, 21, 23, 25, 26, 28, 30, 34, 36, 37, 38, 39, 40, 41, 42, 46], "linear": [6, 23, 25, 28, 29], "true": [6, 7, 8, 9, 14, 16, 21, 23, 24, 25, 35, 40], "abstract": [6, 23, 24], "perform": [6, 8, 9, 23, 24, 25, 27, 28, 29, 30, 31, 34, 36, 37, 38, 39, 41], "logic": [6, 43], "param": [6, 24, 40], "pass": [6, 7, 22, 23, 25, 32, 35, 36, 37, 38, 39, 41, 42, 43, 45], "__quant_init__": [6, 23], "invok": [6, 23, 34, 36, 45, 46], "right": [6, 8, 9, 11, 12, 14, 23, 24, 36, 48], "after": [6, 23, 25, 26, 27, 28, 30, 34, 36, 39, 41, 45, 46], "__init__": [6, 23, 25], "structur": [6, 23, 34], "size": [6, 23, 26, 34, 35, 44, 47], "initializd": [6, 23], "custom": [6, 23, 41, 42], "overridden": [6, 23], "length": [6, 21, 23], "given": [6, 7, 23, 27, 29, 31, 32, 34, 37, 44, 45, 47], "compute_encod": [6, 7, 8, 9, 14, 16, 23, 24, 25], "enter": [6, 7, 23, 27], "context": [6, 7, 23, 25], "observ": [6, 7, 17, 20, 23, 24, 25, 31, 34, 36, 37, 38, 39, 42], "encod": [6, 7, 8, 9, 16, 19, 20, 21, 22, 24, 25, 26, 28, 36, 38, 39, 43], "upon": [6, 7, 23, 25], "exit": [6, 7, 23, 25], "quantizedlinear": [6, 7, 23, 25], "symmetr": [6, 7, 8, 9, 16, 21, 23, 24, 25, 40, 42], "randn": [6, 7, 8, 9, 16, 23, 24], "16": [6, 7, 14, 23, 26], "is_initi": [6, 7, 8, 9, 14, 23, 24], "classmethod": [6, 7], "creat": [6, 23, 25, 26, 28, 34, 35, 36, 39, 42], "instanc": [6, 7, 45], "result": [6, 16, 21, 26, 27, 29, 30, 32, 37, 38, 39, 40, 42], "attribut": [6, 23, 38], "origin": [6, 23, 25, 29, 30, 34, 36, 37, 38, 39, 42, 45], "mai": [6, 7, 16, 23, 26, 30, 34, 36, 37, 38, 40, 41, 42], "assign": [6, 8, 9, 23, 24], "float": [6, 14, 16, 22, 23, 36, 38, 41, 42, 46], "point": [6, 16, 22, 23, 32, 34, 36, 38, 41, 42, 46], "return": [6, 7, 8, 9, 16, 21, 22, 24, 25, 27, 31, 32, 38, 42], "quantized_linear": 6, "get_original_modul": 6, "module_cl": [6, 7], "decor": [6, 7], "regist": [6, 7, 23, 24], "defin": [6, 23, 25, 35, 36, 38, 40, 42], "featur": [7, 23, 26, 27, 28, 34, 37, 38, 42, 43, 45, 46], "under": [7, 23, 38, 40, 45, 46], "heavi": [7, 23, 45, 46], "chang": [7, 23, 25, 26, 34, 38, 39, 40, 42, 46, 48], "occur": [7, 23], "without": [7, 14, 16, 23, 27, 36, 39, 42, 48], "notic": [7, 23, 34], "futur": [7, 23], "verion": [7, 23], "ad": [7, 25, 33, 36, 40, 43], "full": [7, 23, 47], "function": [7, 11, 12, 16, 23, 25, 26, 31, 34, 35, 36, 38, 42, 43, 45, 46], "subclass": 7, "abil": [7, 43], "well": [7, 16, 23, 30, 34, 36, 37, 38, 42, 44], "oper": [7, 23, 25, 35, 36, 37, 40, 41], "allow": [7, 16, 23, 27, 32, 34, 36, 38, 39, 40, 41, 42, 43, 45], "dispatch": 7, "librari": [7, 34], "nativ": [7, 23], "get_default_kernel": 7, "kernel": [7, 23, 29, 44, 47], "callabl": 7, "get_kernel": 7, "current": [7, 29, 32, 33, 34, 35, 40, 44, 47], "doe": [7, 23, 25, 31, 33, 36, 41], "try": [7, 27, 29, 31, 34, 36, 41], "set_default_kernel": 7, "set_kernel": 7, "underli": [7, 41], "wrap": 7, "affin": [8, 9, 10, 11, 12, 16, 22, 23, 24, 25], "shape": [8, 9, 14, 16, 19, 20, 21, 23, 24, 25, 38], "bitwidth": [8, 9, 11, 12, 14, 16, 23, 24, 25, 28, 36, 41, 42], "encoding_analyz": [8, 9, 14, 17, 19, 20, 21, 24], "block_siz": [8, 9, 10, 11, 12, 24], "precis": [8, 9, 11, 12, 14, 24, 36], "out": [8, 9, 11, 12, 14, 24, 27, 30, 34, 38], "clamp": [8, 9, 11, 12, 14, 24, 42], "left": [8, 9, 11, 12, 14, 24, 31, 48], "lceil": [8, 9, 11, 12, 14, 24], "frac": [8, 9, 11, 12, 14, 24], "scale": [8, 9, 10, 11, 12, 14, 16, 24, 28, 36, 37, 38, 39, 42], "rfloor": [8, 9, 11, 12, 14, 24], "offset": [8, 9, 10, 11, 12, 21, 24, 36, 38, 39, 42], "qmin": [8, 9, 11, 12, 24, 42], "qmax": [8, 9, 11, 12, 24, 42], "where": [8, 9, 12, 14, 23, 24, 25, 28, 31, 38, 39, 44, 47, 48], "deriv": [8, 9, 11, 12, 23, 24], "learnabl": [8, 9, 24], "theta_": [8, 9, 24], "min": [8, 9, 19, 21, 23, 24, 25, 38, 42], "max": [8, 9, 14, 19, 21, 23, 24, 25, 34, 37, 38, 42], "tupl": [8, 9, 21, 24], "int": [8, 9, 11, 12, 14, 21, 24], "bool": [8, 9, 11, 12, 21, 24], "asymmetr": [8, 9, 21, 24, 40, 42], "encodinganalyz": [8, 9, 14, 17, 24], "analyz": [8, 9, 19, 20, 21, 22, 23, 24, 27, 29, 34, 35, 38, 42, 45, 46], "calibr": [8, 9, 19, 20, 21, 23, 24, 25, 36, 38, 39, 41, 42], "absolut": [8, 9, 24], "which": [8, 9, 11, 12, 16, 21, 23, 24, 25, 26, 27, 28, 30, 31, 34, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47], "cannot": [8, 9, 24], "until": [8, 9, 24, 27], "properli": [8, 9, 24, 25], "statist": [8, 9, 14, 23, 24, 25, 28, 36, 38, 46], "manual": [8, 9, 24, 27, 34], "valu": [8, 9, 11, 12, 14, 16, 20, 21, 24, 25, 26, 31, 34, 36, 37, 38, 39, 42, 44, 46, 47], "see": [8, 9, 22, 23, 24, 25, 29, 31, 32, 34, 36, 40, 41, 42, 44, 45, 46, 47], "q": [8, 9, 11, 12, 14, 16, 23, 24, 42], "quantizedtensor": [8, 16, 24], "247": [8, 24], "98": [8, 24], "62": [8, 24], "25": [8, 24], "42": [8, 24], "209": [8, 24], "71": [8, 24], "255": [8, 16, 24], "129": [8, 24, 35], "152": [8, 24], "211": [8, 24], "163": [8, 24], "90": [8, 24], "221": [8, 24], "87": [8, 24], "67": [8, 24], "119": [8, 24], "245": [8, 24], "178": [8, 24], "100": [8, 20, 24, 25], "182": [8, 24], "188": [8, 24], "150": [8, 24], "162": [8, 24], "204": [8, 24], "102": [8, 24], "224": [8, 24], "249": [8, 24], "190": [8, 24], "176": [8, 24], "207": [8, 24], "137": [8, 24], "189": [8, 24], "109": [8, 24], "23": [8, 16, 24], "93": [8, 24], "59": [8, 24], "82": [8, 24], "195": [8, 24], "grad_fn": [8, 9, 16, 24], "aliasbackward0": [8, 9, 16, 24], "ones_lik": [8, 9, 24], "21": [8, 21, 24], "38": [8, 16, 24, 34], "148": [8, 24], "208": [8, 24], "108": [8, 24], "212": [8, 24], "127": [8, 16, 24], "230": [8, 24], "193": [8, 24], "70": [8, 24], "199": [8, 24], "168": [8, 24], "220": [8, 24], "200": [8, 24], "180": [8, 24], "225": [8, 24], "121": [8, 24], "104": [8, 24], "248": [8, 24], "114": [8, 24], "187": [8, 24], "175": [8, 24], "149": [8, 24], "167": [8, 24], "253": [8, 24], "dequant": [9, 12, 16, 22, 23, 24, 42], "x_": [9, 12, 24], "qdq": [9, 14, 24], "dequantizedtensor": [9, 16, 24], "9185": [9, 24], "7549": [9, 24], "2974": [9, 24], "8328": [9, 24], "3831": [9, 24], "1303": [9, 24], "3534": [9, 24], "6990": [9, 24], "0375": [9, 24], "1636": [9, 24], "6366": [9, 24], "1522": [9, 24], "6643": [9, 24], "0000": [9, 12, 16, 24], "2559": [9, 24], "0103": [9, 24], "2733": [9, 24], "8027": [9, 24], "0518": [9, 24], "3286": [9, 24], "2097": [9, 24], "3444": [9, 24], "5180": [9, 24], "4677": [9, 24], "4440": [9, 24], "5674": [9, 24], "6414": [9, 24], "1727": [9, 14, 24], "3207": [9, 24], "6774": [9, 24], "7324": [9, 24], "4534": [9, 24], "6393": [9, 24], "3254": [9, 24], "9650": [9, 24], "2556": [9, 24], "5697": [9, 24], "4069": [9, 24], "7673": [9, 24], "0465": [9, 24], "1790": [9, 24], "9488": [9, 24], "1014": [9, 24], "3427": [9, 24], "4714": [9, 24], "0418": [9, 24], "3759": [9, 24], "1731": [9, 24], "3103": [9, 24], "9846": [9, 24], "0039": [9, 24], "9961": [9, 24], "2902": [9, 24], "8314": [9, 24], "6980": [9, 24], "1647": [9, 24], "6353": [9, 24], "1490": [9, 24], "6667": [9, 12, 24], "8078": [9, 24], "2118": [9, 24], "5176": [9, 24], "4471": [9, 24], "5647": [9, 24], "1804": [9, 24], "3216": [9, 24], "7294": [9, 24], "9569": [9, 24], "5725": [9, 24], "4157": [9, 24], "7686": [9, 24], "0471": [9, 24], "9490": [9, 24], "1020": [9, 24], "4706": [9, 24], "3765": [9, 24], "1725": [9, 24], "3137": [9, 24], "9882": [9, 24], "overload": [11, 12], "signatur": [11, 12], "sign": [11, 12, 42], "equival": [11, 12, 14, 25], "begin": [11, 12, 39, 40], "rceil": [11, 12], "text": [11, 12], "end": [11, 12, 25, 34], "lfloor": [11, 12, 14], "posit": [11, 12], "integ": [11, 12, 26, 36, 38], "rang": [11, 12, 20, 21, 25, 26, 28, 31, 36, 37, 38, 39, 41, 42, 43, 46], "over": [11, 12, 21, 23, 26, 31, 34, 46], "neg": [11, 12, 23], "num_step": [11, 12, 21], "num": [11, 12], "_step": [11, 12], "maximum": [11, 12, 14, 21, 23], "arang": [11, 12], "start": [11, 12, 25, 26, 31, 34, 40, 42], "0000e": [11, 12], "5000e": [11, 12], "02": [11, 12], "1921e": [11, 12], "08": [11, 12], "4": [11, 12, 16, 25, 28, 31, 36, 48], "6": [11, 12, 39], "00": [11, 12], "0500e": [11, 12], "1000e": [11, 12], "1500e": [11, 12], "2000e": [11, 12], "2500e": [11, 12], "15": [11, 12, 34, 39], "intermedi": [12, 42], "0667": 12, "1333": 12, "2000": [12, 16], "2667": 12, "3333": 12, "4000": [12, 16], "4667": 12, "5333": 12, "6000": [12, 16], "7333": 12, "8000": 12, "8667": 12, "9333": 12, "exponent_bit": 14, "mantissa_bit": 14, "dtype": [14, 16], "simul": [14, 23, 25, 32, 36, 39, 43], "cast": [14, 23], "expon": 14, "mantissa": 14, "x_c": 14, "log_2": 14, "ieee": [14, 34, 37], "standard": [14, 23], "represent": [14, 16], "_max": 14, "argument": 14, "mutual": 14, "exclus": 14, "repres": [14, 16, 23, 24, 25, 31, 36, 37, 38, 39, 42], "determin": [14, 23, 25, 27, 30, 34, 36, 37, 38], "dynam": [14, 37, 42, 43, 46], "finer": 14, "8998": 14, "0947": 14, "0891": 14, "unlik": 14, "affinequant": 14, "floatquant": 14, "is_bfloat16": 14, "8984": 14, "0859": 14, "1729": 14, "minmaxencodinganalyz": [14, 22], "float16": 14, "is_float16": 14, "8994": 14, "0889": 14, "alia": 14, "hold": [16, 23, 40], "store": 16, "along": [16, 25, 39, 42], "encodingbas": [16, 24], "inform": [16, 36, 38], "necessari": [16, 25, 45], "back": [16, 25, 40], "real": 16, "self": [16, 21, 25], "produc": [16, 21, 31, 38, 45], "57": 16, "312": 16, "153": 16, "205": 16, "set_rang": 16, "128": [16, 25], "x_q": 16, "26": 16, "x_dq": 16, "3000": 16, "equal": [16, 21, 23, 26, 27, 30, 31, 35, 36, 37, 38, 46], "quantized_repr": 16, "data": [16, 25, 26, 28, 33, 36, 37, 38, 39, 41, 42], "rtype": 16, "abl": [16, 25, 26, 45, 46], "carri": 16, "gradient": 16, "thu": 16, "within": [16, 23, 30, 38, 42], "autograd": 16, "backpropag": 16, "requires_grad": 16, "28": 16, "40": 16, "int8": [16, 39, 42, 46], "ha": [16, 25, 30, 31, 34, 37, 39, 42, 45, 48], "been": [16, 36, 39, 42, 48], "subsequ": [16, 35, 37, 39, 40], "about": [16, 25], "wa": [16, 29, 34, 40], "With": 16, "convert": [16, 25, 27, 36, 46], "further": [16, 22, 25, 29, 32, 34, 36, 40], "loss": [16, 22, 25, 26, 32, 36, 38, 42], "39": [16, 25], "51": 16, "521": 16, "41": 16, "quant_dequ": 16, "quantizedequant": [16, 22, 23, 24, 25], "x_qdq": 16, "52": 16, "68": 16, "97": 16, "uint8": 16, "techniqu": [19, 20, 21, 22, 25, 26, 27, 29, 30, 32, 36, 38, 39, 41, 42, 43, 44, 47], "num_bin": [20, 21], "2048": [20, 21], "percentil": 20, "set_percentil": 20, "clip": [20, 21, 40, 42], "largest": 20, "smallest": 20, "when": [20, 22, 23, 25, 26, 32, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 48], "50": [20, 30], "indic": [20, 23, 30, 48], "asymmetric_delta_candid": 21, "17": 21, "symmetric_delta_candid": 21, "101": 21, "offset_candid": 21, "max_parallel": 21, "gamma": 21, "sqnr": [21, 42], "calcul": [21, 23, 31, 37, 38, 42], "per": [21, 23, 28, 36, 37, 38, 40, 41, 42, 43], "histogram": [21, 36, 38, 42, 43], "delta": [21, 42], "search": [21, 31, 39, 40], "mode": [21, 35, 36, 40], "process": [21, 22, 25, 27, 32, 34, 36, 37, 42], "paral": 21, "higher": [21, 28, 31, 39, 41], "memori": [21, 30, 34, 44, 47, 48], "usag": [21, 30, 34, 41], "faster": [21, 26, 32, 39], "factor": [21, 30, 34, 37], "nois": [21, 25, 36, 37, 38, 39, 40], "less": [21, 23, 29, 31], "compute_encodings_from_stat": 21, "stat": 21, "is_symmetr": [21, 40], "lowest": 21, "expect": [21, 25, 34, 36, 38], "_histogram": 21, "split": [21, 23], "els": [21, 25, 37], "softwar": [22, 32, 34], "compress": [22, 29, 32, 43, 44, 46, 47, 48], "must": [22, 23, 28, 32, 33, 38, 40, 48], "edg": [22, 32], "infer": [22, 25, 28, 30, 32, 37, 39, 42, 43], "fix": [22, 32, 36, 41, 42, 43], "optim": [22, 25, 26, 27, 32, 34, 36, 39, 42, 43, 45], "e": [22, 25, 28, 30, 32, 39, 41, 48], "fp32": [22, 26, 32, 37, 38, 39, 41, 42], "post": [22, 25, 26, 27, 32, 34, 39, 42, 43], "fine": [22, 30, 32, 36, 39, 42], "tune": [22, 30, 32, 36, 39, 42], "minim": [22, 32, 34, 36, 42], "accuraci": [22, 25, 26, 27, 30, 31, 32, 34, 36, 37, 38, 39, 41, 42, 43, 46, 48], "incur": [22, 32, 38], "dure": [22, 23, 25, 26, 32, 34, 36, 39, 40, 42, 45, 46], "design": [22, 37], "work": [22, 28, 34, 35, 37, 40], "tutori": [22, 25], "view": [22, 25, 32, 35, 45], "kera": [22, 28, 32, 36, 40, 42, 43], "document": [22, 30, 32, 43], "v1": 22, "pictur": [22, 29, 32], "show": [22, 25, 32, 37, 41], "high": [22, 26, 28, 30, 31, 32, 37, 41, 43, 46], "level": [22, 28, 30, 31, 32, 36, 41, 45], "workflow": [22, 25, 30, 32], "small": [22, 28, 32, 36], "epoch": [22, 25, 32, 34, 36, 39], "recov": [22, 32, 41, 42], "lost": [22, 32], "via": [22, 30, 32, 42], "torchscript": 22, "target": [22, 28, 30, 31, 32, 34, 36, 41, 42, 43], "runtim": [22, 25, 30, 32, 34, 36, 38, 40, 42, 43], "like": [22, 25, 32, 34, 36, 38, 39, 40, 45], "neural": [22, 25, 27, 30, 32, 34, 36, 39, 41, 42, 47], "sdk": [22, 25, 32], "instal": [22, 43], "quickstart": 22, "guid": [22, 30, 37, 41, 43], "adapt": [22, 25, 26, 36, 38, 43], "round": [22, 23, 26, 36, 38, 42], "adaround": [22, 27, 36, 41, 43], "sqnrencodinganalyz": 22, "percentileencodinganalyz": 22, "fakequantizationmixin": [22, 23], "quantizationmixin": [22, 23], "quantize_dequant": 22, "product": [22, 32], "technologi": [22, 32], "subsidiari": [22, 32], "effect": [23, 25, 28, 36, 38, 40, 42], "network": [23, 25, 27, 30, 31, 34, 36, 39, 41, 42, 45, 47], "reduc": [23, 29, 34, 37, 41, 43, 48], "aimet": [23, 25, 32, 35, 40], "serv": [23, 45], "drop": [23, 27, 30, 34, 37, 38, 39, 41, 42], "counterpart": 23, "behavior": [23, 25, 32], "state": [23, 25, 34], "superset": 23, "mean": [23, 25, 29, 40, 42], "extens": 23, "coverag": 23, "limit": [23, 33], "tabl": [23, 31, 35, 45], "basequantizationmixin": 23, "respons": [23, 34], "control": [23, 42], "descript": [23, 35], "dict": [23, 24], "By": [23, 34, 40, 42], "index": [23, 30, 43], "respect": [23, 38], "channel": [23, 28, 30, 31, 33, 34, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48], "dimens": [23, 34, 41, 44, 47], "per_channel_quant": [23, 40], "elementwis": [23, 43], "multipli": [23, 30], "second": [23, 40], "qmul": 23, "quantizedmultipli": 23, "In": [23, 25, 26, 27, 30, 31, 34, 36, 37, 39, 40, 42, 46, 48], "some": [23, 25, 26, 30, 31, 34, 35, 36, 37, 39, 41, 42], "make": [23, 31, 34, 35, 36, 42], "sens": 23, "qadd": 23, "quantizedadd": 23, "befor": [23, 25, 26, 27, 28, 34, 36, 39, 45, 46], "first": [23, 25, 30, 34, 36, 39, 45], "disabl": [23, 31, 34, 38, 40, 42], "while": [23, 26, 31, 35, 36, 39, 41, 42, 45], "activ": [23, 25, 36, 38, 39, 40, 41, 42], "them": [23, 25, 26, 48], "how": [23, 25, 34, 37, 38, 41, 42], "sever": [23, 30], "sampl": [23, 25, 29, 36, 37, 38, 39, 42], "calibration_data_load": 23, "adaptiveavgpool1d": 23, "fakequantizedadaptiveavgpool1d": 23, "adaptiveavgpool2d": 23, "fakequantizedadaptiveavgpool2d": 23, "adaptiveavgpool3d": 23, "fakequantizedadaptiveavgpool3d": 23, "adaptivemaxpool1d": 23, "fakequantizedadaptivemaxpool1d": 23, "adaptivemaxpool2d": 23, "fakequantizedadaptivemaxpool2d": 23, "adaptivemaxpool3d": 23, "fakequantizedadaptivemaxpool3d": 23, "alphadropout": 23, "fakequantizedalphadropout": 23, "avgpool1d": 23, "fakequantizedavgpool1d": 23, "avgpool2d": 23, "fakequantizedavgpool2d": 23, "avgpool3d": 23, "fakequantizedavgpool3d": 23, "batchnorm1d": 23, "fakequantizedbatchnorm1d": 23, "batchnorm2d": [23, 25], "fakequantizedbatchnorm2d": 23, "batchnorm3d": 23, "fakequantizedbatchnorm3d": 23, "celu": 23, "fakequantizedcelu": 23, "channelshuffl": 23, "fakequantizedchannelshuffl": 23, "constantpad1d": 23, "fakequantizedconstantpad1d": 23, "constantpad2d": 23, "fakequantizedconstantpad2d": 23, "constantpad3d": 23, "fakequantizedconstantpad3d": 23, "conv1d": [23, 43], "fakequantizedconv1d": 23, "quantizedconv1d": 23, "conv2d": [23, 25, 29, 34, 43, 48], "fakequantizedconv2d": 23, "quantizedconv2d": [23, 25], "conv3d": 23, "fakequantizedconv3d": 23, "quantizedconv3d": 23, "convtranspose1d": [23, 43], "fakequantizedconvtranspose1d": 23, "convtranspose2d": 23, "fakequantizedconvtranspose2d": 23, "convtranspose3d": 23, "fakequantizedconvtranspose3d": 23, "crossmaplrn2d": 23, "fakequantizedcrossmaplrn2d": 23, "dropout": 23, "fakequantizeddropout": 23, "dropout2d": 23, "fakequantizeddropout2d": 23, "dropout3d": 23, "fakequantizeddropout3d": 23, "elu": 23, "fakequantizedelu": 23, "featurealphadropout": 23, "fakequantizedfeaturealphadropout": 23, "flatten": 23, "fakequantizedflatten": 23, "fold": [23, 26, 27, 28, 36, 37, 38, 43], "fakequantizedfold": 23, "fractionalmaxpool2d": 23, "fakequantizedfractionalmaxpool2d": 23, "fractionalmaxpool3d": 23, "fakequantizedfractionalmaxpool3d": 23, "gelu": 23, "fakequantizedgelu": 23, "quantizedgelu": 23, "glu": 23, "fakequantizedglu": 23, "groupnorm": 23, "fakequantizedgroupnorm": 23, "hardshrink": 23, "fakequantizedhardshrink": 23, "hardsigmoid": 23, "fakequantizedhardsigmoid": 23, "hardswish": 23, "fakequantizedhardswish": 23, "hardtanh": 23, "fakequantizedhardtanh": 23, "ident": [23, 25], "fakequantizedident": 23, "instancenorm1d": 23, "fakequantizedinstancenorm1d": 23, "instancenorm2d": 23, "fakequantizedinstancenorm2d": 23, "instancenorm3d": 23, "fakequantizedinstancenorm3d": 23, "lppool1d": 23, "fakequantizedlppool1d": 23, "lppool2d": 23, "fakequantizedlppool2d": 23, "layernorm": 23, "fakequantizedlayernorm": 23, "quantizedlayernorm": 23, "leakyrelu": 23, "fakequantizedleakyrelu": 23, "localresponsenorm": 23, "fakequantizedlocalresponsenorm": 23, "logsigmoid": 23, "fakequantizedlogsigmoid": 23, "logsoftmax": 23, "fakequantizedlogsoftmax": 23, "maxpool1d": 23, "fakequantizedmaxpool1d": 23, "maxpool2d": 23, "fakequantizedmaxpool2d": 23, "maxpool3d": 23, "fakequantizedmaxpool3d": 23, "maxunpool1d": 23, "fakequantizedmaxunpool1d": 23, "maxunpool2d": 23, "fakequantizedmaxunpool2d": 23, "maxunpool3d": 23, "fakequantizedmaxunpool3d": 23, "mish": 23, "fakequantizedmish": 23, "prelu": 23, "fakequantizedprelu": 23, "pixelshuffl": 23, "fakequantizedpixelshuffl": 23, "pixelunshuffl": 23, "fakequantizedpixelunshuffl": 23, "rrelu": 23, "fakequantizedrrelu": 23, "relu": [23, 25, 37, 40, 48], "fakequantizedrelu": [23, 25], "relu6": [23, 37], "fakequantizedrelu6": 23, "reflectionpad1d": 23, "fakequantizedreflectionpad1d": 23, "reflectionpad2d": 23, "fakequantizedreflectionpad2d": 23, "replicationpad1d": 23, "fakequantizedreplicationpad1d": 23, "replicationpad2d": 23, "fakequantizedreplicationpad2d": 23, "replicationpad3d": 23, "fakequantizedreplicationpad3d": 23, "selu": 23, "fakequantizedselu": 23, "silu": 23, "fakequantizedsilu": 23, "sigmoid": 23, "fakequantizedsigmoid": 23, "quantizedsigmoid": 23, "softmax": [23, 25], "fakequantizedsoftmax": 23, "quantizedsoftmax": [23, 25], "softmax2d": 23, "fakequantizedsoftmax2d": 23, "softmin": 23, "fakequantizedsoftmin": 23, "softplu": 23, "fakequantizedsoftplu": 23, "softshrink": 23, "fakequantizedsoftshrink": 23, "softsign": 23, "fakequantizedsoftsign": 23, "syncbatchnorm": 23, "fakequantizedsyncbatchnorm": 23, "tanh": 23, "fakequantizedtanh": 23, "tanhshrink": 23, "fakequantizedtanhshrink": 23, "threshold": [23, 27], "fakequantizedthreshold": 23, "unflatten": 23, "fakequantizedunflatten": 23, "unfold": 23, "fakequantizedunfold": 23, "upsampl": [23, 35], "fakequantizedupsampl": 23, "upsamplingbilinear2d": 23, "fakequantizedupsamplingbilinear2d": 23, "upsamplingnearest2d": 23, "fakequantizedupsamplingnearest2d": 23, "zeropad2d": 23, "fakequantizedzeropad2d": 23, "bceloss": 23, "fakequantizedbceloss": 23, "bcewithlogitsloss": 23, "fakequantizedbcewithlogitsloss": 23, "bilinear": [23, 35], "fakequantizedbilinear": 23, "ctcloss": 23, "fakequantizedctcloss": 23, "cosinesimilar": 23, "fakequantizedcosinesimilar": 23, "crossentropyloss": [23, 25], "fakequantizedcrossentropyloss": 23, "hingeembeddingloss": 23, "fakequantizedhingeembeddingloss": 23, "huberloss": 23, "fakequantizedhuberloss": 23, "kldivloss": 23, "fakequantizedkldivloss": 23, "l1loss": 23, "fakequantizedl1loss": 23, "mseloss": 23, "fakequantizedmseloss": 23, "multilabelmarginloss": 23, "fakequantizedmultilabelmarginloss": 23, "multilabelsoftmarginloss": 23, "fakequantizedmultilabelsoftmarginloss": 23, "multimarginloss": 23, "fakequantizedmultimarginloss": 23, "nllloss": 23, "fakequantizednllloss": 23, "nllloss2d": 23, "fakequantizednllloss2d": 23, "pairwisedist": 23, "fakequantizedpairwisedist": 23, "poissonnllloss": 23, "fakequantizedpoissonnllloss": 23, "smoothl1loss": 23, "fakequantizedsmoothl1loss": 23, "softmarginloss": 23, "fakequantizedsoftmarginloss": 23, "cosineembeddingloss": 23, "fakequantizedcosineembeddingloss": 23, "gaussiannllloss": 23, "fakequantizedgaussiannllloss": 23, "marginrankingloss": 23, "fakequantizedmarginrankingloss": 23, "tripletmarginloss": 23, "fakequantizedtripletmarginloss": 23, "tripletmarginwithdistanceloss": 23, "fakequantizedtripletmarginwithdistanceloss": 23, "embed": [23, 34, 41], "fakequantizedembed": 23, "embeddingbag": 23, "fakequantizedembeddingbag": 23, "gru": [23, 43], "fakequantizedgru": 23, "rnn": [23, 43], "fakequantizedrnn": 23, "grucel": 23, "fakequantizedgrucel": 23, "rnncell": 23, "fakequantizedrnncel": 23, "lstm": [23, 43], "fakequantizedlstm": 23, "lstmcell": 23, "fakequantizedlstmcel": 23, "adaptivelogsoftmaxwithloss": 23, "fakequantizedadaptivelogsoftmaxwithloss": 23, "aimet_op": 23, "fakequantizedcast": 23, "depthtospacedcrmod": 23, "fakequantizeddepthtospacedcrmod": 23, "onehot": 23, "fakequantizedonehot": 23, "exponenti": 23, "fakequantizedexponenti": 23, "erf": 23, "fakequantizederf": 23, "sqrt": 23, "fakequantizedsqrt": 23, "log": [23, 38], "fakequantizedlog": 23, "ab": [23, 37], "fakequantizedab": 23, "fakequantizedneg": 23, "elementwiseceil": 23, "fakequantizedelementwiseceil": 23, "elementwisefloor": 23, "fakequantizedelementwisefloor": 23, "sin": 23, "fakequantizedsin": 23, "co": 23, "fakequantizedco": 23, "asin": 23, "fakequantizedasin": 23, "atan": 23, "fakequantizedatan": 23, "fakequantizedround": 23, "logicalnot": 23, "fakequantizedlogicalnot": 23, "nonzero": 23, "fakequantizednonzero": 23, "elementwiseunarysign": 23, "fakequantizedelementwiseunarysign": 23, "rsqrt": 23, "fakequantizedrsqrt": 23, "squar": [23, 42], "fakequantizedsquar": 23, "fakequantizedmean": 23, "sum": [23, 25], "fakequantizedsum": 23, "prod": 23, "fakequantizedprod": 23, "argmin": 23, "fakequantizedargmin": 23, "argmax": [23, 25], "fakequantizedargmax": 23, "gather": 23, "fakequantizedgath": 23, "reshap": 23, "fakequantizedreshap": 23, "roialign": 23, "fakequantizedroialign": 23, "permut": 23, "fakequantizedpermut": 23, "indexselect": 23, "fakequantizedindexselect": 23, "topk": 23, "fakequantizedtopk": 23, "tile": 23, "fakequantizedtil": 23, "norm": [23, 26, 28, 36, 37, 38], "fakequantizednorm": 23, "cumsum": 23, "fakequantizedcumsum": 23, "interpol": [23, 31], "fakequantizedinterpol": 23, "normal": [23, 28, 38], "pad": [23, 25], "fakequantizedpad": 23, "fakequantizedshap": 23, "expand": 23, "fakequantizedexpand": 23, "stridedslic": 23, "fakequantizedstridedslic": 23, "matmul": [23, 43], "fakequantizedmatmul": 23, "fakequantizedadd": 23, "fakequantizedmultipli": 23, "subtract": 23, "fakequantizedsubtract": 23, "quantizedsubtract": 23, "divid": [23, 39], "fakequantizeddivid": 23, "floordivid": 23, "fakequantizedfloordivid": 23, "greater": 23, "fakequantizedgreat": 23, "fakequantizedless": 23, "greaterequ": 23, "fakequantizedgreaterequ": 23, "lessequ": 23, "fakequantizedlessequ": 23, "notequ": 23, "fakequantizednotequ": 23, "fakequantizedequ": 23, "remaind": 23, "fakequantizedremaind": 23, "fmod": 23, "fakequantizedfmod": 23, "pow": 23, "fakequantizedpow": 23, "customsilu": 23, "fakequantizedcustomsilu": 23, "fakequantizedmaximum": 23, "fakequantizedmax": 23, "fakequantizedminimum": 23, "fakequantizedmin": 23, "bmm": 23, "fakequantizedbmm": 23, "logicalor": 23, "fakequantizedlogicalor": 23, "logicaland": 23, "fakequantizedlogicaland": 23, "customgath": 23, "fakequantizedcustomgath": 23, "gathernd": 23, "fakequantizedgathernd": 23, "baddbmm": 23, "fakequantizedbaddbmm": 23, "addmm": 23, "fakequantizedaddmm": 23, "scatternd": 23, "fakequantizedscatternd": 23, "dynamicconv2d": 23, "fakequantizeddynamicconv2d": 23, "scatterel": 23, "fakequantizedscatterel": 23, "batchnorm": [23, 27, 37, 48], "fakequantizedbatchnorm": 23, "fakequantizedaimetgroupnorm": 23, "nonmaxsuppress": 23, "fakequantizednonmaxsuppress": 23, "fakequantizedsplit": 23, "concat": [23, 43], "fakequantizedconcat": 23, "fakequantizedwher": 23, "maskedfil": 23, "fakequantizedmaskedfil": 23, "get_encod": 24, "get_legacy_encod": 24, "register_quantization_paramet": 24, "set_legacy_encod": 24, "simpl": [25, 36, 48], "intend": [25, 30], "most": [25, 40], "It": [25, 28, 31, 36, 37, 40, 45, 46, 48], "meant": 25, "demonstr": 25, "art": 25, "eval": [25, 31, 34, 45], "loop": [25, 41], "evalu": [25, 27, 31, 34, 36, 38, 39, 42, 45], "improv": [25, 30, 36, 39, 41, 46], "clearli": 25, "what": [25, 42, 45], "happen": 25, "let": 25, "code": [25, 26], "special": 25, "requir": [25, 26, 28, 30, 34, 36, 37, 40, 42], "look": [25, 45], "torchvis": 25, "devic": [25, 42], "is_avail": 25, "loader": [25, 26], "cifar10_train_data": 25, "dataset": [25, 36, 37, 42], "fashionmnist": 25, "tmp": 25, "cifar10": 25, "transform": [25, 43], "totensor": 25, "cifar10_test_data": 25, "train_load": 25, "util": [25, 28, 36], "dataload": [25, 38], "batch_siz": 25, "shuffl": 25, "test_load": 25, "def": 25, "super": 25, "conv1": 25, "in_channel": 25, "out_channel": 25, "kernel_s": 25, "stride": 25, "bn_1": 25, "conv2": 25, "256": [25, 38], "bn_2": 25, "dim": 25, "data_load": 25, "total": [25, 31, 42], "now": [25, 36, 43, 48], "instanti": [25, 39, 45], "few": [25, 30, 36, 41, 42], "establish": 25, "baselin": [25, 31, 39], "send": 25, "loss_fn": 25, "adam": 25, "lr": 25, "1e": [25, 39], "batch_idx": 25, "enumer": [25, 28], "backward": 25, "zero_grad": 25, "fp_accuraci": 25, "91": 25, "70999908447266": 25, "accur": 25, "coupl": [25, 26], "take": [25, 32, 34, 36, 37, 39, 40, 41, 48], "care": 25, "tool": [25, 34, 37, 46, 48], "quantizationsimmodel": [25, 26, 28], "conform": 25, "guidelin": [25, 26, 30, 39], "math": 25, "wherea": [25, 42], "incorrectli": 25, "ignor": 25, "definit": [25, 36], "complet": [25, 28, 41], "redefin": 25, "thankfulli": 25, "model_prepar": 25, "incompat": 25, "fulli": [25, 33], "prepared_model": 25, "prepare_model": 25, "fp_accuracy_prepar": 25, "assert": 25, "2024": 25, "07": 25, "747": 25, "root": 25, "info": [25, 43], "806": 25, "modelprepar": 25, "node": [25, 39, 42], "module_relu": 25, "module_relu_1": 25, "module_softmax": 25, "graphmodul": 25, "ep": 25, "momentum": 25, "track_running_stat": 25, "12544": 25, "getattr_1": 25, "getitem": 25, "debug": [25, 41], "graph_modul": 25, "print_read": 25, "distinct": 25, "execut": [25, 31, 45], "typic": [25, 30, 36, 38, 39, 40, 42, 45], "adjac": [25, 40], "convolut": [25, 28, 30, 34, 41], "whenev": 25, "possibl": [25, 38, 40, 41], "unnecessari": [25, 48], "gener": [25, 34, 36, 38, 39, 40, 42], "good": [25, 26], "idea": 25, "batch_norm_fold": 25, "sample_input": 25, "iter": [25, 26, 37], "fold_all_batch_norm": 25, "input_shap": 25, "passthrough": 25, "previous": 25, "had": 25, "impact": [25, 31, 41], "readi": [25, 41], "involv": [25, 36, 41], "encount": 25, "therefor": [25, 30, 37], "theoret": 25, "could": [25, 29, 48], "entir": [25, 31, 34], "practic": [25, 34], "usual": [25, 39], "500": [25, 26, 37, 38], "1000": [25, 26, 37, 38], "estim": [25, 36, 37], "configur": [25, 30, 33, 43], "sim": [25, 39, 42], "dummy_input": 25, "default_output_bw": 25, "default_param_bw": 25, "idx": 25, "break": 25, "compar": [25, 38, 39, 46], "quantized_accuraci": 25, "n": [25, 43], "1500015258789": 25, "here": [25, 30, 39, 45], "noth": 25, "than": [25, 33, 39, 45], "everi": [25, 31, 34, 39, 46], "held": 25, "construct": [25, 35], "discuss": [25, 30, 41, 42], "advanc": 25, "re": [25, 36], "satisfi": [25, 27], "One": [25, 30, 34, 44], "qat": [25, 26, 28, 32, 36, 41, 42, 43], "op": [25, 36, 40, 43], "present": [25, 34, 37], "repeat": [25, 29], "time": [25, 27, 34, 35, 39, 45], "post_qat_accuraci": 25, "92": 25, "05333709716797": 25, "happi": 25, "export_path": 25, "model_nam": 25, "fashion_mnist_model": 25, "save": [25, 27, 42, 46], "sent": 25, "nearest": 26, "figur": [26, 31, 41, 48], "singl": [26, 37], "shown": [26, 34, 37, 38, 41], "illustr": [26, 31, 36, 44, 47], "smaller": [26, 32, 41, 44, 47], "subset": [26, 28, 38, 48], "unlabel": [26, 36, 38, 42], "far": 26, "decid": [26, 45], "whether": [26, 39], "awai": 26, "closer": 26, "low": [26, 28, 34, 36, 37, 41], "width": [26, 41, 42, 44, 47, 48], "freez": 26, "refer": [26, 32, 36, 38, 39, 40, 42], "bc": 26, "bnf": 26, "batch": [26, 28, 36, 37, 38], "cle": [26, 36, 41, 43], "cross": [26, 27, 35, 36, 37, 38, 46], "hbf": 26, "awar": [26, 28, 32, 36, 41, 42], "benefit": 26, "don": 26, "But": [26, 34], "benefici": [26, 38, 39], "consid": [26, 31, 36, 41], "better": [26, 27, 36, 37, 39], "help": [26, 31, 34, 36, 37, 38, 41, 45, 46], "Not": [26, 31], "hyper": [26, 39], "expos": 26, "lead": [26, 28, 37, 41, 42], "stabl": 26, "mani": [26, 37, 42], "often": [26, 27, 34, 39], "approxim": [26, 30, 37, 38], "1024": [26, 35], "10000": 26, "moder": 26, "least": [26, 29], "beta": 26, "warm": 26, "period": 26, "offer": 27, "suit": 27, "sequenc": [27, 28, 35, 40], "variou": [27, 30, 34, 36, 41, 42, 43, 46], "combin": [27, 30, 34, 36, 37], "error": [27, 36, 39, 41, 42], "prone": 27, "consum": [27, 34], "addit": [27, 36, 39, 40, 43], "amount": [27, 40], "toler": [27, 30], "As": [27, 29, 30, 31, 34, 36, 37, 38, 42, 44, 47], "soon": 27, "reach": [27, 30], "stop": 27, "summari": 27, "autom": [27, 36], "prepar": [27, 36, 43], "check": [27, 36, 39, 41], "valid": [27, 36, 43], "friendli": [27, 36, 37], "denot": 27, "select": [27, 30, 38, 42, 45, 48], "best": [27, 30, 34, 36, 42], "scheme": [27, 28, 31, 34, 38], "quantschem": 27, "preprat": 27, "mainli": 27, "consist": [27, 42, 48], "three": [27, 30, 46], "stage": 27, "effort": 27, "manner": 27, "fail": [27, 35, 36], "goal": 27, "individu": [28, 29, 30, 31, 34, 36, 38, 41], "adjust": [28, 29, 30, 36, 37, 41], "preceed": 28, "learn": [28, 34, 36, 39, 42, 43], "pcq": [28, 38], "veri": [28, 30, 34, 38, 46, 48], "NOT": [28, 48], "cover": [28, 40, 42], "scenario": [28, 34, 36, 48], "decreas": 28, "main": [28, 40, 43, 46], "issu": [28, 32, 35, 41, 43, 45, 46], "depthwis": [28, 43], "separ": [28, 38, 41, 43], "sinc": [28, 30, 31, 42], "affect": [28, 40, 48], "oscil": 28, "quant": 28, "onc": [28, 29, 34, 38, 39, 42], "flow": [28, 36, 39, 41, 42], "diagram": [28, 31, 34, 42, 44, 47], "explain": [29, 34, 37, 42, 48], "differ": [29, 31, 34, 36, 37, 39, 40, 41, 42], "occurr": 29, "detail": [29, 31, 32, 34, 36, 41, 42, 45, 46], "ratio": [29, 30, 45], "magnitud": 29, "choos": [29, 30, 34], "matrix": 29, "upstream": [29, 48], "also": [29, 30, 31, 36, 38, 40, 41, 42, 43, 45, 46, 48], "gain": [29, 34], "presenc": 29, "connect": [29, 33, 47], "residu": 29, "sometim": [29, 34, 37, 38], "prevent": 29, "final": [29, 30, 31, 39, 41, 45], "attempt": [29, 36, 37], "match": [29, 34, 38, 40, 41, 42, 48], "close": [29, 30, 42], "prior": [29, 36, 38], "collect": [29, 38], "random": [29, 38], "regress": 29, "depth": [30, 41], "svd": [30, 31, 33, 34, 43], "spatial": [30, 31, 33, 34, 43], "ssvd": 30, "prune": [30, 31, 33, 34, 43, 48], "accumul": 30, "mac": [30, 34, 44, 47], "reduct": 30, "uncompress": 30, "algorithm": [30, 31, 34, 41, 48], "overal": [30, 34, 41], "latenc": 30, "bandwidth": 30, "vari": [30, 31, 37, 46], "architectur": 30, "io": [30, 43], "At": [30, 34], "half": 30, "unknown": 30, "apriori": 30, "cssvd": 30, "tri": [30, 36], "75": 30, "would": [30, 34, 40, 43, 45], "pick": [30, 31, 34], "2b": 30, "rel": [30, 36, 41, 46], "avoid": 30, "larg": [30, 39, 44, 47], "2a": 30, "revisit": 30, "ccp": 30, "resnet": 30, "csvd": 30, "66": 30, "basi": [31, 34], "assess": 31, "sensit": [31, 36, 38, 41, 42, 43], "applic": [31, 35], "find": [31, 36, 38, 39, 42], "sure": [31, 35], "highest": 31, "remain": [31, 36, 37, 42], "dictionari": [31, 34, 40], "column": 31, "captur": 31, "predefin": 31, "candid": [31, 34], "unmodifi": 31, "score": [31, 34, 45], "last": [31, 33, 41], "known": [31, 32], "monoton": 31, "fit": 31, "strict": [31, 40, 42], "increas": [31, 37, 40], "procedur": [31, 34], "curv": 31, "core": 31, "cost": [31, 34, 39], "constant": [31, 36], "met": 31, "binari": 31, "solut": [31, 39, 41], "quickli": 31, "suggest": [31, 34, 37], "lower": [31, 36, 41], "lesser": [31, 34], "fall": [31, 40], "drstical": 31, "either": [32, 42], "framework": [32, 36, 40, 42], "meta": [32, 36], "h5": [32, 36], "hw": 32, "ptq": [32, 36, 38, 39], "redund": 32, "conv": [33, 40, 43, 44, 47, 48], "dilat": 33, "modules_to_ignor": 33, "depthwiseconv2d": 33, "guidebook": [34, 36], "advic": 34, "greedi": [34, 45], "phase": [34, 36], "choic": [34, 42], "nomin": 34, "And": 34, "ml": [34, 36, 37, 45, 46], "those": 34, "fc": 34, "certain": [34, 35, 36, 40], "decompos": [34, 44, 47], "term": [34, 44, 45, 46, 47], "sharp": 34, "degrad": 34, "might": [34, 38], "rate": [34, 39], "carefulli": 34, "decai": 34, "togeth": 34, "slow": 34, "someth": [34, 45], "speed": [34, 37, 43], "itself": [34, 42, 44, 47], "part": [34, 36, 37, 38], "experi": 34, "load": 34, "searcher": 34, "Or": 34, "granular": [34, 41, 42, 46], "strike": 34, "balanc": 34, "chosen": 34, "experiment": [34, 40], "major": 34, "sai": 34, "xiangyu": 34, "zhang": 34, "jianhua": 34, "zou": 34, "kaim": 34, "he": 34, "jian": 34, "sun": 34, "deep": 34, "classif": 34, "detect": 34, "transact": 34, "pattern": 34, "analysi": [34, 41], "intellig": 34, "vol": 34, "pp": 34, "1943": 34, "1955": 34, "oct": 34, "2016": 34, "yihui": 34, "intern": [34, 36, 37, 40], "confer": [34, 37], "vision": [34, 37], "iccv": [34, 37], "venic": 34, "2017": 34, "1398": 34, "1406": 34, "jaderberg": 34, "andrea": 34, "vedaldi": 34, "andrew": 34, "zisserman": 34, "expans": 34, "british": 34, "jan": 34, "2014": 34, "andrei": 34, "kuzmin": 34, "marku": [34, 37], "nagel": [34, 37], "saurabh": 34, "pitr": 34, "sandeep": 34, "pendyam": 34, "tijmen": [34, 37], "blankevoort": [34, 37], "taxonomi": 34, "cross_layer_equ": 35, "equalize_model": 35, "graph": [35, 36, 42, 45], "restrict": 35, "successfulli": 35, "potenti": [35, 38, 45, 46], "workaround": 35, "primit": 35, "around": 35, "rewrit": 35, "slice": 35, "written": [35, 36], "caus": [35, 41, 42], "statement": 35, "align_corn": 35, "deconvolut": 35, "deeplabv3": 35, "address": [35, 41, 45], "releas": 35, "hardwar": [36, 37, 42], "howev": [36, 37, 39, 40, 42], "introduc": [36, 40, 42], "due": [36, 37], "predict": 36, "oppos": [36, 40], "advantag": 36, "No": 36, "pipelin": [36, 39, 41, 42], "suffici": [36, 38, 39, 42], "even": 36, "fast": 36, "easi": [36, 38], "still": [36, 41], "gap": 36, "insert": [36, 42], "robust": 36, "longer": [36, 39], "quantsim": [36, 39, 40, 43], "account": [36, 39, 41], "trainabl": 36, "bias": 36, "reflect": [36, 42], "autoqu": [36, 39, 43], "integr": 36, "describ": [36, 37, 41, 42], "standalon": 36, "consecut": [36, 37], "bn": [36, 43], "deprec": 36, "advis": [36, 40], "instead": [36, 37], "quantanalyz": [36, 43], "understand": [36, 40, 45, 46], "prep": 36, "accord": [36, 39, 40, 42], "align": 36, "retri": 36, "continu": [36, 37, 39, 41], "warn": 36, "hand": 36, "satisfactori": [36, 41], "bring": 36, "onto": 36, "thing": 36, "item": 36, "checkpoint": 36, "pb": 36, "trial": 36, "particular": [36, 40], "seem": 36, "off": [36, 37, 40], "bat": 36, "becom": 37, "paper": 37, "2019": 37, "arxiv": 37, "1906": 37, "04721": 37, "surround": 37, "highlight": [37, 45, 46], "big": 37, "discrep": 37, "accept": [37, 41], "wide": 37, "varianc": 37, "across": [37, 38], "seen": [37, 38], "significantli": 37, "similar": [37, 39, 42], "quantizaion": 37, "distribut": [37, 41, 42], "did": 37, "shift": 37, "whose": [37, 40, 48], "empir": 37, "analyt": [37, 45, 46], "extract": 37, "bottleneck": [37, 41], "hybrid": 37, "approach": [37, 42], "mart": 37, "van": 37, "baalen": 37, "seoul": 37, "octob": 37, "hotspot": 38, "analys": 38, "callback": [38, 42], "mse": [38, 42], "plot": 38, "pretrain": [38, 39, 42], "dummi": 38, "label": [38, 39], "metric": [38, 42], "rune": 38, "relat": [38, 42], "doc": [38, 40, 45], "situat": 38, "pinpoint": 38, "culprit": 38, "again": [38, 39, 45], "per_layer_quant_en": 38, "per_layer_quant_dis": 38, "axi": 38, "track": 38, "directli": [38, 42], "min_max_rang": 38, "folder": 38, "enhanc": [38, 42], "toss": 38, "outlier": [38, 42], "displai": [38, 45, 46], "activations_pdf": 38, "weights_pdf": 38, "monitor": 38, "contribut": [38, 41], "read": 38, "per_layer_mse_loss": 38, "mitig": [39, 42], "come": [39, 42], "hyperparamet": 39, "accompani": 39, "found": [39, 42], "throughout": [39, 40, 46], "themselv": 39, "aid": 39, "converg": 39, "schedul": 39, "placement": 40, "rule": 40, "fuse": [40, 42], "thei": [40, 45], "six": 40, "overrul": 40, "turn": 40, "op_typ": 40, "purpos": 40, "empti": 40, "is_output_quant": 40, "is_quant": 40, "strict_symmetr": 40, "unsigned_symmetr": 40, "though": 40, "omit": 40, "altogeth": 40, "asid": 40, "govern": 40, "unsign": [40, 42], "gemm": 40, "is_input_quant": 40, "recogn": [40, 42], "keep": [40, 41], "convent": 40, "preced": 40, "supergroup": [40, 43], "made": 40, "op_list": 40, "member": 40, "sequenti": [40, 41], "branch": 40, "config": [40, 43], "entri": 40, "string": 40, "model_input": 40, "whatev": 40, "earlier": 40, "model_output": 40, "diagnost": 41, "strictli": 41, "insight": [41, 45, 46], "why": 41, "underperform": 41, "tackl": 41, "chart": 41, "saniti": 41, "similarli": 41, "ofth": 41, "independ": 41, "kept": 41, "convers": 41, "toward": 41, "signific": 41, "wise": 41, "uneven": 41, "vanilla": 41, "global": 41, "restor": 41, "rest": 41, "inner": 41, "token": 41, "bert": 41, "reveal": 41, "problemat": [41, 46], "problem": 41, "resort": 41, "revert": 41, "power": 41, "ultim": 42, "deploi": 42, "copi": 42, "ingest": 42, "feed": 42, "000": 42, "yield": 42, "dequantiz": 42, "hook": 42, "intercept": 42, "four": 42, "zero": [42, 43], "vice": 42, "versa": 42, "equat": 42, "textrm": 42, "dfrac": 42, "quad": 42, "whole": 42, "strong": 42, "excess": 42, "signal": 42, "satur": 42, "erro": 42, "static": 42, "alongsid": 42, "ones": 42, "just": [42, 45, 48], "non": 42, "slim": 43, "backslash": 43, "cl": 43, "user_guid": 43, "api_doc": 43, "quantizablemultiheadattent": 43, "kyuykim": 43, "multi": 43, "mangal": 43, "geunle": 43, "bug": 43, "correctli": 43, "leaf": 43, "klhsieh": 43, "akhobar": 43, "resid": 43, "multiheadattent": 43, "ashvkuma": 43, "mha": 43, "pdf": 43, "fp16": 43, "minor": 43, "stand": [43, 44, 47], "adaptiveround": 43, "recurr": 43, "packag": 43, "decomposit": [44, 47], "singular": [44, 47], "\ud835\udc5a": [44, 47], "\ud835\udc5b": [44, 47], "\u210e": [44, 47], "\ud835\udc64": [44, 47], "give": [44, 47], "height": [44, 47, 48], "\ud835\udc58": [44, 47], "k": 44, "rank": [44, 47], "larger": [44, 47], "degre": [44, 47], "assist": [45, 46], "progress": [45, 46], "computation": [45, 46], "task": [45, 46], "websocket": 45, "tell": 45, "listen": 45, "rather": 45, "5006": 45, "compress_model": 45, "visualizecompress": 45, "display_eval_scor": 45, "display_comp_ratio_plot": 45, "directori": 46, "lot": 46, "anoth": [47, 48], "lose": 48, "much": 48, "explicitli": 48, "pictori": 48, "volum": 48, "hxwx8": 48, "hxwx5": 48, "simpli": 48, "propag": 48, "That": 48, "teh": 48, "green": 48, "color": 48, "side": 48, "action": 48, "taken": 48, "pink": 48, "orang": 48}, "objects": {"aimet_torch.v2.nn": [[6, 0, 1, "", "FakeQuantizationMixin"], [7, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.FakeQuantizationMixin": [[6, 1, 1, "", "__quant_init__"], [6, 1, 1, "", "compute_encodings"], [6, 1, 1, "", "from_module"], [6, 1, 1, "", "get_original_module"], [6, 1, 1, "", "implements"], [6, 2, 1, "", "input_quantizers"], [6, 2, 1, "", "output_quantizers"], [6, 2, 1, "", "param_quantizers"], [6, 1, 1, "", "quantized_forward"]], "aimet_torch.v2.nn.QuantizationMixin": [[7, 1, 1, "", "compute_encodings"], [7, 1, 1, "", "get_default_kernel"], [7, 1, 1, "", "get_kernel"], [7, 1, 1, "", "implements"], [7, 1, 1, "", "set_default_kernel"], [7, 1, 1, "", "set_kernel"], [7, 1, 1, "", "wrap"]], "aimet_torch.v2.nn.base": [[23, 0, 1, "", "BaseQuantizationMixin"]], "aimet_torch.v2.nn.base.BaseQuantizationMixin": [[23, 1, 1, "", "__quant_init__"], [23, 1, 1, "", "compute_encodings"], [23, 2, 1, "", "input_quantizers"], [23, 2, 1, "", "output_quantizers"], [23, 2, 1, "", "param_quantizers"], [23, 1, 1, "", "quantized_forward"]], "aimet_torch.v2.quantization": [[13, 3, 0, "-", "affine"], [15, 3, 0, "-", "float"]], "aimet_torch.v2.quantization.affine": [[8, 0, 1, "", "Quantize"], [9, 0, 1, "", "QuantizeDequantize"], [10, 4, 1, "", "dequantize"], [11, 4, 1, "", "quantize"], [12, 4, 1, "", "quantize_dequantize"]], "aimet_torch.v2.quantization.affine.Quantize": [[8, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.QuantizeDequantize": [[9, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer": [[24, 0, 1, "", "Quantize"], [24, 0, 1, "", "QuantizeDequantize"], [24, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[24, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[24, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[24, 1, 1, "", "compute_encodings"], [24, 1, 1, "", "get_encoding"], [24, 1, 1, "", "get_legacy_encodings"], [24, 1, 1, "", "is_initialized"], [24, 1, 1, "", "register_quantization_parameter"], [24, 1, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization.encoding_analyzer": [[17, 0, 1, "", "EncodingAnalyzer"], [19, 0, 1, "", "MinMaxEncodingAnalyzer"], [20, 0, 1, "", "PercentileEncodingAnalyzer"], [21, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer": [[20, 1, 1, "", "set_percentile"]], "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer": [[21, 1, 1, "", "compute_encodings_from_stats"]], "aimet_torch.v2.quantization.float": [[14, 0, 1, "", "FloatQuantizeDequantize"], [14, 0, 1, "", "QuantizeDequantize"]], "aimet_torch.v2.quantization.tensor": [[16, 0, 1, "", "DequantizedTensor"], [16, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "quantize"], [16, 1, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[16, 1, 1, "", "dequantize"], [16, 1, 1, "", "quantize"], [16, 1, 1, "", "quantized_repr"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:attribute", "3": "py:module", "4": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "module", "Python module"], "4": ["py", "function", "Python function"]}, "titleterms": {"aimet": [2, 3, 4, 22, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48], "instal": [2, 3, 4, 32], "quick": 2, "releas": [2, 3, 4, 32, 43], "packag": [2, 3, 4], "system": 2, "requir": [2, 38], "advanc": 2, "instruct": 2, "docker": 3, "set": 3, "variant": [3, 17], "us": [3, 26, 34, 36, 45], "prebuilt": 3, "imag": 3, "build": 3, "local": 3, "start": [3, 22, 32, 45], "contain": 3, "from": [3, 4], "pypi": [3, 4], "environ": [3, 4], "setup": [3, 4], "prerequisit": [4, 25], "gpu": 4, "pytorch": [4, 22, 25, 35, 36, 46], "2": [4, 25, 43], "1": [4, 25, 43], "tensorflow": [4, 36, 46], "13": [4, 43], "onnx": 4, "common": [4, 26], "debian": 4, "torch": 4, "replac": 4, "pillow": 4, "simd": 4, "onnxruntim": 4, "post": [4, 18, 36, 37], "step": 4, "fakequantizationmixin": 6, "nn": 7, "quantizationmixin": 7, "top": [7, 23, 24], "level": [7, 23, 24], "api": [7, 22, 23, 24], "quantiz": [8, 11, 13, 15, 16, 18, 23, 24, 25, 36, 37, 39, 40, 41, 42, 46], "quantizedequant": [9, 14], "dequant": 10, "quantize_dequant": 12, "affin": 13, "class": [13, 16, 23], "function": 13, "floatquantizedequant": 14, "float": [15, 25], "tensor": 16, "encod": [17, 23, 42], "analyz": 17, "train": [18, 25, 36, 37, 39], "minmaxencodinganalyz": 19, "percentileencodinganalyz": 20, "sqnrencodinganalyz": 21, "welcom": 22, "ai": [22, 32], "model": [22, 25, 32, 34, 35, 36], "effici": [22, 32], "toolkit": [22, 32], "doc": 22, "get": [22, 32, 34], "exampl": 22, "featur": [22, 30, 32, 36, 41], "descript": [22, 38], "modul": 23, "configur": [23, 40, 42], "comput": 23, "quickstart": 25, "guid": [25, 32], "overal": [25, 29], "flow": [25, 37], "prepar": 25, "point": 25, "batchnorm": 25, "fold": 25, "fine": [25, 34], "tune": [25, 34], "awar": [25, 39], "export": 25, "quantsim": [25, 42], "adaround": 26, "case": [26, 34, 36], "terminologi": 26, "autoqu": 27, "overview": [27, 28, 31, 32, 34, 37, 38, 39, 40, 42, 45, 46, 48], "workflow": [27, 28, 36, 39, 42], "bn": 28, "re": 28, "estim": 28, "channel": 29, "prune": 29, "procedur": 29, "select": [29, 31, 34], "winnow": [29, 48], "weight": [29, 47], "reconstruct": 29, "compress": [30, 31, 34, 45], "guidebook": [30, 41], "greedi": 31, "ratio": [31, 34], "how": [31, 40, 45, 48], "work": [31, 48], "per": [31, 34], "layer": [31, 34], "explor": 31, "user": [32, 37], "inform": 32, "toc": 32, "tree": 32, "known": 33, "issu": 33, "option": 34, "techniqu": [34, 37], "better": 34, "result": 34, "rank": 34, "round": 34, "faq": [34, 37], "refer": [34, 37], "guidelin": [35, 36], "debug": 36, "analysi": [36, 38], "tool": [36, 45], "quantanalyz": 38, "detail": 38, "qat": 39, "mode": 39, "recommend": 39, "simul": [40, 42], "file": 40, "structur": 40, "individu": 40, "section": 40, "nois": 42, "determin": 42, "paramet": 42, "scheme": 42, "op": 42, "frequent": 42, "ask": 42, "question": 42, "note": 43, "22": 43, "0": 43, "21": 43, "20": 43, "19": 43, "py37": 43, "18": 43, "17": 43, "16": 43, "14": 43, "spatial": 44, "svd": [44, 47], "visual": [45, 46], "design": 45, "bokeh": 45, "server": 45, "session": 45}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"AIMET Installation": [[2, "aimet-installation"]], "Quick Install": [[2, "quick-install"]], "Release Packages": [[2, "release-packages"]], "System Requirements": [[2, "system-requirements"]], "Advanced Installation Instructions": [[2, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[3, "aimet-installation-in-docker"]], "Set variant": [[3, "set-variant"]], "Use prebuilt docker image": [[3, "use-prebuilt-docker-image"]], "Build docker image locally": [[3, "build-docker-image-locally"]], "Start docker container": [[3, "start-docker-container"]], "Install AIMET packages": [[3, "install-aimet-packages"], [4, "install-aimet-packages"]], "From PyPI": [[3, "from-pypi"], [4, "from-pypi"]], "From Release Package": [[3, "from-release-package"], [4, "from-release-package"]], "Environment setup": [[3, "environment-setup"], [4, "environment-setup"]], "AIMET Installation and Setup": [[4, "aimet-installation-and-setup"]], "Install prerequisite packages": [[4, "install-prerequisite-packages"]], "Install GPU packages": [[4, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or TensorFlow": [[4, "install-gpu-packages-for-pytorch-2-1-or-tensorflow"]], "Install GPU packages for PyTorch 1.13 or ONNX": [[4, "install-gpu-packages-for-pytorch-1-13-or-onnx"]], "Install common debian packages": [[4, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[4, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[4, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[4, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[4, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[4, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[4, "post-installation-steps"]], "FakeQuantizationMixin": [[6, "fakequantizationmixin"]], "nn.QuantizationMixin": [[7, "nn-quantizationmixin"]], "Top-level API": [[7, "top-level-api"], [23, "top-level-api"], [24, "top-level-api"]], "Quantize": [[8, "quantize"]], "QuantizeDequantize": [[9, "quantizedequantize"], [14, "quantizedequantize"]], "dequantize": [[10, "dequantize"]], "quantize": [[11, "quantize"]], "quantize_dequantize": [[12, "quantize-dequantize"]], "quantization.affine": [[13, "module-aimet_torch.v2.quantization.affine"]], "Classes": [[13, "classes"], [16, "classes"]], "Functions": [[13, "functions"]], "FloatQuantizeDequantize": [[14, "floatquantizedequantize"]], "quantization.float": [[15, "module-aimet_torch.v2.quantization.float"]], "quantization.tensor": [[16, "quantization-tensor"]], "Encoding Analyzers": [[17, "encoding-analyzers"]], "Variants": [[17, "variants"]], "Post-Training Quantization": [[18, "post-training-quantization"], [36, "post-training-quantization"]], "MinMaxEncodingAnalyzer": [[19, "minmaxencodinganalyzer"]], "PercentileEncodingAnalyzer": [[20, "percentileencodinganalyzer"]], "SqnrEncodingAnalyzer": [[21, "sqnrencodinganalyzer"]], "Welcome to AI Model Efficiency Toolkit PyTorch API Docs!": [[22, "welcome-to-ai-model-efficiency-toolkit-pytorch-api-docs"]], "Getting Started": [[22, null], [32, "getting-started"]], "Examples": [[22, null]], "Feature Descriptions": [[22, null]], "AIMET PyTorch API": [[22, null]], "Quantized Modules": [[23, "quantized-modules"]], "Configuration": [[23, "configuration"]], "Computing Encodings": [[23, "computing-encodings"]], "Quantized Module Classes": [[23, "quantized-module-classes"]], "Quantizers": [[24, "quantizers"]], "Quickstart Guide": [[25, "quickstart-guide"]], "Overall flow": [[25, "overall-flow"]], "PyTorch prerequisites": [[25, "pytorch-prerequisites"]], "Prepare the floating point model for quantization": [[25, "prepare-the-floating-point-model-for-quantization"]], "1) Model preparation": [[25, "model-preparation"]], "2) BatchNorm fold": [[25, "batchnorm-fold"]], "Quantize the model": [[25, "quantize-the-model"]], "Fine-tune the model with quantization aware training": [[25, "fine-tune-the-model-with-quantization-aware-training"]], "Export the quantsim model": [[25, "export-the-quantsim-model"]], "AIMET AdaRound": [[26, "aimet-adaround"]], "AdaRound Use Cases": [[26, "adaround-use-cases"]], "Common terminology": [[26, "common-terminology"]], "Use Cases": [[26, "use-cases"], [36, "use-cases"]], "AIMET AutoQuant": [[27, "aimet-autoquant"]], "Overview": [[27, "overview"], [28, "overview"], [31, "overview"], [32, "overview"], [34, "overview"], [37, "overview"], [38, "overview"], [39, "overview"], [40, "overview"], [42, "overview"], [45, "overview"], [46, "overview"], [48, "overview"]], "Workflow": [[27, "workflow"], [28, "workflow"]], "AIMET BN Re-estimation": [[28, "aimet-bn-re-estimation"]], "AIMET Channel Pruning": [[29, "aimet-channel-pruning"]], "Overall Procedure": [[29, "overall-procedure"]], "Channel Selection": [[29, "channel-selection"]], "Winnowing": [[29, "winnowing"]], "Weight Reconstruction": [[29, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[30, "aimet-compression-features-guidebook"]], "AIMET Greedy Compression Ratio Selection": [[31, "aimet-greedy-compression-ratio-selection"]], "How it works": [[31, "how-it-works"]], "Per-layer Exploration": [[31, "per-layer-exploration"]], "Compression Ratio Selection": [[31, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[32, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[32, "features"]], "Release Information": [[32, "release-information"]], "Installation Guide": [[32, "installation-guide"]], "toc tree": [[32, "toc-tree"]], "AIMET Known Issues": [[33, "aimet-known-issues"]], "AIMET Model Compression": [[34, "aimet-model-compression"]], "Use Case": [[34, "use-case"]], "Compression ratio selection": [[34, "compression-ratio-selection"]], "Model Compression": [[34, "model-compression"]], "Optional techniques to get better compression results": [[34, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[34, "rank-rounding"]], "Per-layer Fine-tuning": [[34, "per-layer-fine-tuning"]], "FAQs": [[34, "faqs"], [37, "faqs"]], "References": [[34, "references"], [37, "references"]], "Model Guidelines for PyTorch": [[35, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[36, "aimet-model-quantization"]], "AIMET Quantization Features": [[36, "aimet-quantization-features"]], "Debugging/Analysis Tools": [[36, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[36, "aimet-quantization-workflow"]], "PyTorch": [[36, "pytorch"], [46, "pytorch"]], "Tensorflow": [[36, "tensorflow"]], "Debugging Guidelines": [[36, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[37, "aimet-post-training-quantization-techniques"]], "User Flow": [[37, "user-flow"]], "AIMET QuantAnalyzer": [[38, "aimet-quantanalyzer"]], "Requirements": [[38, "requirements"]], "Detailed Analysis Descriptions": [[38, "detailed-analysis-descriptions"]], "AIMET Quantization Aware Training": [[39, "aimet-quantization-aware-training"]], "QAT workflow": [[39, "qat-workflow"]], "QAT modes": [[39, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[39, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[40, "quantization-simulation-configuration"]], "Configuration File Structure": [[40, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[40, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[41, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[42, "aimet-quantization-simulation"]], "QuantSim Workflow": [[42, "quantsim-workflow"]], "Simulating Quantization Noise": [[42, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[42, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[42, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[42, "configuring-quantization-simulation-ops"]], "Frequently Asked Questions": [[42, "frequently-asked-questions"]], "AIMET Release Notes": [[43, "aimet-release-notes"]], "1.22.2": [[43, "id1"]], "1.22.1": [[43, "id2"]], "1.22.0": [[43, "id3"]], "1.21.0": [[43, "id4"]], "1.20.0": [[43, "id5"]], "1.19.1.py37": [[43, "py37"]], "1.19.1": [[43, "id6"]], "1.18.0.py37": [[43, "id7"]], "1.18.0": [[43, "id8"]], "1.17.0.py37": [[43, "id9"]], "1.17.0": [[43, "id10"]], "1.16.2.py37": [[43, "id11"]], "1.16.2": [[43, "id12"]], "1.16.1.py37": [[43, "id13"]], "1.16.1": [[43, "id14"]], "1.16.0": [[43, "id15"]], "1.14.0": [[43, "id16"]], "1.13.0": [[43, "id17"]], "AIMET Spatial SVD": [[44, "aimet-spatial-svd"]], "AIMET Visualization": [[45, "aimet-visualization"]], "Design": [[45, "design"]], "Compression": [[45, "compression"]], "Starting a Bokeh Server Session:": [[45, "starting-a-bokeh-server-session"]], "How to use the tool": [[45, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[46, "aimet-visualization-for-quantization"]], "Quantization": [[46, "quantization"]], "TensorFlow": [[46, "tensorflow"]], "AIMET Weight SVD": [[47, "aimet-weight-svd"]], "AIMET Winnowing": [[48, "aimet-winnowing"]], "Winnowing Overview": [[48, "winnowing-overview"]], "How Winnowing Works": [[48, "how-winnowing-works"]]}, "indexentries": {"fakequantizationmixin (class in aimet_torch.v2.nn)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"]], "from_module() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.from_module"]], "get_original_module() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.get_original_module"]], "implements() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.fakequantizationmixin attribute)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.param_quantizers"]], "quantized_forward() (aimet_torch.v2.nn.fakequantizationmixin method)": [[6, "aimet_torch.v2.nn.FakeQuantizationMixin.quantized_forward"]], "quantizationmixin (class in aimet_torch.v2.nn)": [[7, "aimet_torch.v2.nn.QuantizationMixin"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "wrap() (aimet_torch.v2.nn.quantizationmixin class method)": [[7, "aimet_torch.v2.nn.QuantizationMixin.wrap"]], "quantize (class in aimet_torch.v2.quantization.affine)": [[8, "aimet_torch.v2.quantization.affine.Quantize"]], "forward() (aimet_torch.v2.quantization.affine.quantize method)": [[8, "aimet_torch.v2.quantization.affine.Quantize.forward"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine)": [[9, "aimet_torch.v2.quantization.affine.QuantizeDequantize"]], "forward() (aimet_torch.v2.quantization.affine.quantizedequantize method)": [[9, "aimet_torch.v2.quantization.affine.QuantizeDequantize.forward"]], "dequantize() (in module aimet_torch.v2.quantization.affine)": [[10, "aimet_torch.v2.quantization.affine.dequantize"]], "quantize() (in module aimet_torch.v2.quantization.affine)": [[11, "aimet_torch.v2.quantization.affine.quantize"]], "quantize_dequantize() (in module aimet_torch.v2.quantization.affine)": [[12, "aimet_torch.v2.quantization.affine.quantize_dequantize"]], "aimet_torch.v2.quantization.affine": [[13, "module-aimet_torch.v2.quantization.affine"]], "module": [[13, "module-aimet_torch.v2.quantization.affine"], [15, "module-aimet_torch.v2.quantization.float"]], "floatquantizedequantize (class in aimet_torch.v2.quantization.float)": [[14, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.float)": [[14, "aimet_torch.v2.quantization.float.QuantizeDequantize"]], "aimet_torch.v2.quantization.float": [[15, "module-aimet_torch.v2.quantization.float"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[16, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[17, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[19, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[20, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "set_percentile() (aimet_torch.v2.quantization.encoding_analyzer.percentileencodinganalyzer method)": [[20, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.set_percentile"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[21, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "compute_encodings_from_stats() (aimet_torch.v2.quantization.encoding_analyzer.sqnrencodinganalyzer method)": [[21, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.compute_encodings_from_stats"]], "basequantizationmixin (class in aimet_torch.v2.nn.base)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"]], "input_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.base.basequantizationmixin attribute)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin.param_quantizers"]], "quantized_forward() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[23, "aimet_torch.v2.nn.base.BaseQuantizationMixin.quantized_forward"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[24, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[24, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})