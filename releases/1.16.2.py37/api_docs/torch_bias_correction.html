

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET PyTorch Bias Correction API &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.16.2.py37</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.16.2.py37</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../user_guide/index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../user_guide/index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET PyTorch Bias Correction API</a><ul>
<li><a class="reference internal" href="#bias-correction-api">Bias Correction API</a></li>
<li><a class="reference internal" href="#convbninfotype">ConvBnInfoType</a></li>
<li><a class="reference internal" href="#activationtype">ActivationType</a></li>
<li><a class="reference internal" href="#quantization-params">Quantization Params</a></li>
<li><a class="reference internal" href="#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-pytorch-bias-correction-api">
<span id="api-torch-bias-correction"></span><h1>AIMET PyTorch Bias Correction API<a class="headerlink" href="#aimet-pytorch-bias-correction-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="bias-correction-api">
<h2>Bias Correction API<a class="headerlink" href="#bias-correction-api" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="aimet_torch.bias_correction.correct_bias">
<code class="sig-prename descclassname">aimet_torch.bias_correction.</code><code class="sig-name descname">correct_bias</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">quant_params</em>, <em class="sig-param">num_quant_samples</em>, <em class="sig-param">data_loader</em>, <em class="sig-param">num_bias_correct_samples</em>, <em class="sig-param">conv_bn_dict=None</em>, <em class="sig-param">perform_only_empirical_bias_corr=True</em>, <em class="sig-param">layers_to_ignore=None</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.bias_correction.correct_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Corrects bias for each Conv layer of model (unless ignored). A combination of Analytical and Empirical Bias
Correction is used i.e. all the layers which can be corrected using Analytical Bias Correction are corrected
using Analytical Bias Correction and remaining layers are corrected using Empirical method.</p>
<p>Returns an in-place corrected floating point model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – Model to be corrected</p></li>
<li><p><strong>quant_params</strong> (<a class="reference internal" href="#aimet_torch.quantsim.QuantParams" title="aimet_torch.quantsim.QuantParams"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantParams</span></code></a>) – Named tuple for quantization simulation for bias correction</p></li>
<li><p><strong>num_quant_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of samples of images to pass through quantization sim for bias correction.</p></li>
<li><p><strong>data_loader</strong> – data loader for the model</p></li>
<li><p><strong>num_bias_correct_samples</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of samples for Bias correction</p></li>
<li><p><strong>conv_bn_dict</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <a class="reference internal" href="#aimet_common.bias_correction.ConvBnInfoType" title="aimet_common.bias_correction.ConvBnInfoType"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvBnInfoType</span></code></a>]]) – Dict of conv and bn with information related to activation. If None, the function calc it</p></li>
<li><p><strong>perform_only_empirical_bias_corr</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Default True. If true will perform only empirical Bias Corr for all layers
irrespective of the fact that layer is eligible for Analytical Bias Corr.</p></li>
<li><p><strong>layers_to_ignore</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]) – list of layer names for which we need to skip bias correction.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="convbninfotype">
<h2>ConvBnInfoType<a class="headerlink" href="#convbninfotype" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="aimet_common.bias_correction.ConvBnInfoType">
<em class="property">class </em><code class="sig-prename descclassname">aimet_common.bias_correction.</code><code class="sig-name descname">ConvBnInfoType</code><span class="sig-paren">(</span><em class="sig-param">input_bn=None</em>, <em class="sig-param">output_bn=None</em>, <em class="sig-param">in_activation_type=&lt;ActivationType.no_activation: 0&gt;</em>, <em class="sig-param">out_activation_type=&lt;ActivationType.no_activation: 0&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_common.bias_correction.ConvBnInfoType" title="Permalink to this definition">¶</a></dt>
<dd><p>Type for hoding convs with bn info and activation types
Activation types supported are Relu and Relu6</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_bn</strong> – Reference to Input BatchNorm to layer</p></li>
<li><p><strong>output_bn</strong> – Reference to Output BatchNorm to layer</p></li>
<li><p><strong>in_activation_type</strong> (<a class="reference internal" href="#aimet_common.defs.ActivationType" title="aimet_common.defs.ActivationType"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActivationType</span></code></a>) – Type of Activation</p></li>
<li><p><strong>out_activation_type</strong> (<a class="reference internal" href="#aimet_common.defs.ActivationType" title="aimet_common.defs.ActivationType"><code class="xref py py-class docutils literal notranslate"><span class="pre">ActivationType</span></code></a>) – Type of Activation</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="activationtype">
<h2>ActivationType<a class="headerlink" href="#activationtype" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="aimet_common.defs.ActivationType">
<em class="property">class </em><code class="sig-prename descclassname">aimet_common.defs.</code><code class="sig-name descname">ActivationType</code><a class="headerlink" href="#aimet_common.defs.ActivationType" title="Permalink to this definition">¶</a></dt>
<dd><p>Enums to identify activation type</p>
<dl class="attribute">
<dt id="aimet_common.defs.ActivationType.no_activation">
<code class="sig-name descname">no_activation</code><em class="property"> = 0</em><a class="headerlink" href="#aimet_common.defs.ActivationType.no_activation" title="Permalink to this definition">¶</a></dt>
<dd><p>No activation</p>
</dd></dl>

<dl class="attribute">
<dt id="aimet_common.defs.ActivationType.relu">
<code class="sig-name descname">relu</code><em class="property"> = 1</em><a class="headerlink" href="#aimet_common.defs.ActivationType.relu" title="Permalink to this definition">¶</a></dt>
<dd><p>ReLU activation</p>
</dd></dl>

<dl class="attribute">
<dt id="aimet_common.defs.ActivationType.relu6">
<code class="sig-name descname">relu6</code><em class="property"> = 2</em><a class="headerlink" href="#aimet_common.defs.ActivationType.relu6" title="Permalink to this definition">¶</a></dt>
<dd><p>ReLU6 activation</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="quantization-params">
<h2>Quantization Params<a class="headerlink" href="#quantization-params" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="aimet_torch.quantsim.QuantParams">
<em class="property">class </em><code class="sig-prename descclassname">aimet_torch.quantsim.</code><code class="sig-name descname">QuantParams</code><span class="sig-paren">(</span><em class="sig-param">weight_bw=8</em>, <em class="sig-param">act_bw=8</em>, <em class="sig-param">round_mode='nearest'</em>, <em class="sig-param">quant_scheme=&lt;QuantScheme.post_training_tf_enhanced: 2&gt;</em>, <em class="sig-param">config_file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quantsim.QuantParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Data type to hold quantization related params.</p>
<p>Constructor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Weight bitwidth (4-31) to use for quantizing layer weights. Default = 8</p></li>
<li><p><strong>act_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Activation bitwidth(4-31) to use for quantizing layer activations. Default = 8</p></li>
<li><p><strong>round_mode</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Rounding mode. Supported options are ‘nearest’ or ‘stochastic’</p></li>
<li><p><strong>quant_scheme</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Quantization scheme. Supported options are ‘tf_enhanced’ or ‘tf’ or using Quant Scheme Enum
QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced</p></li>
<li><p><strong>config_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Path to Configuration file for model quantizers</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bias Correction related imports</span>
<span class="kn">from</span> <span class="nn">aimet_torch</span> <span class="kn">import</span> <span class="n">bias_correction</span>
<span class="kn">from</span> <span class="nn">aimet_torch.quantsim</span> <span class="kn">import</span> <span class="n">QuantParams</span>
<span class="kn">from</span> <span class="nn">aimet_torch.examples.mobilenet</span> <span class="kn">import</span> <span class="n">MobileNetV2</span>
<span class="kn">from</span> <span class="nn">aimet_torch.utils</span> <span class="kn">import</span> <span class="n">create_fake_data_loader</span>
</pre></div>
</div>
<p><strong>Empirical Bias correction</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bias_correction_empirical</span><span class="p">():</span>
    <span class="n">dataset_size</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

    <span class="n">data_loader</span> <span class="o">=</span> <span class="n">create_fake_data_loader</span><span class="p">(</span><span class="n">dataset_size</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">QuantParams</span><span class="p">(</span><span class="n">weight_bw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">act_bw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">round_mode</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="o">=</span><span class="s1">&#39;tf_enhanced&#39;</span><span class="p">)</span>

    <span class="c1"># Perform Bias Correction</span>
    <span class="n">bias_correction</span><span class="o">.</span><span class="n">correct_bias</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">params</span><span class="p">,</span> <span class="n">num_quant_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                 <span class="n">data_loader</span><span class="o">=</span><span class="n">data_loader</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">num_bias_correct_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Analytical + Empirical Bias correction</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bias_correction_analytical_and_empirical</span><span class="p">():</span>

    <span class="n">dataset_size</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

    <span class="n">data_loader</span> <span class="o">=</span> <span class="n">create_fake_data_loader</span><span class="p">(</span><span class="n">dataset_size</span><span class="o">=</span><span class="n">dataset_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">MobileNetV2</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Find all BN + Conv pairs for analytical BC and remaining Conv for Empirical BC</span>
    <span class="n">module_prop_dict</span> <span class="o">=</span> <span class="n">bias_correction</span><span class="o">.</span><span class="n">find_all_conv_bn_with_activation</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">QuantParams</span><span class="p">(</span><span class="n">weight_bw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">act_bw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">round_mode</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="o">=</span><span class="s1">&#39;tf_enhanced&#39;</span><span class="p">)</span>

    <span class="c1"># Perform Bias Correction</span>
    <span class="n">bias_correction</span><span class="o">.</span><span class="n">correct_bias</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span> <span class="n">params</span><span class="p">,</span> <span class="n">num_quant_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                 <span class="n">data_loader</span><span class="o">=</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">num_bias_correct_samples</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                                 <span class="n">conv_bn_dict</span><span class="o">=</span><span class="n">module_prop_dict</span><span class="p">,</span> <span class="n">perform_only_empirical_bias_corr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Bias correction Data loader format example</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BatchIterator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">data_loader</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_loader</span><span class="p">:</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.16.2.py37</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>