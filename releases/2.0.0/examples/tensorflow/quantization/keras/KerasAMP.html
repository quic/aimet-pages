<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../../../genindex.html" /><link rel="search" title="Search" href="../../../../search.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Automatic Mixed-Precision (AMP) - AIMET</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/aimet-furo.css?v=6d7e6c94" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../../index.html"><div class="brand">AIMET</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../../index.html">
  
  
  <span class="sidebar-brand-text">AIMET</span>
  
</a><div class="doc-versions" data-toggle="doc-versions" role="note" aria-label="versions">

  <span class="doc-current-version" data-toggle="doc-current-version">
    Version: 2.0.0
  </span>
  <br>
  <span class="doc-other-versions" data-toggle="doc-other-versions">
        <a href="https://quic.github.io/aimet-pages/releases/latest/versions.html">Other versions</a>
  </span>

</div><form class="sidebar-search-container" method="get" action="../../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../install/quick-start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../userguide/index.html">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../userguide/quantization_workflow.html">Quantization workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../userguide/debugging_guidelines.html">Debugging guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../userguide/on_target_inference.html">On-target inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quantsim/index.html">Quantization Simulation Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../quantsim/calibration.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../quantsim/qat.html">QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../quantsim/advanced.html">Advanced</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../featureguide/index.html">Feature Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/adaround.html">Adaptive rounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/seq_mse.html">Sequential MSE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/bnf.html">Batch norm folding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/cle.html">Cross-layer equalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/mixed%20precision/index.html">Mixed precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/autoquant.html">Automatic quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/bn.html">Batch norm re-estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/analysis%20tools/index.html">Analysis tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../featureguide/compression/index.html">Compression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apiref/index.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../apiref/torch/index.html">aimet_torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../apiref/tensorflow/index.html">aimet_tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../apiref/onnx/index.html">aimet_onnx</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../release_notes.html">Release Notes</a></li>
</ul>

</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="Automatic-Mixed-Precision-(AMP)">
<h1>Automatic Mixed-Precision (AMP)<a class="headerlink" href="#Automatic-Mixed-Precision-(AMP)" title="Link to this heading">¶</a></h1>
<p>This notebook shows a working code example of how to use AIMET to perform Auto Mixed Precision (AMP). AMP is a technique where given a quantized accuracy target, AIMET finds bit-precision per-layer to meet that accuracy target while trying to optimize the model for inference speed.</p>
<p>As an example, say a particular model is not meeting a desired accuracy target when run in INT8. The Auto Mixed Precision feature will find a minimal set of layers that need to run on say INT16 to get to the desired accuracy. It should be noted that choosing higher precision for some layers necessarily involves a trade-off: lower inferences/sec for higher accuracy and vice-versa.</p>
<p>Alternatively, the AMP feature can be used to generate a pareto curve (accuracy vs. bit-ops) that can guide the user to decide the right operating point for this tradeoff.</p>
<p>This notebook specifically shows working code example for the above.</p>
<section id="Overall-flow">
<h2>Overall flow<a class="headerlink" href="#Overall-flow" title="Link to this heading">¶</a></h2>
<p>This notebook covers the following</p>
<ol class="arabic simple">
<li><p>Instantiate the example evaluation method</p></li>
<li><p>Load the FP32 model and evaluate the model to find the baseline FP32 accuracy</p></li>
<li><p>Create a quantization simulation model (with fake quantization ops inserted)</p></li>
<li><p>Run AMP algorithm on the quantized model</p>
<ol class="arabic simple">
<li><p>Using the Regular AMP method</p></li>
<li><p>Using the Fast AMP Method (AMP 2.0)</p></li>
</ol>
</li>
</ol>
</section>
<section id="What-this-notebook-is-not">
<h2>What this notebook is not<a class="headerlink" href="#What-this-notebook-is-not" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>This notebook is not designed to show state-of-the-art AMP results. For example, it uses a relatively quantization-friendly model like ResNet50. Also, some optimization parameters like number of samples for evaluation are deliberately chosen to have the notebook execute more quickly.</p></li>
</ul>
<hr class="docutils" />
<section id="Dataset">
<h3>Dataset<a class="headerlink" href="#Dataset" title="Link to this heading">¶</a></h3>
<p>This notebook relies on the ImageNet dataset for the task of image classification. If you already have a version of the dataset readily available, please use that. Else, please download the dataset from appropriate location (e.g. <a class="reference external" href="https://image-net.org/challenges/LSVRC/2012/index">https://image-net.org/challenges/LSVRC/2012/index</a>.php#).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATASET_DIR</span> <span class="o">=</span> <span class="s1">&#39;/path/to/dataset&#39;</span>        <span class="c1"># Please replace this with a real directory</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
</div>
<p>We disable logs at the INFO level. We set verbosity to the level as displayed (ERORR), so TensorFlow will display all messages that have the label ERROR (or more critical).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;2&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="1.-Instantiate-the-example-evaluation-method">
<h3>1. Instantiate the example evaluation method<a class="headerlink" href="#1.-Instantiate-the-example-evaluation-method" title="Link to this heading">¶</a></h3>
<p>The following is an example evlauation method which we will used to evaluate the accuracy for the model as well to perform a forward pass on the model. AIMET needs forward pass for calculating the range of values at activations of each layer.Below is an example function which we will use for both evaluation and the forward pass.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.applications.resnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">preprocess_input</span><span class="p">,</span> <span class="n">decode_predictions</span>

<span class="k">def</span><span class="w"> </span><span class="nf">center_crop</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>

    <span class="n">img_height</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">img_width</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">crop_length</span> <span class="o">=</span> <span class="mi">224</span>

    <span class="n">start_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_height</span> <span class="o">-</span> <span class="n">crop_length</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">start_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_width</span> <span class="o">-</span> <span class="n">crop_length</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">cropped_image</span><span class="o">=</span><span class="n">image</span><span class="p">[:</span> <span class="p">,</span>  <span class="n">start_x</span><span class="p">:(</span><span class="n">img_width</span> <span class="o">-</span> <span class="n">start_x</span><span class="p">),</span> <span class="n">start_y</span><span class="p">:(</span><span class="n">img_height</span> <span class="o">-</span> <span class="n">start_y</span><span class="p">),</span> <span class="p">:]</span>

    <span class="k">return</span> <span class="n">cropped_image</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_eval_func</span><span class="p">(</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">get_top5_acc</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">func_wrapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="n">validation_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
            <span class="n">directory</span><span class="o">=</span><span class="n">dataset_dir</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="s1">&#39;inferred&#39;</span><span class="p">,</span>
            <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
        <span class="c1"># If no iterations specified, set to full validation set</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">iterations</span><span class="p">:</span>
            <span class="n">iterations</span> <span class="o">=</span> <span class="n">num_iterations</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="n">top1</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">top5</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">validation_ds</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">center_crop</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">label</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="n">validation_ds</span><span class="o">.</span><span class="n">class_names</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">label</span><span class="p">]</span>
            <span class="n">cnt</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">decode_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]])</span>
            <span class="n">top1</span> <span class="o">+=</span> <span class="n">cnt</span>
            <span class="n">cnt</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">decode_predictions</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">b</span><span class="p">]])</span>
            <span class="n">top5</span> <span class="o">+=</span> <span class="n">cnt</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;=</span> <span class="n">iterations</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">if</span> <span class="n">get_top5_acc</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">top1</span><span class="o">/</span><span class="n">total</span><span class="p">,</span> <span class="n">top5</span><span class="o">/</span><span class="n">total</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">top1</span><span class="o">/</span><span class="n">total</span>
    <span class="k">return</span> <span class="n">func_wrapper</span>



<span class="c1"># Instantiate the evaluation function</span>
<span class="n">eval_func</span> <span class="o">=</span> <span class="n">get_eval_func</span><span class="p">(</span><span class="n">DATASET_DIR</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="2.-Load-the-FP32-model-and-evaluate-the-model-to-find-the-baseline-FP32-accuracy">
<h3>2. Load the FP32 model and evaluate the model to find the baseline FP32 accuracy<a class="headerlink" href="#2.-Load-the-FP32-model-and-evaluate-the-model-to-find-the-baseline-FP32-accuracy" title="Link to this heading">¶</a></h3>
<p>For this example notebook, we are going to load a pretrained ResNet50 model from keras . Similarly, you can load any pretrained tensorflow model instead.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.applications.resnet</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResNet50</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.batch_norm_fold</span><span class="w"> </span><span class="kn">import</span> <span class="n">fold_all_batch_norms</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_model</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span>
        <span class="n">include_top</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="s2">&quot;imagenet&quot;</span><span class="p">,</span>
        <span class="n">input_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">pooling</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
<span class="c1"># We will perform the batch norm folding on the loaded model.</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">fold_all_batch_norms</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># calculate the FP32 model acccuracy</span>

<span class="n">fp32_acccuracy</span> <span class="o">=</span> <span class="n">eval_func</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="3.Create-a-quantization-simulation-model-(with-fake-quantization-ops-inserted)">
<h3>3.Create a quantization simulation model (with fake quantization ops inserted)<a class="headerlink" href="#3.Create-a-quantization-simulation-model-(with-fake-quantization-ops-inserted)" title="Link to this heading">¶</a></h3>
<p>Now we use AIMET to create a QuantizationSimModel. This basically means that AIMET will insert fake quantization ops in the model graph and will configure them.</p>
<p>A few of the parameters are explained here</p>
<ul class="simple">
<li><p><strong>quant_scheme</strong>: We set this to “QuantScheme.post_training_tf_enhanced”</p>
<ul>
<li><p>Supported options are ‘tf_enhanced’ or ‘tf’ or using Quant Scheme Enum QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced</p></li>
</ul>
</li>
<li><p><strong>default_output_bw</strong>: Setting this to 8, essentially means that we are asking AIMET to perform all activation quantizations in the model using integer 8-bit precision</p></li>
<li><p><strong>default_param_bw</strong>: Setting this to 8, essentially means that we are asking AIMET to perform all parameter quantizations in the model using integer 8-bit precision</p></li>
</ul>
<p>There are other parameters that are set to default values in this example. Please check the AIMET API documentation of QuantizationSimModel to see reference documentation for all the parameters.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantScheme</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.quantsim</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationSimModel</span>

<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf_enhanced</span><span class="p">,</span>
        <span class="n">rounding_mode</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span>
        <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">8</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Compute-Encodings">
<h3>Compute Encodings<a class="headerlink" href="#Compute-Encodings" title="Link to this heading">¶</a></h3>
<p>Even though AIMET has added ‘quantizer’ nodes to the model graph but the model is not ready to be used yet. Before we can use the sim model for inference or training, we need to find appropriate scale/offset quantization parameters for each ‘quantizer’ node. For activation quantization nodes, we need to pass unlabeled data samples through the model to collect range statistics which will then let AIMET calculate appropriate scale/offset quantization parameters. This process is sometimes referred
to as calibration. AIMET simply refers to it as ‘computing encodings’.</p>
<p>The following shows an example of a routine that passes unlabeled samples through the model for computing encodings. This routine can be written in many different ways, this is just an example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="4.-Run-AMP-algorithm-on-the-quantized-model">
<h3>4. Run AMP algorithm on the quantized model<a class="headerlink" href="#4.-Run-AMP-algorithm-on-the-quantized-model" title="Link to this heading">¶</a></h3>
<p>AMP algorithm runs in 3 phases (phase-3 is optional). Phase-1 comprises of calculating the sensitivity for each layer. Phase-2 comprises of greedily selecting which layers should have what bitwidth based on options provided by the user. Phase-3 derives a set of mixed-precision solutions having less bitwidth convert op overhead compared to original phase-2 solution. For phase 1 and phase 2 we require to pass data through the model.</p>
<p>So we create a routine to pass unlabeled data samples through the model. This should be fairly simple - use the existing train or validation data loader to extract some samples and pass them to the model. We don’t need to compute any loss metric etc. So we can just ignore the model output for this purpose. A few pointers regarding the data samples</p>
<ul class="simple">
<li><p>In practice, we need a very small percentage of the overall data samples for computing encodings. For example, the training dataset for ImageNet has 1M samples. For phase 1 we only need 500 or 1000 samples. For phase 2 it is recommended to use all of validation data. This is done to speed up AMP execution. Therefore, we define 2 separate functions for phase 1 and phase 2.</p></li>
<li><p>For phase 2, if a large-enough subset of the samples provide a meaningful accuracy score, we can use the subset of samples to speed up the AMP algorithm</p></li>
<li><p>It may be beneficial if the samples used for forward pass are well distributed. It’s not necessary that all classes need to be covered etc. since we are only looking at the range of values at every layer activation. However, we definitely want to avoid an extreme scenario like all ‘dark’ or ‘light’ samples are used - e.g. only using pictures captured at night might not give ideal results. We have two method for doing AMP in Keras. One can opt for any one of the methods.</p>
<ol class="arabic simple">
<li><p>Regular AMP</p></li>
<li><p>Fast AMP (AMP 2.0)</p></li>
</ol>
</li>
</ul>
</section>
<section id="Parameters-for-AMP-algorithm">
<h3>Parameters for AMP algorithm<a class="headerlink" href="#Parameters-for-AMP-algorithm" title="Link to this heading">¶</a></h3>
<p>A few of the parameters required for AMP are explained below</p>
<ul class="simple">
<li><p><strong>candidates</strong> : It is a list of tuples for all possible bitwidth values for activations and parameters. Suppose the possible combinations are-((Activation bitwidth - 8, Activation data type - int), (Parameter bitwidth - 16, parameter data type - int)) ((Activation bitwidth - 16, Activation data type - float), (Parameter bitwidth - 16, parameter data type - float)) candidates will be [((8, QuantizationDataType.int), (16, QuantizationDataType.int)), ((16, QuantizationDataType.float), (16,
QuantizationDataType.float))]</p></li>
<li><p><strong>allowed_accuracy_drop</strong> : Maximum allowed drop in accuracy from FP32 baseline. The pareto front curve is plotted only till the point where the allowable accuracy drop is met. To get a complete plot for picking points on the curve, the user can set the allowable accuracy drop to None.</p></li>
<li><p><strong>results_dir</strong> : Path to save results and cache intermediate results</p></li>
<li><p><strong>clean_start</strong> : If true, any cached information from previous runs will be deleted prior to starting the mixed-precision analysis. If false, prior cached information will be used if applicable. Note it is the user’s responsibility to set this flag to true if anything in the model or quantization parameters changes compared to the previous run.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationDataType</span>

<span class="n">candidates</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">16</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">)),</span>
              <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">))]</span>

<span class="n">allowed_accuracy_drop</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">results_dir</span> <span class="o">=</span> <span class="s1">&#39;/path/to/where/we/want/to/store/intermediate/and/final/results&#39;</span>
</pre></div>
</div>
</div>
</section>
<section id="Regular-AMP">
<h3>Regular AMP<a class="headerlink" href="#Regular-AMP" title="Link to this heading">¶</a></h3>
<p>In this we will need regular eval function as discussed above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">CallbackFunc</span>

<span class="n">eval_callback_phase1</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">eval_callback_phase2</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">forward_pass_call_back</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_func</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="API-Call-for-Regular-AMP">
<h4>API Call for Regular AMP<a class="headerlink" href="#API-Call-for-Regular-AMP" title="Link to this heading">¶</a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.mixed_precision</span><span class="w"> </span><span class="kn">import</span> <span class="n">choose_mixed_precision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.amp.mixed_precision_algo</span><span class="w"> </span><span class="kn">import</span> <span class="n">GreedyMixedPrecisionAlgo</span>

<span class="c1"># Enable phase-3 (optional)</span>
<span class="c1"># GreedyMixedPrecisionAlgo.ENABLE_CONVERT_OP_REDUCTION = True</span>
<span class="c1"># Note: supported candidates ((8,int), (8,int)) &amp; ((16,int), (8,int))</span>

<span class="n">choose_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">eval_callback_phase1</span><span class="p">,</span> <span class="n">eval_callback_phase2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span>
                      <span class="n">results_dir</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_call_back</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Fast-AMP-(AMP-2.0)">
<h3>Fast AMP (AMP 2.0)<a class="headerlink" href="#Fast-AMP-(AMP-2.0)" title="Link to this heading">¶</a></h3>
<p>In this method of AMP instead of using the acuracy score for the evaluation in the phase one we use the SQNR score. This speeds up the phase 1 computation of the AMP and saves some time. To use this version we need require a data loader wrapper instead of phase 1 evaluation callback. Below is a sample code for the same and also a sample call to fast AMP API.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_data_loader_wrapper</span><span class="p">(</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">dataloader_wrapper</span><span class="p">():</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
            <span class="n">directory</span><span class="o">=</span><span class="n">dataset_dir</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="s1">&#39;inferred&#39;</span><span class="p">,</span>
            <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">shuffle</span> <span class="o">=</span> <span class="n">is_training</span><span class="p">,</span>
            <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">center_crop</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">dataloader_wrapper</span>

<span class="n">data_loader_wrapper</span> <span class="o">=</span> <span class="n">get_data_loader_wrapper</span><span class="p">(</span><span class="n">DATASET_DIR</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.mixed_precision</span><span class="w"> </span><span class="kn">import</span> <span class="n">choose_fast_mixed_precision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.amp.mixed_precision_algo</span><span class="w"> </span><span class="kn">import</span> <span class="n">GreedyMixedPrecisionAlgo</span>

<span class="c1"># Enable phase-3 (optional)</span>
<span class="c1"># GreedyMixedPrecisionAlgo.ENABLE_CONVERT_OP_REDUCTION = True</span>
<span class="c1"># Note: supported candidates ((8,int), (8,int)) &amp; ((16,int), (8,int))</span>

<span class="n">choose_fast_mixed_precision</span><span class="p">(</span><span class="n">sim</span><span class="p">,</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">data_loader_wrapper</span><span class="p">,</span> <span class="n">eval_callback_phase2</span><span class="p">,</span> <span class="n">allowed_accuracy_drop</span><span class="p">,</span>
                      <span class="n">results_dir</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">forward_pass_call_back</span><span class="p">)</span>
</pre></div>
</div>
</div>
<hr class="docutils" />
<p>So we have a Mixed precision model after AMP. Now the next step would be to actually take this model to target. For this purpose, we need to export the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;./output/&#39;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s1">&#39;./output/&#39;</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="o">=</span><span class="s1">&#39;resnet50_after_amp&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="Summary">
<h3>Summary<a class="headerlink" href="#Summary" title="Link to this heading">¶</a></h3>
<p>Hope this notebook was useful for you to understand how to use Automatic Mixed Precision in Keras. For more details about the parameters and configuration please refer api docs for mixed precision.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Qualcomm Innovation Center, Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/quic/aimet" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Automatic Mixed-Precision (AMP)</a><ul>
<li><a class="reference internal" href="#Overall-flow">Overall flow</a></li>
<li><a class="reference internal" href="#What-this-notebook-is-not">What this notebook is not</a><ul>
<li><a class="reference internal" href="#Dataset">Dataset</a></li>
<li><a class="reference internal" href="#1.-Instantiate-the-example-evaluation-method">1. Instantiate the example evaluation method</a></li>
<li><a class="reference internal" href="#2.-Load-the-FP32-model-and-evaluate-the-model-to-find-the-baseline-FP32-accuracy">2. Load the FP32 model and evaluate the model to find the baseline FP32 accuracy</a></li>
<li><a class="reference internal" href="#3.Create-a-quantization-simulation-model-(with-fake-quantization-ops-inserted)">3.Create a quantization simulation model (with fake quantization ops inserted)</a></li>
<li><a class="reference internal" href="#Compute-Encodings">Compute Encodings</a></li>
<li><a class="reference internal" href="#4.-Run-AMP-algorithm-on-the-quantized-model">4. Run AMP algorithm on the quantized model</a></li>
<li><a class="reference internal" href="#Parameters-for-AMP-algorithm">Parameters for AMP algorithm</a></li>
<li><a class="reference internal" href="#Regular-AMP">Regular AMP</a><ul>
<li><a class="reference internal" href="#API-Call-for-Regular-AMP">API Call for Regular AMP</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Fast-AMP-(AMP-2.0)">Fast AMP (AMP 2.0)</a></li>
<li><a class="reference internal" href="#Summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../../../_static/documentation_options.js?v=8a448e45"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>