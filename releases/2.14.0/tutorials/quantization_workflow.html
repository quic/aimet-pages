<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Quantization simulation guide" href="quantsim.html" /><link rel="prev" title="Tutorials" href="index.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.07.19 -->
        <title>Quantization workflow - AIMET</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/aimet-furo.css?v=58822075" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">AIMET</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">AIMET</span>
  
</a><div class="doc-versions" data-toggle="doc-versions" role="note" aria-label="versions">

  <span class="doc-current-version" data-toggle="doc-current-version">
    Version: 2.14.0
  </span>
  <br>
  <span class="doc-other-versions" data-toggle="doc-other-versions">
        <a href="https://quic.github.io/aimet-pages/releases/latest/versions.html">Other versions</a>
  </span>

</div><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="../overview/index.html">Overview</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Overview</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview/install/quick-start.html">Quick Start</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview/install/index.html">Install</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Quantization Workflow</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="quantsim.html">Quantization Simulation</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Quantization Simulation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="notebooks.html">Example Notebooks</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Example Notebooks</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="on_target_inference.html">Running Quantized Models on-device</a></li>
<li class="toctree-l2"><a class="reference internal" href="debugging_guidelines.html">Debugging Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../techniques/index.html">Techniques</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Techniques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../techniques/ptq.html">Post Training Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/qat.html">Quantization Aware Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/blockwise.html">Blockwise Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/lpbq.html">Low-Power Blockwise Quantization</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../techniques/mixed_precision/index.html">Mixed precision</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Mixed precision</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../techniques/mixed_precision/mmp.html">Manual mixed precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/mixed_precision/amp.html">Automatic mixed precision</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../techniques/analysis_tools/index.html">Analysis tools</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Analysis tools</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../techniques/analysis_tools/interactive_visualization.html">Interactive visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/analysis_tools/quant_analyzer.html">Quantization analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/analysis_tools/layer_output_generation.html">Layer output generation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../techniques/compression/index.html">Compression</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Compression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../techniques/compression/feature_guidebook.html">Compression guidebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/compression/greedy_compression_ratio_selection.html">Greedy compression ratio selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/compression/visualization_compression.html">Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/compression/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../techniques/compression/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../techniques/compression/channel_pruning.html">Channel pruning</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Channel pruning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../techniques/compression/winnowing.html">Winnowing</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ptq_techniques/index.html">PTQ Techniques</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of PTQ Techniques</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/adaround.html">Adaptive rounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/seq_mse.html">Sequential MSE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/bnf.html">Batch norm folding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/cle.html">Cross-layer equalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/adascale.html">AdaScale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/bn.html">Batch norm re-estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/omniquant.html">OmniQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/autoquant.html">Automatic quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ptq_techniques/spinquant.html">SpinQuant</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apiref/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../external/index.html">External Resources</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of External Resources</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="http://www.qualcomm.com/developer/artificial-intelligence#overview">Qualcomm AI Stack</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/quic/ai-hub-models/">Qualcomm Hub Models</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/quic/ai-hub-apps/">Qualcomm Hub Apps</a></li>
<li class="toctree-l2"><a class="reference external" href="https://aihub.qualcomm.com/">Qualcomm AI Hub</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="quantization-workflow">
<span id="tutorials-quantization-workflow"></span><h1>Quantization workflow<a class="headerlink" href="#quantization-workflow" title="Link to this heading">¶</a></h1>
<p>AIMET offers several quantization techniques to improve the accuracy of quantized models. This section outlines a
recommended, streamlined workflow for selecting appropriate techniques for a given model.</p>
<img alt="../_images/BasicPTQWorkflow.jpg" src="../_images/BasicPTQWorkflow.jpg" />
<p><strong>Workflow Overview:</strong></p>
<ol class="arabic simple">
<li><p><strong>Model conversion</strong>: If starting with a PyTorch model, use torch.onnx.export to convert it to ONNX. This step can be
skipped if an ONNX model is already available.</p></li>
<li><p><strong>Graph Optimization</strong> (Optional): Apply model simplification passes to optimize the ONNX graph, if needed.</p></li>
<li><p><strong>Post-Training Quantization</strong>: Use AIMET ONNX to apply post-training quantization techniques.</p></li>
<li><p><strong>QDQ Model Export</strong>: Export the quantized model as an ONNX QDQ model, which includes QuantizeLinear and
DequantizeLinear nodes to encode quantization parameters.</p></li>
<li><p><strong>Deployment</strong>: The QDQ model can be executed using ONNX Runtime or deployed to downstream toolchains such as the
Qualcomm Neural Processing SDK or the Qualcomm AI Runtime SDK.</p></li>
</ol>
<p><strong>Note</strong>: While this workflow is suitable for a wide range of models, <strong>Generative AI</strong> models typically require a
different approach due to their significantly larger parameter sizes.</p>
<section id="accuracy-vs-performance-tradeoff">
<h2>Accuracy-vs-Performance Tradeoff<a class="headerlink" href="#accuracy-vs-performance-tradeoff" title="Link to this heading">¶</a></h2>
<img alt="../_images/AccuracyPerformanceTradeoff.png" src="../_images/AccuracyPerformanceTradeoff.png" />
<p>Quantization provides several advantages when deploying models on-device compared to their floating-point counterparts:</p>
<ul class="simple">
<li><p><strong>Faster inference</strong></p></li>
<li><p><strong>Reduced memory usage</strong></p></li>
<li><p><strong>Lower power consumption</strong></p></li>
</ul>
<p>These benefits, however, come with a tradeoff in model accuracy—specifically, the task-specific accuracy the model was
originally designed to achieve. For instance, in object detection tasks, this may be measured using metrics such as mean
Intersection over Union (mIOU).</p>
<p>In general, the lower the numerical precision used during quantization, the greater the performance gains. However, the
lower precision often results in reduced accuracy. The extent of this tradeoff is highly model-dependent. Some models
can be quantized to INT8 with minimal impact on accuracy, while others may require higher precision formats to maintain
acceptable accuracy.</p>
</section>
<section id="detailed-workflow">
<h2>Detailed Workflow<a class="headerlink" href="#detailed-workflow" title="Link to this heading">¶</a></h2>
<img alt="../_images/DetailedAimetQuantWorkflow.png" src="../_images/DetailedAimetQuantWorkflow.png" />
<section id="step-1-find-baseline-precision">
<h3>Step 1: Find baseline precision<a class="headerlink" href="#step-1-find-baseline-precision" title="Link to this heading">¶</a></h3>
<p>Using the QuantizationSim feature in AIMET ONNX, you can evaluate model accuracy across various precision formats:</p>
<ul class="simple">
<li><p><strong>w8a8</strong>: INT8 weights, INT8 activations</p></li>
<li><p><strong>w8a16</strong>: INT8 weights, INT16 activations</p></li>
<li><p><strong>w16a16</strong>: INT16 weights, INT16 activations</p></li>
<li><p><strong>fp16</strong>: Float 16 weights, Float 16 activations</p></li>
</ul>
<p>Based on the accuracy results for each format, you can draw the following conclusions:</p>
<ul class="simple">
<li><p>Identify the lowest precision that maintains acceptable accuracy. If latency at this precision is also acceptable, the
model is ready for deployment.</p></li>
<li><p>If w8a8 yields poor accuracy but w8a16 performs well, the model is likely sensitive to <strong>activation quantization</strong>
at INT8.</p></li>
<li><p>If w8a16 yields poor accuracy but w1616 performs well, the model is likely sensitive to <strong>weight quantization</strong>
at INT8.</p></li>
<li><p>If only fp16 maintains acceptable accuracy, the model likely contains layers that are highly sensitive to
quantization — either in weights, activations, or both.</p></li>
</ul>
<p>If the baseline model you found does not give you the desired on-target latency and/or you would like to
find a more performant model, continue to Step 2.</p>
</section>
<section id="step-2-use-lite-mixed-precision">
<h3>Step 2: Use lite mixed precision<a class="headerlink" href="#step-2-use-lite-mixed-precision" title="Link to this heading">¶</a></h3>
<p>Empirical evidence across a broad range of models suggests that only a small subset of layers are typically sensitive
to quantization. This insight can be leveraged to achieve a lower-precision model than what may have been identified in
Step 1.</p>
<img alt="../_images/LiteMixedPrecisionWorkflow.png" src="../_images/LiteMixedPrecisionWorkflow.png" />
<p>In this step, we aim to find more performant model configurations than those explored in Step 1</p>
<ul class="simple">
<li><p><strong>AIMET QuantAnalyzer</strong> identifies layers that are most sensitive to quantization and generates a per-layer sensitivity
report.</p></li>
<li><p><strong>AIMET LiteMP</strong> uses this report to selectively assign higher precision (e.g., FP16) to a configurable percentage of
the most sensitive layers.</p></li>
<li><p>For example, if Step 1 showed poor accuracy at w8a8 but acceptable accuracy at w8a16, QuantAnalyzer + LiteMP can
be used to keep most layers at w8a8 while elevating only the most sensitive ones to FP16.</p></li>
<li><p>Similarly we could also configure a model with base w8a16 precision and a small percentage of the layers in fp16.</p></li>
<li><p>These models can be evaluated using AIMET QuantSim to determine if they meet the desired accuracy.</p></li>
<li><p>We can keep increasing the percentage of layers to flip to higher precision, and evaluate using AIMET QuantSim, till
we find a model mixed precision profile that meets desired accuracy.</p></li>
<li><p>LiteMP can be iteratively adjusted to fine-tune the balance between accuracy and latency.</p></li>
</ul>
<p>At the end of this step, very likely you have found a model which meets desired accuracy. We can export this model and
run on target to determine on-target latency. If the latency meets expectations, we can stop.</p>
<p>Else if we desire to find a more performant model, continue to Step 3</p>
</section>
<section id="step-3-use-automatic-mixed-precision-amp">
<h3>Step 3: Use Automatic Mixed Precision (AMP)<a class="headerlink" href="#step-3-use-automatic-mixed-precision-amp" title="Link to this heading">¶</a></h3>
<p>In the previous step, we applied the LiteMP feature in AIMET ONNX to perform basic mixed precision optimization. For
a more advanced approach, AIMET offers the <strong>Automatic Mixed Precision (AMP)</strong> feature, which runs a comprehensive
search to identify an optimal mixed precision profile. Note that AMP requires significantly more time than LiteMP.</p>
<p><strong>Key benefits of AMP:</strong></p>
<ul class="simple">
<li><p>Supports multiple precision candidates. For example, a suggested candidate set that is observed to work for a wide
range of models is (w8a8, w8a16, float16)</p></li>
<li><p>Allows users to define an accuracy threshold, which guides the algorithm to try and find a profile that meets that
target threshold</p></li>
</ul>
<p>For most models, AMP yields a well-balanced profile that maintains near-floating-point accuracy while improving latency
through integer precision.</p>
<p>If further performance gains are needed, proceed to Step 4.</p>
</section>
<section id="step-4-use-advanced-post-training-quantization-ptq-techniques">
<h3>Step 4: Use advanced Post-Training Quantization (PTQ) techniques<a class="headerlink" href="#step-4-use-advanced-post-training-quantization-ptq-techniques" title="Link to this heading">¶</a></h3>
<p>If the model exhibits sensitivity to weight quantization—evident when accuracy is high with w16a16 but degrades with
w8a16—AIMET provides advanced post-training quantization techniques to improve performance.</p>
<p>A recommended next step is to apply <strong>Adaptive Rounding (AdaRound)</strong>. This method performs layer-wise optimization to
learn a rounding matrix for the weights, which is then folded into the model. The result is a quantized model with
improved accuracy, as evaluated using AIMET’s QuantSim.</p>
<p>After applying AdaRound, repeat Steps 1 through 3 to reassess model accuracy, apply mixed precision if needed, and
proceed with deployment.</p>
</section>
<section id="step-5-use-quantization-aware-training-qat">
<h3>Step 5: Use Quantization-Aware Training (QAT)<a class="headerlink" href="#step-5-use-quantization-aware-training-qat" title="Link to this heading">¶</a></h3>
<p>From our experience, most models are able to quantize to integer precisions (w8a8 or w8a16) with the above
post-training quantization steps. Very rarely, if there is a need to improve latency by keeping most or all of the
model in w8a8 or w8a16 precision, <strong>Quantization Aware Training (QAT)</strong> might be needed.</p>
<p>Do note that QAT is a relatively heavy workflow that requires the users to tweak training hyperparameters and manually
guide the training process to get good results. This is very similar to the effort needed for model training. In
addition, QAT generally takes a lot more time to converge and complete compared to post-training quantization
techniques.</p>
<p>To use QAT, the recommended way is to use AIMET Torch’s QAT feature to train the model in PyTorch. After QAT is
complete, we export the AIMET Torch simulation model to an ONNX along with corresponding quantization encodings. Then
we repeat Steps 1 through 3 to reassess model accuracy, apply mixed precision if needed, and proceed with deployment.</p>
</section>
</section>
<section id="next-deploying-the-model">
<h2>Next: Deploying the model<a class="headerlink" href="#next-deploying-the-model" title="Link to this heading">¶</a></h2>
<p>After we have completed the quantization workflow, we have a deployment ready model exported from AIMET. This model can
be deployed to target - for example using the Qualcomm AI Runtime SDK or Qualcomm AI Hub.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="quantsim.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Quantization simulation guide</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tutorials</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Qualcomm Innovation Center, Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/quic/aimet" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Quantization workflow</a><ul>
<li><a class="reference internal" href="#accuracy-vs-performance-tradeoff">Accuracy-vs-Performance Tradeoff</a></li>
<li><a class="reference internal" href="#detailed-workflow">Detailed Workflow</a><ul>
<li><a class="reference internal" href="#step-1-find-baseline-precision">Step 1: Find baseline precision</a></li>
<li><a class="reference internal" href="#step-2-use-lite-mixed-precision">Step 2: Use lite mixed precision</a></li>
<li><a class="reference internal" href="#step-3-use-automatic-mixed-precision-amp">Step 3: Use Automatic Mixed Precision (AMP)</a></li>
<li><a class="reference internal" href="#step-4-use-advanced-post-training-quantization-ptq-techniques">Step 4: Use advanced Post-Training Quantization (PTQ) techniques</a></li>
<li><a class="reference internal" href="#step-5-use-quantization-aware-training-qat">Step 5: Use Quantization-Aware Training (QAT)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#next-deploying-the-model">Next: Deploying the model</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=8a448e45"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>