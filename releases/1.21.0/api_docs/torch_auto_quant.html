

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET PyTorch AutoQuant API &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.21.0</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.21.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../user_guide/index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../user_guide/index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET PyTorch AutoQuant API</a><ul>
<li><a class="reference internal" href="#top-level-api">Top-level API</a></li>
<li><a class="reference internal" href="#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-pytorch-autoquant-api">
<span id="api-torch-auto-quant"></span><h1>AIMET PyTorch AutoQuant API<a class="headerlink" href="#aimet-pytorch-autoquant-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="top-level-api">
<h2>Top-level API<a class="headerlink" href="#top-level-api" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="aimet_torch.auto_quant.AutoQuant">
<em class="property">class </em><code class="sig-prename descclassname">aimet_torch.auto_quant.</code><code class="sig-name descname">AutoQuant</code><span class="sig-paren">(</span><em class="sig-param">allowed_accuracy_drop</em>, <em class="sig-param">unlabeled_dataset_iterable</em>, <em class="sig-param">eval_callback</em>, <em class="sig-param">default_param_bw=8</em>, <em class="sig-param">default_output_bw=8</em>, <em class="sig-param">default_quant_scheme=&lt;QuantScheme.post_training_tf_enhanced: 2&gt;</em>, <em class="sig-param">default_rounding_mode='nearest'</em>, <em class="sig-param">default_config_file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.auto_quant.AutoQuant" title="Permalink to this definition">¶</a></dt>
<dd><p>Integrate and apply post-training quantization techniques.</p>
<p>AutoQuant includes 1) batchnorm folding, 2) cross-layer equalization,
and 3) Adaround.
These techniques will be applied in a best-effort manner until the model
meets the evaluation goal given as allowed_accuracy_drop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>allowed_accuracy_drop</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – Maximum allowed accuracy drop.</p></li>
<li><p><strong>unlabeled_dataset_iterable</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>[+T_co], <code class="xref py py-class docutils literal notranslate"><span class="pre">Collection</span></code>[+T_co]]) – A collection (i.e. iterable with <cite>__len__</cite>)
that iterates over an unlabeled dataset used for encoding computation.
The values yielded by this iterable are expected to be able to be
passed directly to the model. By default, this iterable will
be also used for Adaround unless otherwise specified by
<cite>self.set_adaround_params</cite>.</p></li>
<li><p><strong>eval_callback</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code>[[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]], <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]) – A function that maps model and the number samples
to the evaluation score. This callback is expected to return a
scalar value representing the model performance evaluated
against exactly <cite>N</cite> samples, where <cite>N</cite> is the number of samples
passed as the second argument of this callback.
NOTE: If <cite>N</cite> is None, the model is expected to be evaluated against
the whole evaluation dataset.</p></li>
<li><p><strong>default_param_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Default bitwidth (4-31) to use for quantizing layer parameters.</p></li>
<li><p><strong>default_output_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Default bitwidth (4-31) to use for quantizing layer inputs andoutputs.</p></li>
<li><p><strong>default_quant_scheme</strong> (<a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a>) – Quantization scheme. Supported values are
QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced.</p></li>
<li><p><strong>default_rounding_mode</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Rounding mode. Supported options are ‘nearest’ or ‘stochastic’</p></li>
<li><p><strong>default_config_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Path to configuration file for model quantizers</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="aimet_torch.auto_quant.AutoQuant.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fp32_model</em>, <em class="sig-param">dummy_input_on_cpu</em>, <em class="sig-param">dummy_input_on_gpu=None</em>, <em class="sig-param">results_dir='/tmp'</em>, <em class="sig-param">cache_id=None</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.auto_quant.AutoQuant.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply post-training quantization techniques.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp32_model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – Model to apply PTQ techniques.</p></li>
<li><p><strong>dummy_input_on_cpu</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Dummy input to the model in CPU memory.</p></li>
<li><p><strong>dummy_input_on_gpu</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code>]) – Dummy input to the model in GPU memory.
This parameter is required if and only if the fp32_model is on GPU.</p></li>
<li><p><strong>results_dir</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Directory to save the results.</p></li>
<li><p><strong>cache_id</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – A string that composes a cache id in combination with results_dir.
If specified, AutoQuant will load/save the PTQ results from/to the file system
if previous PTQ results produced under the same results_dir and cache_id exist,</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Tuple of  (best model, eval score, encoding path front).</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p>ValueError if the model is on GPU and dummy_input_on_gpu is not specified.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="aimet_torch.auto_quant.AutoQuant.set_adaround_params">
<code class="sig-name descname">set_adaround_params</code><span class="sig-paren">(</span><em class="sig-param">adaround_params</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.auto_quant.AutoQuant.set_adaround_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set Adaround parameters.
If this method is not called explicitly by the user, AutoQuant will use
<cite>unlabeled_dataset_iterable</cite> (passed to <cite>__init__</cite>) for Adaround.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>adaround_params</strong> (<a class="reference internal" href="torch_adaround.html#aimet_torch.adaround.adaround_weight.AdaroundParameters" title="aimet_torch.adaround.adaround_weight.AdaroundParameters"><code class="xref py py-class docutils literal notranslate"><span class="pre">AdaroundParameters</span></code></a>) – Adaround parameters.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">SubsetRandomSampler</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">aimet_torch.adaround.adaround_weight</span> <span class="kn">import</span> <span class="n">AdaroundParameters</span>
<span class="kn">from</span> <span class="nn">aimet_torch.auto_quant</span> <span class="kn">import</span> <span class="n">AutoQuant</span>
</pre></div>
</div>
<p><strong>Define constants and helper functions</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">EVAL_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">CALIBRATION_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">_subset_samplers</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">def</span> <span class="nf">_create_sampled_data_loader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">num_samples</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_subset_samplers</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)),</span> <span class="n">num_samples</span><span class="p">)</span>
        <span class="n">_subset_samplers</span><span class="p">[</span><span class="n">num_samples</span><span class="p">]</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                      <span class="n">sampler</span><span class="o">=</span><span class="n">_subset_samplers</span><span class="p">[</span><span class="n">num_samples</span><span class="p">],</span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Prepare model and dataset</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fp32_model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">((</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">))</span>
<span class="c1"># NOTE: In the actual use cases, a real dataset should provide by the users.</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FakeData</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">EVAL_DATASET_SIZE</span><span class="p">,</span>
                                 <span class="n">image_size</span><span class="o">=</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                 <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                 <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Prepare unlabeled dataset</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">class</span> <span class="nc">UnlabeledDatasetWrapper</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">images</span>

<span class="n">unlabeled_dataset</span> <span class="o">=</span> <span class="n">UnlabeledDatasetWrapper</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="n">unlabeled_data_loader</span> <span class="o">=</span> <span class="n">_create_sampled_data_loader</span><span class="p">(</span><span class="n">unlabeled_dataset</span><span class="p">,</span> <span class="n">CALIBRATION_DATASET_SIZE</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Prepare eval callback</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span> <span class="nf">eval_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>

    <span class="n">eval_data_loader</span> <span class="o">=</span> <span class="n">_create_sampled_data_loader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>

    <span class="n">num_correct_predictions</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">eval_data_loader</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">num_correct_predictions</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_correct_predictions</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_samples</span>
</pre></div>
</div>
<p><strong>Create AutoQuant object</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">auto_quant</span> <span class="o">=</span> <span class="n">AutoQuant</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                       <span class="n">unlabeled_dataset_iterable</span><span class="o">=</span><span class="n">unlabeled_data_loader</span><span class="p">,</span>
                       <span class="n">eval_callback</span><span class="o">=</span><span class="n">eval_callback</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>(Optional) Set Adaround parameters</strong></p>
<p>For setting the num_batches parameter, use the following guideline.
The number of batches is used to evaluate the model while calculating the quantization encodings.
Typically we want AdaRound to use around 2000 samples.
For example, if the batch size is 32, num_batches is 64.
If the batch size you are using is different, adjust the num_batches accordingly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ADAROUND_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">adaround_data_loader</span> <span class="o">=</span> <span class="n">_create_sampled_data_loader</span><span class="p">(</span><span class="n">unlabeled_dataset</span><span class="p">,</span> <span class="n">ADAROUND_DATASET_SIZE</span><span class="p">)</span>
<span class="n">adaround_params</span> <span class="o">=</span> <span class="n">AdaroundParameters</span><span class="p">(</span><span class="n">adaround_data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">adaround_data_loader</span><span class="p">))</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_adaround_params</span><span class="p">(</span><span class="n">adaround_params</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Run AutoQuant</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">encoding_path</span> <span class="o">=</span>\
    <span class="n">auto_quant</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fp32_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
                     <span class="n">dummy_input_on_cpu</span><span class="o">=</span><span class="n">dummy_input</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
                     <span class="n">dummy_input_on_gpu</span><span class="o">=</span><span class="n">dummy_input</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.21.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>