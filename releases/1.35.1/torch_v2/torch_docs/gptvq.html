<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>GPTVQ &mdash; AI Model Efficiency Toolkit Documentation: ver 1.35.1</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.35.1
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/quickstart_guide.html">Quickstart Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples/ptq.html">Post-Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Feature Descriptions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/adaround.html"> Adaptive Rounding (AdaRound)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AIMET PyTorch API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quantized_modules.html">Quantized Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantizer.html">Quantizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/nn.quantization_mixin.html">QuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/quantization/affine/index.html">quantization.affine</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/quantization/float/index.html">quantization.float</a></li>
<li class="toctree-l1"><a class="reference internal" href="encoding_analyzer.html">Encoding Analyzers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">GPTVQ</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/torch_docs/gptvq.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="admonition warning" id="api-torch-gptvq">
<p class="admonition-title">Warning</p>
<p>This feature is under heavy development and API changes may occur without notice in future versions.</p>
</div>
<section id="gptvq">
<h1>GPTVQ<a class="headerlink" href="#gptvq" title="Permalink to this heading"></a></h1>
<section id="top-level-api">
<h2>Top Level API<a class="headerlink" href="#top-level-api" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq">
<span class="sig-prename descclassname"><span class="pre">aimet_torch.gptvq.gptvq_weight.GPTVQ.</span></span><span class="sig-name descname"><span class="pre">apply_gptvq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gptvq_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param_encoding_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_names_to_exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_level_module_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gptvq'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq" title="Permalink to this definition"></a></dt>
<dd><p>Returns model with optimized weight rounding of GPTVQ supportable modules
and saves the corresponding parameter quantization encodings to a separate JSON file
that can be imported by QuantizationSimModel for inference or QAT</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – PyTorch model to GPTVQ</p></li>
<li><p><strong>dummy_input</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]) – Dummy input to the model. Used to parse model graph. If the model has more than one input,
pass a tuple. User is expected to place the tensors on the appropriate device</p></li>
<li><p><strong>gptvq_params</strong> (<a class="reference internal" href="#aimet_torch.gptvq.defs.GPTVQParameters" title="aimet_torch.gptvq.defs.GPTVQParameters"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPTVQParameters</span></code></a>) – Dataclass holding GPTVQ parameters</p></li>
<li><p><strong>param_encoding_path</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Path where to store parameter encodings</p></li>
<li><p><strong>module_names_to_exclude</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]) – Module names which are excluded during GPTVQ optimization</p></li>
<li><p><strong>block_level_module_names</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]]]) – List of module name lists to optimize block level GPTVQ optimization instead of leaf module level</p></li>
<li><p><strong>file_name_prefix</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Prefix to use for filename of the encodings file</p></li>
<li><p><strong>config_file_path</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Configuration file path for model quantizers</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>QuantizationSimModel with GPTVQ applied weights and saves corresponding parameter encodings JSON file at provided path</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="gptvq-parameters">
<h2>GPTVQ Parameters<a class="headerlink" href="#gptvq-parameters" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.gptvq.defs.GPTVQParameters">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.gptvq.defs.</span></span><span class="sig-name descname"><span class="pre">GPTVQParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rows_per_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols_per_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vector_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vector_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vector_stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_of_kmeans_iterations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assignment_chunk_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/aimet_torch/gptvq/defs.html#GPTVQParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.gptvq.defs.GPTVQParameters" title="Permalink to this definition"></a></dt>
<dd><p>Data carrier containing GPTVQ parameters</p>
</dd></dl>

<p>Users should set dataloader and forward_fn that are used to layer-wise optimization in GPTVQParameters.
All other parameters are optional and will be used as default values unless explicitly set</p>
</section>
<section id="code-example">
<h2>Code Example<a class="headerlink" href="#code-example" title="Permalink to this heading"></a></h2>
<p>This example shows how to use AIMET to perform GPTVQ</p>
<p><strong>Load the model</strong></p>
<p>For this example, we are going to load a pretrained OPT-125m model from transformers package. Similarly, you can load any
pretrained PyTorch model instead.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">OPTForCausalLM</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">OPTForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/opt-125m&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Apply GPTVQ</strong></p>
<p>We can now apply GPTVQ to this model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_torch.gptvq.defs</span> <span class="kn">import</span> <span class="n">GPTVQParameters</span>
<span class="kn">from</span> <span class="nn">aimet_torch.gptvq.gptvq_weight</span> <span class="kn">import</span> <span class="n">GPTVQ</span>

<span class="k">def</span> <span class="nf">forward_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">GPTVQParameters</span><span class="p">(</span>
    <span class="n">dataloader</span><span class="p">,</span>
    <span class="n">forward_fn</span><span class="o">=</span><span class="n">forward_fn</span><span class="p">,</span>
    <span class="n">num_of_kmeans_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">gptvq_applied_model</span> <span class="o">=</span> <span class="n">GPTVQ</span><span class="o">.</span><span class="n">apply_gptvq</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
    <span class="n">gptvq_params</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
    <span class="n">param_encoding_path</span><span class="o">=</span><span class="s2">&quot;./data&quot;</span><span class="p">,</span>
    <span class="n">module_names_to_exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lm_head&quot;</span><span class="p">],</span>
    <span class="n">file_name_prefix</span><span class="o">=</span><span class="s2">&quot;gptvq_opt&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Note that we set encoding path as <strong>./data</strong> and file_name_prefix as <strong>gptvq_opt</strong> that will be used later when setting QuantizationSimModel</p>
<p><strong>Create the Quantization Simulation Model from GPTVQ applied model</strong></p>
<p>After GPTVQ optimization, we can get gptvq_applied_model object and corresponding encoding files from above step.
To instantiate QuantizationSimModel with this information, users need to instantiate and load gptvq applied model and its encodings like below</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantScheme</span>
<span class="kn">from</span> <span class="nn">aimet_torch.v2.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span>

<span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span>
    <span class="n">gptvq_applied_model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">,</span>
    <span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf</span><span class="p">,</span>
    <span class="n">default_param_bw</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">vector_bw</span><span class="p">,</span>
    <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">sim</span><span class="o">.</span><span class="n">load_encodings</span><span class="p">(</span><span class="s2">&quot;./data/gptvq_opt.encodings&quot;</span><span class="p">,</span> <span class="n">allow_overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Compute the Quantization Encodings</strong></p>
<p>To compute quantization encodings of activations and parameters which were not optimized by GPTVQ,
we can pass calibration data through the model and then subsequently compute the quantization encodings. Encodings here refer to scale/offset quantization parameters.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">forward_fn</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">data_loader</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Export the model</strong></p>
<p>GPTVQ requires additional information such as vector dimension, index bitwidth compared to general affine quantization.
As a result, a new method of exporting encodings to json has been developed to both reduce the exported
encodings file size as well as reduce the time needed to write exported encodings to the json file.</p>
<p>The following code snippet shows how to export encodings in the new 1.0.0 format:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_common</span> <span class="kn">import</span> <span class="n">quantsim</span>

<span class="c1"># Assume &#39;sim&#39; is a QuantizationSimModel object imported from aimet_torch.v2.quantsim</span>

<span class="c1"># Set encoding_version to 1.0.0</span>
<span class="n">quantsim</span><span class="o">.</span><span class="n">encoding_version</span> <span class="o">=</span> <span class="s1">&#39;1.0.0&#39;</span>
<span class="n">sim</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="s1">&#39;exported_model&#39;</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">)</span>
</pre></div>
</div>
<p>The 1.0.0 encodings format is supported by Qualcomm runtime and can be used to export Per-Tensor, Per-Channel, Blockwise,
LPBQ and Vector quantizer encodings. If Vector quantizers are present in the model, the 1.0.0 format must be
used when exporting encodings for Qualcomm runtime.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>