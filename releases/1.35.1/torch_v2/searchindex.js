Search.setIndex({"docnames": ["_templates/autosummary/class", "_templates/autosummary/function", "install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/quantization/affine/index", "torch_docs/api/quantization/float/FloatQuantizeDequantize", "torch_docs/api/quantization/float/index", "torch_docs/api/quantization/tensor", "torch_docs/api/visualization_tools", "torch_docs/blockwise_quantization", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/gptvq", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/quickstart_guide", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["_templates/autosummary/class.rst", "_templates/autosummary/function.rst", "install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/quantization/affine/index.rst", "torch_docs/api/quantization/float/FloatQuantizeDequantize.rst", "torch_docs/api/quantization/float/index.rst", "torch_docs/api/quantization/tensor.rst", "torch_docs/api/visualization_tools.rst", "torch_docs/blockwise_quantization.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/gptvq.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/quickstart_guide.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["&lt;no title&gt;", "&lt;no title&gt;", "AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "QuantizationMixin", "quantization.affine", "FloatQuantizeDequantize", "quantization.float", "quantization.tensor", "Visualization Tools", "Blockwise Quantization", "Encoding Analyzers", "Post-Training Quantization", "GPTVQ", "AIMET: AI Model Efficiency Toolkit Documentation", "Quantized Modules", "Quantizers", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET Batch Norm Re-estimation", "AIMET channel pruning", "AIMET Compression Features Guidebook", "AIMET greedy compression ratio selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET model compression", "Model Guidelines for PyTorch", "AIMET model quantization", "AIMET post-training quantization techniques", "AIMET QuantAnalyzer", "AIMET quantization aware training", "Quantization simulation configuration", "AIMET quantization diagnostics", "AIMET quantization simulation", "AIMET Release Notes", "AIMET spatial SVD", "AIMET visualization", "AIMET visualization for quantization", "AIMET weight SVD", "AIMET winnowing"], "terms": {"name": [0, 1, 3, 4, 6, 11, 15, 17, 18, 31, 36, 37, 39], "escap": [0, 1], "underlin": [0, 1], "qualcomm": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "innov": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "center": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "inc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "ai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "effici": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "toolkit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "quantsim_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "default_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "json": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42], "35": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "The": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42], "pytorch": [2, 3, 6, 15, 17, 20, 21, 22, 26, 31, 32, 34, 36, 37], "gpu": [2, 3, 30, 37], "pypi": 2, "ar": [2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42], "avail": [2, 19, 29, 32, 34, 35], "environ": 2, "meet": [2, 21, 24, 25], "follow": [2, 3, 4, 6, 12, 15, 17, 20, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 38, 41, 42], "64": [2, 7, 12, 13, 18, 20], "bit": [2, 8, 9, 12, 19, 20, 22, 30, 35, 36, 37], "intel": 2, "x86": 2, "compat": [2, 12, 19], "processor": 2, "linux": [2, 4], "ubuntu": [2, 4], "22": [2, 4, 13, 19], "04": [2, 4], "lt": [2, 4], "python": [2, 3, 4], "3": [2, 7, 10, 12, 13, 19, 24, 30, 33, 35], "10": [2, 3, 4, 6, 7, 10, 12, 13, 17, 18, 19, 25, 28, 33], "20": [2, 20, 33], "8": [2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 17, 18, 19, 30, 35, 42], "cuda": [2, 3, 4, 19], "12": [2, 3, 4, 7, 12, 13], "0": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 15, 17, 18, 19, 20, 24, 25, 29, 34], "torch": [2, 3, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 29, 37], "2": [2, 3, 6, 7, 8, 9, 10, 12, 13, 15, 18, 20, 24, 25, 30, 35, 36], "pip": [2, 3, 4, 16, 39], "apt": [2, 3, 4, 16], "get": [2, 3, 4, 15, 28, 40], "liblapack": [2, 3, 4, 16], "libpython3": 2, "dev": [2, 3, 4], "python3": [2, 3, 4, 16], "m": [2, 3, 4, 16], "For": [2, 3, 4, 6, 12, 15, 16, 17, 19, 20, 23, 24, 25, 26, 27, 28, 30, 32, 34, 36], "other": [2, 12, 15, 25, 27, 30, 32, 35, 36, 37], "variant": [2, 4, 20, 21, 22, 30, 31, 32, 36], "latest": [2, 3], "version": [2, 3, 4, 6, 11, 12, 15, 17, 19, 26, 33], "from": [2, 6, 7, 8, 9, 10, 12, 13, 15, 17, 18, 19, 20, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 42], "whl": [2, 3, 4], "file": [2, 3, 4, 12, 15, 19, 30, 32, 33, 36, 37, 40], "host": [2, 3, 4, 37, 39], "http": [2, 3, 4, 31, 37, 39], "github": [2, 3, 4, 37], "com": [2, 3, 4, 37], "quic": [2, 3, 4, 37], "onli": [2, 3, 4, 7, 10, 11, 12, 17, 19, 22, 27, 28, 30, 32, 33, 34, 37, 39, 42], "thi": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 42], "time": [2, 12, 15, 19, 21, 28, 29, 33, 34, 39], "prerequisit": [2, 39], "pre": [2, 3, 4, 23, 26, 31, 32], "requisit": [2, 4], "appli": [2, 6, 7, 12, 15, 17, 18, 19, 20, 21, 22, 28, 30, 31, 33, 34, 35, 36, 37, 39, 40], "all": [2, 3, 6, 11, 12, 15, 17, 19, 23, 25, 28, 31, 32, 34, 35], "mai": [2, 3, 4, 6, 10, 11, 12, 15, 17, 20, 28, 30, 31, 32], "need": [2, 3, 4, 12, 15, 19, 30, 31, 33, 34, 36, 37, 40], "addit": [2, 6, 12, 15, 30, 33, 34, 37], "pleas": [2, 4, 16, 19, 31], "see": [2, 7, 17, 18, 19, 20, 21, 22, 23, 26, 28, 30, 32, 34, 35, 36, 39, 40], "detail": [2, 3, 4, 17, 25, 35, 36, 39, 40], "x": [2, 8, 9, 10, 17, 19, 24, 29, 32], "download": [2, 3, 4, 19], "aimet_torch": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 29], "cu121": [2, 3, 4], "cp310": [2, 3, 4], "manylinux_2_34_x86_64": [2, 3, 4], "f": [2, 3, 4, 19], "org": [2, 3, 4, 31], "torch_stabl": [2, 3, 4], "html": [2, 3, 4, 11, 32, 37, 40], "cpu": [2, 3, 19, 30, 37], "13": [2, 3, 7, 13], "11": [2, 3, 4, 7, 10], "cu117": 2, "tensorflow": [2, 3, 22, 26, 27, 30, 34, 36, 37], "aimet_tensorflow": [2, 4], "cu118": 2, "onnx": [2, 3, 16, 20, 21, 26, 29, 30, 31, 32, 34, 36], "16": [2, 6, 7, 8, 9, 12, 13, 15, 17, 18], "aimet_onnx": [2, 4], "older": 2, "brows": [2, 3, 4], "document": [2, 4, 26, 37, 39], "correspond": [2, 3, 4, 12, 15, 17, 23, 32, 36, 42], "select": [2, 3, 4, 21, 24, 32, 36, 39, 42], "appropri": [2, 4, 6, 12, 15, 17, 25, 35], "platform": [2, 20, 30, 36], "setup": 2, "bash": [2, 3], "command": [2, 3, 4, 39], "shell": 2, "nvidia": [2, 3, 4], "card": 2, "comput": [2, 4, 6, 8, 9, 12, 13, 15, 19, 20, 28, 29, 31, 32, 36, 39, 42], "capabl": [2, 17, 39], "5": [2, 7, 8, 9, 12, 17, 18, 24, 33, 35], "later": [2, 15, 19], "docker": 2, "To": [2, 6, 15, 17, 19, 22, 25, 29, 30, 32, 34, 35, 36, 39, 40], "us": [2, 4, 6, 7, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 24, 26, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40], "acceler": [2, 16, 26, 28], "train": [2, 16, 20, 21, 22, 26, 28, 32, 35, 36, 37], "modul": [2, 6, 11, 12, 15, 16, 19, 30, 37, 42], "an": [2, 6, 10, 11, 12, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 40, 42], "enabl": [2, 3, 12, 16, 22, 26, 30, 32, 34, 36, 37, 39], "minimum": [2, 7, 13], "driver": [2, 4], "455": 2, "i": [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42], "alwai": [2, 25], "recommend": [2, 12, 20, 22, 24, 30, 35], "especi": [2, 30, 33, 35], "newer": 2, "both": [2, 7, 12, 15, 16, 17, 28, 30, 31, 33, 34, 35, 36, 38, 39, 42], "cudnn": 2, "more": [2, 12, 15, 16, 17, 19, 23, 24, 25, 28, 30, 31, 32, 34, 35, 36, 39], "interfac": 2, "support": [2, 6, 12, 15, 23, 24, 26, 27, 28, 29, 30, 31, 34, 35, 36, 37, 41], "There": [2, 29, 31, 33, 40], "two": [2, 12, 19, 25, 26, 28, 30, 31, 32, 33, 36, 38, 40, 41], "wai": [2, 12, 19, 29], "On": 2, "your": [2, 3, 4, 6, 16, 20, 21, 24, 28, 29, 30, 33, 36, 39], "machin": [2, 3, 28], "our": [2, 4, 19], "built": [2, 3, 6, 17], "develop": [2, 3, 4, 11, 12, 15], "imag": [2, 20, 32], "click": 2, "link": [2, 4, 22, 31, 32], "contain": [2, 6, 10, 11, 15, 17, 19, 30, 32, 33, 34, 36], "page": [3, 4, 24, 36, 37], "provid": [3, 4, 6, 8, 9, 12, 15, 16, 19, 20, 24, 25, 28, 30, 31, 32, 34, 35, 36, 39, 40], "instruct": [3, 4, 16], "insid": [3, 6, 17, 19], "variant_str": 3, "ONE": 3, "depend": [3, 4, 10, 24, 30, 34, 37], "desir": [3, 12, 19, 24, 28, 30, 35], "pt113": 3, "tf": [3, 32, 36, 37], "export": [3, 4, 15, 16, 22, 26, 28, 29, 30, 33, 36, 37], "aimet_vari": 3, "one": [3, 12, 15, 19, 23, 28, 33, 37, 38, 39, 41], "workspac": 3, "absolute_path_to_workspac": 3, "docker_image_nam": 3, "artifact": [3, 19], "codelinaro": 3, "docker_container_nam": 3, "any_nam": 3, "note": [3, 4, 12, 15, 19, 26, 39], "feel": 3, "free": [3, 31], "modifi": [3, 4, 30, 36, 37, 42], "you": [3, 4, 6, 15, 20, 21, 24, 26, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40], "want": [3, 6], "If": [3, 4, 6, 7, 8, 9, 12, 15, 17, 18, 19, 20, 21, 24, 25, 29, 30, 31, 32, 34, 35, 39, 40, 42], "skip": [3, 23], "next": [3, 19, 33, 35, 36], "section": [3, 4, 12, 22, 30, 36], "any_tag": 3, "t": [3, 6, 20, 32, 33], "jenkin": 3, "dockerfil": 3, "ensur": [3, 17, 25, 30, 35], "alreadi": [3, 6, 35], "run": [3, 4, 7, 12, 17, 18, 22, 26, 28, 30, 31, 32, 36, 37, 39], "otherwis": [3, 4, 7, 12, 18, 35], "remov": [3, 19, 23, 26, 36, 42], "exist": [3, 6, 12, 17, 36], "new": [3, 7, 12, 15, 16, 18, 19, 30, 37], "p": [3, 13], "grep": 3, "kill": 3, "rm": 3, "u": 3, "id": [3, 39], "user": [3, 6, 12, 15, 16, 20, 24, 28, 32, 35, 37], "g": [3, 19, 22], "v": [3, 12], "etc": [3, 24, 30], "passwd": 3, "ro": 3, "group": [3, 12, 34, 36], "home": 3, "mnt": 3, "entrypoint": 3, "bin": [3, 4, 13], "w": [3, 42], "hostnam": 3, "abov": [3, 4, 12, 15, 16, 28, 31, 36, 39, 42], "base": [3, 6, 7, 8, 9, 12, 13, 17, 18, 23, 24, 25, 30, 39], "filesystem": 3, "add": [3, 6, 17, 19, 34, 36, 37, 42], "order": [3, 4, 6, 12, 17, 19, 22, 23, 30, 33, 34], "access": 3, "replac": [3, 12, 17, 19, 31, 36], "port": [3, 39], "forward": [3, 6, 7, 17, 18, 19, 29, 32, 35, 37], "done": [3, 7, 18, 28, 34, 36], "visual": [3, 28, 30, 31, 32, 35, 37], "api": [3, 11, 19, 26, 29, 30, 34, 37, 39], "can": [3, 7, 10, 12, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42], "achiev": [3, 12, 20, 24], "port_id": 3, "ani": [3, 6, 12, 15, 19, 34, 37], "number": [3, 6, 7, 8, 9, 12, 13, 17, 20, 25, 26, 28, 33, 36, 37, 39, 42], "default": [3, 4, 6, 7, 11, 15, 17, 18, 20, 25, 28, 34, 36, 37, 39], "go": [3, 4, 15, 19], "project": [3, 4], "requir": [3, 4, 6, 12, 15, 19, 22, 24, 28, 30, 31, 34, 35, 39], "each": [3, 4, 6, 11, 12, 17, 18, 19, 22, 23, 24, 25, 28, 30, 31, 32, 33, 34, 35, 36, 40], "identifi": [3, 4, 12, 23, 32, 35, 37, 42], "wish": [3, 4], "some": [3, 4, 17, 19, 20, 24, 25, 29, 30, 31, 33, 35, 36, 42], "tip": [3, 4], "32": [3, 4, 7, 15, 18, 35], "post1": [3, 4], "7": [3, 4, 7, 8, 9, 19, 35, 42], "31": [3, 4], "prepend": [3, 4, 17], "sudo": [3, 4], "y": [3, 4, 19, 32], "we": [3, 4, 12, 15, 17, 19, 20, 24, 28, 30, 31, 35], "also": [3, 4, 12, 23, 28, 30, 32, 34, 36, 37, 40, 42], "wheel": [3, 4], "differ": [3, 4, 12, 23, 25, 28, 30, 31, 33, 35, 36], "which": [3, 4, 6, 7, 10, 12, 13, 15, 16, 17, 18, 19, 22, 24, 25, 28, 30, 31, 32, 34, 36, 37, 39, 42], "tag": [3, 4, 37], "below": [3, 4, 6, 7, 12, 15, 17, 18, 19, 22, 23, 25, 28, 30, 31, 32, 34, 35, 36, 39], "ex": [3, 4, 12], "release_tag": [3, 4], "construct": [3, 4, 19, 29], "root": [3, 4, 19], "url": [3, 4, 39], "download_url": [3, 4], "extens": [3, 4, 17], "wheel_file_nam": [3, 4], "do": [3, 4, 19, 28, 32, 35, 36], "find_pkg_url_str": [3, 4], "specifi": [3, 4, 7, 8, 9, 12, 18, 19, 21, 23, 24, 25, 28, 34, 36, 39], "automat": [3, 4, 12, 24, 28, 30, 32, 37], "common": [3, 12, 35, 40], "variabl": [3, 4, 7, 18, 25], "sourc": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 35], "usr": [3, 4], "lib": [3, 4], "dist": [3, 4], "envsetup": [3, 4], "sh": [3, 4], "unless": [4, 6, 15, 42], "pend": 4, "pip3": 4, "h": [4, 41, 42], "These": [4, 17, 19, 21, 22, 23, 24, 29, 30, 31, 32, 35, 36], "assum": [4, 12, 15, 25], "path": [4, 11, 15], "local": [4, 39], "case": [4, 7, 12, 17, 19, 25, 31, 34], "accordingli": 4, "basic": [4, 16, 19], "updat": [4, 13, 18, 30, 31, 33, 36, 37, 39], "upgrad": 4, "ye": [4, 28], "wget": 4, "gnupg2": 4, "have": [4, 6, 11, 12, 19, 28, 31, 32, 35], "multipl": [4, 12, 17, 26, 28, 37], "set": [4, 6, 11, 12, 15, 17, 18, 20, 24, 25, 28, 29, 31, 32, 33, 34, 35], "altern": [4, 12], "were": [4, 15, 24, 34, 42], "test": 4, "sub": [4, 36], "visit": [4, 16], "archiv": 4, "obtain": [4, 24, 32], "correct": [4, 19, 20, 30, 31, 35], "exact": [4, 22, 30], "up": [4, 12, 20, 28, 34, 42], "date": 4, "execut": [4, 19, 39], "final": [4, 12, 23, 24, 25, 33, 35], "aforement": 4, "repo": 4, "ubuntu2204": 4, "x86_64": 4, "keyring_1": 4, "1_all": 4, "deb": 4, "dpkg": 4, "cat": 4, "reqs_deb_common": 4, "txt": 4, "xarg": 4, "reqs_deb_torch_common": 4, "reqs_deb_onnx_common": 4, "reqs_deb_tf_gpu": 4, "reqs_deb_torch_gpu": 4, "reqs_deb_onnx_gpu": 4, "option": [4, 6, 7, 12, 15, 16, 18, 19, 20, 32, 34, 36], "uninstal": 4, "cach": 4, "dir": 4, "9": [4, 7, 10], "onnxruntime_v": 4, "c": [4, 24], "import": [4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 22, 23], "print": [4, 6, 7, 17, 19, 32], "__version__": 4, "ln": 4, "": [4, 6, 12, 16, 17, 18, 19, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 40, 42], "gnu": 4, "libjpeg": 4, "so": [4, 17, 25, 29, 32], "chose": 4, "between": [4, 12, 17, 31, 32, 34, 36], "class": [6, 8, 12, 13, 15, 18, 19], "v2": [6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19], "nn": [6, 7, 11, 12, 16, 17, 18, 19, 29, 37], "arg": [6, 7, 10, 12, 15, 17, 18], "kwarg": [6, 7, 10, 17, 18], "mixin": [6, 17], "quantiz": [6, 8, 11, 13, 15, 16, 20, 21, 22, 24, 26, 28, 32, 37, 39], "function": [6, 10, 11, 12, 17, 19, 20, 25, 28, 29, 32, 36, 37, 39, 40], "top": [6, 23, 39], "regular": [6, 17, 20, 30, 36], "specif": [6, 12, 17, 19, 21, 22, 26, 29, 30, 31, 34, 37], "input": [6, 7, 8, 9, 11, 12, 13, 15, 17, 18, 19, 23, 25, 28, 32, 34, 36, 38, 41, 42], "output": [6, 7, 12, 17, 18, 19, 23, 28, 31, 32, 34, 36, 37, 38, 41, 42], "paramet": [6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 22, 23, 28, 29, 30, 31, 32, 33, 34, 40], "tensor": [6, 7, 8, 9, 12, 13, 15, 17, 18, 19, 20, 23, 29, 30, 32, 34, 35, 36, 37], "its": [6, 10, 15, 16, 17, 19, 23, 26, 32, 36, 42], "held": [6, 17, 19], "quantizerbas": [6, 17, 18], "object": [6, 10, 11, 12, 15, 17, 18, 19, 22, 30, 33, 36], "dure": [6, 11, 15, 17, 19, 20, 26, 28, 30, 33, 34, 36, 39, 40], "method": [6, 12, 15, 17, 19, 25, 28, 30, 35, 36], "inherit": [6, 17], "layer": [6, 11, 12, 15, 17, 19, 20, 21, 22, 23, 24, 27, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42], "oper": [6, 17, 19, 29, 30, 31, 34, 35], "none": [6, 7, 8, 9, 11, 12, 15, 17, 19, 39], "behav": [6, 17, 35], "exactli": [6, 17, 36], "same": [6, 10, 12, 17, 18, 22, 31, 34, 40], "parent": [6, 17], "input_quant": [6, 17, 19], "modulelist": [6, 17, 19], "output_quant": [6, 17, 19], "param_quant": [6, 12, 17, 19], "moduledict": [6, 17, 19], "map": [6, 7, 10, 12, 17, 25, 32, 34], "associ": [6, 17, 30], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20, 24, 26, 30, 32, 34, 35, 36, 37, 42], "qlinear": [6, 17], "quantizedlinear": [6, 12, 17, 19], "in_featur": [6, 17, 19], "out_featur": [6, 17, 19], "bia": [6, 8, 9, 17, 19, 20, 23, 30, 31, 34, 35, 37], "true": [6, 7, 8, 9, 10, 12, 13, 17, 18, 19, 29, 34], "weight": [6, 11, 12, 13, 15, 17, 19, 20, 22, 24, 28, 30, 31, 32, 33, 34, 35, 36, 40], "abstract": [6, 17, 18], "should": [6, 12, 15, 17, 19, 24], "perform": [6, 7, 12, 15, 17, 18, 19, 21, 22, 23, 24, 25, 28, 30, 31, 32, 33, 35], "logic": [6, 17, 37], "param": [6, 12, 17, 18, 34], "call": [6, 8, 9, 10, 12, 17, 19, 30, 32, 34, 36, 37, 38, 41], "pass": [6, 12, 15, 16, 17, 19, 26, 29, 31, 32, 33, 35, 36, 37, 39], "__quant_init__": [6, 17], "initi": [6, 7, 8, 9, 17, 18, 20, 33, 36], "invok": [6, 17, 28, 30, 39, 40], "right": [6, 7, 8, 9, 17, 18, 42], "after": [6, 13, 15, 17, 19, 20, 21, 22, 24, 28, 30, 35, 39, 40], "__init__": [6, 17, 19], "structur": [6, 17, 28], "size": [6, 7, 12, 15, 17, 18, 20, 29, 38, 41], "initializd": [6, 17], "custom": [6, 17, 35, 36], "overridden": [6, 17, 34], "length": [6, 12, 17], "given": [6, 11, 12, 13, 17, 21, 25, 28, 31], "set_kernel": 6, "kernel": [6, 12, 23, 38, 41], "instanc": [6, 39], "In": [6, 12, 17, 19, 20, 24, 25, 28, 30, 31, 33, 34, 36, 39, 40, 42], "gener": [6, 7, 12, 15, 18, 19, 28, 30, 32, 33, 34, 35, 36], "signatur": [6, 7], "equival": [6, 7, 8, 9, 12, 19], "return": [6, 10, 11, 12, 13, 15, 16, 18, 19, 21, 25, 26, 32, 36], "quantizedtensor": [6, 7, 10, 18], "take": [6, 12, 19, 25, 28, 30, 31, 33, 35, 42], "keyword": 6, "argument": [6, 8, 9, 12], "output_encod": 6, "onc": [6, 22, 23, 28, 32, 33, 36], "within": [6, 10, 17, 24, 32, 36], "compute_encod": [6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19], "context": [6, 17, 19], "callabl": [6, 12], "underli": [6, 35], "q": [6, 7, 8, 9, 10, 17, 18, 36], "def": [6, 15, 19], "int_multipli": 6, "b": [6, 7, 18], "encod": [6, 7, 10, 12, 15, 16, 18, 19, 20, 22, 30, 32, 33, 37], "enc": 6, "affin": [6, 10, 12, 15, 16, 17, 18, 19], "rais": 6, "notimplementederror": 6, "q_output": 6, "quantized_repr": [6, 10], "offset": [6, 7, 12, 13, 15, 18, 30, 32, 33, 36], "dq_output": 6, "scale": [6, 7, 8, 9, 10, 12, 15, 18, 22, 30, 31, 32, 33, 36], "qmult": 6, "quantizedmultipli": [6, 17], "classmethod": 6, "set_default_kernel": 6, "cl": [6, 37], "ha": [6, 10, 12, 15, 19, 24, 25, 30, 31, 33, 36, 39, 42], "been": [6, 10, 11, 12, 15, 36, 42], "get_kernel": 6, "enter": [6, 17, 21], "observ": [6, 13, 17, 18, 19, 28, 31, 32, 36], "upon": [6, 17, 19], "exit": [6, 17, 19], "symmetr": [6, 7, 10, 12, 13, 17, 18, 19, 34, 36], "fals": [6, 7, 10, 12, 13, 15, 17, 18, 19, 29, 34], "randn": [6, 7, 10, 13, 17, 18], "is_initi": [6, 7, 8, 9, 17, 18], "from_modul": 6, "creat": [6, 11, 13, 15, 16, 17, 19, 20, 22, 28, 29, 30, 33, 36], "result": [6, 10, 12, 13, 15, 20, 21, 23, 24, 26, 28, 31, 32, 33, 34, 36], "attribut": [6, 17, 32], "origin": [6, 17, 19, 23, 24, 25, 30, 31, 32, 36, 39], "assign": [6, 7, 17, 18], "float": [6, 8, 10, 12, 13, 16, 30, 32, 35, 36, 40], "point": [6, 10, 12, 16, 26, 30, 32, 35, 36, 40], "linear": [6, 12, 17, 19, 22, 23], "quantized_linear": 6, "get_default_kernel": 6, "type": [6, 10, 11, 12, 15, 17, 18, 28, 30, 32, 34, 36, 39], "current": [6, 27, 41], "doe": [6, 19, 23, 25, 27, 30, 35, 36], "retriev": 6, "implement": [6, 29, 30, 35], "module_cl": 6, "decor": 6, "regist": [6, 18], "definit": [6, 19, 30], "even": 6, "though": [6, 12, 34], "aimet": [6, 15, 17, 19, 26, 29, 34], "subpackag": 6, "conv2d": [6, 12, 17, 19, 23, 28, 37, 42], "awar": [6, 20, 22, 26, 28, 30, 35, 36], "quantizationsimmodel": [6, 11, 12, 15, 16, 19, 20, 22], "throw": 6, "runtim": [6, 12, 15, 16, 19, 24, 26, 28, 30, 32, 34, 36, 37], "error": [6, 21, 30, 32, 33, 35, 36], "when": [6, 12, 15, 16, 17, 19, 20, 28, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42], "encount": [6, 19], "defin": [6, 12, 17, 19, 30, 32, 34, 36], "ask": 6, "doesn": [6, 33], "know": 6, "declar": 6, "subclass": [6, 13], "As": [6, 12, 15, 21, 24, 25, 31, 32, 36], "maskedadd": 6, "self": [6, 10, 19], "mask": 6, "valu": [6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 19, 20, 23, 24, 25, 28, 30, 31, 32, 33, 34, 36, 38, 40, 41], "befor": [6, 11, 17, 19, 20, 21, 22, 28, 30, 32, 33, 36, 40], "typic": [6, 12, 17, 19, 24, 30, 32, 33, 36], "quantizedmaskedadd": 6, "matter": 6, "super": [6, 19], "input_qtzr": 6, "_": [6, 7, 11, 16, 17, 18, 19, 30], "don": [6, 20, 32], "boolean": 6, "value_qtzr": 6, "output_qtzr": 6, "shape": [7, 8, 9, 10, 12, 13, 17, 18, 19, 32], "precis": [7, 8, 9, 16, 18, 30], "out": [7, 8, 9, 18], "clamp": [7, 8, 9, 18, 36], "left": [7, 8, 9, 18, 25, 42], "lceil": [7, 8, 9, 18], "frac": [7, 8, 9, 18], "rfloor": [7, 8, 9, 18], "qmin": [7, 18, 36], "qmax": [7, 18, 36], "where": [7, 8, 9, 15, 18, 19, 22, 25, 32, 38, 39, 41, 42], "deriv": [7, 18, 36], "learnabl": [7, 18], "theta_": [7, 18], "min": [7, 11, 13, 18, 19, 32, 36], "max": [7, 8, 9, 11, 13, 18, 19, 28, 31, 32, 36], "block": [7, 12, 15, 18], "begin": [7, 18, 34], "pmatrix": [7, 18], "b_0": [7, 18], "b_1": [7, 12, 18], "cdot": [7, 18], "b_": [7, 18], "d": [7, 18], "end": [7, 18, 19, 28], "equat": [7, 12, 18, 36], "further": [7, 10, 12, 18, 19, 20, 23, 26, 28], "out_": [7, 18], "j_0": [7, 18], "j_": [7, 18], "input_": [7, 18], "scale_": [7, 18], "i_0": [7, 18], "i_": [7, 18], "offset_": [7, 18], "text": [7, 18], "quad": [7, 18, 36], "forall_": [7, 18], "leq": [7, 18], "i_d": [7, 18], "lfloor": [7, 8, 9, 18], "j_d": [7, 18], "b_d": [7, 18], "tupl": [7, 12, 13, 15, 18], "bitwidth": [7, 8, 9, 10, 12, 15, 17, 18, 19, 22, 30, 35, 36], "int": [7, 8, 9, 12, 13, 18], "bool": [7, 12, 13, 18], "asymmetr": [7, 13, 18, 34, 36], "encoding_analyz": [7, 8, 9, 13, 18], "encodinganalyz": [7, 8, 9, 13, 18], "analyz": [7, 16, 17, 18, 21, 23, 29, 32, 39, 40], "calibr": [7, 11, 12, 13, 15, 16, 17, 18, 19, 30, 32, 33, 35, 36], "absolut": [7, 18], "block_siz": [7, 12, 18], "cannot": [7, 18], "until": [7, 18, 21], "properli": [7, 18, 19], "statist": [7, 8, 9, 11, 13, 17, 18, 19, 22, 30, 32, 40], "manual": [7, 18, 21, 28], "129": [7, 18, 29], "255": [7, 10, 18], "122": [7, 18], "192": [7, 18], "106": [7, 18], "94": [7, 18], "145": [7, 18], "181": [7, 18], "144": [7, 18], "194": [7, 18], "74": [7, 18], "86": [7, 18], "150": [7, 18], "33": [7, 18], "103": [7, 18], "37": [7, 18], "111": [7, 18], "237": [7, 18], "218": [7, 18], "49": [7, 18], "155": [7, 18], "179": [7, 18], "66": [7, 18, 24], "89": [7, 18], "110": [7, 18], "17": [7, 13, 18], "36": [7, 18], "83": [7, 18], "grad_fn": [7, 10, 18], "aliasbackward0": [7, 10, 18], "ones_lik": [7, 18], "187": [7, 18], "186": [7, 18], "131": [7, 18], "203": [7, 18], "80": [7, 13, 18], "143": [7, 18], "152": [7, 18], "226": [7, 18], "55": [7, 18], "172": [7, 18], "207": [7, 18], "146": [7, 18], "216": [7, 18], "238": [7, 18], "141": [7, 18], "178": [7, 18], "188": [7, 18], "63": [7, 18], "59": [7, 18], "19": [7, 13, 18], "162": [7, 18], "30": [7, 18], "109": [7, 18], "quantizedequant": [7, 9, 10, 12, 17, 18, 19], "fake": [7, 8, 9, 18, 19], "dequant": [7, 10, 18], "overlin": [7, 18], "qdq": [7, 8, 9, 18], "dequantizedtensor": [7, 10, 18], "2771": [7, 18], "3038": [7, 18], "0819": [7, 18], "9700": [7, 18], "9487": [7, 18], "1307": [7, 18], "7894": [7, 18], "1709": [7, 18], "2212": [7, 18], "7741": [7, 18], "0295": [7, 18], "2265": [7, 18], "0564": [7, 18], "6177": [7, 18], "0386": [7, 18], "0176": [7, 18], "6054": [7, 18], "8836": [7, 18], "1232": [7, 18], "8229": [7, 18], "5540": [7, 18], "3992": [7, 18], "2363": [7, 18], "2546": [7, 18], "0036": [7, 18], "2355": [7, 18], "1741": [7, 18], "6079": [7, 18], "6247": [7, 18], "0115": [7, 18], "2458": [7, 18], "9157": [7, 18], "4694": [7, 18], "0639": [7, 18], "2568": [7, 18], "0680": [7, 18], "6695": [7, 18], "7932": [7, 18], "1889": [7, 18], "0158": [7, 18], "5695": [7, 18], "5220": [7, 18], "1977": [7, 18], "4475": [7, 18], "0424": [7, 18], "1128": [7, 18], "8796": [7, 18], "1060": [7, 18], "5897": [7, 18], "6196": [7, 18], "9961": [7, 18], "0549": [7, 18], "6431": [7, 18], "0039": [7, 18], "8706": [7, 18], "4706": [7, 18], "2353": [7, 18], "8078": [7, 18], "3451": [7, 18], "1176": [7, 18], "4549": [7, 18], "0471": [7, 18], "5255": [7, 18], "4157": [7, 18], "0784": [7, 18], "5333": [7, 18], "1647": [7, 18], "2118": [7, 18], "2196": [7, 18], "9176": [7, 18], "9490": [7, 18], "7765": [7, 18], "4784": [7, 18], "6039": [7, 18], "3137": [7, 18], "3216": [7, 18], "8000": [7, 18], "4392": [7, 18], "4863": [7, 18], "overload": 7, "list": [7, 12, 15, 17, 18, 25, 27, 29, 34], "sign": [7, 36], "rceil": 7, "posit": 7, "integ": [7, 12, 20, 30, 32], "rang": [7, 11, 13, 19, 20, 22, 25, 30, 31, 32, 33, 35, 36, 37, 40], "over": [7, 13, 17, 20, 25, 28, 40], "neg": [7, 12], "num_step": [7, 13], "num": 7, "_step": 7, "step": [7, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 33, 35], "maximum": [7, 8, 9, 13], "arang": 7, "start": [7, 19, 20, 24, 34, 36], "05": [7, 19], "0000e": 7, "01": [7, 20], "5000e": 7, "02": 7, "1921e": 7, "08": 7, "4": [7, 10, 12, 19, 22, 25, 30, 35, 42], "6": [7, 12, 13, 15, 33, 35], "00": 7, "0500e": 7, "1000e": 7, "1500e": 7, "2000e": 7, "2500e": 7, "15": [7, 28, 33], "14": [7, 19], "quantize_dequant": 7, "0000": [7, 10], "0667": 7, "1333": 7, "2000": [7, 10], "2667": 7, "3333": 7, "4000": [7, 10], "4667": 7, "6000": [7, 10], "6667": 7, "7333": 7, "8667": 7, "9333": 7, "exponent_bit": [8, 9, 12], "mantissa_bit": [8, 9, 12], "dtype": [8, 9, 10, 12, 15], "simul": [8, 9, 12, 15, 16, 17, 19, 26, 30, 33, 37], "cast": [8, 9], "expon": [8, 9, 12], "mantissa": [8, 9, 12], "x_c": [8, 9], "log_2": [8, 9], "ieee": [8, 9, 28, 31], "standard": [8, 9, 17], "represent": [8, 9, 10], "_max": [8, 9], "mutual": [8, 9, 12], "exclus": [8, 9, 12], "repres": [8, 9, 10, 17, 18, 19, 25, 31, 32, 33, 36], "determin": [8, 9, 12, 17, 19, 21, 30, 31, 32, 40], "dynam": [8, 9, 31, 36, 37, 40], "finer": [8, 9, 12], "8998": [8, 9], "0947": [8, 9], "0891": [8, 9], "1727": [8, 9], "unlik": [8, 9], "affinequant": [8, 9], "floatquant": [8, 9], "without": [8, 9, 10, 11, 12, 15, 21, 30, 33, 36, 42], "is_bfloat16": [8, 9], "8984": [8, 9], "0859": [8, 9], "1729": [8, 9], "minmaxencodinganalyz": [8, 9, 13], "float16": [8, 9, 12], "is_float16": [8, 9], "8994": [8, 9], "0889": [8, 9], "alia": [8, 9], "floatquantizedequant": 9, "hold": [10, 12, 15, 17, 34, 35], "store": [10, 12, 15], "along": [10, 12, 19, 33, 36], "encodingbas": [10, 18], "inform": [10, 15, 30], "necessari": [10, 12, 19, 39], "back": [10, 19, 34], "real": [10, 39], "produc": [10, 11, 12, 13, 25, 32], "rtype": 10, "57": 10, "312": 10, "153": 10, "205": 10, "set_rang": 10, "128": [10, 12, 19], "127": 10, "x_q": 10, "26": 10, "23": [10, 13], "x_dq": 10, "3000": 10, "equal": [10, 12, 20, 21, 24, 25, 29, 30, 32, 35, 36, 40], "data": [10, 11, 12, 13, 15, 16, 19, 20, 22, 27, 31, 32, 33, 35, 36], "abl": [10, 19], "carri": 10, "gradient": 10, "thu": 10, "autograd": 10, "allow": [10, 12, 21, 28, 35, 36, 37, 39], "backpropag": 10, "requires_grad": 10, "38": [10, 28], "28": 10, "40": 10, "int8": [10, 33, 36, 40], "subsequ": [10, 15, 29, 31, 34], "well": [10, 12, 15, 28, 31, 32], "about": [10, 19, 26, 32], "wa": [10, 28], "With": [10, 30, 33], "convert": [10, 19, 21, 30, 40], "loss": [10, 16, 19, 20, 26, 28, 30, 32, 36], "39": [10, 19], "51": 10, "521": 10, "41": 10, "quant_dequ": 10, "x_qdq": 10, "52": 10, "68": 10, "97": 10, "uint8": 10, "featur": [11, 12, 15, 20, 21, 22, 28, 31, 32, 35, 36, 37, 39, 40], "under": [11, 12, 15, 32, 34], "heavi": [11, 12, 15, 39, 40], "chang": [11, 12, 15, 19, 20, 28, 32, 33, 34, 36, 40, 42], "occur": [11, 12, 15], "notic": [11, 12, 15], "futur": [11, 12, 15], "visualization_tool": 11, "visualize_stat": 11, "sim": [11, 12, 15, 16, 19, 33, 36], "dummy_input": [11, 12, 15, 19], "save_path": 11, "quant_stats_visu": 11, "interact": 11, "view": [11, 16, 19, 22, 26, 29, 31, 32, 39], "stat": [11, 13], "collect": [11, 12, 25, 32], "expect": [11, 13, 15, 19, 28, 30, 32], "plot": [11, 32], "activ": [11, 12, 15, 17, 19, 30, 32, 33, 34, 35, 36], "quantsim": [11, 12, 15, 16, 30, 33, 34, 37], "includ": [11, 12, 22, 25, 32, 33, 34, 36, 37, 39], "adjust": [11, 12, 20, 22, 23, 24, 30, 31, 35], "threshold": [11, 17, 21], "flag": [11, 18], "whose": [11, 12, 31, 34], "exce": 11, "tabl": [11, 39], "exceed": 11, "save": [11, 15, 19, 36, 40], "quant_schem": [11, 15], "quantschem": [11, 15, 21], "post_training_tf": [11, 15], "data_load": [11, 15, 16, 19], "sampl": [11, 16, 17, 19, 23, 31, 32, 33, 36], "trace": 11, "str": [11, 15], "known": [12, 26], "like": [12, 15, 16, 19, 21, 26, 28, 30, 32, 33, 34], "grid": 12, "counterpart": [12, 17], "process": [12, 13, 16, 19, 21, 23, 25, 26, 28, 31, 36], "particular": [12, 30, 34], "choos": [12, 23, 24, 28], "come": [12, 28, 33], "cover": [12, 36], "whole": [12, 36], "split": 12, "describ": [12, 28, 29, 30, 31, 34, 35, 36, 39], "sever": [12, 17, 24, 32], "pro": 12, "con": 12, "per": [12, 15, 17, 22, 31, 32, 34, 35, 36, 37, 39], "entir": [12, 19, 28], "singl": [12, 20, 25, 28, 31], "benefit": [12, 20], "less": [12, 13, 23, 25, 34], "storag": 12, "space": 12, "drawback": 12, "outlier": [12, 32, 36], "affect": [12, 22, 34], "channel": [12, 15, 17, 22, 24, 25, 27, 28, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42], "individu": [12, 22, 25, 30, 32, 34, 35], "dimens": [12, 15, 17, 35, 38, 41], "compar": [12, 15, 19, 30, 32, 33, 40], "would": [12, 13, 34, 37], "influenc": 12, "resid": [12, 37], "chunk": 12, "across": [12, 31, 32, 40], "improv": [12, 19, 24, 28, 30, 33, 35, 40], "granular": [12, 28, 35, 36, 40], "found": [12, 33, 36], "isol": 12, "optim": [12, 15, 19, 20, 21, 26, 28, 30, 33, 36, 37, 39], "cost": [12, 25, 28, 33], "increas": [12, 25, 31], "favor": 12, "possibl": [12, 19, 25, 32, 34, 35], "similarli": [12, 15, 35], "lead": [12, 20, 22, 31, 35], "better": [12, 20, 21, 28, 30, 31, 33], "accuraci": [12, 16, 19, 20, 21, 24, 25, 26, 28, 30, 31, 32, 33, 35, 36, 37, 40, 42], "part": [12, 28, 31, 32], "basi": 12, "instanti": [12, 15, 19, 39], "relationship": 12, "actual": 12, "being": [12, 23], "rule": [12, 34], "must": [12, 15, 17, 21, 22, 24, 26, 27, 30, 32, 34, 42], "match": [12, 23, 28, 32, 34, 35, 36, 42], "most": [12, 19, 34], "long": [12, 15], "b_2": 12, "b_n": 12, "s_1": 12, "s_2": 12, "s_n": 12, "satisfi": [12, 19, 21], "n": [12, 19, 37], "word": 12, "evenli": 12, "divid": [12, 17, 24, 33], "valid": [12, 21, 30, 37], "sinc": [12, 22, 24, 36], "divis": 12, "permit": 12, "essenti": [12, 16], "invalid": 12, "combin": [12, 21, 24, 28, 30, 31], "3d": 12, "infer": [12, 15, 16, 19, 22, 24, 26, 31, 33, 36, 37], "while": [12, 17, 20, 25, 29, 33, 35], "arbitrari": 12, "experiment": [12, 28], "purpos": 12, "restrict": [12, 29], "place": [12, 15, 34], "constraint": 12, "still": [12, 30, 35], "themselv": [12, 33], "code": [12, 19, 20], "show": [12, 15, 16, 19, 22, 25, 26, 31, 35], "how": [12, 15, 17, 19, 28, 30, 31, 32, 34, 35, 36, 38, 41], "configur": [12, 15, 19, 27, 37], "convolut": [12, 19, 22, 23, 24, 28, 35, 38, 41, 42], "conv_1": 12, "refer": [12, 15, 17, 20, 36], "quantizedconv2d": [12, 17, 19], "work": [12, 28, 31], "too": 12, "linear_1": 12, "scheme": [12, 13, 21, 22, 28, 32], "lower": [12, 25, 30, 35], "thei": [12, 35, 39], "lie": 12, "higher": [12, 13, 22, 25, 33, 35], "leverag": 12, "than": [12, 15, 19, 24, 27, 33, 34], "due": [12, 31], "fact": 12, "expans": [12, 28], "factor": [12, 13, 24, 28, 31], "fashion": 12, "groupedblockquantizedequant": 12, "introduc": [12, 17, 30, 34, 36], "decompressed_bw": 12, "expand": 12, "greater": [12, 24, 25], "block_group": 12, "togeth": 12, "except": 12, "make": [12, 17, 29, 30], "easier": 12, "config_util": 12, "set_blockwise_quantization_for_weight": 12, "consist": [12, 25, 36], "either": [12, 20, 42], "A": [12, 20, 24, 25, 28, 30, 32, 33, 36], "union": [12, 15], "arrai": 12, "in_channel": [12, 19], "out_channel": [12, 19], "conv": [12, 27, 34, 37, 38, 41, 42], "input_channel": 12, "conv2": [12, 19], "linear1": 12, "dim": [12, 19], "lambda": 12, "isinst": 12, "util": [12, 19, 22, 30], "certain": [12, 28, 29, 34], "Of": 12, "signific": [12, 35], "second": [12, 17, 34], "subset": [12, 20, 22, 32, 42], "switch": 12, "docstr": 12, "instead": [12, 15, 30, 31, 42], "4d": 12, "2d": [12, 23, 28, 42], "handl": 12, "mention": 12, "assist": 12, "transform": [12, 15, 19, 37], "set_activation_quantizers_to_float": 12, "set_grouped_blockwise_quantization_for_weight": 12, "decompress": 12, "bw": 12, "experi": [12, 28], "similar": [12, 31, 33, 36], "addition": 12, "effect": [12, 17, 19, 22, 30, 32, 36], "larger": [12, 38, 41], "reduc": [12, 15, 17, 28, 30, 31, 33, 35, 37, 42], "write": [12, 15], "snippet": [12, 15], "format": [12, 15, 18, 21, 27], "encoding_vers": [12, 15], "exported_model": [12, 15], "present": [12, 15, 19, 31], "gather": 13, "is_symmetr": [13, 34], "reset_stat": 13, "reset": 13, "intern": [13, 28, 31, 34], "update_stat": 13, "input_tensor": 13, "involv": [13, 19, 30, 35], "track": [13, 32], "calcul": [13, 17, 25, 31, 32, 33, 36], "100": [13, 15, 19], "math": [13, 19], "pow": 13, "0991": 13, "3696": 13, "_minmaxrang": 13, "1721": 13, "2592": 13, "sqnrencodinganalyz": 13, "num_bin": 13, "2048": [13, 15], "asymmetric_delta_candid": 13, "symmetric_delta_candid": 13, "101": 13, "offset_candid": 13, "21": 13, "max_parallel": 13, "gamma": 13, "sqnr": [13, 36], "record": 13, "histogram": [13, 30, 32, 36, 37], "lowest": [13, 23], "delta": [13, 36], "search": [13, 33, 34], "mode": [13, 18, 29, 30, 34], "parallel": 13, "memori": [13, 24, 28, 38, 41, 42], "usag": [13, 16], "faster": [13, 26], "clip": [13, 34, 36], "nois": [13, 19, 30, 31, 32, 33, 34], "percentil": 13, "3612": 13, "8497": 13, "_histogram": 13, "bin_edg": 13, "8907": 13, "3625": 13, "8343": 13, "3061": 13, "7779": 13, "2497": 13, "2784": 13, "8066": 13, "3348": 13, "8630": 13, "3912": 13, "7080": 13, "2438": 13, "percentileencodinganalyz": 13, "largest": 13, "smallest": 13, "1188": 13, "3368": 13, "27": 13, "5710": 13, "0989": 13, "6269": 13, "1548": 13, "6827": 13, "2106": 13, "2614": 13, "7335": 13, "2056": 13, "6776": 13, "1497": 13, "gptvq_weight": 15, "apply_gptvq": 15, "gptvq_param": 15, "param_encoding_path": 15, "module_names_to_exclud": 15, "block_level_module_nam": 15, "file_name_prefix": 15, "config_file_path": 15, "round": [15, 16, 20, 30, 32, 36], "separ": [15, 22, 32, 35, 37], "qat": [15, 19, 20, 22, 26, 30, 35, 36, 37], "dummi": [15, 32], "pars": 15, "graph": [15, 29, 30, 36, 39], "devic": [15, 16, 19, 36], "gptvqparamet": 15, "dataclass": 15, "exclud": 15, "leaf": [15, 37], "prefix": [15, 17], "filenam": 15, "forward_fn": 15, "row_axi": 15, "col_axi": 15, "rows_per_block": 15, "cols_per_block": 15, "256": [15, 19, 32], "vector_dim": 15, "vector_bw": 15, "vector_strid": 15, "index_bw": 15, "num_of_kmeans_iter": 15, "assignment_chunk_s": 15, "carrier": 15, "dataload": [15, 19, 32], "wise": [15, 35], "explicitli": [15, 42], "load": [15, 28], "pretrain": [15, 33, 36], "opt": 15, "125m": 15, "packag": [15, 37], "optforcausallm": 15, "from_pretrain": 15, "facebook": 15, "now": [15, 19, 37], "gptvq_applied_model": 15, "zero": [15, 36, 37], "lm_head": 15, "gptvq_opt": 15, "default_param_bw": [15, 19], "default_output_bw": [15, 19], "load_encod": 15, "allow_overwrit": [15, 18], "through": [15, 17, 19, 31, 32, 36], "here": [15, 19, 30, 33, 34], "vector": 15, "index": [15, 17, 37], "blockwis": 15, "lpbq": 15, "tool": [16, 19, 31, 40, 42], "compress": [16, 23, 26, 37, 38, 40, 41, 42], "deploi": [16, 36], "edg": [16, 26], "fix": [16, 26, 30, 35, 36, 37], "post": [16, 19, 20, 21, 26, 28, 33, 36, 37], "fine": [16, 24, 26, 30, 33, 36], "tune": [16, 24, 26, 30, 33, 36], "techniqu": [16, 19, 21, 23, 24, 26, 30, 32, 33, 35, 36, 37, 38, 41], "minim": [16, 26, 30, 36], "incur": [16, 26, 32], "pictur": 16, "high": [16, 20, 24, 25, 26, 31, 37, 40], "level": [16, 24, 25, 26, 30, 35, 39], "workflow": [16, 19, 24, 26], "low": [16, 20, 22, 28, 30, 31], "recov": [16, 26, 35, 36], "lost": [16, 26, 36], "via": [16, 24, 36], "torchscript": 16, "target": [16, 22, 24, 25, 26, 28, 30, 35, 36, 37], "neural": [16, 19, 21, 24, 26, 28, 30, 33, 35, 36, 41], "sdk": [16, 19, 26], "instal": [16, 26, 37, 39], "sample_input": [16, 19], "sample_output": 16, "out_dir": 16, "quantized_model": 16, "quickstart": 16, "guid": [16, 24, 31, 35, 37], "depth": [16, 24, 35], "adapt": [16, 19, 20, 30, 32, 37], "adaround": [16, 21, 30, 35, 37], "quantizationmixin": [16, 17], "product": [16, 24, 26], "technologi": [16, 26], "subsidiari": [16, 26], "network": [17, 19, 21, 24, 25, 28, 30, 33, 35, 36, 39, 41], "extra": 17, "serv": [17, 39], "drop": [17, 21, 24, 28, 31, 32, 33, 35, 36], "nativ": 17, "quantizedsoftmax": [17, 19], "softmax": [17, 19], "full": 17, "behavior": [17, 19, 26], "control": [17, 36], "descript": [17, 20, 29], "dict": [17, 18], "By": [17, 20, 28, 36], "mean": [17, 19, 32, 34, 36], "respect": [17, 32], "per_channel_quant": [17, 34], "elementwis": [17, 37], "multipli": [17, 24, 28], "qmul": 17, "sens": 17, "share": 17, "indic": [17, 24, 42], "qadd": 17, "quantizedadd": 17, "first": [17, 19, 28, 30, 33, 35], "disabl": [17, 25, 28, 32, 34, 36], "them": [17, 19, 28], "calibration_data_load": 17, "adaptiveavgpool1d": 17, "quantizedadaptiveavgpool1d": 17, "adaptiveavgpool2d": 17, "quantizedadaptiveavgpool2d": 17, "adaptiveavgpool3d": 17, "quantizedadaptiveavgpool3d": 17, "adaptivemaxpool1d": 17, "quantizedadaptivemaxpool1d": 17, "adaptivemaxpool2d": 17, "quantizedadaptivemaxpool2d": 17, "adaptivemaxpool3d": 17, "quantizedadaptivemaxpool3d": 17, "alphadropout": 17, "quantizedalphadropout": 17, "avgpool1d": 17, "quantizedavgpool1d": 17, "avgpool2d": 17, "quantizedavgpool2d": 17, "avgpool3d": 17, "quantizedavgpool3d": 17, "batchnorm1d": 17, "quantizedbatchnorm1d": 17, "batchnorm2d": [17, 19], "quantizedbatchnorm2d": 17, "batchnorm3d": 17, "quantizedbatchnorm3d": 17, "celu": 17, "quantizedcelu": 17, "channelshuffl": 17, "quantizedchannelshuffl": 17, "constantpad1d": 17, "quantizedconstantpad1d": 17, "constantpad2d": 17, "quantizedconstantpad2d": 17, "constantpad3d": 17, "quantizedconstantpad3d": 17, "conv1d": [17, 37], "quantizedconv1d": 17, "conv3d": 17, "quantizedconv3d": 17, "convtranspose1d": [17, 37], "quantizedconvtranspose1d": 17, "convtranspose2d": 17, "quantizedconvtranspose2d": 17, "convtranspose3d": 17, "quantizedconvtranspose3d": 17, "dropout": 17, "quantizeddropout": 17, "dropout2d": 17, "quantizeddropout2d": 17, "dropout3d": 17, "quantizeddropout3d": 17, "elu": 17, "quantizedelu": 17, "featurealphadropout": 17, "quantizedfeaturealphadropout": 17, "flatten": 17, "quantizedflatten": 17, "fold": [17, 20, 21, 22, 30, 31, 32, 37], "quantizedfold": 17, "fractionalmaxpool2d": 17, "quantizedfractionalmaxpool2d": 17, "fractionalmaxpool3d": 17, "quantizedfractionalmaxpool3d": 17, "gelu": 17, "quantizedgelu": 17, "glu": 17, "quantizedglu": 17, "groupnorm": 17, "quantizedgroupnorm": 17, "hardshrink": 17, "quantizedhardshrink": 17, "hardsigmoid": 17, "quantizedhardsigmoid": 17, "hardswish": 17, "quantizedhardswish": 17, "hardtanh": 17, "quantizedhardtanh": 17, "instancenorm1d": 17, "quantizedinstancenorm1d": 17, "instancenorm2d": 17, "quantizedinstancenorm2d": 17, "instancenorm3d": 17, "quantizedinstancenorm3d": 17, "lppool1d": 17, "quantizedlppool1d": 17, "lppool2d": 17, "quantizedlppool2d": 17, "layernorm": 17, "quantizedlayernorm": 17, "leakyrelu": 17, "quantizedleakyrelu": 17, "localresponsenorm": 17, "quantizedlocalresponsenorm": 17, "logsigmoid": 17, "quantizedlogsigmoid": 17, "logsoftmax": 17, "quantizedlogsoftmax": 17, "maxpool1d": 17, "quantizedmaxpool1d": 17, "maxpool2d": 17, "quantizedmaxpool2d": 17, "maxpool3d": 17, "quantizedmaxpool3d": 17, "maxunpool1d": 17, "quantizedmaxunpool1d": 17, "maxunpool2d": 17, "quantizedmaxunpool2d": 17, "maxunpool3d": 17, "quantizedmaxunpool3d": 17, "mish": 17, "quantizedmish": 17, "prelu": 17, "quantizedprelu": 17, "pixelshuffl": 17, "quantizedpixelshuffl": 17, "pixelunshuffl": 17, "quantizedpixelunshuffl": 17, "rrelu": 17, "quantizedrrelu": 17, "relu": [17, 19, 31, 34, 42], "quantizedrelu": [17, 19], "relu6": [17, 31], "quantizedrelu6": 17, "reflectionpad1d": 17, "quantizedreflectionpad1d": 17, "reflectionpad2d": 17, "quantizedreflectionpad2d": 17, "replicationpad1d": 17, "quantizedreplicationpad1d": 17, "replicationpad2d": 17, "quantizedreplicationpad2d": 17, "replicationpad3d": 17, "quantizedreplicationpad3d": 17, "selu": 17, "quantizedselu": 17, "silu": 17, "quantizedsilu": 17, "sigmoid": 17, "quantizedsigmoid": 17, "softmax2d": 17, "quantizedsoftmax2d": 17, "softmin": 17, "quantizedsoftmin": 17, "softplu": 17, "quantizedsoftplu": 17, "softshrink": 17, "quantizedsoftshrink": 17, "softsign": 17, "quantizedsoftsign": 17, "tanh": 17, "quantizedtanh": 17, "tanhshrink": 17, "quantizedtanhshrink": 17, "quantizedthreshold": 17, "unflatten": 17, "quantizedunflatten": 17, "unfold": 17, "quantizedunfold": 17, "upsampl": [17, 29], "quantizedupsampl": 17, "upsamplingbilinear2d": 17, "quantizedupsamplingbilinear2d": 17, "upsamplingnearest2d": 17, "quantizedupsamplingnearest2d": 17, "zeropad2d": 17, "quantizedzeropad2d": 17, "bceloss": 17, "quantizedbceloss": 17, "bcewithlogitsloss": 17, "quantizedbcewithlogitsloss": 17, "bilinear": [17, 29], "quantizedbilinear": 17, "ctcloss": 17, "quantizedctcloss": 17, "cosinesimilar": 17, "quantizedcosinesimilar": 17, "crossentropyloss": [17, 19], "quantizedcrossentropyloss": 17, "hingeembeddingloss": 17, "quantizedhingeembeddingloss": 17, "huberloss": 17, "quantizedhuberloss": 17, "kldivloss": 17, "quantizedkldivloss": 17, "l1loss": 17, "quantizedl1loss": 17, "mseloss": 17, "quantizedmseloss": 17, "multilabelmarginloss": 17, "quantizedmultilabelmarginloss": 17, "multilabelsoftmarginloss": 17, "quantizedmultilabelsoftmarginloss": 17, "multimarginloss": 17, "quantizedmultimarginloss": 17, "nllloss": 17, "quantizednllloss": 17, "nllloss2d": 17, "quantizednllloss2d": 17, "pairwisedist": 17, "quantizedpairwisedist": 17, "poissonnllloss": 17, "quantizedpoissonnllloss": 17, "smoothl1loss": 17, "quantizedsmoothl1loss": 17, "softmarginloss": 17, "quantizedsoftmarginloss": 17, "cosineembeddingloss": 17, "quantizedcosineembeddingloss": 17, "gaussiannllloss": 17, "quantizedgaussiannllloss": 17, "marginrankingloss": 17, "quantizedmarginrankingloss": 17, "tripletmarginloss": 17, "quantizedtripletmarginloss": 17, "tripletmarginwithdistanceloss": 17, "quantizedtripletmarginwithdistanceloss": 17, "embed": [17, 28, 35], "quantizedembed": 17, "embeddingbag": 17, "quantizedembeddingbag": 17, "gru": [17, 37], "quantizedgru": 17, "rnn": [17, 37], "quantizedrnn": 17, "grucel": 17, "quantizedgrucel": 17, "rnncell": 17, "quantizedrnncel": 17, "lstm": [17, 37], "quantizedlstm": 17, "lstmcell": 17, "quantizedlstmcel": 17, "cumsum": 17, "quantizedcumsum": 17, "sin": 17, "quantizedsin": 17, "co": 17, "quantizedco": 17, "rsqrt": 17, "quantizedrsqrt": 17, "reshap": 17, "quantizedreshap": 17, "matmul": [17, 37], "quantizedmatmul": 17, "subtract": 17, "quantizedsubtract": 17, "quantizeddivid": 17, "bmm": 17, "quantizedbmm": 17, "baddbmm": 17, "quantizedbaddbmm": 17, "addmm": 17, "quantizedaddmm": 17, "concat": [17, 37], "quantizedconcat": 17, "allow_overwit": 18, "get_encod": 18, "get_legacy_encod": 18, "register_quantization_paramet": 18, "set_legacy_encod": 18, "tutori": 19, "simpl": 19, "intend": 19, "It": [19, 22, 23, 25, 33, 42], "meant": 19, "demonstr": 19, "state": 19, "art": 19, "eval": [19, 25, 28, 39], "loop": [19, 35], "evalu": [19, 21, 25, 28, 30, 32, 33, 36, 39], "clearli": 19, "what": [19, 39], "happen": 19, "let": 19, "special": 19, "look": [19, 21], "torchvis": 19, "is_avail": 19, "els": [19, 31], "loader": [19, 20], "cifar10_train_data": 19, "dataset": [19, 30, 31, 36], "fashionmnist": 19, "tmp": 19, "cifar10": 19, "totensor": 19, "cifar10_test_data": 19, "train_load": 19, "batch_siz": 19, "shuffl": 19, "test_load": 19, "conv1": 19, "kernel_s": 19, "pad": 19, "stride": 19, "bn_1": 19, "bn_2": 19, "total": [19, 25, 36], "argmax": 19, "sum": 19, "few": [19, 24], "epoch": [19, 26, 28, 33], "establish": 19, "baselin": [19, 25, 28, 33], "send": 19, "loss_fn": 19, "adam": 19, "lr": 19, "1e": [19, 33], "batch_idx": 19, "enumer": 19, "backward": 19, "zero_grad": 19, "fp_accuraci": 19, "91": 19, "70999908447266": 19, "accur": 19, "coupl": 19, "care": [19, 28], "conform": 19, "guidelin": [19, 30, 33], "wherea": [19, 36], "incorrectli": 19, "ignor": 19, "previou": [19, 24, 35], "complet": [19, 22, 35], "redefin": 19, "thankfulli": 19, "model_prepar": 19, "incompat": 19, "fulli": [19, 27, 28, 41], "prepared_model": 19, "prepare_model": 19, "fp_accuracy_prepar": 19, "assert": 19, "2024": 19, "07": 19, "747": 19, "info": [19, 37], "806": 19, "modelprepar": 19, "ad": [19, 27, 34, 37], "node": [19, 33, 36], "module_relu": 19, "module_relu_1": 19, "module_softmax": 19, "graphmodul": 19, "ep": 19, "momentum": 19, "track_running_stat": 19, "12544": 19, "getattr_1": 19, "getitem": 19, "debug": [19, 35], "graph_modul": 19, "print_read": 19, "distinct": 19, "adjac": [19, 34], "whenev": 19, "unnecessari": [19, 42], "good": [19, 20, 28], "idea": 19, "batch_norm_fold": 19, "iter": [19, 20, 31], "fold_all_batch_norm": 19, "input_shap": 19, "ident": 19, "passthrough": 19, "previous": 19, "had": 19, "impact": [19, 25, 35], "readi": [19, 35], "e": [19, 22], "therefor": [19, 24, 31], "theoret": 19, "could": [19, 42], "practic": [19, 28], "usual": [19, 28, 33, 36], "500": [19, 20, 31, 32], "1000": [19, 20, 31, 32], "estim": [19, 30, 31], "idx": 19, "break": 19, "quantized_accuraci": 19, "1500015258789": 19, "noth": 19, "everi": [19, 25, 28, 33, 40], "discuss": [19, 24, 36], "advanc": 19, "re": [19, 30], "One": 19, "op": [19, 34, 36, 37], "repeat": [19, 23], "post_qat_accuraci": 19, "92": 19, "05333709716797": 19, "happi": 19, "export_path": 19, "model_nam": 19, "fashion_mnist_model": 19, "sent": 19, "nearest": 20, "illustr": [20, 23, 25, 30, 36, 38, 39, 41, 42], "figur": [20, 23, 25, 35, 38, 39, 41, 42], "unlabel": [20, 30, 32], "far": 20, "decid": [20, 39], "whether": [20, 25, 33], "closer": 20, "fp32": [20, 26, 31, 32, 33, 35, 36], "width": [20, 35, 36, 38, 41, 42], "freez": 20, "terminologi": 20, "abbrevi": 20, "bc": 20, "bnf": 20, "batch": [20, 30, 31, 32], "norm": [20, 30, 31, 32], "cle": [20, 21, 30, 35, 37], "cross": [20, 21, 29, 30, 32, 35, 40], "hbf": 20, "sequenc": [20, 21, 22, 29, 34], "help": [20, 25, 28, 30, 31, 32, 33, 35, 40], "might": [20, 32, 35], "speed": [20, 28, 31, 33, 37], "Not": [20, 25], "expos": [20, 32], "stabl": 20, "mani": [20, 24, 31], "often": [20, 21, 28, 33], "approxim": [20, 24, 31, 32], "16x": 20, "1024": [20, 29], "10000": 20, "caution": 20, "avoid": [20, 24], "beta": 20, "warm": 20, "period": 20, "kera": [20, 22, 26, 30, 31, 32, 34, 36, 37], "offer": 21, "suit": 21, "best": [21, 24, 28, 30, 36], "toler": [21, 24], "soon": 21, "reach": 21, "stop": 21, "try": [21, 23, 24, 28, 30, 35], "prone": 21, "consum": [21, 28], "prepar": [21, 30, 37], "check": [21, 30, 33, 35], "friendli": [21, 30, 31], "preprat": 21, "proce": 21, "three": [21, 24, 40], "batchnorm": [21, 31, 42], "effort": 21, "manner": 21, "fail": [21, 29, 30], "goal": 21, "small": [22, 26, 30], "preceed": 22, "learn": [22, 28, 30, 33, 36, 37], "pcq": [22, 32], "scenario": [22, 42], "decreas": 22, "main": [22, 34, 37, 40], "issu": [22, 26, 29, 35, 37, 39, 40], "depthwis": [22, 37], "oscil": 22, "quant": 22, "diagram": [22, 26, 36], "cp": [23, 24, 25, 42], "occurr": 23, "explain": [23, 28, 31, 36], "ratio": [23, 24], "magnitud": 23, "upstream": [23, 42], "gain": [23, 24, 28], "connect": [23, 27, 28, 41], "residu": 23, "sometim": [23, 28, 31, 32], "prevent": [23, 29], "regress": 23, "random": [23, 32], "against": 23, "outlin": 24, "svd": [24, 25, 27, 28, 37], "spatial": [24, 25, 27, 28, 37], "prune": [24, 25, 27, 28, 37, 42], "accumul": [24, 28], "mac": [24, 28, 38, 41], "reduct": [24, 30], "uncompress": 24, "algorithm": [24, 25, 28, 35, 42], "overal": [24, 25, 35], "latenc": 24, "bandwidth": 24, "vari": [24, 31, 40], "websit": 24, "At": [24, 39], "half": 24, "unknown": 24, "ssvd": 24, "f0": 24, "65": 24, "75": 24, "yield": [24, 35, 36], "pick": [24, 25], "2b": 24, "rel": [24, 35, 40], "sai": 24, "veri": [24, 28, 32, 40], "larg": [24, 33, 38, 41], "revisit": 24, "close": [24, 36], "resnet": 24, "50": 24, "assess": 25, "sensit": [25, 30, 32, 35, 36, 37], "find": [25, 30, 32, 33, 36], "maintain": [25, 28], "highest": 25, "dictionari": [25, 28, 34], "column": 25, "score": [25, 28, 39], "unmodifi": 25, "compris": 25, "candid": [25, 28], "omit": [25, 34], "monoton": 25, "fit": 25, "procedur": [25, 39], "curv": 25, "account": [25, 30, 33, 35], "constant": [25, 30], "interpol": 25, "solut": [25, 33, 35], "accept": [25, 31, 35], "suggest": [25, 28, 31], "vice": [25, 35, 36], "versa": [25, 35, 36], "fall": [25, 34], "drastic": 25, "softwar": 26, "framework": [26, 30, 34, 36], "meta": [26, 30], "checkpoint": [26, 30], "h5": [26, 30], "hardwar": [26, 30, 31, 36], "ptq": [26, 30, 32, 33], "redund": 26, "smaller": [26, 35, 38, 41], "limit": 27, "dilat": 27, "modules_to_ignor": 27, "depthwiseconv2d": 27, "last": 27, "librari": 28, "littl": 28, "variou": [28, 30, 35, 36, 37, 40], "singular": [28, 38, 41], "decomposit": [28, 38, 41], "guidebook": 28, "summari": 28, "phase": 28, "inspect": 28, "choic": [28, 36], "greedi": [28, 39], "decompos": [28, 38, 41], "fc": [28, 41], "ml": [28, 30, 31], "give": 28, "tri": [28, 30], "caus": [28, 29, 30, 34, 35], "sharp": 28, "rate": [28, 33], "decai": 28, "respons": 28, "Then": 28, "slow": 28, "someth": 28, "itself": [28, 36, 38], "searcher": 28, "Or": 28, "fewer": 28, "wors": 28, "strike": 28, "balanc": 28, "major": 28, "But": 28, "seem": [28, 30], "xiangyu": 28, "zhang": 28, "jianhua": 28, "zou": 28, "kaim": 28, "he": 28, "jian": 28, "sun": 28, "deep": 28, "classif": 28, "detect": 28, "transact": 28, "pattern": 28, "analysi": [28, 35], "intellig": 28, "vol": 28, "pp": 28, "1943": 28, "1955": 28, "oct": 28, "2016": 28, "yihui": 28, "confer": [28, 31], "vision": [28, 31], "iccv": [28, 31], "venic": 28, "2017": 28, "1398": 28, "1406": 28, "jaderberg": 28, "andrea": 28, "vedaldi": 28, "andrew": 28, "zisserman": 28, "british": 28, "jan": 28, "2014": 28, "andrei": 28, "kuzmin": 28, "marku": [28, 31], "nagel": [28, 31], "saurabh": 28, "pitr": 28, "sandeep": 28, "pendyam": 28, "tijmen": [28, 31], "blankevoort": [28, 31], "taxonomi": 28, "cross_layer_equ": 29, "equalize_model": 29, "potenti": [29, 39, 40], "workaround": 29, "applic": 29, "primit": 29, "sure": 29, "rewrit": 29, "slice": 29, "written": [29, 30], "statement": 29, "align_corn": 29, "deconvolut": 29, "dconvolut": 29, "deeplabv3": 29, "address": [29, 35, 39], "releas": 29, "howev": [30, 31], "briefli": 30, "move": 30, "retrain": 30, "becaus": 30, "pipelin": [30, 33, 35, 36], "suffici": [30, 32, 33, 36], "fast": 30, "easi": 30, "insert": [30, 36], "robust": 30, "longer": [30, 33], "_aimet": 30, "trainabl": 30, "bias": 30, "remain": [30, 31, 36], "reflect": [30, 36], "autoqu": [30, 33, 37], "integr": 30, "standalon": 30, "consecut": [30, 31], "bn": [30, 32, 37], "deprec": 30, "quantanalyz": [30, 37], "autom": 30, "understand": [30, 40], "prep": 30, "attempt": [30, 31], "accord": 30, "complainc": 30, "align": 30, "flow": [30, 35, 36], "put": 30, "retri": 30, "continu": [30, 31, 33, 35], "warn": 30, "hand": 30, "ref": 30, "satisfactori": [30, 35], "onto": 30, "item": 30, "pb": 30, "trial": [30, 35], "diagnost": 30, "becom": 31, "design": 31, "paper": 31, "2019": 31, "arxiv": 31, "ab": 31, "1906": 31, "04721": 31, "surround": 31, "highlight": [31, 39, 40], "big": 31, "discrep": 31, "off": 31, "wide": 31, "varianc": 31, "seen": [31, 32], "significantli": 31, "quantizaion": 31, "shown": [31, 32, 35, 42], "distribut": [31, 35, 36], "did": 31, "shift": 31, "empir": 31, "analyt": [31, 39], "extract": 31, "bottleneck": [31, 35], "hybrid": 31, "approach": [31, 36], "mart": 31, "van": 31, "baalen": 31, "seoul": 31, "octob": 31, "analys": 32, "area": 32, "hotspot": 32, "callback": [32, 36], "mse": [32, 36], "label": [32, 33], "metric": [32, 36], "relat": [32, 36], "doc": 32, "normal": 32, "benefici": 32, "situat": 32, "log": 32, "pinpoint": 32, "culprit": 32, "again": [32, 33], "per_layer_quant_en": 32, "per_layer_quant_dis": 32, "axi": 32, "directli": [32, 36], "min_max_rang": 32, "folder": 32, "enhanc": [32, 36], "delet": 32, "displai": [32, 39, 40], "activations_pdf": 32, "weights_pdf": 32, "squar": [32, 36], "monitor": 32, "contribut": [32, 35], "read": 32, "per_layer_mse_loss": 32, "presenc": 33, "hyperparamet": 33, "converg": 33, "hyper": 33, "schedul": 33, "fuse": [34, 36], "placement": 34, "config": [34, 37], "six": 34, "turn": 34, "op_typ": 34, "empti": 34, "is_output_quant": 34, "is_quant": 34, "strict_symmetr": 34, "unsigned_symmetr": 34, "outsid": 34, "strict": [34, 36], "unsign": [34, 36], "rather": 34, "throughout": [34, 40], "gemm": 34, "is_input_quant": 34, "keep": 34, "convent": 34, "supergroup": [34, 37], "made": 34, "op_list": 34, "member": 34, "sequenti": [34, 35], "branch": 34, "those": 34, "entri": 34, "string": 34, "model_input": 34, "model_output": 34, "insight": [35, 39, 40], "why": 35, "underperform": 35, "chart": 35, "confid": 35, "independ": 35, "kept": 35, "toward": 35, "uneven": 35, "global": 35, "restor": 35, "consid": [35, 38, 41], "rest": 35, "inner": 35, "token": 35, "bert": 35, "reveal": 35, "problemat": [35, 40], "problem": 35, "resort": 35, "revert": 35, "power": 35, "mitig": 36, "recogn": 36, "copi": 36, "ingest": 36, "feed": 36, "000": 36, "de": 36, "hook": 36, "intercept": 36, "four": 36, "textrm": 36, "dfrac": 36, "elimin": 36, "extrem": 36, "induc": 36, "signal": 36, "satur": 36, "erro": 36, "static": 36, "alongsid": 36, "just": [36, 42], "settabl": 36, "non": [36, 39], "intermedi": 36, "slim": 37, "backslash": 37, "io": 37, "user_guid": 37, "api_doc": 37, "quantizablemultiheadattent": 37, "kyuykim": 37, "multi": 37, "mangal": 37, "geunle": 37, "bug": 37, "correctli": 37, "klhsieh": 37, "akhobar": 37, "multiheadattent": 37, "ashvkuma": 37, "mha": 37, "pdf": 37, "abil": 37, "fp16": 37, "minor": 37, "stand": 37, "adaptiveround": 37, "recurr": 37, "\ud835\udc5a": [38, 41], "\ud835\udc5b": [38, 41], "\u210e": [38, 41], "\ud835\udc64": [38, 41], "height": [38, 41, 42], "\ud835\udc58": [38, 41], "rank": [38, 41], "degre": [38, 41], "augment": 39, "progress": [39, 40], "computation": [39, 40], "task": [39, 40], "arrang": 39, "websocket": 39, "listen": 39, "5006": 39, "compress_model": 39, "display_eval_scor": 39, "display_comp_ratio_plot": 39, "visualizecompress": 39, "lot": 40, "term": 41, "anoth": [41, 42], "lose": 42, "much": 42, "volum": 42, "hxwx8": 42, "hxwx5": 42, "preced": 42, "propag": 42, "That": 42, "downstream": 42, "denot": 42, "green": 42, "side": 42, "action": 42, "taken": 42, "pink": 42, "color": 42, "orang": 42, "Its": 42}, "objects": {"aimet_torch.gptvq.defs": [[15, 0, 1, "", "GPTVQParameters"]], "aimet_torch.gptvq.gptvq_weight.GPTVQ": [[15, 1, 1, "", "apply_gptvq"]], "aimet_torch.v2.nn": [[17, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.QuantizationMixin": [[17, 2, 1, "", "__quant_init__"], [17, 2, 1, "", "compute_encodings"], [17, 2, 1, "", "forward"], [6, 2, 1, "", "from_module"], [6, 2, 1, "", "get_default_kernel"], [6, 2, 1, "", "get_kernel"], [6, 2, 1, "", "implements"], [17, 3, 1, "", "input_quantizers"], [17, 3, 1, "", "output_quantizers"], [17, 3, 1, "", "param_quantizers"], [6, 2, 1, "", "set_default_kernel"], [6, 2, 1, "", "set_kernel"]], "aimet_torch.v2.quantization": [[7, 4, 0, "-", "affine"], [9, 4, 0, "-", "float"]], "aimet_torch.v2.quantization.affine": [[7, 0, 1, "", "Quantize"], [7, 0, 1, "", "QuantizeDequantize"], [7, 1, 1, "", "dequantize"], [7, 1, 1, "", "quantize"], [7, 1, 1, "", "quantize_dequantize"]], "aimet_torch.v2.quantization.affine.quantizer": [[18, 0, 1, "", "Quantize"], [18, 0, 1, "", "QuantizeDequantize"], [18, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[18, 2, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[18, 2, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[18, 2, 1, "", "allow_overwrite"], [18, 2, 1, "", "compute_encodings"], [18, 2, 1, "", "get_encoding"], [18, 2, 1, "", "get_legacy_encodings"], [18, 2, 1, "", "is_initialized"], [18, 2, 1, "", "register_quantization_parameter"], [18, 2, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization.encoding_analyzer": [[13, 0, 1, "", "EncodingAnalyzer"], [13, 0, 1, "", "MinMaxEncodingAnalyzer"], [13, 0, 1, "", "PercentileEncodingAnalyzer"], [13, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer": [[13, 2, 1, "", "compute_encodings"], [13, 2, 1, "", "reset_stats"], [13, 2, 1, "", "update_stats"]], "aimet_torch.v2.quantization.float": [[9, 0, 1, "", "FloatQuantizeDequantize"], [9, 0, 1, "", "QuantizeDequantize"]], "aimet_torch.v2.quantization.tensor": [[10, 0, 1, "", "DequantizedTensor"], [10, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[10, 2, 1, "", "dequantize"], [10, 2, 1, "", "quantize"], [10, 2, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[10, 2, 1, "", "dequantize"], [10, 2, 1, "", "quantize"], [10, 2, 1, "", "quantized_repr"]], "aimet_torch.v2.quantsim.config_utils": [[12, 1, 1, "", "set_activation_quantizers_to_float"], [12, 1, 1, "", "set_blockwise_quantization_for_weights"], [12, 1, 1, "", "set_grouped_blockwise_quantization_for_weights"]], "aimet_torch.v2.visualization_tools": [[11, 1, 1, "", "visualize_stats"]]}, "objtypes": {"0": "py:class", "1": "py:function", "2": "py:method", "3": "py:attribute", "4": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "function", "Python function"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "module", "Python module"]}, "titleterms": {"aimet": [2, 3, 4, 16, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42], "instal": [2, 3, 4], "quick": 2, "releas": [2, 3, 4, 26, 37], "packag": [2, 3, 4], "system": 2, "requir": [2, 32], "advanc": 2, "instruct": 2, "docker": 3, "set": 3, "variant": [3, 13], "us": [3, 20, 28, 30], "prebuilt": 3, "imag": 3, "build": 3, "local": 3, "start": [3, 16, 39], "contain": 3, "from": [3, 4], "pypi": [3, 4], "environ": [3, 4], "setup": [3, 4], "prerequisit": [4, 19], "gpu": 4, "pytorch": [4, 16, 19, 29, 30, 40], "2": [4, 19, 37], "1": [4, 19, 37], "13": [4, 37], "onnx": 4, "tensorflow": [4, 40], "common": 4, "debian": 4, "torch": 4, "replac": 4, "pillow": 4, "simd": 4, "onnxruntim": 4, "post": [4, 14, 30, 31], "step": 4, "quantizationmixin": 6, "quantiz": [7, 9, 10, 12, 14, 17, 18, 19, 30, 31, 33, 34, 35, 36, 40], "affin": 7, "class": [7, 9, 10, 17], "function": 7, "floatquantizedequant": 8, "quantizedequant": 8, "float": [9, 19], "tensor": 10, "visual": [11, 39, 40], "tool": [11, 30], "blockwis": 12, "low": 12, "power": 12, "lpbq": 12, "top": [12, 15, 17, 18], "level": [12, 15, 17, 18], "api": [12, 15, 16, 17, 18, 20, 21, 22, 31, 32, 36], "export": [12, 19], "encod": [13, 17, 36], "analyz": 13, "train": [14, 19, 30, 31, 33], "gptvq": 15, "paramet": [15, 20, 36], "code": 15, "exampl": [15, 16], "ai": [16, 26], "model": [16, 19, 26, 28, 29, 30], "effici": [16, 26], "toolkit": [16, 26], "document": 16, "get": 16, "featur": [16, 24, 26, 30], "descript": [16, 32], "modul": 17, "configur": [17, 34, 36], "comput": 17, "quickstart": 19, "guid": [19, 26], "overal": 19, "flow": [19, 31], "prepar": 19, "point": 19, "batchnorm": 19, "fold": 19, "fine": [19, 28], "tune": [19, 28], "awar": [19, 33], "quantsim": [19, 36], "adaround": 20, "case": [20, 28, 30], "hyper": 20, "guidelin": [20, 29], "autoqu": 21, "overview": [21, 22, 25, 26, 28, 31, 32, 33, 34, 36, 39, 40, 42], "workflow": [21, 22, 30, 33, 36], "batch": 22, "norm": 22, "re": 22, "estim": 22, "bn": 22, "channel": 23, "prune": 23, "procedur": 23, "select": [23, 25, 28], "winnow": [23, 42], "weight": [23, 41], "reconstruct": 23, "compress": [24, 25, 28, 39], "guidebook": 24, "greedi": 25, "ratio": [25, 28, 39], "how": [25, 42], "work": [25, 42], "per": [25, 28], "layer": [25, 28, 31], "explor": 25, "user": [26, 31], "more": 26, "inform": 26, "toc": 26, "tree": 26, "known": 27, "issu": 27, "option": 28, "techniqu": [28, 31], "rank": 28, "round": 28, "note": [28, 37], "faq": [28, 31], "refer": [28, 31], "debug": 30, "analysi": [30, 32], "cross": 31, "equal": 31, "quantanalyz": 32, "detail": 32, "qat": 33, "mode": 33, "recommend": 33, "simul": [34, 36], "file": 34, "structur": 34, "modifi": 34, "section": 34, "diagnost": 35, "nois": 36, "determin": 36, "scheme": 36, "oper": 36, "22": 37, "0": 37, "21": 37, "20": 37, "19": 37, "py37": 37, "18": 37, "17": 37, "16": 37, "14": 37, "spatial": 38, "svd": [38, 41], "design": 39, "bokeh": 39, "server": 39, "session": 39}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"AIMET Installation": [[2, "aimet-installation"]], "Quick Install": [[2, "quick-install"]], "Release Packages": [[2, "release-packages"]], "System Requirements": [[2, "system-requirements"]], "Advanced Installation Instructions": [[2, "advanced-installation-instructions"]], "AIMET Installation in Docker": [[3, "aimet-installation-in-docker"]], "Set variant": [[3, "set-variant"]], "Use prebuilt docker image": [[3, "use-prebuilt-docker-image"]], "Build docker image locally": [[3, "build-docker-image-locally"]], "Start docker container": [[3, "start-docker-container"]], "Install AIMET packages": [[3, "install-aimet-packages"], [4, "install-aimet-packages"]], "From PyPI": [[3, "from-pypi"], [4, "from-pypi"]], "From Release Package": [[3, "from-release-package"], [4, "from-release-package"]], "Environment setup": [[3, "environment-setup"], [4, "environment-setup"]], "AIMET Installation and Setup": [[4, "aimet-installation-and-setup"]], "Install prerequisite packages": [[4, "install-prerequisite-packages"]], "Install GPU packages": [[4, "install-gpu-packages"]], "Install GPU packages for PyTorch 2.1 or PyTorch 1.13 or ONNX or TensorFlow": [[4, "install-gpu-packages-for-pytorch-2-1-or-pytorch-1-13-or-onnx-or-tensorflow"]], "Install common debian packages": [[4, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[4, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[4, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[4, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[4, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[4, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[4, "post-installation-steps"]], "QuantizationMixin": [[6, "quantizationmixin"]], "quantization.affine": [[7, "module-aimet_torch.v2.quantization.affine"]], "Classes": [[7, "classes"], [9, "classes"], [10, "classes"]], "Functions": [[7, "functions"]], "FloatQuantizeDequantize": [[8, "floatquantizedequantize"]], "QuantizeDequantize": [[8, "quantizedequantize"]], "quantization.float": [[9, "module-aimet_torch.v2.quantization.float"]], "quantization.tensor": [[10, "quantization-tensor"]], "Visualization Tools": [[11, "visualization-tools"]], "Blockwise Quantization": [[12, "blockwise-quantization"]], "Low Power Blockwise Quantization (LPBQ)": [[12, "low-power-blockwise-quantization-lpbq"]], "Top Level API": [[12, "top-level-api"], [15, "top-level-api"]], "Export": [[12, "export"]], "Encoding Analyzers": [[13, "encoding-analyzers"]], "Variants": [[13, "variants"]], "Post-Training Quantization": [[14, "post-training-quantization"], [30, "post-training-quantization"]], "GPTVQ": [[15, "gptvq"]], "GPTVQ Parameters": [[15, "gptvq-parameters"]], "Code Example": [[15, "code-example"]], "AIMET: AI Model Efficiency Toolkit Documentation": [[16, "aimet-ai-model-efficiency-toolkit-documentation"]], "Getting Started": [[16, "getting-started"]], "Examples": [[16, null]], "Feature Descriptions": [[16, null]], "AIMET PyTorch API": [[16, null]], "Quantized Modules": [[17, "quantized-modules"]], "Top-level API": [[17, "top-level-api"], [18, "top-level-api"]], "Configuration": [[17, "configuration"]], "Computing Encodings": [[17, "computing-encodings"]], "Quantized Module Classes": [[17, "quantized-module-classes"]], "Quantizers": [[18, "quantizers"]], "Quickstart Guide": [[19, "quickstart-guide"]], "Overall flow": [[19, "overall-flow"]], "PyTorch prerequisites": [[19, "pytorch-prerequisites"]], "Prepare the floating point model for quantization": [[19, "prepare-the-floating-point-model-for-quantization"]], "1) Model preparation": [[19, "model-preparation"]], "2) BatchNorm fold": [[19, "batchnorm-fold"]], "Quantize the model": [[19, "quantize-the-model"]], "Fine-tune the model with quantization aware training": [[19, "fine-tune-the-model-with-quantization-aware-training"]], "Export the quantsim model": [[19, "export-the-quantsim-model"]], "AIMET AdaRound": [[20, "aimet-adaround"]], "AdaRound use cases": [[20, "adaround-use-cases"]], "AdaRound hyper parameters guidelines": [[20, "adaround-hyper-parameters-guidelines"]], "AdaRound API": [[20, "adaround-api"]], "AIMET AutoQuant": [[21, "aimet-autoquant"]], "Overview": [[21, "overview"], [22, "overview"], [25, "overview"], [26, "overview"], [28, "overview"], [31, "overview"], [32, "overview"], [33, "overview"], [34, "overview"], [36, "overview"], [39, "overview"], [40, "overview"], [42, "overview"]], "Workflow": [[21, "workflow"], [22, "workflow"]], "AutoQuant API": [[21, "autoquant-api"]], "AIMET Batch Norm Re-estimation": [[22, "aimet-batch-norm-re-estimation"]], "BN Re-estimation API": [[22, "bn-re-estimation-api"]], "AIMET channel pruning": [[23, "aimet-channel-pruning"]], "Procedure": [[23, "procedure"]], "Channel selection": [[23, "channel-selection"]], "Winnowing": [[23, "winnowing"]], "Weight reconstruction": [[23, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[24, "aimet-compression-features-guidebook"]], "AIMET greedy compression ratio selection": [[25, "aimet-greedy-compression-ratio-selection"]], "How it works": [[25, "how-it-works"]], "Per-layer exploration": [[25, "per-layer-exploration"]], "Compression ratio selection": [[25, "compression-ratio-selection"], [28, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[26, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[26, "features"]], "More Information": [[26, "more-information"]], "Release Information": [[26, "release-information"]], "toc tree": [[26, "toc-tree"]], "AIMET Known Issues": [[27, "aimet-known-issues"]], "AIMET model compression": [[28, "aimet-model-compression"]], "Use Case": [[28, "use-case"]], "Model compression": [[28, "model-compression"]], "Optional techniques": [[28, "optional-techniques"]], "Rank Rounding": [[28, "rank-rounding"]], "Per-layer fine-tuning": [[28, "per-layer-fine-tuning"]], "NOTE": [[28, null]], "FAQs": [[28, "faqs"], [31, "faqs"]], "References": [[28, "references"], [31, "references"]], "Model Guidelines for PyTorch": [[29, "model-guidelines-for-pytorch"]], "AIMET model quantization": [[30, "aimet-model-quantization"]], "Use cases": [[30, "use-cases"]], "AIMET quantization features": [[30, "aimet-quantization-features"]], "Debugging and Analysis Tools": [[30, "debugging-and-analysis-tools"]], "AIMET quantization workflow": [[30, "aimet-quantization-workflow"]], "PyTorch": [[30, "pytorch"], [40, "pytorch"]], "Debugging": [[30, "debugging"]], "AIMET post-training quantization techniques": [[31, "aimet-post-training-quantization-techniques"]], "User Flow": [[31, "user-flow"]], "Cross-Layer Equalization API": [[31, "cross-layer-equalization-api"]], "AIMET QuantAnalyzer": [[32, "aimet-quantanalyzer"]], "Requirements": [[32, "requirements"]], "Detailed analysis descriptions": [[32, "detailed-analysis-descriptions"]], "QuantAnalyzer API": [[32, "quantanalyzer-api"]], "AIMET quantization aware training": [[33, "aimet-quantization-aware-training"]], "QAT workflow": [[33, "qat-workflow"]], "QAT modes": [[33, "qat-modes"]], "Recommendations for quantization-aware training": [[33, "recommendations-for-quantization-aware-training"]], "Quantization simulation configuration": [[34, "quantization-simulation-configuration"]], "Configuration file structure": [[34, "configuration-file-structure"]], "Modifying configuration file sections": [[34, "modifying-configuration-file-sections"]], "AIMET quantization diagnostics": [[35, "aimet-quantization-diagnostics"]], "AIMET quantization simulation": [[36, "aimet-quantization-simulation"]], "QuantSim workflow": [[36, "quantsim-workflow"]], "Simulating quantization noise": [[36, "simulating-quantization-noise"]], "Determining quantization parameters (encodings)": [[36, "determining-quantization-parameters-encodings"]], "Quantization schemes": [[36, "quantization-schemes"]], "Configuring quantization simulation operations": [[36, "configuring-quantization-simulation-operations"]], "Quantization Simulation APIs": [[36, "quantization-simulation-apis"]], "AIMET Release Notes": [[37, "aimet-release-notes"]], "1.22.2": [[37, "id1"]], "1.22.1": [[37, "id2"]], "1.22.0": [[37, "id3"]], "1.21.0": [[37, "id4"]], "1.20.0": [[37, "id5"]], "1.19.1.py37": [[37, "py37"]], "1.19.1": [[37, "id6"]], "1.18.0.py37": [[37, "id7"]], "1.18.0": [[37, "id8"]], "1.17.0.py37": [[37, "id9"]], "1.17.0": [[37, "id10"]], "1.16.2.py37": [[37, "id11"]], "1.16.2": [[37, "id12"]], "1.16.1.py37": [[37, "id13"]], "1.16.1": [[37, "id14"]], "1.16.0": [[37, "id15"]], "1.14.0": [[37, "id16"]], "1.13.0": [[37, "id17"]], "AIMET spatial SVD": [[38, "aimet-spatial-svd"]], "AIMET visualization": [[39, "aimet-visualization"]], "Design": [[39, "design"]], "Compression": [[39, "compression"]], "Starting a Bokeh server session": [[39, "starting-a-bokeh-server-session"]], "Visualizing compression ratios": [[39, "visualizing-compression-ratios"]], "AIMET visualization for quantization": [[40, "aimet-visualization-for-quantization"]], "Quantization": [[40, "quantization"]], "TensorFlow": [[40, "tensorflow"]], "AIMET weight SVD": [[41, "aimet-weight-svd"]], "AIMET winnowing": [[42, "aimet-winnowing"]], "Winnowing overview": [[42, "winnowing-overview"]], "How winnowing works": [[42, "how-winnowing-works"]]}, "indexentries": {"quantizationmixin (class in aimet_torch.v2.nn)": [[6, "aimet_torch.v2.nn.QuantizationMixin"], [17, "aimet_torch.v2.nn.QuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.quantizationmixin method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.__quant_init__"], [17, "aimet_torch.v2.nn.QuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"], [17, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "forward() (aimet_torch.v2.nn.quantizationmixin method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.forward"], [17, "aimet_torch.v2.nn.QuantizationMixin.forward"]], "from_module() (aimet_torch.v2.nn.quantizationmixin class method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.from_module"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "input_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[6, "aimet_torch.v2.nn.QuantizationMixin.input_quantizers"], [17, "aimet_torch.v2.nn.QuantizationMixin.input_quantizers"]], "output_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[6, "aimet_torch.v2.nn.QuantizationMixin.output_quantizers"], [17, "aimet_torch.v2.nn.QuantizationMixin.output_quantizers"]], "param_quantizers (aimet_torch.v2.nn.quantizationmixin attribute)": [[6, "aimet_torch.v2.nn.QuantizationMixin.param_quantizers"], [17, "aimet_torch.v2.nn.QuantizationMixin.param_quantizers"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[6, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "quantize (class in aimet_torch.v2.quantization.affine)": [[7, "aimet_torch.v2.quantization.affine.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine)": [[7, "aimet_torch.v2.quantization.affine.QuantizeDequantize"]], "aimet_torch.v2.quantization.affine": [[7, "module-aimet_torch.v2.quantization.affine"]], "dequantize() (in module aimet_torch.v2.quantization.affine)": [[7, "aimet_torch.v2.quantization.affine.dequantize"]], "module": [[7, "module-aimet_torch.v2.quantization.affine"], [9, "module-aimet_torch.v2.quantization.float"]], "quantize() (in module aimet_torch.v2.quantization.affine)": [[7, "aimet_torch.v2.quantization.affine.quantize"]], "quantize_dequantize() (in module aimet_torch.v2.quantization.affine)": [[7, "aimet_torch.v2.quantization.affine.quantize_dequantize"]], "floatquantizedequantize (class in aimet_torch.v2.quantization.float)": [[8, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"], [9, "aimet_torch.v2.quantization.float.FloatQuantizeDequantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.float)": [[8, "aimet_torch.v2.quantization.float.QuantizeDequantize"], [9, "aimet_torch.v2.quantization.float.QuantizeDequantize"]], "aimet_torch.v2.quantization.float": [[9, "module-aimet_torch.v2.quantization.float"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[10, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[10, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[10, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[10, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[10, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[10, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[10, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[10, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "visualize_stats() (in module aimet_torch.v2.visualization_tools)": [[11, "aimet_torch.v2.visualization_tools.visualize_stats"]], "set_activation_quantizers_to_float() (in module aimet_torch.v2.quantsim.config_utils)": [[12, "aimet_torch.v2.quantsim.config_utils.set_activation_quantizers_to_float"]], "set_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[12, "aimet_torch.v2.quantsim.config_utils.set_blockwise_quantization_for_weights"]], "set_grouped_blockwise_quantization_for_weights() (in module aimet_torch.v2.quantsim.config_utils)": [[12, "aimet_torch.v2.quantsim.config_utils.set_grouped_blockwise_quantization_for_weights"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "compute_encodings() (aimet_torch.v2.quantization.encoding_analyzer.encodinganalyzer method)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer.compute_encodings"]], "reset_stats() (aimet_torch.v2.quantization.encoding_analyzer.encodinganalyzer method)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer.reset_stats"]], "update_stats() (aimet_torch.v2.quantization.encoding_analyzer.encodinganalyzer method)": [[13, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer.update_stats"]], "gptvqparameters (class in aimet_torch.gptvq.defs)": [[15, "aimet_torch.gptvq.defs.GPTVQParameters"]], "apply_gptvq() (in module aimet_torch.gptvq.gptvq_weight.gptvq)": [[15, "aimet_torch.gptvq.gptvq_weight.GPTVQ.apply_gptvq"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[18, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "allow_overwrite() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.allow_overwrite"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[18, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})