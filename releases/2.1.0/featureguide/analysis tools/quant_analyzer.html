<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Layer output generation" href="layer_output_generation.html" /><link rel="prev" title="Interactive visualization" href="interactive_visualization.html" />

    <!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Quantization analyzer - AIMET</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../_static/aimet-furo.css?v=22b0637d" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">AIMET</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">AIMET</span>
  
</a><div class="doc-versions" data-toggle="doc-versions" role="note" aria-label="versions">

  <span class="doc-current-version" data-toggle="doc-current-version">
    Version: 2.1.0
  </span>
  <br>
  <span class="doc-other-versions" data-toggle="doc-other-versions">
        <a href="https://quic.github.io/aimet-pages/releases/latest/versions.html">Other versions</a>
  </span>

</div><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/quick-start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../userguide/index.html">User Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of User Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/quantization_tools.html">AIMET features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/quantization_workflow.html">Quantization workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/debugging_guidelines.html">Debugging guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../userguide/on_target_inference.html">On-target inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../quantsim/index.html">Quantization Simulation Guide</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Quantization Simulation Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../quantsim/calibration.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../quantsim/qat.html">QAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../quantsim/blockwise.html">Blockwise quantization</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Feature Guide</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Feature Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../adaround.html">Adaptive rounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../seq_mse.html">Sequential MSE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bnf.html">Batch norm folding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cle.html">Cross-layer equalization</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../mixed%20precision/index.html">Mixed precision</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Mixed precision</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../mixed%20precision/mmp.html">Manual mixed precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mixed%20precision/amp.html">Automatic mixed precision</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../autoquant.html">Automatic quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bn.html">Batch norm re-estimation</a></li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Analysis tools</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Analysis tools</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="interactive_visualization.html">Interactive visualization</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Quantization analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="layer_output_generation.html">Layer output generation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../compression/index.html">Compression</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Compression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../compression/feature_guidebook.html">Compression guidebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/greedy_compression_ratio_selection.html">Greedy compression ratio selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/visualization_compression.html">Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../compression/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../compression/channel_pruning.html">Channel pruning</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Channel pruning</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../compression/winnowing.html">Winnowing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../quantized%20LoRa/index.html">Quantized LoRa</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Quantized LoRa</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../quantized%20LoRa/qw_lora.html">QW-LoRa</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quantized%20LoRa/qwa_lora.html">QWA-LoRa</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../apiref/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../apiref/torch/index.html">aimet_torch</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of aimet_torch</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/migration_guide.html">Migrate to aimet_torch 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/quantsim.html">aimet_torch.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/adaround.html">aimet_torch.adaround</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../apiref/torch/nn.html">aimet_torch.nn</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of aimet_torch.nn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizationMixin.html">QuantizationMixin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveAvgPool1d.html">QuantizedAdaptiveAvgPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveAvgPool2d.html">QuantizedAdaptiveAvgPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveAvgPool3d.html">QuantizedAdaptiveAvgPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveMaxPool1d.html">QuantizedAdaptiveMaxPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveMaxPool2d.html">QuantizedAdaptiveMaxPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAdaptiveMaxPool3d.html">QuantizedAdaptiveMaxPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAlphaDropout.html">QuantizedAlphaDropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAvgPool1d.html">QuantizedAvgPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAvgPool2d.html">QuantizedAvgPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedAvgPool3d.html">QuantizedAvgPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedBCELoss.html">QuantizedBCELoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedBCEWithLogitsLoss.html">QuantizedBCEWithLogitsLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedBatchNorm1d.html">QuantizedBatchNorm1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedBatchNorm2d.html">QuantizedBatchNorm2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedBatchNorm3d.html">QuantizedBatchNorm3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedBilinear.html">QuantizedBilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCELU.html">QuantizedCELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCTCLoss.html">QuantizedCTCLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedChannelShuffle.html">QuantizedChannelShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCircularPad1d.html">QuantizedCircularPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCircularPad2d.html">QuantizedCircularPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCircularPad3d.html">QuantizedCircularPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConstantPad1d.html">QuantizedConstantPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConstantPad2d.html">QuantizedConstantPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConstantPad3d.html">QuantizedConstantPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConv1d.html">QuantizedConv1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConv2d.html">QuantizedConv2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConv3d.html">QuantizedConv3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConvTranspose1d.html">QuantizedConvTranspose1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConvTranspose2d.html">QuantizedConvTranspose2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedConvTranspose3d.html">QuantizedConvTranspose3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCosineEmbeddingLoss.html">QuantizedCosineEmbeddingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCosineSimilarity.html">QuantizedCosineSimilarity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedCrossEntropyLoss.html">QuantizedCrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedDropout.html">QuantizedDropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedDropout1d.html">QuantizedDropout1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedDropout2d.html">QuantizedDropout2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedDropout3d.html">QuantizedDropout3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedELU.html">QuantizedELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedEmbedding.html">QuantizedEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedEmbeddingBag.html">QuantizedEmbeddingBag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedFeatureAlphaDropout.html">QuantizedFeatureAlphaDropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedFlatten.html">QuantizedFlatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedFold.html">QuantizedFold</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedFractionalMaxPool2d.html">QuantizedFractionalMaxPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedFractionalMaxPool3d.html">QuantizedFractionalMaxPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedGELU.html">QuantizedGELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedGLU.html">QuantizedGLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedGRU.html">QuantizedGRU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedGRUCell.html">QuantizedGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedGaussianNLLLoss.html">QuantizedGaussianNLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedGroupNorm.html">QuantizedGroupNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedHardshrink.html">QuantizedHardshrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedHardsigmoid.html">QuantizedHardsigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedHardswish.html">QuantizedHardswish</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedHardtanh.html">QuantizedHardtanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedHingeEmbeddingLoss.html">QuantizedHingeEmbeddingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedHuberLoss.html">QuantizedHuberLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedInstanceNorm1d.html">QuantizedInstanceNorm1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedInstanceNorm2d.html">QuantizedInstanceNorm2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedInstanceNorm3d.html">QuantizedInstanceNorm3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedKLDivLoss.html">QuantizedKLDivLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedL1Loss.html">QuantizedL1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLPPool1d.html">QuantizedLPPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLPPool2d.html">QuantizedLPPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLSTM.html">QuantizedLSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLSTMCell.html">QuantizedLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLayerNorm.html">QuantizedLayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLeakyReLU.html">QuantizedLeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLinear.html">QuantizedLinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLocalResponseNorm.html">QuantizedLocalResponseNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLogSigmoid.html">QuantizedLogSigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedLogSoftmax.html">QuantizedLogSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMSELoss.html">QuantizedMSELoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMarginRankingLoss.html">QuantizedMarginRankingLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMaxPool1d.html">QuantizedMaxPool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMaxPool2d.html">QuantizedMaxPool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMaxPool3d.html">QuantizedMaxPool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMaxUnpool1d.html">QuantizedMaxUnpool1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMaxUnpool2d.html">QuantizedMaxUnpool2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMaxUnpool3d.html">QuantizedMaxUnpool3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMish.html">QuantizedMish</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMultiLabelMarginLoss.html">QuantizedMultiLabelMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMultiLabelSoftMarginLoss.html">QuantizedMultiLabelSoftMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedMultiMarginLoss.html">QuantizedMultiMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedNLLLoss.html">QuantizedNLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedNLLLoss2d.html">QuantizedNLLLoss2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedPReLU.html">QuantizedPReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedPairwiseDistance.html">QuantizedPairwiseDistance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedPixelShuffle.html">QuantizedPixelShuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedPixelUnshuffle.html">QuantizedPixelUnshuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedPoissonNLLLoss.html">QuantizedPoissonNLLLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedRNN.html">QuantizedRNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedRNNCell.html">QuantizedRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedRReLU.html">QuantizedRReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReLU.html">QuantizedReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReLU6.html">QuantizedReLU6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReflectionPad1d.html">QuantizedReflectionPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReflectionPad2d.html">QuantizedReflectionPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReflectionPad3d.html">QuantizedReflectionPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReplicationPad1d.html">QuantizedReplicationPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReplicationPad2d.html">QuantizedReplicationPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedReplicationPad3d.html">QuantizedReplicationPad3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSELU.html">QuantizedSELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSiLU.html">QuantizedSiLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSigmoid.html">QuantizedSigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSmoothL1Loss.html">QuantizedSmoothL1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftMarginLoss.html">QuantizedSoftMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftmax.html">QuantizedSoftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftmax2d.html">QuantizedSoftmax2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftmin.html">QuantizedSoftmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftplus.html">QuantizedSoftplus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftshrink.html">QuantizedSoftshrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedSoftsign.html">QuantizedSoftsign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedTanh.html">QuantizedTanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedTanhshrink.html">QuantizedTanhshrink</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedThreshold.html">QuantizedThreshold</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedTripletMarginLoss.html">QuantizedTripletMarginLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedTripletMarginWithDistanceLoss.html">QuantizedTripletMarginWithDistanceLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedUnflatten.html">QuantizedUnflatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedUnfold.html">QuantizedUnfold</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedUpsample.html">QuantizedUpsample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedUpsamplingBilinear2d.html">QuantizedUpsamplingBilinear2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedUpsamplingNearest2d.html">QuantizedUpsamplingNearest2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedZeroPad1d.html">QuantizedZeroPad1d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedZeroPad2d.html">QuantizedZeroPad2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.nn.QuantizedZeroPad3d.html">QuantizedZeroPad3d</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../apiref/torch/quantization.html">aimet_torch.quantization</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of aimet_torch.quantization</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.QuantizedTensorBase.html">QuantizedTensorBase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.QuantizedTensor.html">QuantizedTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.DequantizedTensor.html">DequantizedTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.affine.Quantize.html">Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.affine.QuantizeDequantize.html">QuantizeDequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.float.FloatQuantizeDequantize.html">FloatQuantizeDequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.affine.quantize.html">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.affine.quantize_dequantize.html">quantize_dequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../apiref/torch/generated/aimet_torch.quantization.affine.dequantize.html">dequantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/seq_mse.html">aimet_torch.seq_mse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/lpbq.html">aimet_torch.quantsim.config_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/bnf.html">aimet_torch.batch_norm_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/cle.html">aimet_torch.cross_layer_equalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/model_preparer.html">aimet_torch.model_preparer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/model_validator.html">aimet_torch.model_validator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/mp.html">aimet_torch.mixed_precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/quant_analyzer.html">aimet_torch.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/autoquant.html">aimet_torch.autoquant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/bn.html">aimet_torch.bn_reestimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/interactive_visualization.html">aimet_torch.visualization_tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/layer_output_generation.html">aimet_torch.layer_output_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/peft_lora.html">aimet_torch.peft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/compress.html">aimet_torch.compress</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/v1/quantsim.html">aimet_torch.v1.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/v1/adaround.html">aimet_torch.v1.adaround</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/v1/seq_mse.html">aimet_torch.v1.seq_mse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/v1/quant_analyzer.html">aimet_torch.v1.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/v1/autoquant.html">aimet_torch.v1.autoquant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/torch/v1/amp.html">aimet_torch.v1.amp</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../apiref/tensorflow/index.html">aimet_tensorflow</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of aimet_tensorflow</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html">aimet_tensorflow.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/adaround.html">aimet_tensorflow.adaround</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/bnf.html">aimet_tensorflow.batch_norm_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/cle.html">aimet_tensorflow.cross_layer_equalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/amp.html">aimet_tensorflow.mixed_precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/quant_analyzer.html">aimet_tensorflow.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/autoquant.html">aimet_tensorflow.auto_quant_v2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/layer_output_generation.html">aimet_tensorflow.layer_output_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/model_preparer.html">aimet_tensorflow.model_preparer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/tensorflow/compress.html">aimet_tensorflow.compress</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../apiref/onnx/index.html">aimet_onnx</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of aimet_onnx</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/quantsim.html">aimet_onnx.quantsim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/adaround.html">aimet_onnx.adaround</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/seq_mse.html">aimet_onnx.seq_mse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/lpbq.html">aimet_onnx.quantsim.set_grouped_blockwise_quantization_for_weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/bnf.html">aimet_onnx.batch_norm_fold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/cle.html">aimet_onnx.cross_layer_equalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/amp.html">aimet_onnx.mixed_precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/quant_analyzer.html">aimet_onnx.quant_analyzer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/autoquant.html">aimet_onnx.auto_quant_v2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apiref/onnx/layer_output_generation.html">aimet_onnx.layer_output_utils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../release_notes.html">Release Notes</a></li>
</ul>

</div></div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="quantization-analyzer">
<span id="featureguide-quant-analyzer"></span><h1>Quantization analyzer<a class="headerlink" href="#quantization-analyzer" title="Link to this heading">¶</a></h1>
<section id="context">
<h2>Context<a class="headerlink" href="#context" title="Link to this heading">¶</a></h2>
<p>The Quantization analyzer (QuantAnalyzer) automatically performs several analyses to identify sensitive areas in your model. To use QuantAnalyzer, you pass in callbacks to perform forward passes and evaluations, and optionally a dataloader for mean square error (MSE) loss analysis.</p>
<p>For each analysis, QuantAnalyzer generates JSON and/or HTML files containing the data, and plots for
visualization.</p>
</section>
<section id="analysis-descriptions">
<h2>Analysis descriptions<a class="headerlink" href="#analysis-descriptions" title="Link to this heading">¶</a></h2>
<p>QuantAnalyzer performs the following analyses.</p>
<section id="sensitivity-to-weight-and-activation-quantization">
<h3>1: Sensitivity to weight and activation quantization<a class="headerlink" href="#sensitivity-to-weight-and-activation-quantization" title="Link to this heading">¶</a></h3>
<p>QuantAnalyzer compares the accuracies of the original FP32 model, an activation-only quantized model,
and a weight-only quantized model. This helps determine which AIMET quantization technique(s) will
be more effective in the model.</p>
<p>For example, in situations where the model is more sensitive to activation quantization, post-training
quantization (PTQ) techniques like Adaptive Rounding (Adaround) or Cross-layer Equalization (CLE) might
not be very helpful.</p>
<p>Quantized accuracy metrics for your model are printed as part of AIMET logging.</p>
</section>
<section id="per-layer-quantizer-enablement">
<h3>2: Per-layer quantizer enablement<a class="headerlink" href="#per-layer-quantizer-enablement" title="Link to this heading">¶</a></h3>
<p>Sometimes the accuracy drop incurred from quantization can be attributed to only a subset of layers
within the model. QuantAnalyzer finds such layers by enabling and disabling individual quantizers to
observe how the quantized model accuracy metric changes.</p>
<p>Two types of quantizer enablement analyses are performed:</p>
<p>1. <strong>One at a time</strong>: Disable all quantizers across the model and, for each layer, enable only that layer’s output quantizer. Perform evaluation with the provided callback, giving accuracy values for each
layer in the model when it’s the sole quantized layer. This and pinpoints hotspots by exposing the effects of individual
layer quantization.</p>
<p>2. <strong>Elimination</strong>: Enable all quantizers across the model and, for each layer, disable only that layer’s output quantizer. Perform evaluation with the provided callback, giving accuracy values for each
layer in the model when only that layer’s quantizer is disabled.</p>
<p>AIMET outputs the results of these analyses as <cite>per_layer_quant_enabled.html</cite> and
<cite>per_layer_quant_disabled.html</cite> respectively. These files contain plots of the quantized
model accuracy metrics for each layer.</p>
<p>JSON files <cite>per_layer_quant_enabled.json</cite> and <cite>per_layer_quant_disabled.json</cite> are also produced,
containing the data shown in the .html plots.</p>
</section>
<section id="per-layer-encodings-min-max-range">
<h3>3: Per-layer encodings min-max range<a class="headerlink" href="#per-layer-encodings-min-max-range" title="Link to this heading">¶</a></h3>
<p>As part of quantization, encoding parameters for each quantizer must be calculated.
These parameters are used to map floating point values to
quantized integer values and include scale, offset, min, and max.</p>
<p>QuantAnalyzer tracks the min and max encoding parameters computed by each quantizer in the model
as a result of forward passes through the model with representative data (from which the scale and
offset values can be directly obtained).</p>
<p>AIMET outputs HTML plots and JSON files to the min_max_ranges folder for each activation quantizer
and each parameter quantizer, containing the encoding min/max values for each.</p>
<p>If per-channel quantization (PCQ) is enabled, encoding min and max values are shown for all the channels
of each weight parameter.</p>
</section>
<section id="per-layer-statistics-histogram">
<h3>4: Per-layer statistics histogram<a class="headerlink" href="#per-layer-statistics-histogram" title="Link to this heading">¶</a></h3>
<p>Under the TF-enhanced quantization scheme, min/max encoding values for each quantizer are obtained
by deleting outliers from the histogram of tensor values seen at the quantizer.</p>
<p>When this quantization scheme is selected, QuantAnalyzer outputs the histogram of tensor values seen at each quantizer in the model.</p>
<p>These plots are available as part of the <cite>activations_pdf</cite> and <cite>weights_pdf</cite> folders. There is a
separate .html plot for each quantizer.</p>
</section>
<section id="per-layer-mean-square-error-loss">
<h3>5: Per-layer mean-square-error loss<a class="headerlink" href="#per-layer-mean-square-error-loss" title="Link to this heading">¶</a></h3>
<p>QuantAnalyzer can monitor each layer’s output in the original FP32 model as well as the corresponding
layer output in the quantized model and calculate the MSE loss between the two.</p>
<p>This helps identify which layers may contribute more to quantization noise.</p>
<p>To enable this optional analysis, you pass in a dataloader that QuantAnalyzer reads from.
Approximately <strong>256 samples</strong> are sufficient for the analysis.</p>
<p>A <cite>per_layer_mse_loss.html</cite> file is generated containing a plot that maps layer quantizers on the
x-axis to MSE loss on the y-axis. A corresponding <cite>per_layer_mse_loss.json</cite> file is generated
containing data used in the .html file.</p>
</section>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">¶</a></h2>
<p>To call the QuantAnalyzer API, provide the following:</p>
<ul class="simple">
<li><p>An FP32 pre-trained model for analysis</p></li>
<li><p>A dummy input for the model. This can contain random values but it must match the shape of the model’s expected input</p></li>
<li><p>A user-defined function for passing 500-1000 representative data samples through the model for quantization calibration</p></li>
<li><p>A user-defined function for passing labeled data through the model for evaluation, returning an accuracy metric</p></li>
<li><p>(Optional, for running MSE loss analysis) A dataloader providing unlabeled data to be passed through the model</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Typically on quantized runtimes, batch normalization (BN) layers are folded where possible. So
that you don’t have to call a separate API to do so, QuantAnalyzer automatically performs Batch
Norm Folding before running its analysis.</p>
</div>
</section>
<section id="workflow">
<h2>Workflow<a class="headerlink" href="#workflow" title="Link to this heading">¶</a></h2>
<section id="step-1-importing-libraries">
<h3>Step 1 Importing libraries<a class="headerlink" href="#step-1-importing-libraries" title="Link to this heading">¶</a></h3>
<p>Import required libraries.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-0">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantScheme</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.model_preparer</span><span class="w"> </span><span class="kn">import</span> <span class="n">prepare_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_torch.v1.quant_analyzer</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantAnalyzer</span><span class="p">,</span> <span class="n">CallbackFunc</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-1">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantScheme</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">CallbackFunc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.model_preparer</span><span class="w"> </span><span class="kn">import</span> <span class="n">prepare_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_tensorflow.keras.quant_analyzer</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantAnalyzer</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-2" name="sd-tab-set-0" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-2">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnxruntime</span><span class="w"> </span><span class="kn">import</span> <span class="n">InferenceSession</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onnxsim</span><span class="w"> </span><span class="kn">import</span> <span class="n">simplify</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.defs</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantScheme</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_common.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">CallbackFunc</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">aimet_onnx.quant_analyzer</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantAnalyzer</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-2-preparing-the-calibration-callback">
<h3>Step 2 Preparing the calibration callback<a class="headerlink" href="#step-2-preparing-the-calibration-callback" title="Link to this heading">¶</a></h3>
<p>Prepare the callback for calibration.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-3" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-3">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward_pass_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NOTE: This is intended to be the user-defined model calibration function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s calibration function does not</span>
<span class="sd">    match this signature, please create a simple wrapper around this callback function.</span>

<span class="sd">    A callback function for model calibration that simply runs forward passes on the model to</span>
<span class="sd">    compute encoding (delta/offset). This callback function should use representative data and should</span>
<span class="sd">    be subset of entire train/validation dataset (~1000 images/samples).</span>

<span class="sd">    :param model: PyTorch model.</span>
<span class="sd">    :param _: Argument(s) of this callback function. Up to the user to determine the type of this parameter.</span>
<span class="sd">    E.g. could be simply an integer representing the number of data samples to use. Or could be a tuple of</span>
<span class="sd">    parameters or an object representing something more complex.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># User action required</span>
    <span class="c1"># User should create data loader/iterable using representative dataset and simply run</span>
    <span class="c1"># forward passes on the model.</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-4" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-4">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>2.1 Prepare toy dataset to run example code</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">NUM_SAMPLES</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">INPUT_SHAPES</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">NUM_SAMPLES</span><span class="p">,</span> <span class="o">*</span><span class="n">INPUT_SHAPES</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">NUM_SAMPLES</span><span class="p">)]</span>

<span class="n">image_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="n">label_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">((</span><span class="n">image_dataset</span><span class="p">,</span> <span class="n">label_dataset</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">unlabeled_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>2.2 Prepare forward pass callback</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward_pass_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NOTE: This is intended to be the user-defined model calibration function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s calibration function does not</span>
<span class="sd">    match this signature, please create a simple wrapper around this callback function.</span>

<span class="sd">    A callback function for model calibration that simply runs forward passes on the model to</span>
<span class="sd">    compute encoding (delta/offset). This callback function should use representative data and should</span>
<span class="sd">    be subset of entire train/validation dataset (~1000 images/samples).</span>

<span class="sd">    :param model: tf.keras.Model object.</span>
<span class="sd">    :param _: Argument(s) of this callback function. Up to the user to determine the type of this parameter.</span>
<span class="sd">    E.g. could be simply an integer representing the number of data samples to use. Or could be a tuple of</span>
<span class="sd">    parameters or an object representing something more complex.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># User action required</span>
    <span class="c1"># User should create data loader/iterable using representative dataset and simply run</span>
    <span class="c1"># forward passes on the model.</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">unlabeled_dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-5" name="sd-tab-set-1" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-5">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward_pass_callback</span><span class="p">(</span><span class="n">session</span><span class="p">:</span> <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NOTE: This is intended to be the user-defined model calibration function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s calibration function does not</span>
<span class="sd">    match this signature, please create a simple wrapper around this callback function.</span>

<span class="sd">    A callback function for model calibration that simply runs forward passes on the model to</span>
<span class="sd">    compute encoding (delta/offset). This callback function should use representative data and should</span>
<span class="sd">    be subset of entire train/validation dataset (~1000 images/samples).</span>

<span class="sd">    :param session: OnnxRuntime Inference Session.</span>
<span class="sd">    :param _: Argument(s) of this callback function. Up to the user to determine the type of this parameter.</span>
<span class="sd">    E.g. could be simply an integer representing the number of data samples to use. Or could be a tuple of</span>
<span class="sd">    parameters or an object representing something more complex.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># User action required</span>
    <span class="c1"># User should create data loader/iterable using representative dataset and simply run</span>
    <span class="c1"># forward passes on the model.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-3-preparing-the-evaluation-callback">
<h3>Step 3 Preparing the evaluation callback<a class="headerlink" href="#step-3-preparing-the-evaluation-callback" title="Link to this heading">¶</a></h3>
<p>Prepare the callback for quantized model evaluation.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-6" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-6">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">eval_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NOTE: This is intended to be the user-defined model evaluation function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s calibration function does not</span>
<span class="sd">    match this signature, please create a simple wrapper around this callback function.</span>

<span class="sd">    A callback function for model evaluation that determines model performance. This callback function is</span>
<span class="sd">    expected to return scalar value representing the model performance evaluated against entire</span>
<span class="sd">    test/evaluation dataset.</span>

<span class="sd">    :param model: PyTorch model.</span>
<span class="sd">    :param _: Argument(s) of this callback function. Up to the user to determine the type of this parameter.</span>
<span class="sd">    E.g. could be simply an integer representing the number of data samples to use. Or could be a tuple of</span>
<span class="sd">    parameters or an object representing something more complex.</span>
<span class="sd">    :return: Scalar value representing the model performance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># User action required</span>
    <span class="c1"># User should create data loader/iterable using entire test/evaluation dataset, perform forward passes on</span>
    <span class="c1"># the model and return single scalar value representing the model performance.</span>
    <span class="k">return</span> <span class="mf">.8</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-7" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-7">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">eval_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NOTE: This is intended to be the user-defined model evaluation function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s calibration function does not</span>
<span class="sd">    match this signature, please create a simple wrapper around this callback function.</span>

<span class="sd">    A callback function for model evaluation that determines model performance. This callback function is</span>
<span class="sd">    expected to return scalar value representing the model performance evaluated against entire</span>
<span class="sd">    test/evaluation dataset.</span>

<span class="sd">    :param model: tf.keras.Model object.</span>
<span class="sd">    :param _: Argument(s) of this callback function. Up to the user to determine the type of this parameter.</span>
<span class="sd">    E.g. could be simply an integer representing the number of data samples to use. Or could be a tuple of</span>
<span class="sd">    parameters or an object representing something more complex.</span>
<span class="sd">    :return: Scalar value representing the model performance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># User action required</span>
    <span class="c1"># User should create data loader/iterable using entire test/evaluation dataset, perform forward passes on</span>
    <span class="c1"># the model and return single scalar value representing the model performance.</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                  <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">(),</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">CategoricalAccuracy</span><span class="p">())</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">acc</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-8" name="sd-tab-set-2" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-8">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">eval_callback</span><span class="p">(</span><span class="n">session</span><span class="p">:</span> <span class="n">InferenceSession</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NOTE: This is intended to be the user-defined model evaluation function.</span>
<span class="sd">    AIMET requires the above signature. So if the user&#39;s calibration function does not</span>
<span class="sd">    match this signature, please create a simple wrapper around this callback function.</span>

<span class="sd">    A callback function for model evaluation that determines model performance. This callback function is</span>
<span class="sd">    expected to return scalar value representing the model performance evaluated against entire</span>
<span class="sd">    test/evaluation dataset.</span>

<span class="sd">    :param session: OnnxRuntime Inference Session.</span>
<span class="sd">    :param _: Argument(s) of this callback function. Up to the user to determine the type of this parameter.</span>
<span class="sd">    E.g. could be simply an integer representing the number of data samples to use. Or could be a tuple of</span>
<span class="sd">    parameters or an object representing something more complex.</span>
<span class="sd">    :return: Scalar value representing the model performance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># User action required</span>
    <span class="c1"># User should create data loader/iterable using entire test/evaluation dataset, perform forward passes on</span>
    <span class="c1"># the model and return single scalar value representing the model performance.</span>
    <span class="k">return</span> <span class="mf">.8</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-4-preparing-model">
<h3>Step 4 Preparing model<a class="headerlink" href="#step-4-preparing-model" title="Link to this heading">¶</a></h3>
<p>Prepare the model, callback functions, and dataloader as required per platform.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-9" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-9">
PyTorch</label><div class="sd-tab-content docutils">
<p><strong>Prepare model, callback functions, and data</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
    <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># User action required</span>
    <span class="c1"># User should pass actual argument(s) of the callback functions.</span>
    <span class="n">forward_pass_callback_fn</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">eval_callback_fn</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_callback</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-10" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-10">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>Prepare the model</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">ResNet50</span><span class="p">()</span>
    <span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-11" name="sd-tab-set-3" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-11">
ONNX</label><div class="sd-tab-content docutils">
<p><strong>Prepare model, callback functions and dataloader</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
    <span class="c1"># Simplify the model</span>
    <span class="n">onnx_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">simplify</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
    <span class="n">dummy_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">dummy_input</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;input&#39;</span><span class="p">:</span> <span class="n">dummy_data</span><span class="p">}</span>

    <span class="c1"># User action required</span>
    <span class="c1"># User should pass actual argument(s) of the callback functions.</span>
    <span class="n">forward_pass_callback_fn</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">eval_callback_fn</span> <span class="o">=</span> <span class="n">CallbackFunc</span><span class="p">(</span><span class="n">eval_callback</span><span class="p">,</span> <span class="n">func_callback_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># User action required</span>
    <span class="c1"># User should use unlabeled dataloader, so if the dataloader yields labels as well user should discard them.</span>
    <span class="n">unlabeled_data_loader</span> <span class="o">=</span> <span class="n">_get_unlabled_data_loader</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-5-creating-the-quantanalyzer">
<h3>Step 5 Creating the QuantAnalyzer<a class="headerlink" href="#step-5-creating-the-quantanalyzer" title="Link to this heading">¶</a></h3>
<p>Create the QuantAnalyzer.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-12" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-12">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">quant_analyzer</span> <span class="o">=</span> <span class="n">QuantAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">prepared_model</span><span class="p">,</span>
                                   <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">,</span>
                                   <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_callback_fn</span><span class="p">,</span>
                                   <span class="n">eval_callback</span><span class="o">=</span><span class="n">eval_callback_fn</span><span class="p">)</span>

    <span class="c1"># User action required</span>
    <span class="c1"># User should use unlabeled dataloader, so if the dataloader yields labels as well user should use discard them.</span>
    <span class="n">unlabeled_data_loader</span> <span class="o">=</span> <span class="n">_get_unlabled_data_loader</span><span class="p">()</span>
    <span class="c1"># Approximately 256 images/samples are recommended for MSE loss analysis. So, if the dataloader</span>
    <span class="c1"># has batch_size of 64, then 4 number of batches leads to 256 images/samples.</span>
    <span class="n">quant_analyzer</span><span class="o">.</span><span class="n">enable_per_layer_mse_loss</span><span class="p">(</span><span class="n">unlabeled_dataset_iterable</span><span class="o">=</span><span class="n">unlabeled_data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-13" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-13">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">quant_analyzer</span> <span class="o">=</span> <span class="n">QuantAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">prepared_model</span><span class="p">,</span>
                                   <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_callback_fn</span><span class="p">,</span>
                                   <span class="n">eval_callback</span><span class="o">=</span><span class="n">eval_callback_fn</span><span class="p">)</span>

    <span class="c1"># Approximately 256 images/samples are recommended for MSE loss analysis. So, if the dataset</span>
    <span class="c1"># has batch_size of 64, then 4 number of batches leads to 256 images/samples.</span>
    <span class="n">quant_analyzer</span><span class="o">.</span><span class="n">enable_per_layer_mse_loss</span><span class="p">(</span><span class="n">unlabeled_dataset</span><span class="o">=</span><span class="n">unlabeled_dataset</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-14" name="sd-tab-set-4" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-14">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">quant_analyzer</span> <span class="o">=</span> <span class="n">QuantAnalyzer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">onnx_model</span><span class="p">,</span>
                                   <span class="n">dummy_input</span><span class="o">=</span><span class="n">dummy_input</span><span class="p">,</span>
                                   <span class="n">forward_pass_callback</span><span class="o">=</span><span class="n">forward_pass_callback_fn</span><span class="p">,</span>
                                   <span class="n">eval_callback</span><span class="o">=</span><span class="n">eval_callback_fn</span><span class="p">)</span>
    <span class="c1"># Approximately 256 images/samples are recommended for MSE loss analysis. So, if the dataloader</span>
    <span class="c1"># has batch_size of 64, then 4 number of batches leads to 256 images/samples.</span>
    <span class="n">quant_analyzer</span><span class="o">.</span><span class="n">enable_per_layer_mse_loss</span><span class="p">(</span><span class="n">unlabeled_dataset_iterable</span><span class="o">=</span><span class="n">unlabeled_data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-6-running-the-analysis">
<h3>Step 6 Running the analysis<a class="headerlink" href="#step-6-running-the-analysis" title="Link to this heading">¶</a></h3>
<p>Finally, run the QuantAnalyzer to analyze the data.</p>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-15" name="sd-tab-set-5" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-15">
PyTorch</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">quant_analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf_enhanced</span><span class="p">,</span>
                           <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                           <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                           <span class="n">config_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">results_dir</span><span class="o">=</span><span class="s2">&quot;./quant_analyzer_results/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-16" name="sd-tab-set-5" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-16">
TensorFlow</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">quant_analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf_enhanced</span><span class="p">,</span>
                           <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                           <span class="n">default_output_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                           <span class="n">config_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">results_dir</span><span class="o">=</span><span class="s2">&quot;./quant_analyzer_results/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<input id="sd-tab-item-17" name="sd-tab-set-5" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-17">
ONNX</label><div class="sd-tab-content docutils">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">quant_analyzer</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf_enhanced</span><span class="p">,</span>
                           <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                           <span class="n">default_activation_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                           <span class="n">config_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">results_dir</span><span class="o">=</span><span class="s2">&quot;./quant_analyzer_results/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="api">
<h2>API<a class="headerlink" href="#api" title="Link to this heading">¶</a></h2>
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-18" name="sd-tab-set-6" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="torch" for="sd-tab-item-18">
PyTorch</label><div class="sd-tab-content docutils">
<p><strong>Top level APIs</strong></p>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_common.utils.CallbackFunc">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_common.utils.</span></span><span class="sig-name descname"><span class="pre">CallbackFunc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func_callback_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_common/defs.html#CallbackFunc"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_common.utils.CallbackFunc" title="Link to this definition">¶</a></dt>
<dd><p>Class encapsulating call back function and it’s arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></span>) – Callable Function</p></li>
<li><p><strong>func_callback_args</strong> – Arguments passed to the callable function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_torch.quant_analyzer.</span></span><span class="sig-name descname"><span class="pre">QuantAnalyzer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modules_to_ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_torch/v2/quant_analyzer.html#QuantAnalyzer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer" title="Link to this definition">¶</a></dt>
<dd><p>QuantAnalyzer tool provides</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>model sensitivity to weight and activation quantization</p></li>
<li><p>per layer sensitivity analysis</p></li>
<li><p>per layer encoding (min - max range)</p></li>
<li><p>per PDF analysis and</p></li>
<li><p>per layer MSE analysis</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></span>) – FP32 model to analyze for quantization.</p></li>
<li><p><strong>dummy_input</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>]</span>) – Dummy input to model.</p></li>
<li><p><strong>forward_pass_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../mixed%20precision/amp.html#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – A callback function for model calibration that simply runs
forward passes on the model to compute encoding (delta/offset). This
callback function should use representative data and should be subset of
entire train/validation dataset (~1000 images/samples).</p></li>
<li><p><strong>eval_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../mixed%20precision/amp.html#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – A callback function for model evaluation that determines model
performance. This callback function is expected to return scalar value
representing the model performance evaluated against entire test/evaluation dataset.</p></li>
<li><p><strong>modules_to_ignore</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>]]</span>) – Excludes certain modules from being analyzed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.analyze">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">analyze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">QuantScheme.post_training_tf_enhanced</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_param_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_output_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./tmp/'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.analyze" title="Link to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Analyze model for quantization and point out sensitive parts/hotspots of the model by performing</dt><dd><ol class="arabic simple">
<li><p>model sensitivity to quantization,</p></li>
<li><p>perform per layer sensitivity analysis by enabling and disabling quant wrappers,</p></li>
<li><p>export per layer encodings min - max ranges,</p></li>
<li><p>export per layer statistics histogram (PDF) when quant scheme is TF-Enhanced,</p></li>
<li><p>per layer MSE analysis</p></li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_scheme</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/torch/v1/quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a></span>) – Quantization scheme. Supported values are
QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced.</p></li>
<li><p><strong>default_param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer parameters.</p></li>
<li><p><strong>default_output_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer inputs and outputs.</p></li>
<li><p><strong>config_file</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Path to configuration file for model quantizers.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p><strong>Alternatively, you can run specific utility</strong></p>
<p>You can avoid running all the utilities that QuantAnalyzer offers and only run those of your interest.
For this you need to have the <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code> object, Then you call the desired
QuantAnalyzer utility of your interest and pass the same object to it.</p>
<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">check_model_sensitivity_to_quantization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization" title="Link to this definition">¶</a></dt>
<dd><p>Perform the sensitivity analysis to weight and activation quantization
individually.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantizationSimModelInterface</span></code></span>) – Quantsim model.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>FP32 eval score, weight-quantized eval score, act-quantized eval score.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">perform_per_layer_analysis_by_enabling_quant_wrappers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers" title="Link to this definition">¶</a></dt>
<dd><p>NOTE: Option 1</p>
<ol class="arabic simple">
<li><p>All quant wrappers’ parameters and activations quantizers are disabled.</p></li>
<li><dl class="simple">
<dt>Based on occurrence for every quant wrappers</dt><dd><ul class="simple">
<li><p>Each quant wrapper’s parameters and activations quantizers are enabled as per JSON config file and set to bit-width specified.</p></li>
<li><p>Measure and record eval score on subset of dataset.</p></li>
<li><p>Disable enabled quantizers in step 1.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Returns dictionary containing quant wrapper name and corresponding eval score.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantizationSimModelInterface</span></code></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise eval score dictionary. dict[layer_name] = eval_score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">perform_per_layer_analysis_by_disabling_quant_wrappers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers" title="Link to this definition">¶</a></dt>
<dd><p>NOTE: Option 2</p>
<ol class="arabic simple">
<li><p>All quant wrappers’ parameters and activations quantizers are enabled as per JSON config file and set to bit-width specified.</p></li>
<li><dl class="simple">
<dt>Based on occurrence for every quant wrappers</dt><dd><ul class="simple">
<li><p>Each quant wrapper’s parameters and activations quantizers are disabled.</p></li>
<li><p>Measure and record eval score on subset of dataset.</p></li>
<li><p>Enable disabled quantizers in step 1.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Returns dictionary containing quant wrapper name and corresponding eval score.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantizationSimModelInterface</span></code></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise eval score dictionary. dict[layer_name] = eval_score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">export_per_layer_encoding_min_max_range</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range" title="Link to this definition">¶</a></dt>
<dd><p>Export encoding min and max range for all weights and activations. results_dir should have
html files in following format.</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><p>-activations.html
-weights.html</p>
</dd>
</dl>
<p>If per channel quantization(PCQ) is enabled then,</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><p>-activations.html
-{wrapped_module_name}_{param_name}.html</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantizationSimModelInterface</span></code></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise min-max range for weights and activations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">export_per_layer_stats_histogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram" title="Link to this definition">¶</a></dt>
<dd><p>NOTE: Not to invoke when quantization scheme is not TF-Enhanced.</p>
<p>Export histogram that represents a PDF of collected statistics by a quantizer for every
quant wrapper. After invoking this API, results_dir should have html files in following
format for every quantizers of quant wrappers.</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">-a<var>ctivations_pdf</var></span></kbd></dt>
<dd><p>name_{input/output}_{index}.html</p>
</dd>
<dt><kbd><span class="option">-w<var>eights_pdf</var></span></kbd></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">-n<var>ame</var></span></kbd></dt>
<dd><p>param_name_{channel_index}.html</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantizationSimModelInterface</span></code></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">export_per_layer_mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss" title="Link to this definition">¶</a></dt>
<dd><p>NOTE: Need to pass same model input data through both fp32 and quantsim model to
tap output activations of each layer.</p>
<p>Export MSE loss between fp32 and quantized output activations for each layer.
:type sim: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">_QuantizationSimModelInterface</span></code></span>
:param sim: Quantsim model.
:type results_dir: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>
:param results_dir: Directory to save the results.
:return layer wise MSE loss. dict[layer_name] = MSE loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span></p>
</dd>
</dl>
</dd></dl>

</div>
<input id="sd-tab-item-19" name="sd-tab-set-6" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="tf" for="sd-tab-item-19">
TensorFlow</label><div class="sd-tab-content docutils">
<p><strong>Top level APIs</strong></p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_tensorflow.keras.quant_analyzer.</span></span><span class="sig-name descname"><span class="pre">QuantAnalyzer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>QuantAnalyzer tool provides</p>
<ol class="arabic simple">
<li><p>model sensitivity to weight and activation quantization</p></li>
<li><p>per layer sensitivity analysis</p></li>
<li><p>per layer encoding (min - max range)</p></li>
<li><p>per PDF analysis and</p></li>
<li><p>per layer MSE analysis</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></span>) – FP32 model to analyze for quantization.</p></li>
<li><p><strong>forward_pass_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../mixed%20precision/amp.html#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – A callback function for model calibration that simply runs
forward passes on the model to compute encoding (delta/offset). This
callback function should use representative data and should be subset of
entire train/validation dataset (~1000 images/samples).</p></li>
<li><p><strong>eval_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../mixed%20precision/amp.html#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – A callback function for model evaluation that determines model
performance. This callback function is expected to return scalar value
representing the model performance evaluated against entire test/evaluation dataset.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">analyze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">QuantScheme.post_training_tf_enhanced</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rounding_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_param_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_output_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./tmp/'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.analyze"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Analyze model for quantization and point out sensitive parts/hotspots of the model by performing</dt><dd><ol class="arabic simple">
<li><p>model sensitivity to quantization,</p></li>
<li><p>perform per layer sensitivity analysis by enabling and disabling quant wrappers,</p></li>
<li><p>export per layer encodings min - max ranges,</p></li>
<li><p>export per layer statistics histogram (PDF) when quant scheme is TF-Enhanced,</p></li>
<li><p>per layer MSE analysis</p></li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_scheme</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/torch/v1/quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a></span>) – Quantization scheme. Supported values are
QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced.</p></li>
<li><p><strong>rounding_mode</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – The round scheme to used. One of: ‘nearest’ or ‘stochastic’, defaults to ‘nearest’</p></li>
<li><p><strong>default_param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer parameters.</p></li>
<li><p><strong>default_output_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer inputs and outputs.</p></li>
<li><p><strong>config_file</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Path to configuration file for model quantizers.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">check_model_sensitivity_to_quantization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_param_bw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_output_bw</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.check_model_sensitivity_to_quantization"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Perform the sensitivity analysis to weight and activation quantization
individually.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>default_param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer parameters.</p></li>
<li><p><strong>default_output_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer inputs and outputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>FP32 eval score, weight-quantized eval score, act-quantized eval score.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">enable_per_layer_mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unlabeled_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_batches</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.enable_per_layer_mse_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Enable per layer MSE loss analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>unlabeled_dataset</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">DatasetV2</span></code></span>) – tf.data.Dataset provided as input to the model
and used to calculate mse loss</p></li>
<li><p><strong>num_batches</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Maximum number of batches to be used for MSE loss calculation</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">export_per_layer_encoding_min_max_range</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.export_per_layer_encoding_min_max_range"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Export encoding min and max range for all weights and activations. results_dir should have
html files in following format.</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><p>-activations.html
-weights.html</p>
</dd>
</dl>
<p>If per channel quantization(PCQ) is enabled then,</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><p>-activations.html
-{wrapped_module_name}_{param_name}.html</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise min-max range for weights and activations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">export_per_layer_mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.export_per_layer_mse_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>NOTE: Need to pass same model input data through both fp32 and quantsim model to
tap output activations of each layer.</p>
<p>Export MSE loss between fp32 and quantized output activations for each layer.
:type sim: <span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>
:param sim: Quantsim model.
:type results_dir: <span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>
:param results_dir: Directory to save the results.
:return layer wise MSE loss. dict[layer_name] = MSE loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">export_per_layer_stats_histogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.export_per_layer_stats_histogram"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>NOTE: Not to invoke when quantization scheme is not TF-Enhanced.</p>
<p>Export histogram that represents a PDF of collected statistics by a quantizer for every
quant wrapper. After invoking this API, results_dir should have html files in following
format for every quantizers of quant wrappers.</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">-a<var>ctivations_pdf</var></span></kbd></dt>
<dd><p>name_{input/output}_{index}.html</p>
</dd>
<dt><kbd><span class="option">-w<var>eights_pdf</var></span></kbd></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">-n<var>ame</var></span></kbd></dt>
<dd><p>param_name_{channel_index}.html</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">perform_per_layer_analysis_by_disabling_quant_wrappers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>NOTE: Option 2</p>
<ol class="arabic simple">
<li><p>All quant wrappers’ parameters and activations quantizers are enabled as per JSON config file and set to bit-width specified.</p></li>
<li><dl class="simple">
<dt>For every quant wrappers, based on occurrence:</dt><dd><ol class="lowerroman simple">
<li><p>Each quant wrapper’s parameters and activations quantizers are disabled.</p></li>
<li><p>Measure and record eval score on subset of dataset.</p></li>
<li><p>Enable disabled quantizers in step i.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Returns dictionary containing quant wrapper name and corresponding eval score.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise eval score dictionary. dict[layer_name] = eval_score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">perform_per_layer_analysis_by_enabling_quant_wrappers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_tensorflow/keras/quant_analyzer.html#QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>NOTE: Option 1</p>
<ol class="arabic simple">
<li><p>All quant wrappers’ parameters and activations quantizers are disabled.</p></li>
<li><dl class="simple">
<dt>For every quant wrappers, based on occurrence:</dt><dd><ol class="lowerroman simple">
<li><p>Each quant wrapper’s parameters and activations quantizers are enabled as per JSON config file and set to bit-width specified.</p></li>
<li><p>Measure and record eval score on subset of dataset.</p></li>
<li><p>Disable enabled quantizers in step i.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Returns dictionary containing quant wrapper name and corresponding eval score.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/tensorflow/quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel" title="aimet_tensorflow.keras.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer-wise eval score dictionary. dict[layer_name] = eval_score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<input id="sd-tab-item-20" name="sd-tab-set-6" type="radio">
<label class="sd-tab-label" data-sync-group="platform" data-sync-id="onnx" for="sd-tab-item-20">
ONNX</label><div class="sd-tab-content docutils">
<p><strong>Top level APIs</strong></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is recommended to use onnx-simplifier before applying quant-analyzer.</p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="aimet_onnx.quant_analyzer.QuantAnalyzer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">aimet_onnx.quant_analyzer.</span></span><span class="sig-name descname"><span class="pre">QuantAnalyzer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_pass_callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_callback</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.quant_analyzer.QuantAnalyzer" title="Link to this definition">¶</a></dt>
<dd><p>QuantAnalyzer provides following utilities:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>model sensitivity to weight and activation quantization</p></li>
<li><p>per layer sensitivity analysis</p></li>
<li><p>per layer encoding (min - max range)</p></li>
<li><p>per layer quantizer historgram analysis and</p></li>
<li><p>per layer MSE analysis</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">ModelProto</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ONNXModel</span></code>]</span>) – FP32 model to analyze for quantization.</p></li>
<li><p><strong>dummy_input</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>]</span>) – Dummy input to model.</p></li>
<li><p><strong>forward_pass_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../mixed%20precision/amp.html#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – A callback function for model calibration that simply runs
forward passes on the model to compute encoding (delta/offset). This
callback function should use representative data and should be subset of
entire train/validation dataset (~1000 images/samples).</p></li>
<li><p><strong>eval_callback</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../mixed%20precision/amp.html#id1" title="aimet_common.defs.CallbackFunc"><code class="xref py py-class docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></span>) – A callback function for model evaluation that determines model
performance. This callback function is expected to return scalar value
representing the model performance evaluated against entire test/evaluation dataset.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">enable_per_layer_mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unlabeled_dataset_iterable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_batches</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.enable_per_layer_mse_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss" title="Link to this definition">¶</a></dt>
<dd><p>Enables per layer MSE loss analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>unlabeled_dataset_iterable</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Iterable</span></code></span>) – A collection (i.e. iterable with <cite>__len__</cite>)
that iterates over an unlabeled dataset. The values yielded by this iterable are expected
to be able to be passed directly to the model.</p></li>
<li><p><strong>num_batches</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Number of batches. Approximately 256 samples/images are recommended,
so if batch size of data loader is 64, then 4 number of batches leads to 256 samples/images.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="aimet_onnx.quant_analyzer.QuantAnalyzer.analyze">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">analyze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">QuantScheme.post_training_tf_enhanced</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_param_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_activation_bw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./tmp/'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.analyze"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#aimet_onnx.quant_analyzer.QuantAnalyzer.analyze" title="Link to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Analyzes model for quantization and point out sensitive parts/hotspots of the model by performing</dt><dd><ol class="arabic simple">
<li><p>model sensitivity to quantization,</p></li>
<li><p>perform per layer sensitivity analysis by enabling and disabling quantizers,</p></li>
<li><p>export per layer encodings min - max ranges,</p></li>
<li><p>export per layer quantizer stats histogram,</p></li>
<li><p>per layer MSE analysis</p></li>
</ol>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_scheme</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/torch/v1/quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a></span>) – Quantization scheme. Supported values are
QuantScheme.post_training_tf or QuantScheme.post_training_tf_enhanced.</p></li>
<li><p><strong>default_param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer parameters.</p></li>
<li><p><strong>default_activation_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer inputs and outputs.</p></li>
<li><p><strong>config_file</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]</span>) – Path to configuration file for model quantizers.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p><strong>Alternatively, you can run specific utility</strong></p>
<p>You can avoid running all the utilities that QuantAnalyzer offers and only run those of your interest.
For this you need to have the <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code> object, Then you call the desired
QuantAnalyzer utility of your interest and pass the same object to it.</p>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">create_quantsim_and_encodings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_scheme</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_param_bw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_activation_bw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_file</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.create_quantsim_and_encodings"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Creates quantsim object and computes encodings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_scheme</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/torch/v1/quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a></span>) – Quantization scheme.</p></li>
<li><p><strong>default_param_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer parameters.</p></li>
<li><p><strong>default_activation_bw</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></span>) – Default bitwidth (4-31) to use for quantizing layer inputs and outputs.</p></li>
<li><p><strong>config_file</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Path to configuration file for model quantizers.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Quantsim object.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">check_model_sensitivity_to_quantization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.check_model_sensitivity_to_quantization"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Performs model sensitivity analysis to weight and activation quantization individually.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>FP32 eval score, weight-quantized eval score, act-quantized eval score.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">perform_per_layer_analysis_by_enabling_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.perform_per_layer_analysis_by_enabling_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Performs layer-wise quantization sensitivity analysis by enabling its quantizers</p>
<ol class="arabic simple">
<li><p>All parameter and activation quantizers are disabled.</p></li>
<li><dl class="simple">
<dt>For every layer, based on occurrence:</dt><dd><ol class="loweralpha simple">
<li><p>Each layer’s parameters and activations quantizers are enabled as per JSON config file
and set to bit-width specified.</p></li>
<li><p>Measure and record eval score on subset of dataset.</p></li>
<li><p>Disable enabled quantizers in step a.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Returns dictionary containing layer name and corresponding eval score.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise eval score dictionary. dict[layer_name] = eval_score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">perform_per_layer_analysis_by_disabling_quantizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.perform_per_layer_analysis_by_disabling_quantizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Performs layer-wise quantization sensitivity analysis by disabling its quantizers</p>
<ol class="arabic simple">
<li><p>All parameter and activation quantizers are enabled as per JSON config file
and set to bit-width specified.</p></li>
<li><dl class="simple">
<dt>For every layer, based on occurrence:</dt><dd><ol class="loweralpha simple">
<li><p>Each layer’s parameters and activations quantizers are disabled.</p></li>
<li><p>Measure and record eval score on subset of dataset.</p></li>
<li><p>Enable disabled quantizers in step a.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Returns dictionary containing layer name and corresponding eval score.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise eval score dictionary. dict[layer_name] = eval_score</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">export_per_layer_encoding_min_max_range</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.export_per_layer_encoding_min_max_range"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Exports encoding min and max range for all weights and activations. results_dir has
html files in following format.</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><p>-activations.html,
-weights.html</p>
</dd>
</dl>
<p>If per channel quantization(PCQ) is enabled then,</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><p>-activations.html,
-{layer_name}_{param_name}.html</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise min-max range for weights and activations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">export_per_layer_stats_histogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.export_per_layer_stats_histogram"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>NOTE: Not to invoke when quantization scheme is not TF-Enhanced.</p>
<p>Exports histogram that represents a PDF of collected statistics by a quantizer.
After invoking this API, results_dir should have html files in following
format for every quantizers in the model.</p>
<dl class="option-list">
<dt><kbd><span class="option">-r<var>esults_dir</var></span></kbd></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">-a<var>ctivations_pdf</var></span></kbd></dt>
<dd><p>name_{input/output}_{index}.html</p>
</dd>
<dt><kbd><span class="option">-w<var>eights_pdf</var></span></kbd></dt>
<dd><dl class="option-list">
<dt><kbd><span class="option">-n<var>ame</var></span></kbd></dt>
<dd><p>param_name_{channel_index}.html</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-prename descclassname"><span class="pre">QuantAnalyzer.</span></span><span class="sig-name descname"><span class="pre">export_per_layer_mse_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/aimet_onnx/quant_analyzer.html#QuantAnalyzer.export_per_layer_mse_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Exports MSE loss between fp32 and quantized output activations for each layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="../../apiref/onnx/quantsim.html#aimet_onnx.quantsim.QuantizationSimModel" title="aimet_onnx.quantsim.QuantizationSimModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantizationSimModel</span></code></a></span>) – Quantsim model.</p></li>
<li><p><strong>results_dir</strong> (<span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></span>) – Directory to save the results.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>layer wise MSE loss. dict[layer_name] = MSE loss.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="layer_output_generation.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Layer output generation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="interactive_visualization.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Interactive visualization</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2020, Qualcomm Innovation Center, Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/quic/aimet" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Quantization analyzer</a><ul>
<li><a class="reference internal" href="#context">Context</a></li>
<li><a class="reference internal" href="#analysis-descriptions">Analysis descriptions</a><ul>
<li><a class="reference internal" href="#sensitivity-to-weight-and-activation-quantization">1: Sensitivity to weight and activation quantization</a></li>
<li><a class="reference internal" href="#per-layer-quantizer-enablement">2: Per-layer quantizer enablement</a></li>
<li><a class="reference internal" href="#per-layer-encodings-min-max-range">3: Per-layer encodings min-max range</a></li>
<li><a class="reference internal" href="#per-layer-statistics-histogram">4: Per-layer statistics histogram</a></li>
<li><a class="reference internal" href="#per-layer-mean-square-error-loss">5: Per-layer mean-square-error loss</a></li>
</ul>
</li>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#workflow">Workflow</a><ul>
<li><a class="reference internal" href="#step-1-importing-libraries">Step 1 Importing libraries</a></li>
<li><a class="reference internal" href="#step-2-preparing-the-calibration-callback">Step 2 Preparing the calibration callback</a></li>
<li><a class="reference internal" href="#step-3-preparing-the-evaluation-callback">Step 3 Preparing the evaluation callback</a></li>
<li><a class="reference internal" href="#step-4-preparing-model">Step 4 Preparing model</a></li>
<li><a class="reference internal" href="#step-5-creating-the-quantanalyzer">Step 5 Creating the QuantAnalyzer</a></li>
<li><a class="reference internal" href="#step-6-running-the-analysis">Step 6 Running the analysis</a></li>
</ul>
</li>
<li><a class="reference internal" href="#api">API</a><ul>
<li><a class="reference internal" href="#aimet_common.utils.CallbackFunc"><code class="docutils literal notranslate"><span class="pre">CallbackFunc</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.check_model_sensitivity_to_quantization"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.check_model_sensitivity_to_quantization()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_enabling_quant_wrappers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.perform_per_layer_analysis_by_disabling_quant_wrappers()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_encoding_min_max_range"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_encoding_min_max_range()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_stats_histogram"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_stats_histogram()</span></code></a></li>
<li><a class="reference internal" href="#aimet_torch.quant_analyzer.QuantAnalyzer.export_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.export_per_layer_mse_loss()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.quant_analyzer.QuantAnalyzer"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.quant_analyzer.QuantAnalyzer.enable_per_layer_mse_loss"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.enable_per_layer_mse_loss()</span></code></a></li>
<li><a class="reference internal" href="#aimet_onnx.quant_analyzer.QuantAnalyzer.analyze"><code class="docutils literal notranslate"><span class="pre">QuantAnalyzer.analyze()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=8a448e45"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>