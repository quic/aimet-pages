

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET Model Compression &#8212; AI Model Efficiency Toolkit Documentation: ver 1.9.0</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AI Model Efficiency Toolkit Documentation: ver 1.9.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET Model Compression</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#use-case">Use Case</a></li>
<li><a class="reference internal" href="#compression-ratio-selection">Compression ratio selection</a></li>
<li><a class="reference internal" href="#model-compression">Model Compression</a></li>
<li><a class="reference internal" href="#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li><a class="reference internal" href="#rank-rounding">Rank Rounding</a></li>
<li><a class="reference internal" href="#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#faqs">FAQs</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-model-compression">
<span id="ug-model-compression"></span><h1>AIMET Model Compression<a class="headerlink" href="#aimet-model-compression" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>AIMET provides a model compression library that can be used to reduce a model’s MAC and memory costs with a minimal
drop in accuracy. AIMET supports various compression schemes like Weight SVD, Spatial SVD and Channel Pruning.</p>
</div>
<div class="section" id="use-case">
<h2>Use Case<a class="headerlink" href="#use-case" title="Permalink to this headline">¶</a></h2>
<p>AIMET allows user to take a trained model and compress it to desired compression ratio which can be further fine-tuned and exported to a target.
All of the compression schemes in AIMET use a two-step process - Compression ratio selection followed by model
compression.</p>
<img alt="../_images/compression_use_case.PNG" src="../_images/compression_use_case.PNG" />
<p>The following sub-sections explain these steps in more detail.</p>
</div>
<div class="section" id="compression-ratio-selection">
<h2>Compression ratio selection<a class="headerlink" href="#compression-ratio-selection" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="greedy_compression_ratio_selection.html#ug-greedy-comp-ratio-selection"><span class="std std-ref">Greedy Compression Ratio Selection</span></a>: During this phase, individual layers of the original model are analyzed to determine optimal compression ratios per layer. Currently AIMET supports the Greedy Compression Ratio Selection method.</p></li>
<li><p>Manual Compression Ratio Selection: As an alternative to AIMET automatically selecting optimal compression ratios per layer, the user has a choice to specify compression ratios manually per layer. The suggested procedure would be to use the Greedy Compression Ratio Selection method to get a nominal set of compression ratios first. And then use this as the starting point for manually changing compression ratios for one or more layers.</p></li>
</ul>
<p>To visualize various usage of the compression tool we can use:</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="visualization_compression.html">Visualization</a></li>
</ul>
</div>
</div>
<div class="section" id="model-compression">
<h2>Model Compression<a class="headerlink" href="#model-compression" title="Permalink to this headline">¶</a></h2>
<p>In this phase, AIMET will apply the compression ratios per layer to create a compressed model.
Currently, AIMET supports the following model compression algorithms.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="weight_svd.html">Weight SVD</a></li>
<li class="toctree-l1"><a class="reference internal" href="spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l1"><a class="reference internal" href="channel_pruning.html">Channel Pruning</a></li>
</ul>
</div>
</div>
<div class="section" id="optional-techniques-to-get-better-compression-results">
<h2>Optional techniques to get better compression results<a class="headerlink" href="#optional-techniques-to-get-better-compression-results" title="Permalink to this headline">¶</a></h2>
<p>AIMET supports the following techniques that can be optionally used to get better compression results</p>
<ul class="simple">
<li><p>Rank-rounding</p></li>
<li><p>Per-layer fine-tuning</p></li>
</ul>
<div class="section" id="rank-rounding">
<h3>Rank Rounding<a class="headerlink" href="#rank-rounding" title="Permalink to this headline">¶</a></h3>
<p>Often ML runtime-software like those for Embedded ML accelerators, will prefer the dimensions of layers like Conv2d or FC to be of a certain multiplicity. Matching the expected dimension size will result in optimal runtime for that layer. AIMET techniques like Weight/Spatial SVD or Channel Pruning, try to decompose layers or reduce layers - specifically in terms of output channels and input channels. The rank-rounding feature in AIMET will try and reduce layers to match a user-provided multiplicity. By default this feature is disabled. At present, AIMET allows the user to specify a multiplicity-factor for the entire model, not on a per-layer basis.</p>
<p>Users can make use of this feature to generate more optimal models for running on embedded targets.</p>
</div>
<div class="section" id="per-layer-fine-tuning">
<h3>Per-layer Fine-tuning<a class="headerlink" href="#per-layer-fine-tuning" title="Permalink to this headline">¶</a></h3>
<p>Given a user-model and desired compression-ratio, the user may sometimes notice a sharp degradation in accuracy after compression but before fine-tuning. One technique that might help the overall compression of such scenarios, is using a feature called per-layer fine-tuning. When this feature is selected, AIMET invokes a user-provided fine-tuning function after compressing every layer that was selected for compression. This is done during the Model Compression phase in the diagram shown above.</p>
<p>Note: The user is responsible for choosing appropriate learning-rates and other training parameters for fine-tuning. Using this feature may require the user to carefully pick the learning rates and learning-rate-decay parameters to be used during fine-tuning.</p>
</div>
</div>
<div class="section" id="faqs">
<h2>FAQs<a class="headerlink" href="#faqs" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p>Which technique is the best technique to use for compression?</p>
<p><em>We see best results when Spatial SVD is performed followed by Channel Pruning.</em></p>
</li>
<li><p>Can we combine the different techniques?</p>
<p><em>Yes, as stated in 1, different techniques can be combined together to get better accuracy. Compression can be combined with Post-training Quantization techniques as well to get a better model for target.</em></p>
</li>
<li><p>How to take a model to target after compression?</p>
<p><em>To take a model to target it needs to be first compressed using the above techniques and then it should be quantized and exported to target</em></p>
</li>
<li><p>Greedy rank selection is very slow. Can something be done to speed it up?</p>
<p><em>Greedy rank selection in itself is not time consuming. The time consuming part is creating the eval-score dictionary. For different experiments, eval-score dictionary can be generated once and then loaded into the searcher. Or, one can reduce the number of candidates over which the eval-score dictionary is created. But lesser the number of candidates, lesser the granularity. To strike a balance the value of 10 candidates was chosen.</em></p>
</li>
<li><p>Is per-layer fine tuning helpful?</p>
<p><em>Per-layer fine tuning is an experimental technique. We have not observed major gains by using it. But one can try out if it works for their model. In practice, we have observed that the best combination is to do say 1 epoch of fine-tuning per-layer and then do say 10-15 epochs of fine-tuning for the entire compressed model at the end.</em></p>
</li>
</ol>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Xiangyu Zhang, Jianhua Zou, Kaiming He, and Jian Sun. “Accelerating Very Deep Convolutional Networks for Classification and Detection.” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943-1955, 1 Oct. 2016.</p></li>
<li><p>Yihui He, Xiangyu Zhang, and Jian Sun. “Channel Pruning for Accelerating Very Deep Neural Networks.” IEEE International Conference on Computer Vision (ICCV), Venice, 2017, pp. 1398-1406.</p></li>
<li><p>Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. “Speeding up Convolutional Neural Networks with Low Rank Expansions.” British Machine Vision Conference, Jan. 2014.</p></li>
<li><p>Andrey Kuzmin, Markus Nagel, Saurabh Pitre, Sandeep Pendyam, Tijmen Blankevoort, Max Welling. “Taxonomy and Evaluation of Structured Compression of Convolutional Neural Networks.”</p></li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AI Model Efficiency Toolkit Documentation: ver 1.9.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>